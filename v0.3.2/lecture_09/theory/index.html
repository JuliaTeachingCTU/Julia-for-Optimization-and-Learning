<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Theory of neural networks Â· Julia for Machine Learning</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Julia for Machine Learning logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Julia for Machine Learning logo"/></a><div class="docs-package-name"><span class="docs-autofit">Julia for Machine Learning</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why/">Why Julia?</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Installation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../installation/julia/">Julia</a></li><li><a class="tocitem" href="../../installation/vscode/">Visual Studio Code</a></li><li><a class="tocitem" href="../../installation/git/">Git</a></li><li><a class="tocitem" href="../../installation/tutorial/">Quickstart guide</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Variables and basic operators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Elementary functions</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data structures</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: Control flow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional evaluations</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and iterators</a></li><li><a class="tocitem" href="../../lecture_02/scope/">Soft local scope</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_03/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_03/scope/">Scope of variables</a></li><li><a class="tocitem" href="../../lecture_03/exceptions/">Exception handling</a></li><li><a class="tocitem" href="../../lecture_03/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/standardlibrary/">Standard library</a></li><li><a class="tocitem" href="../../lecture_04/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_04/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_04/otherpackages/">Other useful packages</a></li><li><a class="tocitem" href="../../lecture_04/interaction/">Interaction with other languages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Type system and generic programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/compositetypes/">Abstract and composite types</a></li><li><a class="tocitem" href="../../lecture_05/currencies/">Generic programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Code organization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/modules/">Files and modules</a></li><li><a class="tocitem" href="../../lecture_06/pkg/">Package manager</a></li><li><a class="tocitem" href="../../lecture_06/develop/">Package development</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">Course requirements</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../final_project/homeworks/">Homework</a></li><li><a class="tocitem" href="../../final_project/project/">Final project</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">7: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/theory/">Introduction to continuous optimization</a></li><li><a class="tocitem" href="../../lecture_07/unconstrained/">Unconstrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/constrained/">Constrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">8: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/theory/">Introduction to regression and classification</a></li><li><a class="tocitem" href="../../lecture_08/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_08/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_08/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox" checked/><label class="tocitem" for="menuitem-13"><span class="docs-label">9: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Theory of neural networks</a><ul class="internal"><li><a class="tocitem" href="#Neural-networks"><span>Neural networks</span></a></li><li><a class="tocitem" href="#Layers"><span>Layers</span></a></li><li><a class="tocitem" href="#Loss-functions"><span>Loss functions</span></a></li><li><a class="tocitem" href="#Making-predictions"><span>Making predictions</span></a></li><li><a class="tocitem" href="#Approximation-quality"><span>Approximation quality</span></a></li><li><a class="tocitem" href="#Overfitting-and-regularization"><span>Overfitting and regularization</span></a></li><li><a class="tocitem" href="#Computation-of-gradients"><span>Computation of gradients</span></a></li></ul></li><li><a class="tocitem" href="../nn/">Neural networks</a></li><li><a class="tocitem" href="../exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">10: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">11: Statistics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_11/theory/">Statistics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-16" type="checkbox"/><label class="tocitem" for="menuitem-16"><span class="docs-label">12: Ordinary differential equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_12/theory/">Differential equations</a></li><li><a class="tocitem" href="../../lecture_12/ode/">Wave equation</a></li><li><a class="tocitem" href="../../lecture_12/diff_eq/">Julia package</a></li><li><a class="tocitem" href="../../lecture_12/optimal_control/">Optimal control</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">9: Neural networks I.</a></li><li class="is-active"><a href>Theory of neural networks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Theory of neural networks</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/VaclavMacha/JuliaCourse/blob/master/docs/src/lecture_09/theory.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Theory-of-neural-networks"><a class="docs-heading-anchor" href="#Theory-of-neural-networks">Theory of neural networks</a><a id="Theory-of-neural-networks-1"></a><a class="docs-heading-anchor-permalink" href="#Theory-of-neural-networks" title="Permalink"></a></h1><p>Neural networks appeared for the first time decades ago but were almost forgotten after a few years. Their resurgence in the last one or two decades is mainly due to available computational power. Their impressive list of applications include:    </p><ul><li>One of the first applications was reading of postal codes to automatize sorting of letters. Since only ten black and white digits can appear at five predetermined locations, simple networks could be used.</li><li>A similar type of neural (convolutional) networks is used in autonomous vehicles to provide information about cars, pedestrians or traffic signs. These networks may also use bounding boxes to specify the position of the desired object.</li><li>While the previous techniques used 2D structure of the input (image), recurrent neural networks are used for series-type data (text, sound). The major application is automatic translators.</li><li>Another application includes generating new content. While there may exist useful applications such as artistic composition (music or writing scripts), these networks are often used to generate fake content (news, images).</li></ul><h2 id="Neural-networks"><a class="docs-heading-anchor" href="#Neural-networks">Neural networks</a><a id="Neural-networks-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-networks" title="Permalink"></a></h2><p>The first three bullets from the previous paragraph are all used for classification. The idea is the same as for linear networks. For an input <span>$x$</span> with a label <span>$y$</span>, the classifier <span>$f$</span> minimizes the loss between the prediction <span>$f(w;x)$</span> and the label <span>$y$</span>. We stress that <span>$f$</span> has two parameters: <span>$w$</span> is to be trained (weights) while <span>$x$</span> are inputs (data). Having <span>$n$</span> samples (data points), this results in</p><p class="math-container">\[\operatorname{minimize}\qquad \frac1n\sum_{i=1}^n \operatorname{loss}(y_i, f(w;x_i)).\]</p><p>The previous lecture used the linear classifier <span>$f(x)=w^\top x$</span> and the cross-entropy loss for classification and the squared <span>$l_2$</span> norm <span>$\operatorname{loss}(y, \hat y) = (y - \hat y)^2$</span> for regression.</p><p>The main idea of neural networks is to use a more complex function <span>$f$</span> than linear with a certain structure such that:</p><ul><li>It has good approximative quality.</li><li>It does not contain many parameters to learn (train).</li><li>The computation of derivatives (training) is simple.</li></ul><h2 id="Layers"><a class="docs-heading-anchor" href="#Layers">Layers</a><a id="Layers-1"></a><a class="docs-heading-anchor-permalink" href="#Layers" title="Permalink"></a></h2><p>The previous bullets are achieved in an elegant way by representing the neural network via a layered structure. The input goes into the first layers, the output of the first layer goes into the second layer and so on. Mathematically speaking, a network <span>$f$</span> with <span>$M$</span> layers has the structure</p><p class="math-container">\[f(x) = (f_M \circ \dots \circ f_1)(x),\]</p><p>where <span>$f_1,\dots,f_M$</span> are individual layers. Since two layers that are not next to each other (such as the first and the third layer) are never directly connected (except skip connections), the function value can be propagated through the network simply. The same holds for the gradients, which can be easily computed via chain rules.</p><p><img src="../nn.png" alt/></p><h4 id="Dense-layer"><a class="docs-heading-anchor" href="#Dense-layer">Dense layer</a><a id="Dense-layer-1"></a><a class="docs-heading-anchor-permalink" href="#Dense-layer" title="Permalink"></a></h4><p>The dense layer is the simplest layer which has the form</p><p class="math-container">\[f_m(a) = l_m(W_ma + b_m),\]</p><p>where <span>$W_m$</span> is a matrix of appropriate dimensions, <span>$b_m$</span> is the bias (shift) and <span>$l_m$</span> is an activation function. The weights of the neural network, which need to be trained, would be <span>$w=(W_m,b_m)_m$</span> in this case.</p><p>The activation function is usually written as <span>$l_m:\mathbb{R}\to\mathbb{R}$</span> and its operation on the vector <span>$W_mz + b_m$</span> is understood componentwise. Examples of activation functions include:</p><p class="math-container">\[\begin{aligned}
&amp;\text{Sigmoid:}&amp;l(z) &amp;= \frac{1}{1+e^{-z}} ,\\
&amp;\text{ReLU:}&amp;l(z) &amp;= \operatorname{max}\{0,z\}, \\
&amp;\text{Softplus:}&amp;l(z) &amp;= \log(1+e^z), \\
&amp;\text{Swish:}&amp;l(z) &amp;= \frac{z}{1+e^{-z}} ,\\
\end{aligned}\]</p><p><img src="../Activation.svg" alt/></p><h4 id="Softmax-layer"><a class="docs-heading-anchor" href="#Softmax-layer">Softmax layer</a><a id="Softmax-layer-1"></a><a class="docs-heading-anchor-permalink" href="#Softmax-layer" title="Permalink"></a></h4><p>The cross-entropy loss function (see below) requires that its input is a probability distribution. To achieve this, the softmax layer is applied directly before the loss function. Its formulation is</p><p class="math-container">\[\operatorname{softmax}(a_1,\dots,a_K) = \frac{1}{\sum_{k=1}^K e^{a_k}}(e^{a_1}, \dots, e^{a_K}).\]</p><p>The exponential ensures that all outputs are positive. The normalization ensures that the sum of the outputs is one. Therefore, it is a probability distribution. When a dense layer precedes the softmax layer, it is used without any activation function (as, for example, ReLU would result in many probabilities being the same).</p><h4 id="One-hot-and-one-cold-representation"><a class="docs-heading-anchor" href="#One-hot-and-one-cold-representation">One-hot and one-cold representation</a><a id="One-hot-and-one-cold-representation-1"></a><a class="docs-heading-anchor-permalink" href="#One-hot-and-one-cold-representation" title="Permalink"></a></h4><p>One-hot and one-cold representations are directly connected with the softmax layer. The one-hot representation is &quot;the normal one&quot;, while the one-cold representation is its probability distribution.</p><p>For example, having 10 digits, label <span>$y=3$</span> has one-cold representation <span>$3$</span> and one-hot representation <span>$(0,0,0,1,0,0,0,0,0,0)$</span>. Here, we count from <span>$0$</span> to <span>$9$</span>.</p><h4 id="Other-layers"><a class="docs-heading-anchor" href="#Other-layers">Other layers</a><a id="Other-layers-1"></a><a class="docs-heading-anchor-permalink" href="#Other-layers" title="Permalink"></a></h4><p>There are many other layers (convolutional, recurrent, pooling), which we will go through in the next lesson.</p><h2 id="Loss-functions"><a class="docs-heading-anchor" href="#Loss-functions">Loss functions</a><a id="Loss-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-functions" title="Permalink"></a></h2><p>The most commonly used loss functions are:</p><ul><li>(Mean) square error<p class="math-container">\[\operatorname{loss}(y,\hat y) = (y-\hat y)^2.\]</p></li><li>Cross-entropy<p class="math-container">\[\operatorname{loss}(y,\hat y) = \sum_{k=1}^K y_k\log \hat y_k.\]</p></li><li>Binary cross-entropy<p class="math-container">\[\operatorname{loss}(y,\hat y) = y\log \hat y + (1-y)\log(1- \hat y).\]</p></li></ul><p>Mean square error is used for regression problems while both cross-entropies for classification problem. The former for multi-class (<span>$K&gt;2$</span>) and the latter for binary (<span>$K=2$</span>) problems.</p><h2 id="Making-predictions"><a class="docs-heading-anchor" href="#Making-predictions">Making predictions</a><a id="Making-predictions-1"></a><a class="docs-heading-anchor-permalink" href="#Making-predictions" title="Permalink"></a></h2><p>For classification with <span>$K$</span> classes, the classifier <span>$f$</span> predict a probability distribution of <span>$K$</span> classes. The prediction is the label with the highest probability. Using the terminology from above, the classifier&#39;s output has the one-hot form, while the actual prediction has the one-cold form.</p><p>The most common metric for evaluating classifiers is the accuracy defined by</p><p class="math-container">\[\operatorname{accuracy} = \frac 1n\sum_{i=1}^n I(y_i = \hat y_i),\]</p><p>where <span>$I$</span> is the characteristic (0/1) function which counts how often the argument is satisfied. With abuse of notation, we use both <span>$y_i$</span> and <span>$\hat y_i$</span> as their one-cold representation. Therefore, accuracy measures the fraction of samples with correct predictions.</p><h2 id="Approximation-quality"><a class="docs-heading-anchor" href="#Approximation-quality">Approximation quality</a><a id="Approximation-quality-1"></a><a class="docs-heading-anchor-permalink" href="#Approximation-quality" title="Permalink"></a></h2><p>Even shallow neural networks (not many layers) can approximate any continuous function as the next theorem states.</p><div class = "theorem-body">
<header class = "theorem-header">Theorem: Universal approximation of neural networks</header><p><p>Let <span>$g:[a,b]\to \mathbb{R}$</span> be a continuous function defined on an interval. Then for every <span>$\varepsilon&gt;0$</span>, there is a neural network <span>$f$</span> such that <span>$\|f-g\|_{\infty}\le \varepsilon$</span>.</p><p>Moreover, this network can be chosen as a chain of the following two layers:</p><ul><li>Dense layer with ReLU activation function.</li><li>Dense layer with identity activation function.</li></ul></p></div><p>As the proof suggests (Exercise 1), the price to pay is that the network needs to be extremely wide (lots of hidden neurons).</p><h2 id="Overfitting-and-regularization"><a class="docs-heading-anchor" href="#Overfitting-and-regularization">Overfitting and regularization</a><a id="Overfitting-and-regularization-1"></a><a class="docs-heading-anchor-permalink" href="#Overfitting-and-regularization" title="Permalink"></a></h2><p>The previous theorem says that any continuous classifier can be approximated to arbitrary precision by a sufficiently large network. Large networks contain a large number of parameters. If the amount of samples is the same, the network&#39;s complexity cannot be increased because there would be more parameters than samples. In such cases, the network may overfit the data.</p><p><img src="../Overfit.svg" alt/></p><p>This figure shows data with quadratic dependence and a small added error. While the complex classifier (a polynomial of order 9) fits the data perfectly, the correct classifier (a polynomial of order 2) does not fit the data so well, but it is much better at predicting unseen samples. The more complicated classifier overfits the data. </p><h4 id="Preventing-overfitting"><a class="docs-heading-anchor" href="#Preventing-overfitting">Preventing overfitting</a><a id="Preventing-overfitting-1"></a><a class="docs-heading-anchor-permalink" href="#Preventing-overfitting" title="Permalink"></a></h4><p>To prevent overfitting, multiple techniques were developed:</p><ul><li><em>Early stopping</em> stops the algorithm before it finds the optimum. This goes against the spirit of optimization as the loss function is actually not optimized.</li><li><em>Regularization</em> adds a term to the objective funtion, usually the squared <span>$l_2$</span> norm of weights<p class="math-container">\[\operatorname{minimize}\qquad \frac1n\sum_{i=1}^n \operatorname{loss}(y_i, f(w;x_i)) + \frac{\lambda}{2}\|w\|^2.\]</p>The more complicated classifier from the figure above contains (among others) the term <span>$20222x^9$</span>. Since the coefficient is huge, its <span>$l_2$</span> norm would be huge as well. Regularization prevents such classifiers. Another possibility is the (non-differentiable) <span>$l_1$</span> norm, which induces sparsity (many weights should be zero).</li><li><em>Simple networks</em> cannot approximate overly complicated functions and they can also prevent overfitting.</li></ul><h4 id="Train-test-split"><a class="docs-heading-anchor" href="#Train-test-split">Train-test split</a><a id="Train-test-split-1"></a><a class="docs-heading-anchor-permalink" href="#Train-test-split" title="Permalink"></a></h4><p>How should the classifier be evaluated? The figure above suggests that it is a bad idea to evaluate it on the same data on which they were trained. For this reason, the dataset is usually split into training and testing sets. The classifier is trained on the training and evaluated on the testing set. The classifier is not allowed to see the testing set during training. When the classifier contains a large number of hyperparameters, which need to be tuned, the dataset is split into training, validation and testing sets. Then models with multiple hyperparameters are trained on the training set, the best values of hyperparameters are selected on the validation set, and the classifier performance is evaluated on the testing set.</p><h2 id="Computation-of-gradients"><a class="docs-heading-anchor" href="#Computation-of-gradients">Computation of gradients</a><a id="Computation-of-gradients-1"></a><a class="docs-heading-anchor-permalink" href="#Computation-of-gradients" title="Permalink"></a></h2><p>We will derive the gradients for the most common case of the objective</p><p class="math-container">\[L(w) := \sum_{i=1}^n \operatorname{loss}(y_i, f(w;x_i)).\]</p><p>If the classifier has only a single output (as is the case for regression or binary classification), then the chain rule yields</p><p class="math-container">\[\nabla L(w) = \sum_{i=1}^n \operatorname{loss}&#39;(y_i, f(w;x_i))\nabla_w f(w;x_i).\]</p><p>The most difficult term to compute is <span>$\nabla_w f(w;x_i)$</span>. All neural networks presented in this course have a layered structure. For an input <span>$x$</span>, the evalutation of <span>$f(w;x)$</span> is initialized by <span>$a_0=x$</span> and then the iterative update</p><p class="math-container">\[\begin{aligned}
z_m &amp;= W_ma_{m-1} + b_m, \\
a_m &amp;= l_m(z_m)
\end{aligned}\]</p><p>for <span>$m=1,\dots,M$</span> is performed. The first equation <span>$z_m = W_ma_{m-1} + b_m$</span> performs a linear mapping, while <span>$a_m = l_m(z_m)$</span> applies the activation function <span>$l_m$</span> to each component of <span>$z_m$</span>. The parameters of the network are <span>$(W_m,b_m)_m$</span>. Since <span>$a_M=f(w;x)$</span>, the chain rule implies</p><p class="math-container">\[\begin{aligned}
\nabla_{W_m} f &amp;= \nabla_{W_m}a_M = \nabla_{z_M}a_M\nabla_{z_{M-1}}a_M\nabla_{a_{M-1}}z_{M-1}\dots \nabla_{z_m}a_m\nabla_{W_m}z_m, \\
\nabla_{b_m} f &amp;= \nabla_{b_m}a_M = \nabla_{z_M}a_M\nabla_{z_{M-1}}a_M\nabla_{a_{M-1}}z_{M-1}\dots \nabla_{z_m}a_m\nabla_{b_m}z_m.
\end{aligned}\]</p><p>Care needs to be taken with this expression, for example <span>$\nabla_{W_m}z_m$</span> differentiates a vector with respect to a matrix. The computation of <span>$\nabla_{W_m} f$</span> and <span>$\nabla_{b_m} f$</span> is almost the same and only the last term differs. This is the basics for an efficient computational procedure.</p><p>Now we need to compute the individual derivatives</p><p class="math-container">\[\begin{aligned}
\nabla_{a_{m-1}} z_m &amp;= W_m, \\
\nabla_{z_m} a_m &amp;= \operatorname{Diag}(l_m&#39;(z_m)).
\end{aligned}\]</p><p>The derivative in <span>$l_m&#39;(z_m)$</span> is understood componentwise and <span>$\operatorname{Diag}$</span> makes a diagonal matrix from the vector.</p><p>Combining all these relations allow computing the derivative of the whole network.</p><div class = "info-body">
<header class = "info-header">Computation of derivatives</header><p><p>This computation of derivatives looks complicated. However, it is just a complicated notation of a simple chain rule.</p><p>The forward pass starts with the input (which equals to <span>$a_0$</span>), computes the values <span>$(z_m,a_m)$</span> in a forward way and finishes with evaluating the value of the classifier <span>$f$</span>.</p><p>The backward pass starts with the classifier value (which equals to <span>$a_M$</span>), computes the partial derivatives in a backward way and chains them together to finish evaluating the derivative of the classifier <span>$\nabla f$</span>.</p><p>This computation is extremely efficient because the forward pass (computing function value) and the backward pass (computing derivatives) have the same complexity. Compare this with the finite difference method, where the computation of derivatives is much more expensive.</p></p></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../lecture_08/exercises/">Â« Exercises</a><a class="docs-footer-nextpage" href="../nn/">Neural networks Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 13 April 2021 11:23">Tuesday 13 April 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
