<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Unconstrained optimization Â· Numerical computing in Julia</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><script data-outdated-warner="">function maybeAddWarning () {
    const head = document.getElementsByTagName('head')[0];

    // Add a noindex meta tag (unless one exists) so that search engines don't index this version of the docs.
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        head.appendChild(meta);
    };

    // Add a stylesheet to avoid inline styling
    const style = document.createElement('style');
    style.type = 'text/css';
    style.appendChild(document.createTextNode('.outdated-warning-overlay {  position: fixed;  top: 0;  left: 0;  right: 0;  box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);  z-index: 999;  background-color: #ffaba7;  color: rgba(0, 0, 0, 0.7);  border-bottom: 3px solid #da0b00;  padding: 10px 35px;  text-align: center;  font-size: 15px; }  .outdated-warning-overlay .outdated-warning-closer {    position: absolute;    top: calc(50% - 10px);    right: 18px;    cursor: pointer;    width: 12px; }  .outdated-warning-overlay a {    color: #2e63b8; }    .outdated-warning-overlay a:hover {      color: #363636; }'));
    head.appendChild(style);

    const div = document.createElement('div');
    div.classList.add('outdated-warning-overlay');
    const closer = document.createElement('div');
    closer.classList.add('outdated-warning-closer');

    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This documentation is not for the latest version. <br> <a href="' + href + '">Go to the latest documentation</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', maybeAddWarning);
} else {
    maybeAddWarning();
};
</script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img alt="Numerical computing in Julia logo" class="docs-light-only" src="../../assets/logo.svg"/><img alt="Numerical computing in Julia logo" class="docs-dark-only" src="../../assets/logo-dark.svg"/></a><div class="docs-package-name"><span class="docs-autofit">Numerical computing in Julia</span></div><form action="../../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Installation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../installation/julia/">Julia</a></li><li><a class="tocitem" href="../../installation/vscode/">Visual Studio Code</a></li><li><a class="tocitem" href="../../installation/git/">Git</a></li><li><a class="tocitem" href="../../installation/tutorial/">Quick Start Guide</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">1: Variables and basic operators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Elementary Functions</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data Structures</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">2: Control flow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional Evaluation</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and Iterators</a></li><li><a class="tocitem" href="../../lecture_02/scope/">Soft Local Scope</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">3: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_03/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_03/scope/">Scope of Variables</a></li><li><a class="tocitem" href="../../lecture_03/exceptions/">Exception Handling</a></li><li><a class="tocitem" href="../../lecture_03/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">4: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/basics/">Package Management</a></li><li><a class="tocitem" href="../../lecture_04/standardlibrary/">Standard Library</a></li><li><a class="tocitem" href="../../lecture_04/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_04/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_04/otherpackages/">Other Useful Packages</a></li></ul></li><li><span class="tocitem">5: Composite types and constructors</span></li><li><span class="tocitem">6: Modules and enviroments</span></li><li><input checked="" class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">7: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../theory/">Introduction to continuous optimization</a></li><li class="is-active"><a class="tocitem" href="">Unconstrained optimization</a><ul class="internal"><li><a class="tocitem" href="#Theory-of-Unconstrained-optimization"><span>Theory of Unconstrained optimization</span></a></li><li class="toplevel"><a class="tocitem" href="#Visualization-of-gradients"><span>Visualization of gradients</span></a></li><li><a class="tocitem" href="#comp-grad"><span>Computation of gradients</span></a></li><li class="toplevel"><a class="tocitem" href="#Numerical-methods"><span>Numerical methods</span></a></li><li><a class="tocitem" href="#Gradient-descent"><span>Gradient descent</span></a></li><li><a class="tocitem" href="#Adaptive-stepsize"><span>Adaptive stepsize</span></a></li></ul></li><li><a class="tocitem" href="../constrained/">Constrained optimization</a></li><li><a class="tocitem" href="../exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">8: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/theory/">Theory of regression and classification</a></li><li><a class="tocitem" href="../../lecture_08/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_08/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_08/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">9: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_09/nn/">Neural networks</a></li><li><a class="tocitem" href="../../lecture_09/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">10: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><span class="tocitem">11: Statistics</span></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">12: Ordinary differential equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_12/theory/">Differential equations</a></li><li><a class="tocitem" href="../../lecture_12/ode/">Wave equation</a></li><li><a class="tocitem" href="../../lecture_12/diff_eq/">Julia package</a></li><li><a class="tocitem" href="../../lecture_12/optimal_control/">Optimal control</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">7: Optimization</a></li><li class="is-active"><a href="">Unconstrained optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Unconstrained optimization</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/VaclavMacha/JuliaCourse/blob/master/docs/src/lecture_07/unconstrained.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="Unconstrained-optimization"><a class="docs-heading-anchor" href="#Unconstrained-optimization">Unconstrained optimization</a><a id="Unconstrained-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Unconstrained-optimization" title="Permalink"></a></h1><p>Unconstrained optimization means that we optimize a function on the whole space <span>$X=\mathbb{R}^n$</span>.</p><h2 id="Theory-of-Unconstrained-optimization"><a class="docs-heading-anchor" href="#Theory-of-Unconstrained-optimization">Theory of Unconstrained optimization</a><a id="Theory-of-Unconstrained-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Theory-of-Unconstrained-optimization" title="Permalink"></a></h2><p>What do we look for when we minimize a function <span>$f$</span> over some <span>$X$</span>? The optimal point would be a global minimum, which is a point <span>$x\in X$</span> which satisfies</p><p class="math-container">\[f(x) \le f(y) \text{ for all }y\in X.\]</p><p>This point is often very difficult to find. Sometimes we are able to find a local minimum, which is a global minimum on some small neighbourhood of <span>$x$</span>.</p><div class="theorem-body"><header class="theorem-header">Theorem: Connection between optimization problems and gradients</header><p></p><p>Consider a differentiable function <span>$f$</span> over <span>$X=\mathbb{R}^n$</span>. If <span>$x$</span> is its local minimum, then <span>$\nabla f(x)=0$</span>. Conversely, if <span>$f$</span> is convex, then every point <span>$x$</span> with <span>$\nabla f(x)=0$</span> is a global minimum of <span>$f$</span>.</p><p></p></div><p>Points with <span>$\nabla f(x)=0$</span> are known as stationary points. Optimization algorithms often try to find them with the hope that they minimize the function <span>$f$</span>.</p><p><img alt="" src="../minmax.svg"/></p><div class="info-body"><header class="info-header">Take care</header><p></p><p>This theorem does not hold if <span>$X$</span> is not the whole space.</p><p></p></div><p>Most of optimizaton algorithms do not search for a global minimum but they instead apply some iterative procedure which looks for a stationary point. That means they try to find a point, where the gradient equals to zero. But what is the gradient? For a function <span>$f:\mathbb{R}\to \mathbb{R}$</span>, its gradient is defined by</p><p class="math-container">\[f'(x) = \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}.\]</p><p>For a mapping  <span>$f:\mathbb{R}^n\to \mathbb{R}^m$</span>, its Jacobian is a matrix <span>$\nabla f(x)$</span> of size <span>$m\times n$</span> of partial derivatives</p><p class="math-container">\[(\nabla f(x))_{i,j} = \frac{\partial f_i}{\partial x_j}(x) = \lim_{h\to 0}\frac{f_i(x_1,\dots,x_{j-1},x_j+h,x_{j+1},\dots,x_n)-f(x_1,\dots,x_n)}{h}\]</p><div class="info-body"><header class="info-header">Confusion</header><p></p><p>Gradient <span>$\nabla f(x)$</span> of a function <span>$f:\mathbb{R}^n\to\mathbb{R}$</span> should be of size  <span>$1\times n$</span> but it is commonly considered as <span>$n\times 1$</span>.</p><p></p></div><p>Functions to optimize are usually complex. Then the definition cannot be used to compute the gradient. Instead, the objective function <span>$f$</span> is rewritten as a composition of simpler functions, these simpler functions are differentiated and the chain rule is applied to get <span>$\nabla f$</span>.</p><div class="theorem-body"><header class="theorem-header">Theorem: Chain</header><p></p><p>Consider two differentiable functions <span>$f:\mathbb{R}^m\to\mathbb{R}^s$</span> and <span>$g:\mathbb{R}^n\to\mathbb{R}^m$</span>. Then its composition <span>$h(x) := f(g(x))$</span> is differentiable with Jacobian</p><p class="math-container">\[\nabla h(x) = \nabla f(g(x))\nabla g(x).\]</p><p></p></div><h1 id="Visualization-of-gradients"><a class="docs-heading-anchor" href="#Visualization-of-gradients">Visualization of gradients</a><a id="Visualization-of-gradients-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization-of-gradients" title="Permalink"></a></h1><p>For the numerical experiments, we will consider the following function</p><p class="math-container">\[f(x) = \sin(x_1 + x_2) + \cos(x_1)^2\]</p><p>on domain <span>$[-3,1]\times [-2,1]$</span>.</p><div class="exercise-body"><header class="exercise-header">Contour plot</header><p></p><p>Write a function <code>g(x)</code> which computes the derivative of <span>$f$</span> at a point  <span>$x$</span>.</p><p>Plot the contours of <span>$f$</span> on the given domain. Use the optional argument <code>color = :jet</code> for better visualization.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>Function <code>f(x)</code> takes as an input a vector of two dimensions and returns a scalar. Therefore, the gradient is a two-dimensional vector, which we create by <code>[?; ?]</code>. Its components are computed from the chain rule.</p><pre><code class="language-julia">f(x) = sin(x[1] + x[2]) + cos(x[1])^2
g(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]</code></pre><p>Since sometimes it is better to use notation <span>$f(x)$</span> and sometimes <span>$f(x_1,x_2)$</span>, we overload the function <code>f</code></p><pre><code class="language-julia">f(x1,x2) = f([x1;x2])

f([0; 0])
f(0, 0)</code></pre><pre class="documenter-example-output">1.0
1.0</pre><p>We use the <code>Plots</code> package for plotting. We create the discretization <code>xs</code> and <code>ys</code> of both axis and then call the <code>contourf</code> function.</p><pre><code class="language-julia">using Plots

xs = range(-3, 1, length = 40)
ys = range(-2, 1, length = 40)

contourf(xs, ys, f, color = :jet)</code></pre><p></p></details><p><img alt="" src="../grad1.svg"/></p><h2 id="comp-grad"><a class="docs-heading-anchor" href="#comp-grad">Computation of gradients</a><a id="comp-grad-1"></a><a class="docs-heading-anchor-permalink" href="#comp-grad" title="Permalink"></a></h2><p>The simplest way to compute the gradients is to use a finite difference approximation. It replaces the limit in</p><p class="math-container">\[f'(x) = \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]</p><p>by fixing some <span>$h$</span> and approximates the gradient by</p><p class="math-container">\[f'(x) \approx \frac{f(x+h)-f(x)}{h}.\]</p><div class="exercise-body"><header class="exercise-header">Finite difference approximation</header><p></p><p>Write a function <code>finite_difference</code> which computes the approximation of <span>$f'(x)$</span> by finite differences. The inputs are a function <span>$f:\mathbb R\to\mathbb R$</span> and a point <span>$x\in\mathbb{R}$</span>. It should have an optional input <span>$h\in\mathbb{R}$</span>, for which you need to choose a reasonable value.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>We just need to rewrite the formula above. Since the argument <code>h</code> is optional, it should be after <code>;</code>. Its good default value is anything between <span>$10^{-10}$</span> and <span>$10^{-5}$</span>. We specify <code>x::Real</code> as a sanity check for the case when a function of more variables is passed as input.</p><pre><code class="language-julia">finite_difference(f, x::Real; h=1e-8) = (f(x+h) - f(x)) / h</code></pre><p></p></details><p>This way of computing the gradient has two disadvantages:</p><ol><li>It is slow. For a function of <span>$n$</span> variables, we need to evaluate the function at least <span>$n+1$</span> times to get the whole gradient.</li><li>It is not precise. We will show this in the next example.</li></ol><div class="exercise-body"><header class="exercise-header">Finite difference approximation</header><p></p><p>Fix a point <span>$x=(-2,-1)$</span>. For a proper discretization of <span>$h\in [10^{-15}, 10^{-1}]$</span> compute the finite difference approximation of the partial derivative of <span>$f$</span> with respect to the second variable.</p><p>Plot the dependence of this approximation on <span>$h$</span>. Add the true derivative computed from <code>g</code>.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>To compute the partial derivative with respect to the second argument, we need to fix the first argument and vary only the second one. We create an autonomous function <code>y -&gt; f(-2, y)</code> and another function <code>fin_diff</code> which for an input <code>h</code> computes the finite difference.</p><pre><code class="language-julia">x = [-2; -1]
fin_diff(h) = finite_difference(y -&gt; f(-2, y), -1; h=h)</code></pre><p>The true gradient is computed by <code>g(x)</code>. It returns a vector of length two. Since we need only the partial derivative with respect to the second component, we select it by adding  <code>[2]</code>.</p><pre><code class="language-julia">true_grad = g(x)[2]</code></pre><p>Now we create the discretization of <span>$h$</span> in <code>hs</code>. When the orders of magnitude are so different, logarithmic scale should be used. For this reason, we create a uniform discretization of the interval <span>$[-15,-1]$</span> and then use it as an exponent.</p><pre><code class="language-julia">hs = 10. .^ (-15:0.01:-1)</code></pre><p>There are many possibilities of how to create the plot. Probably the simplest one is to plot the function <code>fin_diff</code> and then add the true gradient (which does not depend on <span>$h$</span> and is, therefore, a horizontal line) via <code>hline!</code></p><pre><code class="language-julia">plot(hs, fin_diff,
    xlabel = "h",
    ylabel = "Partial gradient wrt y",
    label = ["Approximation" "True gradient"],
    xscale = :log10,
)

hline!([true_grad]; label =  "True gradient")</code></pre><p>Another possibility is to use only one call for the <code>plot</code> function. The <span>$x$</span> axis is <code>hs</code>, while for the <span>$y$</span> axis we need to concatenate the true gradient <code>true_grad</code> and its finite difference approximation <code>fin_diff.(hs)</code> by <code>hcat</code>. It is also possible to use <code>[? ?]</code> but not <code>[?, ?]</code> or <code>[?; ?]</code> (try it). To get the same shape of the arrays, we need to repeat <code>true_grad</code> from a scalar to a vector of the same length as <code>fin_diff</code>. Since <code>repeat</code> requires the input to be an array, we need to create it by <code>[true_grad]</code>.</p><pre><code class="language-julia">data = hcat(fin_diff.(hs), repeat([true_grad], length(hs)))
plot(hs, data,
    xlabel = "h",
    ylabel = "Partial gradient wrt y",
    label = ["Approximation" "True gradient"],
    xscale = :log10,
)</code></pre><p></p></details><p><img alt="" src="../grad2.svg"/></p><p>We see that the approximation is good if the value <span>$h$</span> is not too small or too large. It cannot be too large because the definition of the gradient considers the limit to zero. It cannot be too small because then the numerical errors kick in. This is connected with machine precision, which is most vulnerable to subtraction of two numbers of almost the same value. A simple example shows</p><p class="math-container">\[(x + h)^2 - x^2 = 2xh + h^2\]</p><p>but the numerical implementation</p><pre><code class="language-julia-repl">julia&gt; x = 1;

julia&gt; h = 1e-13;

julia&gt; (x+h)^2 - x^2
1.9984014443252818e-13

julia&gt; 2*x*h + h^2
2.0000000000001e-13</code></pre><p>gives an error already on the third decimal point.</p><p>Finally, we show how the gradients look like.</p><div class="exercise-body"><header class="exercise-header">Direction of gradients</header><p></p><p>Plot the contours of <span>$f$</span> and its gradient at <span>$(-2,-1)$</span>.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>We use the same functions as before. Since we want to add a line, we use <code>plot!</code> instead of <code>plot</code>. We specify its parameters in an optional argument <code>line = (:arrow, 4, :black)</code>. These parameters add the pointed arrow, the thickness and the colour of the line. Since we do not want any legend, we use <code>label = ""</code>.</p><pre><code class="language-julia">x = [-2; -1]
Î± = 0.25
x_grad = [x x.+Î±.*g(x)]

contourf(xs, ys, f; color = :jet)
plot!(x_grad[1, :], x_grad[2, :];
    line = (:arrow, 4, :black),
    label = "",
)</code></pre><p></p></details><p><img alt="" src="../grad3.svg"/></p><p>The gradient is perpendicular to the contour lines. This makes perfect sense. Since the gradient is the direction of steepest ascent, and since the contours have constant values, it needs to be like this. Try this with different values of <span>$x$</span>.</p><h1 id="Numerical-methods"><a class="docs-heading-anchor" href="#Numerical-methods">Numerical methods</a><a id="Numerical-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-methods" title="Permalink"></a></h1><p>This part introduces the most basic optimization algorithm called gradient (or steepest) descent.</p><h2 id="Gradient-descent"><a class="docs-heading-anchor" href="#Gradient-descent">Gradient descent</a><a id="Gradient-descent-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-descent" title="Permalink"></a></h2><p>We learnt that the gradient is the direction of steepest descent. The straightforward idea is to move in the opposite direction. This gives rise to the gradient descent algorithm</p><p class="math-container">\[x^{k+1} = x^k - \alpha^k\nabla f(x^k).\]</p><p>The stepsize <span>$\alpha^k&gt;0$</span> can be tuned as a hyperparameter.</p><div class="info-body"><header class="info-header">Terminology</header><p></p><p>In classical optimization, the usual terminology is:</p><ul><li>Variable is to be optimized.</li><li>Parameter is external (fixed) such as material parameters.</li></ul><p>In machine learning, the usual terminology is:</p><ul><li>Parameter is to be optimized.</li><li>Hyperparameter is an external model parameter which is not optimized and needs to be tuned. The example is the steplength because the gradient descent finds a different solution for different steplength but it is not changed during the optimization.</li></ul><p>The different terminology (and the fact that there are adaptive schemes to select the steplenght which should make it a parameter instead of a hyperparameter) makes the notation confusing.</p><p></p></div><div class="exercise-body"><header class="exercise-header">Gradient descent</header><p></p><p>Implement function <code>optim</code> which takes as inputs function <span>$f$</span>, its gradient, starting point <span>$x^0$</span> and fixed stepsize <span>$\alpha$</span> and runs the gradient descent. Its output should be the first 100 iterations.</p><p>This example is rather artificial because usually only the last iteration is returned and some stopping criterion is employed instead of the fixed number of iterations. We want to get all iterations to make visualizations.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>First we need to create an empty array into which we store the iterates. Then at every iteration we compute the gradient <code>g(x)</code>, perform the update and save the new value of <span>$x$</span>.</p><pre><code class="language-julia">function optim(f, g, x, Î±; max_iter=100)
    xs = zeros(length(x), max_iter+1)
    xs[:,1] = x
    for i in 1:max_iter
        x -= Î±*g(x)
        xs[:,i+1] = x
    end
    return xs
end</code></pre><p></p></details><p>The implementation does not use the values of <span>$f$</span> but only its gradient <span>$\nabla f$</span>. Moreover, if the algorithm converges <span>$x^k \to \bar x$</span>, then passing to the limit in the gradient update results in <span>$\nabla f(\bar x)=0$</span>. Therefore, as most optimization methods, gradient descent looks for stationary points.</p><p>Before plotting the path taken by gradient descent, we create <code>create_anim</code> function which creates animations of <code>path</code> over the contour plot of <code>f</code>. From <code>xlims</code> and <code>ylim</code>, it creates discretizations <code>xs</code> and <code>ys</code> and then plots the contour plot as background. Since <code>Animation</code> requires updating a graph, we start with an empty graph and in a for loop over <code>path</code>, we push the new image to the animation. The final commands <code>gif</code> saves the animation into <code>file_name</code>.</p><pre><code class="language-julia">function create_anim(f, path, xlims, ylims; file_name = "", fps=15)
    xs = range(xlims...; length = 100)
    ys = range(ylims...; length = 100)
    plt = contourf(xs, ys, f, color = :jet, axis = false, ticks = false, cbar = false)

    # adds an empty plot to plt
    plot!(Float64[], Float64[]; line = (4, :black), label = "")

    # extracts last plot series
    plt_path = plt.series_list[end]

    # creates the  animation
    anim = Animation()
    for x in eachcol(path)
        push!(plt_path, x[1], x[2]) # add new point to plt_grad
        frame(anim)
    end
    gif(anim, file_name; fps = fps, show_msg = false)
    return nothing
end</code></pre><p>We now plot how gradient descent behaves.</p><div class="exercise-body"><header class="exercise-header">Gradient descent</header><p></p><p>Use the implementation of the gradient descent to minimize the function</p><p class="math-container">\[f(x) = \sin(x_1 + x_2) + \cos(x_1)^2\]</p><p>from the starting point <span>$x^0=(0,-1)$</span> and constant stepsize <span>$\alpha=0.1$</span>. Store all iterations into matrix <code>xs</code>.</p><p>Plot how the iterations evolve. You need to save the animation with the gif extension.</p><p>Use one line of code to evaluate the function values for all iterations <code>xs</code> (hint: you need to iterate via <code>eachcol(xs)</code> or <code>eachrow(xs)</code> depending on how you represent <code>xs</code>). Plot these values.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>We call <code>optim</code> written in the previous exercise and then create the animation.</p><pre><code class="language-julia">x_gd = optim([], g, [0; -1], 0.1)

xlims = (-3, 1)
ylims = (-2, 1)
create_anim(f, x_gd, xlims, ylims; file_name = "anim1.gif")</code></pre><p>To plot the function values, we need to iterate over all columns. We use <code>[? for x in eachcol(x_gd)]</code> and apply <code>f(x)</code> instead of <code>?</code>. Another (more complicated) way is to iterate over indices instead of vectors and write <code>[f(x_gs[:,i]) for i in 1:size(x_gd,2)]</code>.</p><pre><code class="language-julia">f_gd = [f(x) for x in eachcol(x_gd)]

plot(f_gd, label="", xlabel="Iteration", ylabel="Function value")</code></pre><p></p></details><p><img alt="" src="../anim1.gif"/></p><p><img alt="" src="../obj.svg"/></p><p>The convergence looks very nice, and the function value decreases. First, the decrease is faster, but when the iterations get closer to the minimum, it slows down.</p><p>What happens if we choose a different stepsize though? Let us try with two different values. First let us try <span>$\alpha=0.01$</span>.</p><pre><code class="language-julia">x_gd = optim([], g, [0; -1], 0.01)

create_anim(f, x_gd, xlims, ylims; file_name = "anim2.gif")</code></pre><p><img alt="" src="../anim2.gif"/></p><p>We see that when the stepsize is reduced, the steps are shorter and we would need to increase the number of iterations (and thus time) to converge. When the stepsize is larger, say <span>$\alpha=1$</span>, the situation is different.</p><pre><code class="language-julia">x_gd = optim([], g, [0; -1], 1)

create_anim(f, x_gd, xlims, ylims; file_name = "anim3.gif")</code></pre><p><img alt="" src="../anim3.gif"/></p><p>For a large stepsize, the algorithm gets close to the solution and then starts jumping around. If we further increase the stepsize, it will even diverge to infinity. Try it.</p><h2 id="Adaptive-stepsize"><a class="docs-heading-anchor" href="#Adaptive-stepsize">Adaptive stepsize</a><a id="Adaptive-stepsize-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptive-stepsize" title="Permalink"></a></h2><p>To handle this numerical instability, safeguards are introduced. One of the possibilities is the Armijo condition which automatically selects the stepsize. It looks for <span>$\alpha^k$</span> which satisfies</p><p class="math-container">\[f(x^k - \alpha^k\nabla f(x^k)) \le f(x^k) - c \alpha^k \|\nabla f(x^k)\|^2.\]</p><p>Here  <span>$c\in(0,1)$</span> is a small constant, usually <span>$c=10^{-4}$</span>. Since the left-hand side is the function value at the new iterate <span>$x^{k+1}$</span>, the Armijo condition ensures that the sequence of function values is strictly decreasing. This prevents oscillations.</p><p>The implementation of <code>optim(f, g, x, Î±; max_iter=100)</code> from the exercise above is rather stupid because it does not allow to modify the selection of the step. The simplest fix would be to include if conditions inside the function. However, this would result in a long function, which may be difficult to debug and modify. A more elegant solution is to create an abstract class</p><pre><code class="language-julia">abstract type Step end</code></pre><p>and for each possible step selection method implement a <code>optim_step</code> method, which selects the step. First, we create the gradient descent class <code>GD</code> as a subclass of <code>Step</code> by</p><pre><code class="language-julia">struct GD &lt;: Step
    Î±::Real
end</code></pre><p>It is a structure with parameter <code>Î±</code>. Then we create the <code>optim_step</code> function by</p><pre><code class="language-julia">optim_step(s::GD, f, g, x) = -s.Î±*g(x)</code></pre><p>Due to the first input argument, it will be called only for the  <code>GD</code> stepsize. To access the parameter <code>Î±</code>, we need to retrieve it from the structure by <code>s.Î±</code>. Now we can modify the <code>optim</code> function by</p><pre><code class="language-julia">function optim(f, g, x, s::Step; max_iter=100)
    xs = zeros(length(x), max_iter+1)
    xs[:,1] = x
    for i in 1:max_iter
        x += optim_step(s, f, g, x)
        xs[:,i+1] = x
    end
    return xs
end</code></pre><p>The specification of the input <code>s::Step</code> allows for any subclass of the abstract class <code>Step</code>. Using this implentation results in</p><pre><code class="language-julia">gd = GD(0.1)
x_opt = optim(f, g, [-1;0], gd)

create_anim(f, x_opt, xlims, ylims; file_name = "anim4.gif")</code></pre><p><img alt="" src="../anim4.gif"/></p><p>We obtained the same results as in the previous case. This is not surprising as the code does exactly the same things; it is only written differently. The next exercise shows the power of defining the <code>Step</code> class.</p><div class="exercise-body"><header class="exercise-header">Armijo condition</header><p></p><p>Implement the <code>Armijo</code> subclass of the <code>Step</code> class. It should have two parameters <code>c</code> from the definition and <code>Î±_max</code> which will be the initial value of <span>$\alpha$</span>. The value <span>$\alpha$</span> should be divided by two until the Armijo condition is satisfied.</p><p>Then run the optimization with the Armijo selection of the stepsize and plot the animation.</p><p></p></div><details class="solution-body"><summary class="solution-header">Solution:</summary><p></p><p>We define the class in the same way as for <code>GD</code>:</p><pre><code class="language-julia">struct Armijo &lt;: Step
    c::Real
    Î±_max::Real
end</code></pre><p>For the search for the stepsize, we first save the values for the function value <span>$f(x)$</span> and the gradient <span>$\nabla f(x)$</span>. If we do not do this, it will be recomputed at every step. Then we initialize the value of <span>$\alpha$</span> and run the while loop until the Armijo condition is satisfied. We added a termination condition (also a safe check) <code>Î± &lt;= 1e-6</code> to prevent the loop for continuing indefinitely.</p><pre><code class="language-julia">function optim_step(s::Armijo, f, g, x)
    fun = f(x)
    grad = g(x)
    Î± = s.Î±_max
    while f(x .- Î±*grad) &gt; fun - s.c*Î±*(grad'*grad)
        Î± /= 2
        if Î± &lt;= 1e-6
            warning("Armijo line search failed.")
            break
        end
    end
    return -Î±*grad
end</code></pre><p>Then we create the <code>Armijo</code> object and run the optimization again.</p><pre><code class="language-julia">gd = Armijo(1e-4, 1)
x_opt = optim(f, g, [0;-1], gd)

create_anim(f, x_opt, xlims, ylims; file_name = "anim5.gif")</code></pre><p></p></details><p><img alt="" src="../anim5.gif"/></p><p>Since the Armijo condition determines the optimal stepsize automatically, the convergence is much faster than for gradient descent. Moreover, it is not necessary to specify the stepsize (which may cause small convergence of even divergence for gradient descent). The price to pay is that every iteration needs to perform several function evalutions, which is not the case for standard gradient descent.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../theory/">Â« Introduction to continuous optimization</a><a class="docs-footer-nextpage" href="../constrained/">Constrained optimization Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 1 February 2021 10:04">Monday 1 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>