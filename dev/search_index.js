var documenterSearchIndex = {"docs":
[{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"using BSON\nusing Flux\nusing MLDatasets\nusing DataFrames\nusing Plots\nusing Flux: onehotbatch, onecold, flatten, params\n\nCore.eval(Main, :(using Flux)) # hide\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nMNIST(Float32, :train)\n\nfunction reshape_data(X::AbstractArray{<:Real, 3})\n    s = size(X)\n    return reshape(X, s[1], s[2], 1, s[3])\nend\n\nfunction train_or_load!(file_name, m, args...; force=false, kwargs...)\n\n    !isdir(dirname(file_name)) && mkpath(dirname(file_name))\n\n    if force || !isfile(file_name)\n        train_model!(m, args...; file_name=file_name, kwargs...)\n    else\n        m_weights = BSON.load(file_name)[:m]\n        Flux.loadparams!(m, params(m_weights))\n    end\nend\n\nfunction load_data(dataset; T=Float32, onehot=false, classes=0:9)\n    X_train, y_train = dataset(T, :train)[:]\n    X_test, y_test = dataset(T, :test)[:]\n\n    X_train = reshape_data(X_train)\n    X_test = reshape_data(X_test)\n\n    if onehot\n        y_train = onehotbatch(y_train, classes)\n        y_test = onehotbatch(y_test, classes)\n    end\n\n    return X_train, y_train, X_test, y_test\nend\n\nT = Float32\nX_train, y_train, X_test, y_test = load_data(MLDatasets.MNIST; T=T, onehot=true)","category":"page"},{"location":"lecture_11/exercises/#Exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"The first two exercises handle training neural networks on GPUs instead of CPUs. Even though this is extremely important for reducing the training time, we postponed it to the exercises because some course participants may not have a compatible GPU for training. If anyone is not able to do these two exercises, we apologize.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 1: Operations on GPUs\nWhile most computer operations are performed on CPUs (central processing unit), neural networks are trained on other hardware such as GPUs (graphics processing unit) or specialized hardware such as TPUs.To use GPUs, include packages Flux and CUDA. Then generate a random matrix Ain mathbbR^100times 100 and a random vector bin mathbbR^100. They will be stored in the memory (RAM), and the computation will be performed on CPU. To move them to the GPU memory and allow computations on GPU, use gpu(A) or the more commonly used A |> gpu.Investigate how long it takes to perform multiplication Ab if both objects are on CPU, GPU or if they are saved differently. Check that both multiplications resulted in the same vector.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe beginning is simpleusing Flux\nusing CUDA\n\nA = randn(100,100)\nb = randn(100)\nA_g = A |> gpu\nb_g = b |> gpuTo test the time, we measure the time for multiplicationjulia> @time A*b;\n0.069785 seconds (294.76 k allocations: 15.585 MiB, 14.75% gc time)\n\njulia> @time A_g*b_g;\n0.806913 seconds (419.70 k allocations: 22.046 MiB)\n\njulia> @time A_g*b;\n0.709140 seconds (720.01 k allocations: 34.860 MiB, 1.53% gc time)We see that all three times are different. Can we infer anything from it? No! The problem is that during the first call to a function, some compilation usually takes place. We should always compare only the second time.julia> @time A*b;\n0.000083 seconds (1 allocation: 896 bytes)\n\njulia> @time A_g*b_g;\n0.000154 seconds (11 allocations: 272 bytes)\n\njulia> @time A_g*b;\n0.475280 seconds (10.20 k allocations: 957.125 KiB)We conclude that while the computation on CPU and GPU takes approximately the same time, it takes much longer when using the mixed types.To compare the results, the first idea would be to runnorm(A*b - A_g*b_g)which would result in an error. We cannot use any operations on arrays stored both on CPU and GPU. The correct way is to move the GPU array to CPU and only then to compute the normjulia> using LinearAlgebra\n\njulia> norm(A*b - cpu(A_g*b_g))\n1.2004562847861718e-5The norm is surprisingly large. Checking the typesjulia> (typeof(A), typeof(A_g))\n(Matrix{Float64}, CUDA.CuMatrix{Float32})we realize that one of the arrays is stored in Float64 while the second one in Float32. Due to the different number of saved digits, the multiplication results in this error.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"The previous exercise did not show any differences when performing a matrix-vector multiplication. The probable reason was that the running times were too short. The following exercise shows the time difference when applied to a larger problem.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 2:\nLoad the MNIST dataset and the model saved in data/mnist.bson. Compare the evaluation of all samples from the testing set when done on CPU and GPU. For the latter, you need to convert the model to GPU.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe load the data, model and convert everything to GPUusing CUDA\n\nm = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m)\n\nm_g = m |> gpu\nX_test_g = X_test |> gpuNow we can measure the evaluation time. Remember that we need to compile all the functions by evaluating at least one sample before doing so.m(X_test[:,:,:,1:1])\nm_g(X_test_g[:,:,:,1:1])julia> @time m(X_test);\n1.190033 seconds (40.24 k allocations: 1.069 GiB, 21.73% gc time)\n\njulia> @time m_g(X_test_g);\n0.071805 seconds (789 allocations: 27.641 KiB)Using GPU speeded the computation by more than ten times.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"info: Computation on GPU:\nUsing GPUs speeds up the training of neural networks in orders of magnitude. However, one needs to be aware of some pitfalls.Make sure that all computation is performed either on CPU or GPU. Do not mix them. When computing on GPU, make sure that all computations are fast. One important example isaccuracy(x, y) = mean(onecold(cpu(m(x))) .== onecold(cpu(y)))Because onecold accesses individual elements of an array, it is extremely slow on GPU. For this reason, we need to move the arrays on CPU first.Another thing to remember is to always convert all objects to CPU before saving them.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"Exercises which do not require GPUs start here.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 3:\nLoad the network from data/mnist.bson. Then create a 10times 10 table, where the (i+1j+1) entry is the number of samples, where digit i was misclassified as digit j. This matrix is called the confusion matrix.Convert the confusion matrix into a dataframe and add labels.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nFirst, we load the data as many times beforem = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m)When creating a table, we specify that its entries are Int. We save the predictions y_hat and labels y. Since we do not use the second argument to onecold, the entries of y_hat and y are between 1 and 10. Then we run a for loop over all misclassified samples and add to the error counts.y_hat = onecold(m(X_test))\ny = onecold(y_test)\n\nerrors = zeros(Int, 10, 10)\nfor i in findall(y_hat .!= y)\n    errors[y[i], y_hat[i]] += 1\nendTo create the dataframe, we use df = DataFrame(errors). It prints correctly integers and not strings. We change labels x1 to miss0, ... Similarly, we add the labels as the first column.using DataFrames\n\ndf = DataFrame(errors, :auto)\n\nrename!(df, [Symbol(\"miss$(i)\") for i in 0:9])\ninsertcols!(df, 1, :label => string.(0:9))\n\nnothing # hide","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"df # hide","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"Surprisingly, the largest number of misclassifications is 9 into 7. One would expect 8 to 0, 5 to 6 or 8 to 9. We investigate this in the next exercise.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 4:\nPlot all images which are 9 but were classified as 7.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nTo plot all these misclassified images, we find their indices and use the function imageplot. Since y are stored in the 1:10 format, we need to specify classes.using ImageInspector\n\nclasses = 0:9\n\ntargets = onecold(y_test, classes)\npredicts = onecold(m(X_test), classes)\n\nimageplot(1 .- X_test, findall((targets .== 9) .& (predicts .== 7)); nrows=3)\nsavefig(\"miss.svg\") # hide","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"We see that some of the nines could be recognized as a seven even by humans.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"The following exercise depicts how images propagate through the network.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 5: Visualization of neural networks 1\nWe know that the output of the convolutional layers has the same number of dimensions as the inputs. If the activation function is the sigmoid, the output values stay within 01 and can also be interpreted as images. Use the same network as before but replace ReLU by sigmoid activation functions. Load the model from data/mnist_sigmoid.bson (you can check that the model accuracy is 0.9831).For all digits, select the first five samples from the training set of this digit. Then create 5times 5 graph (there will be 10 of them for each digit), where each column corresponds to one sample. The rows should be:The original image.\nThe first channel of the layer after the first pooling layer.\nThe last channel of the layer after the first pooling layer.\nThe first channel of the layer after the second pooling layer.\nThe last channel of the layer after the second pooling layer.Discuss the images.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nTo create the network and to load the data, we usem = Chain(\n    Conv((2,2), 1=>16, sigmoid),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, sigmoid),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist_sigmoid.bson\")\ntrain_or_load!(file_name, m)Before plotting, we perform a for loop over the digits. Then onecold(y_train, classes) .== i creates a BitArray with ones if the condition is satisfied, and zeros if the condition is not satisfied. Then findall(???) selects all ones, and ???[1:5] finds the first five indices. Since we need to plot the original image, and the images after the second and fourth layer (there is always a convolutional layer before the pooling layer), we save these values into z1, z2 and z3. Then we need to access to desired channels and plot then via the ImageInspector package.using ImageInspector\n\nclasses = 0:9\nplts = []\nfor i in classes\n    jj = 1:5\n    ii = findall(onecold(y_train, classes) .== i)[jj]\n\n    z1 = X_train[:,:,:,ii]\n    z2 = m[1:2](X_train[:,:,:,ii])\n    z3 = m[1:4](X_train[:,:,:,ii])\n\n    kwargs = (nrows = 1, size = (600, 140))\n    plot(\n        imageplot(1 .- z1[:, :, 1, :], jj; kwargs...),\n        imageplot(1 .- z2[:, :, 1, :], jj; kwargs...),\n        imageplot(1 .- z2[:, :, end, :], jj; kwargs...),\n        imageplot(1 .- z3[:, :, 1, :], jj; kwargs...),\n        imageplot(1 .- z3[:, :, end, :], jj; kwargs...);\n        layout = (5,1),\n        size=(700,800)\n    )\n    savefig(\"Layers_$(i).svg\")\nendWe plot and comment on three selected digits below.","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"Digit 0","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"Digit 1","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"Digit 9","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"We may observe several things:","category":"page"},{"location":"lecture_11/exercises/","page":"Exercises","title":"Exercises","text":"The functions inside the neural network do the same operations on all samples. The second row is always a black digit on a grey background.\nThe size of the image decreases when propagated deeper into the network. The second and third rows (after the second layer) contain more pixels than the fourth and fifth rows (after the fourth layer).\nThe channels of the same layer produce different outputs. While the second row (first channel after the second layer) depicts black digits on a grey background, the third row (last channel after the second layer) depicts white digits on black background.\nEach digit produce different images. This is important for separation and correct predictions.","category":"page"},{"location":"lecture_05/Plots/#Plots.jl","page":"Plots.jl","title":"Plots.jl","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The Plots package is not a standard plotting package known from other languages. The Plots package provides a unified interface and toolset for creating plots. The plots themselves are drawn by different backends, like GR, PyPlot, PGFPlotsX, or Plotly. If one backend does not support desired features, it is possible to switch to another backend with one command without any further changes to the code.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"warning: Time for the first plot:\nCompared to Python or Matlab, it takes some time to create the first plot in a new Julia session. In Julia, all functions are compiled during their first run, which slows the first run down.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The core of the Plots package is the plot function that provides an interface for creating all types of plots. The default plot style is the line style. The line plot can be created by calling the plot function on two vectors.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots\nx = range(0, 2π; length = 100)\ny = sin.(x)\nplot(x, y)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Depending on the environment and backend, the plot is displayed in a plot pane, a stand-alone window, or the browser, see the official documentation for more details. Each input column is treated as a separate plot series. Thus, it is possible to create multiple plots at once.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"y = hcat(sin.(x), cos.(x))\nplot(x, y)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"To add a new curve to an existing plot can be done by the plot! function. This follows the standard Julia practice that functions with ! modify inputs.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot!(x, sin.(x .+ π/4))","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The Plots package determines the current plot by employing the global variable Plots.CURRENT_PLOT. It is possible to name a figure and use it later for plotting.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plt = plot(x, hcat(sin.(x), cos.(x)))\nplot!(plt, x, sin.(x .+ π/4))","category":"page"},{"location":"lecture_05/Plots/#Plot-attributes","page":"Plots.jl","title":"Plot attributes","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"So far, we did not change any style in the plots. The Plots package provides a large number of plot attributes to modify the plot appearance. The package follows a simple rule: Positional arguments are data (which should be plotted), while keyword arguments are attributes (which modify the style). This list of attributes includes:","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"label: the label for a series, which appears in a legend.\nxguide, yguide: axis guide (label).\nlegend: legend position.\ntitle: plot title.\nxticks, yticks: position and labels for ticks.\ncolor: series color.\nlinestyle: style of the line.\nlinewidth: width of the line.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The names of the attributes are in almost all cases intuitive and sufficiently descriptive.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\ny = hcat(sin.(x), cos.(x))\nplot(x, y;\n    label = [\"sine\" \"cosine\"],\n    xguide = \"x\",\n    yguide = \"y\",\n    legend = :bottomleft,\n    title = \"Trigonometric functions\",\n    xticks = (0:0.5π:2π, [\"0\", \"0.5π\", \"π\", \"1.5π\", \"2π\"]),\n    color = [:red :blue],\n    linestyle = [:dash :dot],\n    linewidth = [2 4],\n)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"We use multiple values for some attributes to use a different setting for both curves. The logic is the same as for input data: each column corresponds to one series. Therefore, we have to use row vectors. When column vectors are used for attributes, the different values are applied to data points.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The following example creates a sine function plot from n data points. As a linewidth attribute, we use a range from 1 to 50 of length n: each point will be of different width. The same applies to the color attribute. We use the palette function to generate n colors from the viridis color scheme. Then each color is applied to one point.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"n = 200\nx = range(0, 2π; length = n)\nlinewidth = range(1, 50; length = n)\ncolor = palette(:viridis, n)\nxlims = (0, 7)\nylims = (-1.2, 1.2)\nlabel = \"\"\n\nplot(x, sin.(x); linewidth, color, label, xlims, ylims)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"It is possible to use both column and row vectors as attributes at the same time. In the following example, we add a cosine function into the previous plot and set its color to red.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(x, [sin.(x) cos.(x)]; linewidth, color = [color :red], label, xlims, ylims)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"There is a large number of attributes. The Plots package provides the plotattr function to print all attributes for series, plots, subplots, or axes.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(:Series)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The plotattr function accepts any of the following arguments: :Plots, :Series, :Subplot, and :Axis. It is also possible to use the plotattr function to print a concrete attribute description.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"title\")","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The example above uses a String instead of Symbol. Be aware that not all attributes are supported. Attributes that can be specified for different axes, such as xguide and yguide, are often not supported.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"xguide\")","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Descriptions for these attributes can be found using the attribute name without the axis specification, i.e., guide instead of xguide.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"guide\")","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"warning: Exercise:\nConsider the following set of equationsbeginaligned\nx(t)  = cos(3t) \ny(t)  = sin(2t)\nendalignedwhere t in 0 2pi. Create a plot of the curve described by the equations above. Use plot attributes to set the following propertiesThe line width should start at 1, increase to 50 and then decrease back to 1.\nThe line color should change with the changing line width.Use :viridis color scheme or any other color scheme supported by the Plots package. Use additional plot attributes to get a nice looking graph.Hints:use the palette function combined with the collect function to generate a vector of colors from the :viridis color scheme.\nremove all decorators by using: axis = nothing, border = :none.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"details: Solution:\nWe first define vector t by the range function with a predefined length.n = 1000\nt = range(0, 2π; length = n)\nnothing # hideThen we define functions described by the set of equations in the exercise description.fx(t) = cos(3t)\nfy(t) = sin(2t)\nnothing # hideSince we want to use different plot attributes for each point, the attributes will have length n. Since the linewidth should first increase and then decrease, we use twice range and then vcat them into one column vector.linewidth = vcat(\n    range(1, 50; length = n ÷ 2),\n    range(50, 1; length = n - n ÷ 2)\n)\nnothing # hideWe used integer division to set the length in the range function. In the same way, we can create a vector of colors. The Plots package provides the palette function that allows generating equidistantly spaced colors from a color scheme.c = palette(:viridis, 2);\ntypeof(c)The palette function returns the ColorPalette type. Since we want to concatenate two vectors of colors together, we have to use the collect function to extract the vector of colors from the ColorPalette type.c = collect(palette(:viridis, 2))Now we can use a similar code as before in combination with the rev keyword to change the order.color = vcat(\n    collect(palette(:viridis, n ÷ 2)),\n    collect(palette(:viridis, n - n ÷ 2; rev = true))\n)\nnothing # hideFinally, we can call the plot function with input arguments and attributes defined above. We use axis = nothing and border = :none to remove all decorators such as ticks or axis frame.plot(fx.(t), fy.(t);\n    linewidth,\n    color,\n    lims = (-1.2, 1.2),\n    legend = false,\n    axis = nothing,\n    border = :none,\n)\n\nsavefig(\"plot_exercise1.svg\") # hide","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_05/Plots/#Function-plotting","page":"Plots.jl","title":"Function plotting","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The previous section showed basic functionality of the plot function. We first calculated the values to be plotted and then created the graphs. However, it is possible to pass functions directly to the plot function.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"t = range(0, 2π; length = 100)\nplot(t, [sin, cos]; label = [\"sine\" \"cosine\"])","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"It is even possible to pass two functions first and then the vector of values, where these functions will be evaluated.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(sin, x -> sin(2x), t; linewidth = 2, label = \"\")","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Instead of a vector of values, we can also use a similar syntax as for ranges with the starting point, stopping point, and optionally length.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(sin, x -> sin(2x), 0, 2π, 100; linewidth = 2, label = \"\")","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"warning: Exercise:\nCreate a plot given by the following set of equations:beginaligned\nx(t)  = (a + b)cos(t) - b cdot cos left( left(fracab + 1 right)t right) \ny(t)  = (a + b)sin(t) - b cdot sin left( left(fracab + 1 right)t right) \nendalignedwhere a = 423, b = 235 and t in -15 20. Use additional plot attributes to get a nicely looking graph.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"details: Solution:\nThis exercise is straightforward. We first define the functions described by the set of equations.fx(t; a = 4.23, b = 2.35) = (a + b)*cos(t) - b*cos((a/b + 1)*t)\nfy(t; a = 4.23, b = 2.35) = (a + b)*sin(t) - b*sin((a/b + 1)*t)\n\nnothing # hideNow we plot these functions.plot(fx, fy, -15, 20, 500;\n    linewidth = 2,\n    legend = false,\n    axis = nothing,\n    border = :none,\n)\n\nsavefig(\"plot_exercise2.svg\") # hide","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_05/Plots/#Changing-the-plotting-series","page":"Plots.jl","title":"Changing the plotting series","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The previous section used only line plots. However, there are many other series types, such as scatter plots, heatmaps, or contours. One way to change the plot series is the seriestype attribute. The following example plots the sine function by the scatter series type.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\ny = sin.(x)\nplot(x, y; seriestype = :scatter)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The second way is to use a specialized function provided for each series type. These functions have the same name as the corresponding series type.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"scatter(x, y)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"warning: Exercise:\nConsider the following function:f(x y) = fracx^2 cdot y^2x^4 + y^4Draw this function for x y in -5 5. Use the following three plot series contourf, heatmap, and surface with the following settings::viridis color scheme,\ncamera angle (25, 65),\nno legend, color bar, or decorators (axis, frame and ticks).","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"details: Solution:\nAs usual, we first define the function and the values, where it will be evaluated.x = range(-5, 5; length = 200)\nfz(x, y) = x^2*y^2/(x^4 + y^4)\nnothing # hideSince we want to create three different plots with the same attributes, we create a named tuple to store the attribute values. This allows us to reuse them.kwargs = (\n    color = :viridis,\n    legend = false,\n    cbar = false,\n    axis = nothing,\n    border = :none,\n)\nnothing # hideWe can use the plot function with the seriestype = :contourf keyword to draw a filled contour plot. The simpler option is to use the contourf function.contourf(x, x, fz; kwargs...) # or plot(x, x, fz; seriestype = :contourf, kwargs...)(Image: )We used the triple-dot syntax to unpack keyword arguments. Recall that in this case, the semi-colon is mandatory. Similarly, we can draw the heatmap plot.heatmap(x, x, fz; kwargs...)(Image: )For the surface plot, we can change the camera angle by setting the camera attribute.surface(x, x, fz; camera = (25, 65), kwargs...)(Image: )","category":"page"},{"location":"lecture_05/Plots/#Subplots","page":"Plots.jl","title":"Subplots","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Sometimes it is useful to create a plot with multiple subplots. The Plots package provides the layout keyword to do so.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\nplot(x, [sin, cos, tan, sinc];\n    layout = 4,\n    linewidth = 2,\n    legend = false,\n    title = [\"1\" \"2\" \"3\" \"4\"],\n)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"This example creates four curves at once. The layout keyword tells Plots package to draw each curve in a separate subplot. Attributes with multiple values (row vectors) apply each value to one subplot. The Plots package also provides the grid function used to create a subplot grid manually. For example, we can easily change the grid to 4x1 and set the height of each subplot.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(x, [sin, cos, tan, sinc];\n    layout = grid(4, 1; heights = [0.1 ,0.4, 0.4, 0.1]),\n    linewidth = 2,\n    legend = false,\n)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"It is possible to create more advanced layouts with the @layout macro. In the example below, we create a non-symmetric layout with one subplot in the first row and two subplots in the second row. Moreover, we set the width of the first subplot in the second row to be 0.3 of the whole plot width.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"l = @layout [a ; b{0.3w} c]\nplot(x, [sin, cos, tan]; layout = l, linewidth = 2, legend = false)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"All examples above can also be created incrementally. To recreate the last graph, we first create three plots.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"linewidth = range(1, 20; length = 100)\np1 = plot(x, sin; legend = false, line_z = 1:100, color = :viridis, linewidth)\np2 = plot(x, cos; legend = false, line_z = 1:100, color = :Blues_9, linewidth)\np3 = plot(x, tan; legend = false, line_z = 1:100, color = :hsv, linewidth)\nnothing # hide","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The line_z keyword allows for applying different colours to different points. Then we can use the plot function and the layout keyword to create the final plot.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"l = @layout [a ; b{0.3w} c]\nplot(p1, p2, p3; layout = l)","category":"page"},{"location":"lecture_05/Plots/#Animations","page":"Plots.jl","title":"Animations","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The following example creates an animation by updating an existing curve. We first create an empty graph and specify all its attributes.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"n = 300\nplt = plot(Float64[], [sin, cos];\n    legend = false,\n    xlims = (0, 6π),\n    ylims = (-1.1, 1.1),\n    linewidth = range(1, 20; length = n),\n    color = palette(:viridis, n),\n    axis = nothing,\n    border = :none\n)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Then we create an empty animation by the Animation function.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"anim = Animation()","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Finally, we use the for loop and the frame function to create an animation. The second line uses the push! function to append new points to the plt plot defined before. The frame function captures the current state of the plt plot and creates a new frame for the animation.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"for x in range(0, 6π; length = n)\n    push!(plt, x, [sin(x), cos(x)])\n    frame(anim)\nend","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"When the animation is created, we can save it as a gif using the gif function.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"gif(anim, \"animsincos.gif\", fps = 15)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Another way how to create an animation is by the @animate macro. We now create the following 3D surface plot.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(-5, 5; length = 400)\nfz(x, y) = x^2*y^2/(x^4 + y^4)\nplt = surface(x, x, fz;\n    camera = (30, 65),\n    color = :viridis,\n    legend = false,\n    axis = nothing,\n    border = :none,\n    cbar = false,\n)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"We can create an animation by modifying some parameters of the plot. For example, to change the camera angle, we use the plot! function with the camera keyword arguments.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"anim = @animate for i in vcat(30:60, 60:-1:30)\n    plot!(plt, camera = (i, 65))\nend","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Finally, we save the animation by the gif  function as in the previous example.","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"gif(anim, \"animsurf.gif\", fps = 15)","category":"page"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_05/Plots/#Integration-with-other-packages","page":"Plots.jl","title":"Integration with other packages","text":"","category":"section"},{"location":"lecture_05/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Plots package provides a simple way of defining special plots for custom data types using the so-called recipes (recipes are defined in a stand-alone package RecipeBase). By defining custom recipes, it is possible to change the data preprocessing before they are plotted. Many packages provide specialized plot recipes. For example, StatsPlots provides recipes for plotting histograms and boxplots or violin plots. This package also offers recipes to treat DataFrames and Distributions, allowing simple plotting of tabular data and distributions.","category":"page"},{"location":"lecture_01/operators/#Arithmetic-operators","page":"Elementary functions","title":"Arithmetic operators","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Basic arithmetic operations are defined in Julia standard libraries, and all these operators are supported on all primitive numeric types","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Expression Name Description\nx + y binary plus performs addition\nx - y binary minus performs subtraction\nx * y times performs multiplication\nx / y divide performs division\nx ÷ y integer divide x / y, truncated to an integer\nx \\ y inverse divide equivalent to y / x\nx ^ y power raises x to the yth power\nx % y remainder equivalent to rem(x,y)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Here are some simple examples using arithmetic operators","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> 1 + 2\n3\n\njulia> 2*3\n6\n\njulia> 4/3\n1.3333333333333333","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"All of these operators can also be applied directly to any variable that represents a numeric value","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> x = 1;\n\njulia> y = 3;\n\njulia> (x + 2)/(y - 1) - 4*(x - 2)^2\n-2.5","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Note that we use a semicolon after some expressions. In the REPL, if we evaluate any expression, its result is printed. If we use the semicolon, the output is omitted. It is similar behaviour as in Matlab, but in Julia, the printing is automatic only in the REPL.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"A numeric literal placed directly before an identifier or parentheses is treated as multiplication","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> 2(3 + 4) # equivalent to 2*(3 + 4)\n14","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"warning: Exercise:\nDetermine the value and type of y given by the following expressiony = frac(x + 2)^2 - 4(x - 2)^p - 2where x = 4 and p = 5.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"details: Solution:\nFirst, we define variables x and pjulia> x = 4\n4\n\njulia> p = 5\n5then we can use the combination of basic arithmetic operators to compute the value of yjulia> y = ((x + 2)^2 - 4)/(x - 2)^(p - 2)\n4.0The type of y can be determined using the typeof functionjulia> typeof(y)\nFloat64Note that the resulting type of y is Float64 even though the result can be represented as an integer. The reason is that we divide two integersjulia> typeof((x + 2)^2 - 4)\nInt64\n\njulia> typeof((x - 2)^(p - 2))\nInt64Because this operation generally does not result in an integer, dividing two integers always returns a floating-point number. If we want to get an integer, we can use the integer division operator ÷ (can be typed as \\div<tab>)julia> y_int = ((x + 2)^2 - 4)÷(x - 2)^(p - 2)\n4\n\njulia> typeof(y_int)\nInt64","category":"page"},{"location":"lecture_01/operators/#Promotion-system","page":"Elementary functions","title":"Promotion system","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"The section about variables showed that there are many numeric types in Julia. To ensure that the correct type is always used, Julia has a promotion system that converts input values of mixed types to a type that can correctly represent all values. The promotion of mixed type variables can be done manually using the promote function. As an example, we can mention the promotion of multiple numeric types","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> x = 1.0 # Float64\n1.0\n\njulia> y = 2 # Int64\n2\n\njulia> xp, yp = promote(x, y)\n(1.0, 2.0)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In this case, the resulting type of variables xp and yp is Float64 as can be checked using the typeof function","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> typeof(xp)\nFloat64\n\njulia> typeof(yp)\nFloat64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Strictly speaking, not all Int64 values can be represented exactly as Float64 values. The promotion system generally tries to return a type that approximates well most values of either input type.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"The promote function accepts any number of input arguments","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> promote(1, 2f0, true, 4.5, Int32(1))\n(1.0, 2.0, 1.0, 4.5, 1.0)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"The resulting type of promotion can be determined by the promotion_type function. This function is similar to the promote function and will accept any number of input arguments, but the inputs have to be types and not values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> promote_type(Float64, Int64, Bool, Int32)\nFloat64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Although this may seem complicated, type promotion is done automatically in most cases, and the user does not have to worry about it. To demonstrate the promotion system in practice, consider the following example: we sum the value of type Int64 with the value of type Float32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> x = 1 # Int64\n1\n\njulia> y = 2f0 # Float32\n2.0f0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Since the \"smallest\" type that can represent both values correctly is Float32, the result is of type Float32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> z = x + y\n3.0f0\n\njulia> typeof(z)\nFloat32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"warning: Exercise:\nAll of these values represent number 1. Determine the smallest type which can represent them.x = 1\ny = 1f0\nz = true\nw = Int32(1)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"details: Solution:\nTo get the correct promotion type, we can use a combination of the promote and typeof functionsjulia> xp, yp, zp, wp = promote(x, y, z, w)\n(1.0f0, 1.0f0, 1.0f0, 1.0f0)\n\njulia> typeof(xp)\nFloat32or the promote_type and typeof functionsjulia> promote_type(typeof(x), typeof(y), typeof(z), typeof(w))\nFloat32","category":"page"},{"location":"lecture_01/operators/#Updating-operators","page":"Elementary functions","title":"Updating operators","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Every binary arithmetic operator also has an updating version that assigns the operation's result back into its left operand. The updating version of the binary operator is formed by placing a = symbol immediately after the operator. For example, writing x += 3 is equivalent to writing x = x + 3","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> x = 1\n1\n\njulia> x += 3 # x = x + 3\n4\n\njulia> x *= 4 # x = x * 4\n16\n\njulia> x /= 2 # x = x / 2\n8.0\n\njulia> x \\= 16 # x = x \\ 16 = 16 / x\n2.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"warning: Exercise:\nCompute the value of y given by the following expressiony = frac(x + 4)^frac32(x + 1)^p - 1where x = 5 and p = 3. Then multiply the result by 8, add 3, divide by 3, and subtract 1. What are all the intermediate results and the final result?","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"details: Solution:\nFirst, we calculate the value of yjulia> x = 5;\n\njulia> p = 3;\n\njulia> y = (x + 4)^(3/2)/(x + 1)^(p - 1)\n0.75Then we can use the update operators to get all the intermediate results as well as the final resultjulia> y *= 8\n6.0\n\njulia> y += 3\n9.0\n\njulia> y /= 3\n3.0\n\njulia> y -= 1\n2.0","category":"page"},{"location":"lecture_01/operators/#Numeric-comparison","page":"Elementary functions","title":"Numeric comparison","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In addition to arithmetic and updating operators, basic comparison operators are also defined in Julia's standard libraries.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Operator Name\n== equality\n!=, ≠ inequality\n< less than\n<=, ≤ less than or equal to\n> greater than\n>=, ≥ greater than or equal to\n& bitwise and\n| bitwise or","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"All these operators always return a boolean value (true or false) as the following example shows","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> 1 == 1\ntrue\n\njulia> 1 == 1.0\ntrue\n\njulia> -1 <= 1\ntrue\n\njulia> -1 ≥ 1\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In most programming languages, comparison operators are strictly binary, i.e., they can be used to compare only two values at a time. As an example, we can use a comparison of three numbers in Matlab","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":">> 3 > 2 > 1\n\nans =\n\n  logical\n\n   0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Even though the condition holds, the result is false (logical 0). The correct way to write such a condition in Matlab is as follows","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":">> 3 > 2 & 2 > 1\n\nans =\n\n  logical\n\n   1","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In Julia (and Python, for example), both ways of writing conditions are correct and lead to the same result","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> 3 > 2 > 1\ntrue\n\njulia> 3 > 2 & 2 > 1\ntrue","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In fact, comparison operators can be arbitrarily chained as in the following example","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> 1 < 2 <= 2 < 3 == 3 > 2 >= 1 == 1 < 3 != 5\ntrue","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"In general, the user should always try to write code that is easy to read. Even though writing expressions as in the example above is possible, the user should always consider if it is necessary.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Comparison of special values such as NaN can lead to unexpected behaviour","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> NaN == NaN\nfalse\n\njulia> NaN != NaN\ntrue\n\njulia> NaN < NaN\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"To avoid unexpected result, Julia provides additional functions to compare numbers for special values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Function Tests if\nisequal(x, y) x and y are identical\nisfinite(x) x is a finite number\nisinf(x) x is infinite\nisnan(x) x is not a number","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Function isequal considers NaNs equal to each other","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> isequal(NaN, NaN)\ntrue\n\njulia> !isequal(NaN, NaN)\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"We used the operator ! to negate the output of the isequal function in the example above. This operator is called boolean not and can be used to negate boolean values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> !true\nfalse\n\njulia> !false\ntrue","category":"page"},{"location":"lecture_01/operators/#Rounding-functions","page":"Elementary functions","title":"Rounding functions","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Julia provides several functions for rounding numbers, as can be seen in the following table","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Function Description\nround(x) round x to the nearest integer\nfloor(x) round x towards -Inf\nceil(x) round x towards +Inf\ntrunc(x) round x towards zero","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"These functions can be used without specifying output types. In such a case, the output has the same type as the input variable","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> x = 3141.5926\n3141.5926\n\njulia> round(x)\n3142.0\n\njulia> floor(x)\n3141.0\n\njulia> ceil(x)\n3142.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"However, in many cases, it makes sense to convert the rounded value to a different type. For example, if the rounded value can be represented as an integer, it makes sense to convert the rounded value to an integer. The output type (only subtypes of Integer with the exception of Bool) can be passed as the first argument to all rounding functions from the table above","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> round(Int64, x)\n3142\n\njulia> floor(Int32, x)\n3141\n\njulia> ceil(Int16, x)\n3142","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"All rounding functions also support additional keyword arguments:","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"If the digits keyword argument is provided, it rounds to the specified number of digits after the decimal place in the base specified by the base keyword argument.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> round(x; digits = 3)\n3141.593","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"If the sigdigits keyword argument is provided, it rounds to the specified number of significant digits in the base specified by the base keyword argument.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> round(x; sigdigits = 3)\n3140.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"warning: Exercise:\nUse rounding functions to solve the following tasks:Round 1252.1518 to the nearest larger integer and convert the resulting value to Int64.\nRound 1252.1518 to the nearest smaller integer and convert the resulting value to Int16.\nRound 1252.1518 to 2 digits after the decimal point.\nRound 1252.1518 to 3 significant digits.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"details: Solution:\nThe ceil function rounds numbers to the nearest larger value, and since we want the result to be of type Int64, we have to pass this type as a first argumentjulia> x = 1252.1518\n1252.1518\n\njulia> ceil(Int64, x)\n1253Similarly, the floor function rounds numbers to the nearest smaller valuejulia> floor(Int16, x)\n1252The number of digits after the decimal point can be controlled using the digits keywordjulia> round(x; digits = 2)\n1252.15and the number of significant digits using the sigdigits keywordjulia> round(x; sigdigits = 3)\n1250.0","category":"page"},{"location":"lecture_01/operators/#Numerical-conversions","page":"Elementary functions","title":"Numerical conversions","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"The previous section showed that numerical conversions could be done by using rounding functions with a specified type of output variable. This works only for converting floating-point numbers to integers. Julia also provides a more general way of how to perform conversions between different (not only numerical) types: notation T(x) or convert(T,x) converts x to a value of type T.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"If T is a floating-point type, the result is the nearest representable value, which could be positive or negative infinity","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> convert(Float32, 1.234)\n1.234f0\n\njulia> Float32(1.234)\n1.234f0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"If T is an integer type, an InexactError is raised if x is not representable by T","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"julia> convert(Int64, 1.0)\n1\n\njulia> Int64(1.0)\n1\n\njulia> convert(Int64, 1.234)\nERROR: InexactError: Int64(1.234)\n[...]\n\njulia> Int64(1.234)\nERROR: InexactError: Int64(1.234)\n[...]","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"Conversion to other types works in a similar way.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"warning: Exercise:\nUse the proper numeric conversion to get the correct result (not approximate) of summing the following two numbersx = 1//3\ny = 0.5Hint: rational numbers can be summed without approximation.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary functions","title":"Elementary functions","text":"details: Solution:\nFirstly, we can try just to sum the given numbersjulia> x + y\n0.8333333333333333The result of this operation is a floating-point number. However, in this specific case, we have a rational number and a floating-point number that can also be represented as a rational number. The exact result can be obtained by converting the variable y to a rational numberjulia> x + Rational(y)\n5//6","category":"page"},{"location":"lecture_08/exercises/#l7-exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 1: Solving a system of linear equations\nThe update of Newton's method computes A^-1b. The most intuitive way of writing this is to use inv(A) * b, which first computes the inverse of A and then multiplies it with a vector. However, this approach has several disadvantages:Specialized algorithms for solving the linear system Ax=b cannot be used.\nWhen A is sparse, this inverse is dense and additional memory is needed to store the dense matrix.For these reasons, the linear system of equations is solved by A \\ b, which calls specialized algorithms.Use the package BenchmarkTools to benchmark both possibilities.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe first create a random matrix A and a random vector b.using BenchmarkTools\n\nn = 1000\nA = randn(n,n)\nb = randn(n)We first verify that both possibilities result in the same number.julia> using LinearAlgebra\n\njulia> norm(inv(A)*b - A \\ b)\n9.321906736594836e-12We benchmark the first possibility.julia> @btime inv($A)*($b)\n71.855 ms (6 allocations: 8.13 MiB)We benchmark the second possibility.julia> @btime ($A) \\ ($b)\n31.126 ms (4 allocations: 7.64 MiB)The second possibility is faster and has lower memory requirements.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 2: Bisection method\nSimilarly to Newton's method, the bisection method is primarily designed to solve equations by finding their zero points. It is only able to solve equations f(x)=0 where fmathbbRtomathbbR. It starts with an interval ab where f has opposite values f(a)f(b)0. Then it selects the middle point on ab and halves the interval so that the new interval again satisfies the constraint on opposite signs f(a)f(b)0. This is repeated until the function value is small or until the interval has a small length.Implement the bisection method and use it to minimize f(x) = x^2 - x on -11. During the implementation, do not evaluate f unless necessary.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nFirst, we write the bisection method. We initialize it with arguments f and the initial interval ab. We also specify the optional tolerance. First, we save the function value fa = f(a) to not need to recompute it every time. The syntax fa == 0 && return a is a bit complex. Since && is the \"and\" operator, this first checks whether fa == 0 is satisfied, and if so, it evaluates the second part. However, the second part exits the function and returns a. Since we need to have f(a)f(b)0, we check this condition, and if it is not satisfied, we return an error message. Finally, we run the while loop, where every iteration halves the interval. The condition on opposite signs is enforced in the if condition inside the loop.function bisection(f, a, b; tol=1e-6)\n    fa = f(a)\n    fb = f(b)\n    fa == 0 && return a\n    fb == 0 && return b\n    fa*fb > 0 && error(\"Wrong initial values for bisection\")\n    while b-a > tol\n        c = (a+b)/2\n        fc = f(c)\n        fc == 0 && return c\n        if fa*fc > 0\n            a = c\n            fa = fc\n        else\n            b = c\n            fb = fc\n        end\n    end\n    return (a+b)/2\nend\nnothing # hideThis implementation is efficient in the way that only one function evaluation is needed per iteration. The price to pay are additional variables fa, fb and fc.To use the bisection method to minimize a function f(x), we use it find the solution of the optimality condition f(x)=0.f(x) = x^2 - x\ng(x) = 2*x - 1\nx_opt = bisection(g, -1, 1)\nnothing # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"println(round(x_opt, digits=4)) # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 3: JuMP\nThe library to perform optimization is called JuMP. Install it, go briefly through its documentation, and use it to solve the linear optimization problembeginaligned\ntextminimizeqquad x_1 + x_2 + x_5 \ntextsubject toqquad x_1+2x_2+3x_3+4x_4+5x_5 = 8 \nx_3+x_4+x_5 = 2 \nx_1+x_2 = 2\nendaligned","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe best start is the official documentation of the JuMP package. Since JuMP is only an interface for solvers, we need to include an actual solver as well. For linear programs, we can use using GLPK, for non-linear ones, we would need to use using Ipopt. We specify the constraints in a matrix form. It is possible to write them directly via @constraint(model, x[1] + x[2] == 2). This second way is more pleasant for complex constraints. Since x is a vector, we need to use value.(x) instead of the wrong value(x).using JuMP\nusing GLPK\n\nA = [1 2 3 4 5; 0 0 1 1 1; 1 1 0 0 0]\nb = [8; 2; 2]\nc = [1; 1; 0; 0; 1]\nn = size(A, 2)\n\nmodel = Model(GLPK.Optimizer)\n\n@variable(model, x[1:n] >= 0)\n\n@objective(model, Min, c'*x)\n@constraint(model, A*x .== b)\noptimize!(model)\n\nx_val = value.(x)\nnothing # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"println(round.(x_val, digits=4)) # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 4: SQP\nDerive the SQP method for optimization problem with only equality constraintsbeginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad h_j(x) = 0 j=1dotsJ\nendalignedSQP writes the Karush-Kuhn-Tucker optimality conditions and then applies Newton's method to solve the resulting system of equations. Apply the obtained algorithm tobeginaligned\ntextminimizeqquad sum_i=1^10 ix_i^4 \ntextsubject toqquad sum_i=1^10 x_i = 1\nendalignedVerify that the numerically obtained solution is correct.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe Lagrangian readsL(xmu) = f(x) + sum_j=1^Jmu_j h_j(x)Since there are no inequality constraints, the optimality conditions contain no complementarity and readbeginaligned\nnabla f(x) + sum_j=1^Jmu_j nabla h_j(x) = 0\nh_j(x) = 0\nendalignedThe Newton method's at iteration k has some pair (x^kmu^k) and performs the updatebeginpmatrix x^k+1  mu^k+1 endpmatrix = beginpmatrix x^k  mu^k endpmatrix - beginpmatrix nabla^2 f(x^k) + sum_j=1^J mu_j^k nabla^2 h_j(x^k)  nabla h(x^k)  nabla h(x^k)^top  0 endpmatrix^-1 beginpmatrix nabla f(x^k) + sum_j=1^Jmu_j^k nabla h_j(x^k)  h(x^k) endpmatrix We define functions f and h and their derivates and Hessians for the numerical implementation. The simplest way to create a diagonal matrix is Diagonal from the LinearAlgebra package. It can be, of course, done manually as well. using LinearAlgebra\n\nn = 10\nf(x) = sum((1:n) .* x.^4)\nf_grad(x) = 4*(1:n).*x.^3\nf_hess(x) = 12*Diagonal((1:n).*x.^2)\nh(x) = sum(x) - 1\nh_grad(x) = ones(n)\nh_hess(x) = zeros(n,n)\nnothing # hideTo implement SQP, we first randomly generate initial x and mu and then write the procedure derived above. Since we update x in a for loop, we need to define it as a global variables; otherwise, it will be a local variable, and the global (outside of the loop) will not update. We can write inv(A)*b or the more efficient A\\b. To subtract from x, we use the shortened notation x -= ?, which is the same as x = x - ?.x = randn(n)\nμ = randn()\nfor i in 1:100\n    global x, μ\n    A = [f_hess(x) + μ*h_hess(x) h_grad(x); h_grad(x)' 0]\n    b = [f_grad(x) + μ*h_grad(x); h(x)]\n    step = A \\ b\n    x -= step[1:n]\n    μ -= step[n+1] \nendThe need to differentiate global and local variables in scripts is one reason why functions should be used as much as possible.To validate, we need to verify the optimality and the feasibility; both need to equal zero. These are the same as the b variable. However, we cannot call b directly, as it is inside the for loop and therefore local only.f_grad(x) + μ*h_grad(x)\nh(x)","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"println(round.(x, digits=4)) # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 5 (theory)\nShow that the primal formulation for a problem with no inequalities is equivalent to the min-max formulation.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe primal problem with no inequalities readsbeginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad h_j(x) = 0 j=1dotsJ\nendalignedThe Lagrangian has formL(xlambdamu) = f(x) + sum_j=1^J mu_j h_j(x)Now consider the min-max formulationoperatorname*minimize_xquad operatorname*maximize_muquad f(x) + sum_j=1^J mu_j h_j(x)If h_j(x)neq 0, then it is simple to choose mu_jso that the inner maximization problem has the optimal value +infty. However, since the outer problem minimizes the objective, the value of +infty is irrelevant. Therefore, we can ignore all points with h_j(x)neq 0 and prescribe h_j(x)=0 as a hard constraint. That is precisely the primal formulation.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 6 (theory)\nDerive the dual formulation for the linear programming.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe linear programbeginaligned\ntextminimizeqquad c^top x \ntextsubject toqquad Ax=b \nxge 0\nendalignedhas the LagrangianL(xlambdamu) = c^top x - lambda^top x + mu^top (b-Ax) = (c - lambda - A^topmu)^top x + b^top muWe need to have - lambda^top x because we require constraints g(x)le 0 or in other words -xle 0. The dual problem from its definition readsoperatorname*maximize_lambdage0 mu quad operatorname*minimize_x quad (c - lambda - A^topmu)^top x + b^top muSince the minimization with respect to x is unconstrained, the same arguments as the previous exercise imply the hard constraint c - lambda - A^topmu=0. Then we may simplify the dual problem intobeginaligned\ntextmaximizeqquad b^top mu \ntextsubject toqquad c - lambda - A^topmu = 0 \nlambdage 0\nendalignedFrom this formulation, we may remove lambda and obtain A^top mule c. This is the desired dual formulation.","category":"page"},{"location":"lecture_07/modules/#Files-and-modules","page":"Files and modules","title":"Files and modules","text":"","category":"section"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"When writing code, it is essential to organize it effectively. There are three main ways of achieving this:","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Split code into multiple files.\nUse modules to create global scopes.\nCreate separate packages by extracting code with general functionality.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"These three approaches are often used together. This lecture describes how to use them in Julia.","category":"page"},{"location":"lecture_07/modules/#Files","page":"Files and modules","title":"Files","text":"","category":"section"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"The first and most basic approach is to split code into multiple files. Such files have to be of an appropriate type, i.e., Julia files with the .jl extension. These files can be loaded into the global scope by the include function.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"include(\"/absolute/path/to/the/file/filename.jl\")\ninclude(\"../relative/path/to/the/file/filename.jl\")","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"The  include function evaluates the source file content in the global scope of the module, where the include call occurs. If a file is included multiple times, it is also evaluated multiple times.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Even though using separate files to organize code can be very useful, this approach also has several disadvantages. For example, since all files are evaluated in the same global scope, we have to avoid clashes of variable/function names from different files.  This problem can be solved by using modules as described in the following section.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"info: Main module:\nIf we run a code in the REPL, the code is evaluated in the Main module, which serves as the default global scope. We can check this by the @__MODULE__ macro that returns the module in which the macro is evaluated.julia> @__MODULE__\nMainThe parentmodule function determines the module containing the (first) definition of a generic function.julia> foo() = 1\nfoo (generic function with 1 method)\n\njulia> parentmodule(foo)\nMain","category":"page"},{"location":"lecture_07/modules/#Modules","page":"Files and modules","title":"Modules","text":"","category":"section"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Modules allow users to specify which data from the module is visible outside of the module. In the section Scope of variables, we briefly mentioned that modules in Julia introduce a new global scope. In other words, modules in Julia are separate variable workspaces that provide three key features. They all help to prevent unexpected name clashes.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"They define top-level definitions (global variables) without worrying about name conflicts.\nThey control the visibility of variables/functions/types outside of the module via exporting.\nThey control the visibility of variables/functions/types from other modules via importing.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"The following example defines the module Points. We create it with the module keyword and load the LinearAlgebra package by the using keyword. Then we use the export keyword to export the Point type and the distance function. Finally, we write the actual content of the module.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"module Points\n\nusing LinearAlgebra\n\nexport Point, distance\n\nstruct Point{T <: Real}\n    x::T\n    y::T\nend\n\ncoordinates(p::Point) = (p.x, p.y)\nBase.show(io::IO, p::Point) = print(io, coordinates(p))\ndistance(p::Point, q::Point) = norm(coordinates(q) .- coordinates(p), 2)\n\nend\nnothing # hide","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Assume now that we want to load this module from a different file. Since each package core is a module, packages are loaded in the same way as modules. We need to specify using Main.Points or using .Points because we defined the package in the Main scope. If we loaded an external package Points, we would use using Points. After loading a package, we can directly access all the exported data.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"using .Points # alternatively using Main.Points\n\np = Point(4,2)\nq = Point(2,2)\ndistance(p, q)","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"It is also possible to access all non-exported functions and types. To do so, we need to specify which module they are defined in. For example, we can call the non-exported coordinates function by the following syntax:","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Points.coordinates(p)\nPoints.coordinates(q)","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"When writing a module, we have to decide which functions and types we want to export. The rule of thumb is that we export only the data end-users should use.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"To redefine or extend an imported function, we need to specify the module. We can use the following way to redefine the distance function:","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"using .Points: coordinates\n\nfunction Points.distance(p::Point, q::Point)\n    d = sqrt(sum(abs2, coordinates(q) .- coordinates(p)))\n    return \"Distance is $d\"\nend\n\nnothing # hide","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"We can see the same syntax in the Points module, where we extend the show function from the Base module. We used the using .Points: coordinates syntax to call the coordinates function without specifying the module name.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"p = Point(4,2)\nq = Point(2,2)\ndistance(p, q)","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"Besides the using keyword, Julia also provides the import keyword to import modules and packages. Its behaviour is slightly different; for more information, see the official documentation.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"compat: Relative and absolute module paths:\nIn the previous section, we added a dot before the module name in the using keyword. The reason is that if we import a module, the system consults an internal table of top-level modules to find the given module name. If the module does not exist, the system attempts to require(:ModuleName), which typically results in loading code from an installed package. However, if we evaluate code in the REPL, the code is evaluated in the Main module. Then Points are not in a top-level module but in a submodule of Main.julia> Points\nMain.Points\n\njulia> parentmodule(Points)\nMainNon-top-level modules can be loaded by both absolute and relative paths.using Main.Points\nusing .PointsAdding one more leading dot moves the path one additional level up in the module hierarchy. For example, using ..Points would look for Points in the enclosing module for Main rather than Main itself.","category":"page"},{"location":"lecture_07/modules/","page":"Files and modules","title":"Files and modules","text":"compat: Modules and files:\nSince modules are associated only with module expressions, files are largely unrelated to modules. One can have multiple files in a module.module MyModule\n\ninclude(\"file1.jl\")\ninclude(\"file2.jl\")\n\nendIt is also possible to have multiple modules in a file.module MyModule1\n...\nend\n\nmodule MyModule2\n...\nend","category":"page"},{"location":"lecture_01/variables/#Variables","page":"Variables","title":"Variables","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In Julia (as in other languages), a variable is a name that refers to a value. Contrary to languages like C or C++, and similarly to Python or MATLAB, variables can be created without type specification, i.e., a variable can be declared simply by using the = sign","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 2\n2","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable is inferred automatically and can be checked using the typeof function","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> typeof(x)\nInt64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In this case, the variable x is of type Int64, which is a type that represents signed integers. Since x is a number, we can apply basic mathematical operations to it","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> y = x + 1\n3\n\njulia> typeof(y)\nInt64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable x is preserved because the sum of two integers is also an integer. We can also reuse the name of the variable and assign a new value to it","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 4\n4","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable x is still Int64, but it is also possible to assign a value of a different type to x","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 3.1415\n3.1415\n\njulia> typeof(x)\nFloat64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In this case, the variable x is of type Float64, which is a type that represents floating-point numbers.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"warning: Exercise:\nCreate the following three variables:Variable x with value 1.234.\nVariable y with value 1//2.\nVariable z with value x + y*im.What are the types of these three variables?","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"details: Solution:\nAll three variables can be declared simply by assigning the value to the given variable namejulia> x = 1.234\n1.234\n\njulia> y = 1//2\n1//2\n\njulia> z = x + y*im\n1.234 + 0.5imand types can be checked using the typeof functionjulia> typeof(x)\nFloat64\n\njulia> typeof(y)\nRational{Int64}\n\njulia> typeof(z)\nComplexF64 (alias for Complex{Float64})","category":"page"},{"location":"lecture_01/variables/#Primitive-numeric-types","page":"Variables","title":"Primitive numeric types","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"There are many types in Julia. In fact, every object in Julia has its type. As an example, we can mention the hierarchy of primitive numeric types","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"(Image: )","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"All types shown in blue are abstract types, i.e., it is impossible to create an instance of such a type. Abstract types are useful for creating logical type hierarchy. Types highlighted in green are concrete types. In many cases, it is useful to have the choice to choose which type to use. As an example, we can see floating-point numbers. There are four concrete types for floating-point numbers. If we want to maximize the precision of some calculations, we can use BigFloat. Using BigFloat increases precision but also increases computational time. On the other hand, if we want to speed up the code, we can use the type with lower precision, such as Float32. However, in most cases, the user does not have to take care of types and use the default type.","category":"page"},{"location":"lecture_01/variables/#Variable-names","page":"Variables","title":"Variable names","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Julia provides an extremely flexible system for naming variables. Variable names are case-sensitive and have no semantic meaning, i.e., the language will not treat variables differently based on their names.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> I_am_float = 3.1415\n3.1415\n\njulia> CALL_ME_RATIONAL = 1//3\n1//3\n\njulia> MyString = \"MyVariable\"\n\"MyVariable\"","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Here I_am_float contains a floating-point number, CALL_ME_RATIONAL is a rational number (can be used if the exact accuracy is needed) and MyString contains a string (a piece of text).","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Moreover, in the Julia REPL and several other Julia editing environments, it is possible to use many Unicode (UTF-8 encoding) math symbols by typing the backslashed LaTeX symbol name followed by tab. It is also possible to use many other non-math symbols. For example, the variable name δ can be entered by typing \\delta<tab>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> δ = 1\n1","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"or pizza symbol 🍕 can be entered by typing \\:pizza:<tab>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> 🍕 = \"It's time for pizza!!!\"\n\"It's time for pizza!!!\"","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The list of all Unicode characters that can be entered via tab completion of LaTeX-like abbreviations in the Julia REPL is provided in the official manual.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Julia will even let the user redefine built-in constants and functions if needed (although this is not recommended to avoid potential confusions)","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> π = 2\n2\n\njulia> π\n2","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"However, if the user tries to use a variable name that corresponds to a built-in constant or function already in use, Julia will throw an error","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> ℯ\nℯ = 2.7182818284590...\n\njulia> ℯ = 2\nERROR: cannot assign a value to imported variable Base.ℯ from module Main\n[...]","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The only explicitly disallowed names for variables are the names of built-in reserved keywords listed in the following table","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Reserved words:     \nbaremodule begin break catch const continue\ndo else elseif end export false\nfinally for function global if import\nlet local macro module quote return\nstruct true try using while ","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> struct = 3\nERROR: ParseError:\n# Error @ none:1:8\nstruct = 3\n#      ╙ ── unexpected `=`\n[...]","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In many cases, it is beneficial to have the choice to use special symbols as variable names. It may increase the code's readability, especially when the user needs to implement mathematical algorithms, where it is common to use the greek alphabet. However, excessive use of special symbols can be confusing.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"info: Stylistic Conventions:\nWhile there are almost no restrictions on valid names in Julia, it is useful to adopt the following conventions:Names of variables are in lower case.\nWord separation can be indicated by underscores (_), but the use of underscores is discouraged unless the name would be hard to read otherwise.\nDo not overuse special symbols, i.e., avoid using symbols like 🍕 as variable names.For more information about stylistic conventions, see the official style guide or Blue Style.","category":"page"},{"location":"lecture_04/functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"In Julia, a function is an object that maps a tuple of argument values to a return value. There are multiple ways to create a function. Each of them is useful in different situations. The first way is the function ... end syntax.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"function plus(x,y)\n    x + y\nend","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The plus function accepts two arguments x and y, and returns their sum.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus(2, 3)\n5\n\njulia> plus(2, -3)\n-1","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"By default, functions in Julia return the last evaluated expression, which was x + y. It is useful to return something else with the return keyword in many situations. The previous example is equivalent to:","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"function plus(x,y)\n    return x + y\nend","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Even though both functions do the same, it is always good to use the return keyword. It usually improves code readability and can prevent potential confusion.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"function plus(x, y)\n    return x + y\n    println(\"I am a useless line of code!!\")\nend","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The example above contains the println function on the last line. However, if the function is called, nothing is printed into the REPL. This is because expressions after the return keyword are never evaluated.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus(4, 5)\n9\n\njulia> plus(3, -5)\n-2","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is also possible to return multiple values at once. This can be done by writing multiple comma-separated values after the return keyword (or on the last line when return is omitted).","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"function powers(x)\n    return x, x^2, x^3, x^4\nend","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This syntax creates a tuple of values, and then this tuple is returned as a function output. The powers function returns the first four powers of the input x.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> ps = powers(2)\n(2, 4, 8, 16)\n\njulia> typeof(ps)\nNTuple{4, Int64}","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Note that the function returns NTuple{4, Int64} which is a compact way of representing the type for a tuple of length N = 4 where all elements are of the same type. Since the function returns a tuple, returned values can be directly unpacked into multiple variables. This can be done in the same way as unpacking tuples.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> x1, x2, x3, x4 = powers(2)\n(2, 4, 8, 16)\n\njulia> x3\n8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"warning: Exercise:\nWrite function power(x::Real, p::Integer) that for a number x and a (possibly negative) integer p computes x^p without using the ^ operator. Use only basic arithmetic operators +, -, *, / and the if condition. The annotation p::Integer ensures that the input p is always an integer.Hint: use recursion.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"details: Solution:\nTo use recursion, we have to split the computation into three parts:p = 0: the function should return 1.\np > 0: the function should be called recursively with arguments x, p - 1 and the result should be multiplied by x.\np < 0: then it is equivalent to call the power function with arguments 1/x, -p.These three cases can be defined using the if-elseif as follows:function power(x::Real, p::Integer)\n    if p == 0\n        return 1\n    elseif p > 0\n        return x * power(x, p - 1)\n    else\n        return power(1/x, -p)\n    end\nendWe use type annotation for function arguments to ensure that the input arguments are always of the proper type. In the example above, the first argument must be a real number, and the second argument must be an integer.julia> power(2, 5)\n32\n\njulia> power(2, -2)\n0.25\n\njulia> power(2, 5) ≈ 2^5\ntrue\n\njulia> power(5, -3) ≈ 5^(-3)\ntrueIf we call the function with arguments of wrong types, an error will occur.julia> power(2, 2.5)\nERROR: MethodError: no method matching power(::Int64, ::Float64)\n[...]We will discuss type annotation later in the section about methods.","category":"page"},{"location":"lecture_04/functions/#One-line-functions","page":"Functions","title":"One-line functions","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Besides the traditional function declaration syntax above, it is possible to define a function in a compact one-line form","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"plus(x, y) = x + y","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"that is equivalent to the previous definition of the plus function","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus(4, 5)\n9\n\njulia> plus(3, -5)\n-2","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This syntax is similar to mathematical notation, especially in combination with the Greek alphabet. For example, function","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"f(varphi) = - 4 cdot sinleft(varphi - fracpi12right)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"can be in Julia defined in an almost identical form.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"f(φ) = -4sin(φ - π/12)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The one-line syntax also allows to create more complex functions with some intermediate calculations by using brackets and semicolons to separate expressions. The last expression in brackets is then returned as the function output.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"g(x) = (x -= 1; x *= 2; x)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"In this example, the g function subtracts 1 from the input x and then returns its multiplication by 2.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> g(3)\n4","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"However, for better code readability, the traditional multiline syntax is preferred for more complex functions.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"warning: Exercise:\nWrite a one-line function that returns true if the input argument is an even number and false otherwise.Hint: use modulo function and ternary operator ?.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"details: Solution:\nFrom the section about the ternary operator, we know that the syntaxa ? b : cmeans: if a is true, evaluate b; otherwise, evaluate c. Since even numbers are divisible by 2, we can check it by the modulo function mod(x, 2) == 0. This results in the following function.even(x::Integer) = mod(x, 2) == 0 ? true : falseWe again used type annotation to ensure that the argument is an integer.julia> even(11)\nfalse\n\njulia> even(14)\ntrue","category":"page"},{"location":"lecture_04/functions/#Optional-arguments","page":"Functions","title":"Optional arguments","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is advantageous to use predefined values as function arguments in many cases. Arguments with a default value are typically called optional arguments. Like in Python, optional arguments can be created by assigning a default value to the normal argument. The following function has only one argument, which is optional with the default value world.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"hello(x = \"world\") = println(\"Hello $(x).\")","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Since the argument is optional, we can call the function without it. In such a case, the default value is copied to the argument value. If the function is called with a non-default value, the default value is ignored.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> hello()\nHello world.\n\njulia> hello(\"people\")\nHello people.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"In the same way, it is possible to define multiple optional arguments. It is even possible to define optional arguments that depend on other arguments. However, these arguments must be sorted: mandatory arguments must always precede optional arguments.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"powers(x, y = x*x, z = y*x, v = z*x) = x, y, z, v","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This function has one mandatory and three optional arguments. If only the first argument x is provided, the function returns its first four powers.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> powers(2)\n(2, 4, 8, 16)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Otherwise, the function output depends on the given input arguments. For example, if two arguments x and y are provided, the function returns these two arguments unchanged together with x*y and x^2*y.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> powers(2, 3)\n(2, 3, 6, 12)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The optional arguments can depend only on the previously defined arguments; otherwise, an error occurs.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"f(x = 1, y = x) = (x, y)\ng(x = y, y = 1) = (x, y)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The definition of f is correct, and the definition of g is incorrect since the variable y is not defined when we define x.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> f()\n(1, 1)\n\njulia> g()\nERROR: UndefVarError: `y` not defined\n[...]","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"warning: Exercise:\nWrite a function which computes the value of the following quadratic formq_abc(xy) = ax^2 + bxy + cy^2where a b c x in mathbbR. Use optional arguments to set default values for parametersa = 1 quad b = 2a quad c = 3(a + b)What is the function value at point (4 2) for default parameters? What is the function value at the same point if we use c = 3?","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"details: Solution:\nThe quadratic form can be implemented as follows:q(x, y, a = 1, b = 2*a, c = 3*(a + b)) = a*x^2 + b*x*y + c*y^2Since we want to evaluate q at (4 2) with default parameters, we can use only the first two arguments.julia> q(4, 2)\n68In the second case, we want to evaluate the function at the same point with c = 3. However, it is not possible to set only the last optional argument. We have to set all previous optional arguments too. For the first two optional arguments, we use the default values, i.e., a = 1 and b = 2*a = 2.julia> q(4, 2, 1, 2, 3)\n44","category":"page"},{"location":"lecture_04/functions/#Keyword-arguments","page":"Functions","title":"Keyword arguments","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The previous exercise shows the most significant disadvantage of optional arguments: It is impossible to change only one optional argument unless it is the first one. Luckily, keyword arguments can fix this issue. The syntax is the same as for optional arguments, with one exception: Use a semicolon before the first keyword argument.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"linear(x; a = 1, b = 0) = a*x + b","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This function is a simple linear function, where a represents the slope, and b means the intercept. We can call the function with the mandatory arguments only.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> linear(2)\n2","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"We can also change the value of any keyword argument by assigning a new value to its name.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> linear(2; a = 2)\n4\n\njulia> linear(2; b = 4)\n6\n\njulia> linear(2; a = 2, b = 4)\n8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The semicolon is not mandatory and can be omitted. Moreover, the order of keyword arguments is arbitrary. It is even possible to mix keyword arguments with positional arguments, as shown in the following example.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> linear(b = 4, 2, a = 2) # If you use this, you will burn in hell :D\n8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"However, this is a horrible practice and should never be used.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Julia also provides one nice feature to pass keyword arguments. Imagine that we have variables a and b, and we want to pass them as keyword arguments to the linear function defined above. The standard way is:","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> a, b = 2, 4\n(2, 4)\n\njulia> linear(2; a = a, b = b)\n8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Julia allows a shorter version which can be used if the variable name and the name of the keyword argument are the same. In such a case, we may use the following simplification.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> linear(2; a, b)\n8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"warning: Exercise:\nWrite a probability density function for the Gaussian distributionf_mu sigma(x) = frac1sigma sqrt 2pi  expleft -frac12 left( fracx - musigma right) ^2 rightwhere mu in mathbbR and sigma^2  0. Use keyword arguments to obtain the standardized normal distribution (mu = 0 and sigma = 1). Check that the inputs are correct.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Bonus: verify that this function is a probability density function, i.e., its integral equals 1.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"details: Solution:\nThe probability density function for the Gaussian distribution equals tofunction gauss(x::Real; μ::Real = 0, σ::Real = 1)\n    σ^2 > 0 || error(\"the variance `σ^2` must be positive\")\n    return exp(-1/2 * ((x - μ)/σ)^2)/(σ * sqrt(2*π))\nendWe used type annotation to ensure that all input arguments are real numbers. We also checked whether the standard deviation sigma is positive.julia> gauss(0)\n0.3989422804014327\n\njulia> gauss(0.1; μ = 1, σ = 1)\n0.2660852498987548The integral of the probability density function over all real numbers should equal one. We can check it numerically by discretizing the integral into a finite sum.julia> step = 0.01\n0.01\n\njulia> x = -100:step:100;\n\njulia> sum(gauss, x) * step\n1.0000000000000002\n\njulia> g(x) = gauss(x; μ = -1, σ = 1.4);\n\njulia> sum(g, x) * step\n1.0000000000000007We use the sum function, which can accept a function as the first argument and apply it to each value before summation. The result is the same as sum(gauss.(x)). The difference is that the former, similarly to generators, does not allocate an array. The summation is then multiplied by the stepsize 0.01 to approximate the continuous interval [-100, 100].We can also visualize the probability density functions with the Plots.jl package.using Plots\nfunction gauss(x::Real; μ::Real = 0, σ::Real = 1)\n    σ^2 > 0 || error(\"the variance `σ^2` must be positive\")\n    return exp(-1/2 * ((x - μ)/σ)^2)/(σ * sqrt(2*π))\nendusing Plots\nx = -15:0.1:15\n\nplot(x, gauss.(x); label = \"μ = 0, σ = 1\", linewidth = 2, xlabel = \"x\", ylabel = \"f(x)\");\nplot!(x, gauss.(x; μ = 4, σ = 2); label = \"μ = 4, σ = 2\", linewidth = 2);\nplot!(x, gauss.(x; μ = -3, σ = 2); label = \"μ = -3, σ = 2\", linewidth = 2);\nsavefig(\"gauss.svg\") # hide(Image: )","category":"page"},{"location":"lecture_04/functions/#Variable-number-of-arguments","page":"Functions","title":"Variable number of arguments","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It may be convenient to define a function that accepts any number of arguments. Such functions are traditionally known as varargs functions (abbreviation for variable number of arguments). Julia defines the varargs functions by the triple-dot syntax (splat operator) after the last positional argument.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"nargs(x...) = println(\"Number of arguments: \", length(x))","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The arguments to this function are packed into a tuple x and then the length of this tuple (the number of input arguments) is printed. The input arguments may have different types.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> nargs()\nNumber of arguments: 0\n\njulia> nargs(1, 2, \"a\", :b, [1,2,3])\nNumber of arguments: 5","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The splat operator can also be used to pass multiple arguments to a function. Imagine the situation, where we want to use values of a tuple as arguments to a function. We can do this manually.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> args = (1, 2, 3)\n(1, 2, 3)\n\njulia> nargs(args[1], args[2], args[3])\nNumber of arguments: 3","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The simpler way is to use the splat operator to unpack the tuple of arguments directly to the function.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> nargs(args...)\nNumber of arguments: 3","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This is different from the case where the tuple is not unpacked.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> nargs(args)\nNumber of arguments: 1","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The same syntax can be used for any iterable object, such as ranges or arrays.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> nargs(1:100)\nNumber of arguments: 1\n\njulia> nargs(1:100...)\nNumber of arguments: 100\n\njulia> nargs([1,2,3,4,5])\nNumber of arguments: 1\n\njulia> nargs([1,2,3,4,5]...)\nNumber of arguments: 5","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is also possible to use the same syntax to define a function with an arbitrary number of keyword arguments. Consider the following situation, where we want to define a function that computes the modulo of a number and then rounds the result. To define this function, we can use the combination of the mod and round functions. Since round has many keyword arguments, we want to have an option to use them. In such a case, we can use the following syntax to define the roundmod function.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"roundmod(x, y; kwargs...) = round(mod(x, y); kwargs...)","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"With this simple syntax, we can pass all keyword arguments to the round function without defining them in the roundmod function.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> roundmod(12.529, 5)\n3.0\n\njulia> roundmod(12.529, 5; digits = 2)\n2.53\n\njulia> roundmod(12.529, 5; sigdigits = 2)\n2.5","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"This construction is beneficial whenever there are multiple chained functions, and only the deepest ones need keyword arguments.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"warning: Exercise:\nWrite a function wrapper, that accepts a number and applies one of round, ceil or floor functions based on the keyword argument type. Use the function to solve the following tasks:Round 1252.1518 to the nearest larger integer and convert the resulting value to Int64.\nRound 1252.1518 to the nearest smaller integer and convert the resulting value to Int16.\nRound 1252.1518 to 2 digits after the decimal point.\nRound 1252.1518 to 3 significant digits.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"details: Solution:\nThe one way to define this function is the if-elseif-else statement.function wrapper(x...; type = :round, kwargs...)\n    if type == :ceil\n        return ceil(x...; kwargs...)\n    elseif type == :floor\n        return floor(x...; kwargs...)\n    else\n        return round(x...; kwargs...)\n    end\nendThe type keyword argument is used to determine which function should be used. We use an optional number of arguments as well as an optional number of keyword arguments.julia> x = 1252.1518\n1252.1518\n\njulia> wrapper(Int64, x; type = :ceil)\n1253\n\njulia> wrapper(Int16, x; type = :floor)\n1252\n\njulia> wrapper(x; digits = 2)\n1252.15\n\njulia> wrapper(x; sigdigits = 3)\n1250.0The second way to solve this exercise is to use the fact that it is possible to pass functions as arguments. We can omit the if conditions and directly pass the appropriate function.wrapper_new(x...; type = round, kwargs...) = type(x...; kwargs...)In the function definition, we use the type keyword argument as a function and not as a symbol.julia> wrapper_new(1.123; type = ceil)\n2.0If we use, for example, a Symbol instead of a function, an error will occur.julia> wrapper_new(1.123; type = :ceil)\nERROR: MethodError: objects of type Symbol are not callable\n[...]Finally, we can test the wrapper_new function with the same arguments as for the wrapper function.julia> x = 1252.1518\n1252.1518\n\njulia> wrapper_new(Int64, x; type = ceil)\n1253\n\njulia> wrapper_new(Int16, x; type = floor)\n1252\n\njulia> wrapper_new(x; digits = 2)\n1252.15\n\njulia> wrapper_new(x; sigdigits = 3)\n1250.0","category":"page"},{"location":"lecture_04/functions/#Anonymous-functions","page":"Functions","title":"Anonymous functions","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is also common to use anonymous functions, i.e., functions without a specified name. Anonymous functions can be defined in almost the same way as normal functions.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"h1 = function (x)\n    x^2 + 2x - 1\nend\nh2 = x ->  x^2 + 2x - 1\nnothing # hide","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Those two function declarations create functions with automatically generated names. Then variables h1 and h2 only refer to these functions. The primary use for anonymous functions is passing them to functions that take other functions as arguments such as the plot function.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"using Plots\n\nf(x,a) = (x + a)^2\nplot(-1:0.01:1, x -> f(x,0.5))\n\nsavefig(\"Plots.svg\") # hide","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"(Image: )","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Another example is the map function, which applies a function to each value of an iterable object and returns a new array containing the resulting values.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> map(x -> x^2 + 2x - 1, [1,3,-1])\n3-element Vector{Int64}:\n  2\n 14\n -2","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Julia also provides the reserved word do to create anonymous functions. The following example is slightly more complicated. The do ... end block creates an anonymous function with inputs (x, y), which prints them a returns their sum. This anonymous function is then passed to map as the first argument.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> map([1,3,-1], [2,4,-2]) do x, y\n           println(\"x = $(x), y = $(y)\")\n           return x + y\n       end\nx = 1, y = 2\nx = 3, y = 4\nx = -1, y = -2\n3-element Vector{Int64}:\n  3\n  7\n -3","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"However, it is usually better to create an actual function beforehand.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"function f(x, y)\n    println(\"x = $(x), y = $(y)\")\n    return x + y\nend","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"and then use it as the first argument of the map function.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> map(f, [1,3,-1], [2,4,-2])\nx = 1, y = 2\nx = 3, y = 4\nx = -1, y = -2\n3-element Vector{Int64}:\n  3\n  7\n -3","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"There are many possible uses quite different from the map function, such as managing system state. For example, the following code ensures that the opened file is eventually closed.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"open(\"outfile\", \"w\") do io\n    write(io, data)\nend","category":"page"},{"location":"lecture_04/functions/#Dot-syntax-for-vectorizing-functions","page":"Functions","title":"Dot syntax for vectorizing functions","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"In technical-computing languages, it is common to have vectorized versions of functions. Consider that we have a function f(x). Its vectorized version is a function that applies function f to each element of an array A and returns a new array f(A). Such functions are beneficial in languages, where loops are slow and vectorized versions of functions are written in a low-level language (C, Fortran,...) and are much faster.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"In Julia, vectorized functions are not required for performance, and indeed it is often beneficial to write loops. They can still be convenient. Consider computing the sine function for all elements of [0, π/2, 3π/4]. We can do this by using a loop.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> x = [0, π/2, 3π/4];\n\njulia> A = zeros(length(x));\n\njulia> for (i, xi) in enumerate(x)\n           A[i] = sin(xi)\n       end\n\njulia> A\n3-element Vector{Float64}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Or by a list compherension.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> A = [sin(xi) for xi in x]\n3-element Vector{Float64}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"However, the most convenient way is to use dot syntax for vectorizing functions.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> A = sin.(x)\n3-element Vector{Float64}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is possible to use this syntax for any function to apply it to each element of iterable inputs. This allows us to write simple functions which accept, for example, only numbers as arguments, and then we can easily apply them to arrays.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"plus(x::Real, y::Real) = x + y","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"We defined a function that accepts two real numbers and returns their sum. This function works only for two numbers.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus(1,3)\n4\n\njulia> plus(1.4,2.7)\n4.1","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"If we try to apply this function to arrays, an error occurs.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> x = [1,2,3,4]; # column vector\n\njulia> plus(x, x)\nERROR: MethodError: no method matching plus(::Vector{Int64}, ::Vector{Int64})\n[...]","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"However, we can use the dot syntax for vectorizing functions. The plus function will then be applied to arrays x and y element-wise.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus.(x, x)\n4-element Vector{Int64}:\n 2\n 4\n 6\n 8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"More generally, if we have a function f and use dot syntax f.(args...), then it is equivalent to calling the broadcast function as in broadcast(f, args...).","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> broadcast(plus, x, x)\n4-element Vector{Int64}:\n 2\n 4\n 6\n 8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The dot syntax allows us to operate on multiple arrays even of different shapes. The following example takes a column vector and a row vector, broadcasts them into the matrix (the smallest superset of both vectors) and then performs the sum.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> y = [1 2 3 4]; # row vector\n\njulia> plus.(x, y)\n4×4 Matrix{Int64}:\n 2  3  4  5\n 3  4  5  6\n 4  5  6  7\n 5  6  7  8","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Similarly, it can be used to broadcast a scalar to a vector in the following examples.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> plus.(x, 1)\n4-element Vector{Int64}:\n 2\n 3\n 4\n 5","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"For more information, see the section about broadcasting in the official documentation.","category":"page"},{"location":"lecture_04/functions/#Function-composition-and-piping","page":"Functions","title":"Function composition and piping","text":"","category":"section"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"As in mathematics, functions in Julia can be composed. If we have two functions f mathcalX  rightarrow mathcalY and g mathcalY  rightarrow mathcalZ, then their composition can be mathematically written as","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"(g circ f)(x) = g(f(x)) quad forall x in mathcalX","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"We can compose functions using the function composition operator ∘ (can be typed by \\circ<tab>).","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> (sqrt ∘ +)(3, 6) # equivalent to sqrt(3 + 6)\n3.0","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"It is even possible to compose multiple functions at once.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> (sqrt ∘ abs ∘ sum)([-3, -6, -7])  # equivalent to sqrt(abs(sum([-3, -6, -7])))\n4.0","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Piping or using a pipe is another concept of chain functions. It can be used to pass the output of one function as an input to another one. In Julia, it can be done by the pipe operator |>.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> [-3, -6, -7] |> sum |> abs |> sqrt\n4.0","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"The pipe operator can be combined with broadcasting.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> [-4, 9, -16] .|> abs .|> sqrt\n3-element Vector{Float64}:\n 2.0\n 3.0\n 4.0","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"Or as in the next example, we can use broadcasting in combination with the pipe operator to apply a different function to each element of the given vector.","category":"page"},{"location":"lecture_04/functions/","page":"Functions","title":"Functions","text":"julia> [\"a\", \"list\", \"of\", \"strings\"] .|> [uppercase, reverse, titlecase, length]\n4-element Vector{Any}:\n  \"A\"\n  \"tsil\"\n  \"Of\"\n 7","category":"page"},{"location":"lecture_03/scope/#Soft-local-scope","page":"Soft local scope","title":"Soft local scope","text":"","category":"section"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"The scope of a variable is the region of a code where the variable is visible. There are two main types of scopes in Julia: global and local, and we will discuss it later. In this section, we will only focus on loops.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Every variable created inside a loop is local, i.e., it is possible to use it only inside the loop.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"julia> for i in 1:2\n           t = 1 + i\n           @show t\n       end\nt = 2\nt = 3\n\njulia> t\nERROR: UndefVarError: `t` not defined","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"The variable i in the example above is also local. A similar behaviour happens in nested loops:","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"julia> for j in 1:5\n           for i in 1:2\n               @show i + j\n           end\n           i\n       end\ni + j = 2\ni + j = 3\nERROR: UndefVarError: `i` not defined\n[...]","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Variable j is a local variable defined in the outer loop.  This means that it is visible inside the inner loop and can be used there. On the other hand, variable i is a local variable from the inner loop and cannot be accessed in the outer loop.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"What happens if use variables from the global scope inside loops? In this case, it depends whether the loop is created in interactive (REPL, Jupyter notebook) or non-interactive context (file, eval). In the interactive case (in the REPL in our case), global variables can be accessed and modified in local scopes without any restrictions.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"julia> s = 0\n0\n\njulia> for i = 1:10\n           t = 1 + i # new local variable t\n           s = t # assign a new value to the global variable\n       end\n\njulia> s\n11","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"In this case, if we want to assign a value to a variable, there are two possibilities:","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Variable t: there is no global variable with the same name. A new local variable is created.\nVariable s: there is a global variable with the same name. A new value is assigned to the global variable.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"However, in the non-interactive case, the variables behave differently. In the following example, we create a Julia code as a string and then evaluate it using the include_string function.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"julia> code = \"\"\"\n       s = 0\n       for i = 1:10\n           t = 1 + i # new local variable t\n           s = t # new local variable s and warning\n       end\n       s\n       \"\"\";\n\njulia> include_string(Main, code)\n┌ Warning: Assignment to `s` in soft scope is ambiguous because a global variable by the same name exists: `s` will be treated as a new local. Disambiguate by using `local s` to suppress this warning or `global s` to assign to the existing global variable.\n└ @ string:4\n0","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"In this case, if we want to assign a value to a variable inside a loop, there are two possibilities:","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Variable t: there is no global variable with the same name. A new local variable is created.\nVariable s: there is a global variable with the same name. The assignment in the soft scope is ambiguous, and a new local variable is created.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"In our example, the variable s is defined before the loop as global. In the loop, we get a warning that the assignment to s in soft scope is ambiguous, and a new local variable s is created instead. The behaviour described above can be changed by specifying that variable s is local.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"code_local = \"\"\"\ns = 0\nfor i = 1:10\n    t = 1 + i # new local variable t\n    local s = t # assigning a new value to the local variable\nend\ns\n\"\"\"","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Another option is to specify that the variable s is global.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"code_global = \"\"\"\ns = 0\nfor i = 1:10\n    t = 1 + i # new local variable t\n    global s = t # assigning a new value to the global variable\nend\ns\n\"\"\"","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"When we evaluate the strings, no warning is produced.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"julia> include_string(Main, code_global)\n11\n\njulia> include_string(Main, code_local)\n0","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"There are two obvious questions:","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Why does it not work like the REPL everywhere?\nWhy does it not work like in files everywhere? Why is the warning not skipped?","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"Since the behaviour from REPL approximates the behaviour inside a function body, it has the advantage of being intuitive and convenient. In particular, it makes it easy to move code back and forth between a function body and the REPL when trying to debug a function. However, it may easily lead to confusion and errors, especially if the code is long or split into multiple files. The intent of the following code is obvious: we want to modify the existing global variable s inside the loop.","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"s = 0\nfor i = 1:10\n    s += i\nend","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"However, real code is usually more complicated. Consider the following example:","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"x = 200\n\n# much later, maybe in a different file\n\nfor i = 1:10\n    x = 1000\n    println(x)\nend\n\n# much later, maybe in yet another file\n\ny = x + 234","category":"page"},{"location":"lecture_03/scope/","page":"Soft local scope","title":"Soft local scope","text":"It is not clear what should happen here. Should the variable x inside the loop be considered local or global? If it is local inside the loop, then the variable y will be 434. On the other hand, if it is global inside the loop, then we assign a new value to it, and the variable y will be 1234. We can accidentally change a variable value and get incorrect results because we use the same variable name multiple times in different scopes.  In this case, it is complicated to find why the results are wrong since there is no error in the code. Julia prints the warning about the ambiguity in such cases to help users. For more information, see the official documentation.","category":"page"},{"location":"lecture_04/exceptions/#Exception-handling","page":"Exception handling","title":"Exception handling","text":"","category":"section"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"Unexpected behaviour may often occur during running code, which may lead to the situation that some function cannot return a reasonable value. Such behaviour should be handled by either terminating the program with a proper diagnostic error message or allowing that code to take appropriate action.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"In the following example, we define a factorial function in the same way as we did in the Short-circuit evaluation section.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"function fact(n)\n    isinteger(n) && n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"We use the error function, which throws the ErrorException if the input argument does not meet the given conditions. This function works quite well and returns a reasonable error message for incorrect inputs.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"julia> fact(1.4)\nERROR: argument must be non-negative integer\n[...]\n\njulia> fact(-5)\nERROR: argument must be non-negative integer\n[...]","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"However, it is better to use error messages as descriptive as possible. In the case above, the error message can also include the argument value. Julia provides several predefined types of exceptions that can be used to create more descriptive error messages. In our example, we want to check whether the argument is a non-negative integer. The more specific DomainError can do this.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"function fact(n)\n    isinteger(n) && n >= 0 || throw(DomainError(n, \"argument must be non-negative integer\"))\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"We must use the throw function because the DomainError(x, msg) function only creates an instance of the type DomainError, but it does not raise an error.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"julia> fact(1.4)\nERROR: DomainError with 1.4:\nargument must be non-negative integer\n[...]\n\njulia> fact(-5)\nERROR: DomainError with -5:\nargument must be non-negative integer\n[...]","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"The error message now contains a short description, the input value, and the type of exception. Now imagine that due to an error, the fact function is used to calculate the factorial from a string.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"julia> fact(\"a\")\nERROR: MethodError: no method matching isinteger(::String)\nClosest candidates are:\n  isinteger(::BigFloat) at mpfr.jl:859\n  isinteger(::Missing) at missing.jl:100\n  isinteger(::Integer) at number.jl:20\n  ...\nStacktrace:\n [1] fact(::String) at ./REPL[1]:2\n [2] top-level scope at REPL[2]:1","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"In this case, the MethodError is raised for the isinteger function. Since the DomainError function is not even called, the error says nothing about the fact function. We can track that the error occurs when calling the fact function using the Stacktrace section located under the error message. The Stacktrace provides us with an ordered list of function calls (starting from the last one) that preceded the error. In this case, the last function call before the error is fact(::String). It tells us that the error occurs in the function fact with a string as the input argument. In this particular case, it makes sense to define factorial function only for real numbers. This can be done by entering the input type in the function declaration.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"function fact_new(n::Real)\n    isinteger(n) && n >= 0 || throw(DomainError(n, \"argument must be non-negative integer\"))\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"This function declaration will only work for subtypes of Real. Otherwise, the MethodError will occur.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"julia> fact_new(\"aaa\")\nERROR: MethodError: no method matching fact_new(::String)\n[...]","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"The MethodError provides two important pieces of information. First, it states that the fact_new function is not defined for arguments of type String. Second, it shows the list of methods closest to the one we called. In this case, the fact_new function has only one method, which works for any subtype of Real. This can be verified by using the methods function.","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"julia> methods(fact_new)\n# 1 method for generic function \"fact_new\" from Main:\n [1] fact_new(n::Real)\n     @ none:1","category":"page"},{"location":"lecture_04/exceptions/","page":"Exception handling","title":"Exception handling","text":"A more precise description and a list of all predefined exception types can be found in the official documentation.","category":"page"},{"location":"lecture_03/loops/#Loops","page":"Loops and iterators","title":"Loops","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"While if conditions are evaluated only once, loops are assessed multiple times.","category":"page"},{"location":"lecture_03/loops/#for-and-while-loops","page":"Loops and iterators","title":"for and while loops","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"As in other languages, Julia supports two basic constructs for repeated evaluation: while andfor loops. Loops are useful to repeat the same computation multiple times with different values. A typical example is performing operations on array elements.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The while loop evaluates the condition, and as long it remains true, it evaluates the body of the while loop. If the condition is false, the while loop is terminated. If the condition is false before the first iteration, the whole while loop is skipped.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> i = 1\n1\n\njulia> while i <= 5\n           @show i\n           i += 1\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The @show macro in this example prints the results of an expression. It can also be used to print multiple variables at once.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> a, b, c = 1, \"hello\", :world;\n\njulia> @show (a, b, c);\n(a, b, c) = (1, \"hello\", :world)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The for loops are created similarly to Matlab. The following example iterates over all integers from 1 to 5, and in each iteration, we use the @show macro to print the current value of the variable i.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:5\n           @show i\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"info: An alternative notation for <code>for</code> loops:\nThere are two alternative notations for the for loop. It is possible to use the = or ∈ symbol instead of the in keyword.julia> for i = 1:5\n          @show i\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5However, it is better to use the in keyword to improve code readability. Regardless of which notation is used, it is essential to be consistent and use the same notation in all for loops.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"In Julia (similarly to Python), it is possible to loop not only over ranges but over any iterable object such as arrays or tuples. This is advantageous because it allows getting elements of iterable objects directly without using indices.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> persons = [\"Alice\", \"Bob\", \"Carla\", \"Daniel\"];\n\njulia> for name in persons\n           println(\"Hi, my name is $name.\")\n       end\nHi, my name is Alice.\nHi, my name is Bob.\nHi, my name is Carla.\nHi, my name is Daniel.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"It is also possible to iterate over other data structures such as dictionaries. In such a case, we get a tuple of the key and the corresponding value in each iteration.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> persons = Dict(\"Alice\" => 10, \"Bob\" => 23, \"Carla\" => 14, \"Daniel\" => 34);\n\njulia> for (name, age) in persons\n           println(\"Hi, my name is $name and I am $age old.\")\n       end\nHi, my name is Carla and I am 14 old.\nHi, my name is Alice and I am 10 old.\nHi, my name is Daniel and I am 34 old.\nHi, my name is Bob and I am 23 old.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nUse for or while loop to print all integers between 1 and 100 which can be divided by both 3 and 7.Hint: use the mod function.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nFirst, we need to check if a given integer is divisible by both 3 and 7. This can be performed using the mod function in combination with the if-else statement as follows:julia> i = 21\n21\n\njulia> if mod(i, 3) == 0 && mod(i, 7) == 0\n          println(\"$(i) is divisible by 3 and 7\")\n       end\n21 is divisible by 3 and 7or using the short-circuit evaluationjulia> i = 21\n21\n\njulia> mod(i, 3) == mod(i, 7) == 0 && println(\"$(i) is divisible by 3 and 7\")\n21 is divisible by 3 and 7When we know how to check the conditions, it is easy to write a for loop to iterate over integers from 1 to 100.julia> for i in 1:100\n           mod(i, 3) == mod(i, 7) == 0 && @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84A while loop can be created in a similar wayjulia> i = 0;\n\njulia> while i <= 100\n           i += 1\n           mod(i, 3) == mod(i, 7) == 0 && @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84The for loop should be used here because the range is known before-hand and unlike the while loop, it does not require to initialize i.","category":"page"},{"location":"lecture_03/loops/#break-and-continue","page":"Loops and iterators","title":"break and continue","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Sometimes it is useful to stop the loop when some condition is satisfied. This is done by the break keyword. In the following example, the loop iterates over the range from 1 to 10 and breaks when i == 4, i.e., only the first three numbers are printed.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:10\n           i == 4 && break\n           @show i\n       end\ni = 1\ni = 2\ni = 3","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Another useful feature is to skip elements using the continue keyword. The following code prints all even numbers from 1 to 10.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:10\n           mod(i, 2) == 0 || continue\n           @show i\n       end\ni = 2\ni = 4\ni = 6\ni = 8\ni = 10","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The code after the continue keyword is not evaluated.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nRewrite the code from the exercise above. Use a combination of the while loop and the keyword continue to print all integers between 1 and 100 divisible by both 3 and 7. In the declaration of the while loop use the true value instead of a condition. Use the break keyword and a proper condition to terminate the loop.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nThe true value creates an infinite loop, i.e., it is necessary to end the loop with the break keyword. Because the variable i represents an integer and we want to iterate over integers between 1 and 100, the correct termination condition is i > 100.julia> i = 0;\n\njulia> while true\n           i += 1\n           i > 100 && break\n           mod(i, 3) == mod(i, 7) == 0 || continue\n           @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84We used the short-circuit evaluation to break the loop. To check that the integer is divisible, we use the same condition as before. However, we must use || instead of && because we want to use the continue keyword.","category":"page"},{"location":"lecture_03/loops/#Nested-loops","page":"Loops and iterators","title":"Nested loops","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"In Julia, nested loops can be created in a similar way as in other languages.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:3\n           for j in i:3\n               @show (i, j)\n           end\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The range of the inner loop depends on the variable i from the outer loop. This style of writing nested loops is typical in other languages. Julia allows for an additional shorter syntax:","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:3, j in i:3\n           @show (i, j)\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Even though the output is the same, this syntax is not equivalent to the previous one. The main difference is when using the break keyword. If we use the traditional syntax and the break keyword inside the inner loop, it breaks only the inner loop. On the other hand, if we use the shorter syntax, the break keyword breaks both loops.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for i in 1:3\n           for j in i:10\n               j > 3 && break\n               @show (i, j)\n           end\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)\n\njulia> for i in 1:3, j in i:10\n           j > 3 && break\n           @show (i, j)\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"There are other limitations of the shorter syntax, such as the impossibility to perform any operation outside the inner loop. Nevertheless, it is a useful syntax in many cases.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nUse nested loops to create a matrix with elements given by the formulaA_i j = frac12expleftfrac12 (x_i^2 - y_j^2) right quad i in 1 2 3 quad j in  1 2 3 4where x in 04 23 46 and y in 14 -31 24 52.Bonus: try to create the same matrix in a more effective way.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nFirst, we have to define vectors x and y, and an empty array of the proper size and element type to use in nested loops.x = [0.4, 2.3, 4.6]\ny = [1.4, -3.1, 2.4, 5.2]\nA = zeros(Float64, length(x), length(y))The element type specification can be omitted since the default value type is Float64. Now we have to use proper indices to fill A. In this case, we use the indices 1:length(x) for x and 1:length(y) for y.julia> for i in 1:length(x), j in 1:length(y)\n           A[i, j] = exp((x[i]^2 - y[j]^2)/2)/2\n       end\n\njulia> A\n3×4 Matrix{Float64}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329There are more efficient ways to create this array. The one way is to use broadcasting.julia> y_row = y'\n1×4 adjoint(::Vector{Float64}) with eltype Float64:\n 1.4  -3.1  2.4  5.2\n\njulia> A = @. exp((x^2 - y_row^2)/2)/2\n3×4 Matrix{Float64}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329We use the @ . macro to perform all operations elementwise. Since x is a column vector and y_row is a row vector, x - y_row uses broadcasting to create a matrix.The third way to create this matrix is to use list comprehension. Due to its importance, we dedicate a whole section to it.","category":"page"},{"location":"lecture_03/loops/#List-comprehension","page":"Loops and iterators","title":"List comprehension","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"As we mentioned in the last exercise, one way to create an array with prescribed elements is to use list comprehension. Comprehensions provide a general and powerful way to construct arrays, and the syntax is similar to the set construction notation from mathematics.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"A = [f(x, y, ...) for x in X, y in Y, ...]","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The previous example reads: The function f will be evaluated for each combination of elements of iterable objects  X, Y, etc. The result will be an n-dimensional array of size (length(X), length(Y), ...). Returning to the previous exercise, we can create the required array as follows:","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> X = [0.4, 2.3, 4.6];\n\njulia> Y = [1.4, -3.1, 2.4, 5.2];\n\njulia> A = [exp((x^2 - y^2)/2)/2 for x in X, y in Y]\n3×4 Matrix{Float64}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"The resulting array type depends on the types of the computed elements. A type can be prepended to the comprehension to control the type explicitly.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> A = Float32[exp((x^2 - y^2)/2)/2 for x in X, y in Y]\n3×4 Matrix{Float32}:\n    0.203285    0.00443536     0.030405  7.27867f-7\n    2.64284     0.0576626      0.395285  9.46275f-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"A handy feature is the possibility to filter values when creating list comprehensions by the if keyword. In such a case, the result will always be a vector. In the next example, we create a vector of tuples (x, y, x + y), where x + y < 5.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> [(x, y, x + y)  for x in 1:10, y in 1:10 if x + y < 5]\n6-element Vector{Tuple{Int64, Int64, Int64}}:\n (1, 1, 2)\n (2, 1, 3)\n (3, 1, 4)\n (1, 2, 3)\n (2, 2, 4)\n (1, 3, 4)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nUse the list comprehension to create a vector of all integers from 1 to 100 divisible by 3 and 7 simultaneously. What is the sum of all these integers?","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nWe can use list comprehension with the same condition that we used in the exercise in the first section.julia> v = [i for i in 1:100 if mod(i, 3) == mod(i, 7) == 0]\n4-element Vector{Int64}:\n 21\n 42\n 63\n 84Then we can use the sum function to get their sum.julia> sum(v)\n210","category":"page"},{"location":"lecture_03/loops/#Generator-expressions","page":"Loops and iterators","title":"Generator expressions","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"List comprehensions can also be written without the enclosing square brackets. This produces an object known as a generator. When iterating over a generator, the values are generated on demand instead of pre-allocating an array. For example, the following expression sums a series without allocating the full array in memory.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> gen = (1/n^2 for n in 1:1000);\n\njulia> sum(gen)\n1.6439345666815615\n\njulia> sum(1/n^2 for n in 1:1000)\n1.6439345666815615","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"It is possible to write nested list comprehensions and generators. The syntax is similar to writing nested loops.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> [(i,j) for i in 1:3, j in 1:2]\n3×2 Matrix{Tuple{Int64, Int64}}:\n (1, 1)  (1, 2)\n (2, 1)  (2, 2)\n (3, 1)  (3, 2)\n\njulia> gen = ((i,j) for i in 1:3, j in 1:2);\n\njulia> collect(gen)\n3×2 Matrix{Tuple{Int64, Int64}}:\n (1, 1)  (1, 2)\n (2, 1)  (2, 2)\n (3, 1)  (3, 2)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Iterables may refer to outer loop variables. However, in such a case, it is necessary to use the for keyword before each iterable statement, and the result will be a vector.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> gen = ((i,j) for i in 1:3 for j in 1:i);\n\njulia> collect(gen)\n6-element Vector{Tuple{Int64, Int64}}:\n (1, 1)\n (2, 1)\n (2, 2)\n (3, 1)\n (3, 2)\n (3, 3)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Generated values can also be filtered using the if keyword.  Similarly to list comprehensions, the result in such a case is a vector.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> gen = ((i,j) for i in 1:3 for j in 1:i if i+j == 4);\n\njulia> collect(gen)\n2-element Vector{Tuple{Int64, Int64}}:\n (2, 2)\n (3, 1)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nUse a generator to sum the square of all integers from 1 to 100, which are divisible by 3 and 7 simultaneously.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nThere are two ways how to solve this exercise. The first one creates a generator and then uses the sum function.julia> gen = (i^2 for i in 1:100 if mod(i, 3) == mod(i, 7) == 0);\n\njulia> typeof(gen)\nBase.Generator{Base.Iterators.Filter{var\"#2#4\",UnitRange{Int64}},var\"#1#3\"}\n\njulia> sum(gen)\n13230It is worth noting that gen is a Generator object and not an array. The second way uses the shorter syntax that allows us to write a generator inside the sum function.julia> sum(i^2 for i in 1:100 if mod(i, 3) == mod(i, 7) == 0)\n13230","category":"page"},{"location":"lecture_03/loops/#Iterators","page":"Loops and iterators","title":"Iterators","text":"","category":"section"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Many structures are iterable in Julia. However, it is not sufficient to iterate only over elements of a structure in many cases. Consider the situation when we have the following array, and we want to iterate over all its elements and print all indices and the corresponding values.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> A = [2.3 4.5; 6.7 7.1]\n2×2 Matrix{Float64}:\n 2.3  4.5\n 6.7  7.1\n\njulia> for i in 1:length(A)\n           println(\"i = $(i) and A[i] = $(A[i])\")\n       end\ni = 1 and A[i] = 2.3\ni = 2 and A[i] = 6.7\ni = 3 and A[i] = 4.5\ni = 4 and A[i] = 7.1","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"There is an even more straightforward way. We can do the same using the enumerate function that returns an iterator (an iterable object that can be iterated in for loops). It produces couples of the form (i, x[i]).","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for (i, val) in enumerate(A)\n           println(\"i = $(i) and A[i] = $(val)\")\n       end\ni = 1 and A[i] = 2.3\ni = 2 and A[i] = 6.7\ni = 3 and A[i] = 4.5\ni = 4 and A[i] = 7.1","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Other beneficial functions return iterators. For example, the eachcol function returns an iterator that iterates over matrix columns.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for col in eachcol(A)\n           println(\"col = $(col)\")\n       end\ncol = [2.3, 6.7]\ncol = [4.5, 7.1]","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"Similarly, eachrow returns an iterator that iterates over matrix rows. Another convenient function is the zip function, which zips together multiple iterable objects and iterates over them simultaneously.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for (i, j, k) in zip([1, 4, 2, 5], 2:12, (:a, :b, :c))\n           @show (i, j, k)\n       end\n(i, j, k) = (1, 2, :a)\n(i, j, k) = (4, 3, :b)\n(i, j, k) = (2, 4, :c)","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"In this case, the iterable objects were of different lengths. The iterator returned by the zip function will have the same length as the shortest of its inputs. It is also possible to combine these handy functions.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"julia> for (i, vals) in enumerate(zip([1, 4, 2, 5], 2:12, (:a, :b, :c)))\n           @show (i, vals)\n       end\n(i, vals) = (1, (1, 2, :a))\n(i, vals) = (2, (4, 3, :b))\n(i, vals) = (3, (2, 4, :c))","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"warning: Exercise:\nCreate a matrix with elements given by the following formulaA_i j = frac12expleftfrac12 (x_i^2 - y_j^2) right quad i in 1 2 3  j in  1 2 3 4where x in 04 23 46, y in 14 -31 24 52. Compute the sum of all elements in each row and print the following message:Sum of all elements in a row i is i_sumwhere i represents row's number and i_sum the sum of all elements in this row. Do the same for each column and print the following message:Sum of all elements in a column i is i_sumHint: use iterators eachcol and eachrow.","category":"page"},{"location":"lecture_03/loops/","page":"Loops and iterators","title":"Loops and iterators","text":"details: Solution:\nFirst, we have to generate the matrix A. It can be done using list comprehension as follows:X = [0.4, 2.3, 4.6]\nY = [1.4, -3.1, 2.4, 5.2]\nA = [exp((x^2 - y^2)/2)/2 for x in X, y in Y]To compute the sum of each row and print the appropriate message, we use the combination of enumerate and eachrow functions.julia> for (i, row) in enumerate(eachrow(A))\n           println(\"Sum of all elements in a row $(i) is $(sum(row))\")\n       end\nSum of all elements in a row 1 is 0.2381259460051036\nSum of all elements in a row 2 is 3.0957940729669864\nSum of all elements in a row 3 is 8647.66342895583Similarly, to compute the sum of each column and print the appropriate message, we use the combination of enumerate and eachcol functions.julia> for (i, row) in enumerate(eachcol(A))\n           println(\"Sum of all elements in a column $(i) is $(sum(row))\")\n       end\nSum of all elements in a column 1 is 7385.236904243371\nSum of all elements in a column 2 is 161.13431527671185\nSum of all elements in a column 3 is 1104.5996863997295\nSum of all elements in a column 4 is 0.026443054989612996","category":"page"},{"location":"lecture_08/gradients/#Gradients","page":"Gradients","title":"Gradients","text":"","category":"section"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"To minimize a function, it is useful to use derivatives. For a function fmathbbRto mathbbR, its gradient is defined by","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"f(x) = lim_hto 0fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"For a mapping  fmathbbR^nto mathbbR^m, its Jacobian is a matrix nabla f(x) of size mtimes n of partial derivatives","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(nabla f(x))_ij = fracpartial f_ipartial x_j(x) = lim_hto 0fracf_i(x_1dotsx_j-1x_j+hx_j+1dotsx_n)-f(x_1dotsx_n)h","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"The formal definition is more complicated, but this one is better for visualization.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"info: Confusion:\nGradient nabla f(x) of a function fmathbbR^ntomathbbR should be of size  1times n but it is commonly considered as ntimes 1.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"Functions are usually complicated, and this definition cannot be used to compute the gradient. Instead, the objective function f is rewritten as a composition of simple functions, these simple functions are differentiated, and the chain rule is applied to get nabla f.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"todo: Theorem: Chain\nConsider two differentiable functions fmathbbR^mtomathbbR^s and gmathbbR^ntomathbbR^m. Then its composition h(x) = f(g(x)) is differentiable with Jacobiannabla h(x) = nabla f(g(x))nabla g(x)","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"The derivative is the direction of the steepest ascent. The following figure shows the vector field of derivatives, where each arrow shows the direction and size of derivatives at the points in the domain. Since a function has the same function values along its contour lines and since derivate is the direction of the steepest ascent, derivatives are perpendicular to contour lines. The figure also shows that local minima and local maxima have zero derivatives.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(Image: )","category":"page"},{"location":"lecture_08/gradients/#Visualization-of-gradients","page":"Gradients","title":"Visualization of gradients","text":"","category":"section"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"For the numerical experiments, we will consider the following function","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"f(x) = sin(x_1 + x_2) + cos(x_1)^2","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"on domain -31times -21.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"warning: Exercise: Contour plot\nWrite a function g(x) which computes the derivative of f at a point  x. Plot the contours of f on the domain. Hint: Use the keyword argument color = :jet for better visualization.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"details: Solution:\nFunction f(x) takes as an input a vector of two dimensions and returns a scalar. Therefore, the gradient is a two-dimensional vector, which we create by [?; ?]. Its components are computed from the chain rule.f(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nnothing # hideSince sometimes it is better to use notation f(x) and sometimes f(x_1x_2), we overload the function f.f(x1,x2) = f([x1;x2])\n\nf([0; 0])\nf(0, 0)\n\nnothing # hideprintln(f([0; 0])) # hide\nprintln(f(0, 0)) # hideWe use the Plots package for plotting. We create the discretization xs and ys of both axis and then call the contourf function.using Plots\n\nxs = range(-3, 1, length = 40)\nys = range(-2, 1, length = 40)\n\ncontourf(xs, ys, f, color = :jet)\n\nsavefig(\"grad1.svg\") # hide","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(Image: )","category":"page"},{"location":"lecture_08/gradients/#comp-grad","page":"Gradients","title":"Computation of gradients","text":"","category":"section"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"The simplest way to compute the gradients is to use a finite difference approximation. It replaces the limit in","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"f(x) = lim_hto 0fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"by fixing some h and approximates the gradient by","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"f(x) approx fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"warning: Exercise: Finite difference approximation\nWrite a function finite_difference which computes the approximation of f(x) by finite differences. The inputs are a function fmathbb Rtomathbb R and a point xinmathbbR. It should have an optional input hinmathbbR, for which you need to choose a reasonable value.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"details: Solution:\nIt is sufficient to rewrite the formula above. Since the argument h is optional, it should be after ;. Its good default value is anything between 10^-10 and 10^-5. We specify x::Real as a sanity check for the case when a function of more variables is passed as input.finite_difference(f, x::Real; h=1e-8) = (f(x+h) - f(x)) / h\nnothing # hide","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"This way of computing the gradient has two disadvantages:","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"It is slow. For a function of n variables, we need to evaluate the function at least n+1 times to get the whole gradient.\nIt is not precise, as the following example shows.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"warning: Exercise: Finite difference approximation\nFix a point x=(-2-1). For a proper discretization of hin 10^-15 10^-1 compute the finite difference approximation of the partial derivative of f with respect to the second variable.Plot the dependence of this approximation on h. Add the true derivative computed from g.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"details: Solution:\nTo compute the partial derivative with respect to the second argument, we need to fix the first argument and vary only the second one. We create an anonymous function y -> f(-2, y) and another function fin_diff which for an input h computes the finite difference.x = [-2; -1]\nfin_diff(h) = finite_difference(y -> f(x[1], y), x[2]; h=h)\n\nnothing # hideThe true gradient is computed by g(x). It returns a vector of length two. Since we need only the partial derivative with respect to the second component, we select it by adding  [2].true_grad = g(x)[2]\n\nnothing # hideNow we create the discretization of h in hs. When the orders of magnitude are so different, the logarithmic scale should be used. For this reason, we create a uniform discretization of the interval -15-1 and then use it as an exponent.hs = 10. .^ (-15:0.01:-1)\n\nnothing # hideThere are many possibilities of how to create the plot. Probably the simplest one is to plot the function fin_diff and then add the true gradient (which does not depend on h and is, therefore, a horizontal line) via hline!.plot(hs, fin_diff,\n    xlabel = \"h\",\n    ylabel = \"Partial gradient wrt y\",\n    label = [\"Approximation\" \"True gradient\"],\n    xscale = :log10,\n)\n\nhline!([true_grad]; label =  \"True gradient\")\n\nsavefig(\"grad2.svg\") # hide","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(Image: )","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"The approximation is good if h is not too small or too large. It cannot be too large because the definition of the gradient considers the limit to zero. It cannot be too small because the numerical errors kick in. This is connected with machine precision, which is most vulnerable to subtracting two numbers of almost the same value. A simple example shows","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(x + h)^2 - x^2 = 2xh + h^2","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"but the numerical implementation","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"x = 1;\nh = 1e-13;\n(x+h)^2 - x^2\n2*x*h + h^2","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"gives an error already at the fourth valid digit. It is important to realize how numbers are stored. Julia uses the IEEE 754 standard. For example, Float64 uses 64 bits to store the number, from which 1 bit represents the sign, 11 bits the exponent and 52 bits the significand precision. As 2^52approx 10^16, numbers are stored with a 16-digit precision. Since the exponent is stored separately, it is possible to represent numbers smaller than the machine precision, such as 10^-25. To prevent numerical errors, all computations are done in higher precision, and the resulting variable is rounded to the type precision.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"Finally, we show how the gradients look like.","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"warning: Exercise: Direction of gradients\nReproduce the previous figure with the vector field of derivatives. Therefore, plot the contours of f and its gradients at a grid of its domain -31times -21.Hint: when a plot is updated in a loop, it needs to be saved to a variable plt and then displayed via display(plt).","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"details: Solution:\nFirst we reduce the number of grid elements and plot the contour plot.xs = range(-3, 1, length = 20)\nys = range(-2, 1, length = 20)\n\nplt = contourf(xs, ys, f;\n    xlims = (minimum(xs), maximum(xs)),\n    ylims = (minimum(ys), maximum(ys)),\n    color = :jet\n)We use the same functions as before. Since we want to add a line, we use plot! instead of plot. We specify its parameters in an optional argument line = (:arrow, 2, :black). These parameters add the pointed arrow, the thickness and the colour of the line. Since we do not want any legend, we use label = \"\". Finally, since we want to create a grid, we make a loop over xs and ys.α = 0.25\nfor x1 in xs, x2 in ys\n    x = [x1; x2]\n    x_grad = [x x.+α.*g(x)]\n\n    plot!(x_grad[1, :], x_grad[2, :];\n        line = (:arrow, 2, :black),\n        label = \"\",\n    )\nend\ndisplay(plt)\n\nsavefig(\"grad3.svg\") # hide","category":"page"},{"location":"lecture_08/gradients/","page":"Gradients","title":"Gradients","text":"(Image: )","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"function plot_histogram(xs, f; kwargs...)\n    plt = histogram(xs;\n        label=\"Sampled density\",\n        xlabel = \"x\",\n        ylabel = \"pdf(x)\",\n        nbins = 85,\n        normalize = :pdf,\n        opacity = 0.5,\n        kwargs...\n    )\n\n    plot!(plt, range(minimum(xs), maximum(xs); length=100), f;\n        label=\"True density\",\n        line=(4,:black),\n    )\n\n    return plt\nend","category":"page"},{"location":"lecture_12/glm/#statistics","page":"Linear regression revisited","title":"Linear regression revisited","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"This section revisits the linear regression. The classical statistical approach uses derives the same formulation for linear regression as the optimization approach. Besides point estimates for parameters, it also computes their confidence intervals and can test whether some parameters can be omitted from the model. We will start with hypothesis testing and then continue with regression.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Julia provides lots of statistical packages. They are summarized at the JuliaStats webpage. This section will give a brief introduction to many of them.","category":"page"},{"location":"lecture_12/glm/#Theory-of-hypothesis-testing","page":"Linear regression revisited","title":"Theory of hypothesis testing","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Hypothesis testing verifies whether data satisfy a given null hypothesis H_0. Most of the tests need some assumptions about the data, such as normality. Under the validity of the null hypothesis, the test derives that a transformation of the data follows some distribution. Then it constructs a confidence interval of this distribution and checks whether the transformed variable lies in this confidence interval. If it lies outside of it, the test rejects the null hypothesis. In the opposite case, it fails to reject the null hypothesis. The latter is different from confirming the null hypothesis. Hypothesis testing is like a grumpy professor during exams. He never acknowledges that a student knows the topic sufficiently, but he is often clear that the student does not know it.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"An example is the one-sided Student's t-test that verifies that a one-dimensional dataset has mean mu. It can be generalized to compare the mean (performance) of two datasets. Under some assumptions, it derives that","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"t = sqrtnfrachat mu - muhatsigma","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"follows the Student's distribution with n-1 degrees of freedom. Here, n is the number of datapoints. Their mean is hat mu and their standard deviation hat sigma. Instead of computing the confidence interval, the usual way is to define the p-value","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"p = 2minmathbb P(Tle t mid H_0) mathbb P(Tge tmid H_0)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"If the p-value is smaller than a given threshold, usually 5, the null hypothesis is rejected. In the opposite case, it is not rejected. The p-value is a measure of the probability that an observed difference could have occurred just by random chance.","category":"page"},{"location":"lecture_12/glm/#Hypothesis-testing","page":"Linear regression revisited","title":"Hypothesis testing","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"We first randomly generate data from the normal distribution with zero mean.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"using Random\nusing Statistics\nusing LinearAlgebra\nusing Plots\n\nRandom.seed!(666)\n\nn = 1000\nxs = randn(n)\n\nnothing # hide","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The following exercise performs the t-test to check whether the data come from a distribution with zero mean.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"warning: Exercise:\nUse the t-test to verify whether the samples were generated from a distribution with zero mean.Hints:The Student's distribution is invoked by TDist().\nThe probability mathbb P(Tle t) equals to the distribution function F(t), which can be called by cdf.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"details: Solution:\nWe compute the statistic t, then define the Student's distribution with n-1 degrees of freedom, evaluate the distribution function at t and finally compute the p-value.using Distributions\n\nt = mean(xs) / std(xs) * sqrt(n)\n\nprob = cdf(TDist(n-1), t)\np = 2*min(prob, 1-prob)The p-value is significantly larger than 5. Therefore, we cannot reject the zero hypothesis, which is fortunate because the data were generated from the normal distribution with zero mean.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Even though the computation of the p-value is simple, we can use the HypothesisTests package. When we run the test, it gives us the same results as we computed.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"using HypothesisTests\n\nOneSampleTTest(xs)","category":"page"},{"location":"lecture_12/glm/#Theory-of-generalized-linear-models","page":"Linear regression revisited","title":"Theory of generalized linear models","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The statistical approach to linear regression is different from the one from machine learning. It also assumes a linear prediction function:","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornamepredict(wx) = w^top x","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Then it considers some invertible link function gmathbb Rto mathbb R and assumes that y conditioned on x follows an apriori specified distribution with density f. The parameters of this distribution are unknown, but the distribution should satisfy the conditional expectation E(ymid x) = g^-1(w^top x). The goal is to find the weights w by the maximum likelihood estimate. This technique maximizes the likelihood function:","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornamemaximizeqquad prod_i=1^n f(y_i)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Since the density is the derivative of the distribution function, the term f(y_i) describes the \"probability\" of y_i under density f. If y_i are independent, then the product is the joint probability for all samples. Therefore, maximizing the likelihood function amounts to finding the parameters of the apriori specified distribution such that the observed samples y_i have the highest probability. Since these distributions are usually taken from the exponential family, the log-likelihood","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornamemaximizeqquad sum_i=1^n log f(y_i)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"is often maximized. Since the logarithm is an increasing function, these two formulas are equivalent.","category":"page"},{"location":"lecture_12/glm/#Case-1:-Linear-regression","page":"Linear regression revisited","title":"Case 1: Linear regression","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The first case considers g(z)=z to be the identity function and ymid x with the normal distribution N(mu_i sigma^2). Then","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"w^top x_i = g^-1(w^top x_i) = mathbb E(y_i mid x_i) = mu_i","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"and, therefore, we need the solve the following optimization problem:","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornamemaximize_wqquad sum_i=1^n log left(frac1sqrt2pisigma^2expleft(frac-(y_i - w^top x_i)^22sigma^2right)right)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Since we maximize with respect to w, most terms behave like constants, and this optimization problem is equivalent to","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornameminimize_wqquad sum_i=1^n (y_i - w^top x_i)^2","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"This is precisely linear regression as derived in the previous lectures.","category":"page"},{"location":"lecture_12/glm/#Case-2:-Logistic-regression","page":"Linear regression revisited","title":"Case 2: Logistic regression","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The second case considers g(z)=log z to be the logarithm function and ymid x with the Poisson distribution Po(lambda). The inverse function to g is g^-1(z)=e^z. Since the Poisson distribution has non-negative discrete values with probabilities mathbb P(Y=k) = frac1klambda^ke^-lambda, labels y_i must also be non-negative integers. The same formula for the conditional expectation as before yields:","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"e^w^top x_i = g^-1(w^top x_i) = mathbb E(y_i mid x_i) = lambda_i","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Plugging this term into the log-likelihood function results in the following optimization problem:","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornamemaximize_wqquad sum_i=1^nlogleft( frac1y_ilambda_i^y_i e^-lambda_iright)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"By using the formula for lambda_i and getting rid of constants, we transform this problem into","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"operatornameminimize_wqquad  sum_i=1^n left(e^w^top x_i - y_iw^top x_iright)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"This function is similar to the one derived for logistic regression.","category":"page"},{"location":"lecture_12/glm/#Linear-models","page":"Linear regression revisited","title":"Linear models","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"We will use the Employment and Wages in Spain dataset because it is slightly larger than the iris dataset. It contains 5904 observations of wages from 738 companies in Spain from 1983 to 1990. We will estimate the dependence of wages on other factors such as employment or cash flow. We first load the dataset and transform the original log-wages into non-normalized wages. We use base 2 to obtain relatively small numbers.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"using RDatasets\n\nwages = dataset(\"plm\", \"Snmesp\")\nwages.W = 2. .^ (wages.W)\n\nnothing # hide","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"We can use the already known procedure to compute the best fit. ","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"X = Matrix(wages[:, [:N, :Y, :I, :K, :F]])\nX = hcat(ones(size(X,1)), X)\ny = wages[:, :W]\n\nw0 = (X'*X) \\ (X'*y)\n\nnothing # hide","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Another possibility is to use the package GLM and its command lm for linear models. ","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"using GLM\n\nmodel = lm(@formula(W ~ 1 + N + Y + I + K + F), wages)","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The table shows the parameter values and their confidence intervals. Besides that, it also tests the null hypothesis H_0 w_j = 0 whether some of the regression coefficients can be omitted. The t statistics is in column t, while its p-value in column Pr(>|t|). The next exercise checks whether we can achieve the same results with fewer features.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"warning: Exercise:\nCheck that the solution computed by hand and by lm are the same.Then remove the feature with the highest p-value and observe whether there was any performance drop. The performance is usually evaluated by the coeffient of determination denoted by R^2in01. Its higher values indicate a better model.Hint: Use functions coef and r2.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"details: Solution:\nSince the parameters for both approaches are almost the same, the approaches give the same result. norm(coef(model) - w0)The table before this exercise shows that the p-value for feature K is 33. We define the reduced model without this feature.model_red = lm(@formula(W ~ 1 + N + Y + I + F), wages)Now we show the performances of both models.(r2(model), r2(model_red))Since we observe only a small performance drop, we could omit this feature without changing the model prediction capability.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The core assumption of this approach is that y follows the normal distribution. We use the predict function for predictions and then use the plot_histogram function written earlier to plot the histogram and a density of the normal distribution. For the normal distribution, we need to specify the correct mean and variance.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"y_hat = predict(model)\n\nplot_histogram(y_hat, x -> pdf(Normal(mean(y_hat), std(y_hat)), x))","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"Another possibility would be the fit function from the Distributions package.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"plot_histogram(y_hat, x -> pdf(fit(Normal, y_hat), x))","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The results look identical. The distribution resembles the normal distribution, but there are some differences. We can use the more formal Kolmogorov-Smirnov, which verifies whether a sample comes from some distribution.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"test_normality = ExactOneSampleKSTest(y_hat, Normal(mean(y_hat), std(y_hat)))","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The result is expected. The p-value is close to 1, which means that we reject the null hypothesis that the data follow the normal distribution even though it is not entirely far away.","category":"page"},{"location":"lecture_12/glm/#Generalized-linear-models","page":"Linear regression revisited","title":"Generalized linear models","text":"","category":"section"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"While the linear models do not transform the labels, the generalized models transform them by the link function. Moreover, they allow choosing other than the normal distribution for labels. Therefore, we need to specify the link function g and the distribution of y mid x.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"We repeat the same example with the link function g(z) = sqrtz and the inverse Gaussian distribution for the labels. Since we want to use the generalized linear model, we replace lm by glm.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"model = glm(@formula(W ~ 1 + N + Y + I + K + F), wages, InverseGaussian(), SqrtLink())","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"The following exercise plots the predictions for the generalized linear model.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"warning: Exercise:\nCreate the scatter plot of predictions and labels. Do not use the predict function.","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"details: Solution:\nDue to the construction of the generalized linear model, the prediction equals g^-1(w^top x). We save it into hat y.g_inv(z) = z^2\n\ny_hat = g_inv.(X*coef(model))\n\nnothing # hideThe scatter plot is now simple.scatter(y, y_hat;\n    label=\"\",\n    xlabel=\"Label\",\n    ylabel=\"Prediction\",\n)\n\nsavefig(\"glm_predict.svg\") # hide","category":"page"},{"location":"lecture_12/glm/","page":"Linear regression revisited","title":"Linear regression revisited","text":"(Image: )","category":"page"},{"location":"lecture_01/strings/#Strings","page":"Strings","title":"Strings","text":"","category":"section"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In Julia, as in other programming languages, a string is a sequence of one or more characters and can be created using quotes.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"Hello, world.\"\n\"Hello, world.\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The strings are immutable and, therefore, cannot be changed after creation. However, it is simple to create a new string from parts of existing strings. Individual characters of a string can be accessed via square brackets and indices (the same syntax as for arrays).","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1] # returns the first character\n'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The return type, in this case, is a Char.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> typeof(str[1])\nChar","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"A Char value represents a single character. It is just a 32-bit primitive type with a special literal representation and appropriate arithmetic behaviour. Chars can be created using an apostrophe.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> 'x'\n'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"It is also possible to convert characters to a numeric value representing a Unicode and vice versa.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> Int('x')\n120\n\njulia> Char(120)\n'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Substrings from the existing string can be extracted via square brackets. The indexing syntax is similar to the one for arrays.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1:5] # returns the first five characters\n\"Hello\"\n\njulia> str[[1,2,5,6]]\n\"Heo,\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"We used the range 1:5 to access the first five elements of the string (further details on ranges are given in the section on arrays). Be aware that the expressions str[k] and str[k:k] do not give the same results.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1] # returns the first character as Char\n'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)\n\njulia> str[1:1] # returns the first character as String\n\"H\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"When using strings, we have to pay attention to following characters with special meaning: \\, \" and $. In order to use them as regular characters, they need to be escaped with a backslash (\\). For example, unescaped double quote (\") would end the string prematurely, forcing the rest being interpreted as Julia code. This is a common malicious attack vector called code injection.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str1 = \"This is how a string is created: \\\"string\\\".\"\n\"This is how a string is created: \\\"string\\\".\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Similarly, the dollar sign is reserved for string interpolation (it will be explained soon). If we want to use it as a character, we have to use a backslash too.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str2 = \"\\$\\$\\$ dollars everywhere \\$\\$\\$\"\n\"\\$\\$\\$ dollars everywhere \\$\\$\\$\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"The $ will be fine.\"\nERROR: ParseError:\n# Error @ none:1:7\n\"The $ will be fine.\"\n#     └ ── identifier or parenthesized expression expected after $ in string\n[...]","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"No, they won't. If used incorrectly, Julia will throw an error. Printing of strings can be done by the print function or the println function that also add a new line at the end of the string.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> println(str1)\nThis is how a string is created: \"string\".\n\njulia> println(str2)\n$$$ dollars everywhere $$$","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"There is one exception to using quotes inside a string: quotes without backslashes can be used in multi-line strings. Multi-line strings can be created using triple quotes syntax as follows:","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> mstr = \"\"\"\n       This is how a string is created: \"string\".\n       \"\"\"\n\"This is how a string is created: \\\"string\\\".\\n\"\n\njulia> print(mstr)\nThis is how a string is created: \"string\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"This syntax is usually used for docstring for functions. It will have the same form after printing it in the REPL.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"\"\"\n             Hello,\n             world.\n           \"\"\"\n\"  Hello,\\n  world.\\n\"\n\njulia> print(str)\n  Hello,\n  world.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"warning: Exercise:\nCreate a string with the following textQuotation is the repetition or copy of someone else's statement or thoughts. \nQuotation marks are punctuation marks used in text to indicate a quotation. \nBoth of these words are sometimes abbreviated as \"quote(s)\".and print it into the REPL. The printed string should look the same as the text above, i.e., each sentence should be on a separate line. Use an indent of length 4 for each sentence.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"details: Solution:\nThere are two basic ways to get the right result. The first is to use a multi-line string and write the message in the correct form.julia> str = \"\"\"\n           Quotation is the repetition or copy of someone else's statement or thoughts.\n           Quotation marks are punctuation marks used in text to indicate a quotation.\n           Both of these words are sometimes abbreviated as \"quote(s)\".\n       \"\"\";\n\njulia> println(str)\n    Quotation is the repetition or copy of someone else's statement or thoughts.\n    Quotation marks are punctuation marks used in text to indicate a quotation.\n    Both of these words are sometimes abbreviated as \"quote(s)\".We do not have to add backslashes to escape quotation marks in the text. The second way is to use a regular string and the new line symbol \\n. In this case, it is necessary to use backslashes to escape quotation marks. Also, we have to add four spaces before each sentence to get a proper indentation.julia> str = \"    Quotation is the repetition or copy of someone else's statement or thoughts.\\n    Quotation marks are punctuation marks used in text to indicate a quotation.\\n    Both of these words are sometimes abbreviated as \\\"quote(s)\\\".\";\n\njulia> println(str)\n    Quotation is the repetition or copy of someone else's statement or thoughts.\n    Quotation marks are punctuation marks used in text to indicate a quotation.\n    Both of these words are sometimes abbreviated as \"quote(s)\".","category":"page"},{"location":"lecture_01/strings/#String-concatenation-and-interpolation","page":"Strings","title":"String concatenation and interpolation","text":"","category":"section"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"One of the most common operations on strings is their concatenation. It can be done using the string function that accepts any number of input arguments and converts them to a single string.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> string(\"Hello,\", \" world\")\n\"Hello, world\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that it is possible to concatenate strings with numbers and other types that can be converted to strings.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> a = 1.123\n1.123\n\njulia> string(\"The variable a is of type \", typeof(a), \" and its value is \", a)\n\"The variable a is of type Float64 and its value is 1.123\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In general, it is not possible to perform mathematical operations on strings, even if the strings look like numbers. However, there are two exceptions. The * operator performs string concatenation.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"Hello,\" * \" world\"\n\"Hello, world\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Unlike the string function, which works for other types, this approach can only be applied to Strings. The second exception is the ^ operator, which performs repetition.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"Hello\"^3\n\"HelloHelloHello\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The example above is equivalent to calling the repeat function.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> repeat(\"Hello\", 3)\n\"HelloHelloHello\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Using the string function to concatenate strings can be cumbersome due to long expressions. To simplify the strings' construction, Julia allows interpolation into string literals with the $ symbol.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> a = 1.123\n1.123\n\njulia> string(\"The variable a is of type \", typeof(a), \" and its value is \", a)\n\"The variable a is of type Float64 and its value is 1.123\"\n\njulia> \"The variable a is of type $(typeof(a)), and its value is $(a)\"\n\"The variable a is of type Float64, and its value is 1.123\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"We use parentheses to separate expressions that should be interpolated into a string. It is not mandatory, but it can prevent mistakes. In the example below, we can see different results with and without parentheses.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"$typeof(a)\"\n\"typeof(a)\"\n\njulia> \"$(typeof(a))\"\n\"Float64\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In the case without parentheses, only the function name is interpolated into the string. In the second case, the expression typeof(a) is interpolated into the string literal. It is more apparent when we declare a variable myfunc that refers to typeof function","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> myfunc = typeof\ntypeof (built-in function)\n\njulia> \"$myfunc(a)\"\n\"typeof(a)\"\n\njulia> \"$(myfunc(a))\"\n\"Float64\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Both concatenation and string interpolation call string to convert objects into string form. Most non-AbstractString objects are converted to strings closely corresponding to how they are entered as literal expressions.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> v = [1,2,3]\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> \"vector: $v\"\n\"vector: [1, 2, 3]\"\n\njulia> t = (1,2,3)\n(1, 2, 3)\n\njulia> \"tuple: $(t)\"\n\"tuple: (1, 2, 3)\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"warning: Exercise:\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Print the following message for a given vector","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\"<vec> is a vector of length <len> with elements of type <type>\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"where <vec> is the string representation of the given vector, <len> is the actual length of the given vector, and <type> is the type of its elements. Use the following two vectors.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"  a = [1,2,3]\n  b = [:a, :b, :c, :d]\n  ```\n\n  **Hint:** use the `length` and `eltype` functions.\n\n!!! details \"Solution:\"\n  We will show two ways how to solve this exercise. The first way is to use the `string` function in combination with the `length` function to get the length of the vector, and the `eltype` function to get the type of its elements.\n\n  ```jldoctest\n  julia> a = [1,2,3];\n\n  julia> str = string(a, \" is a vector of length \",  length(a), \" with elements of type \", eltype(a));\n\n  julia> println(str)\n  [1, 2, 3] is a vector of length 3 with elements of type Int64\n  ```\n\n  The second way is to use string interpolation.\n\n  ```jldoctest\n  julia> b = [:a, :b, :c, :d];\n\n  julia> str = \"$(b) is a vector of length $(length(b)) with elements of type $(eltype(b))\";\n\n  julia> println(str)\n  [:a, :b, :c, :d] is a vector of length 4 with elements of type Symbol\n  ```\n\n## Useful functions\n\nA handy function is the `join` function that performs string concatenation. Additionally, it supports defining a custom separator and a different separator for the last element.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \") \"apples, bananas and pineapples\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nIn many cases, it is necessary to split a given string according to some conditions. In such cases, the `split` function can be used.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest joins julia> str = \"JuliaLang is a pretty cool language!\" \"JuliaLang is a pretty cool language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> split(str) 6-element Vector{SubString{String}}:  \"JuliaLang\"  \"is\"  \"a\"  \"pretty\"  \"cool\"  \"language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nBy default, the function splits the given string based on whitespace characters. This can be changed by defining a delimiter.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest joins julia> split(str, \" a \") 2-element Vector{SubString{String}}:  \"JuliaLang is\"  \"pretty cool language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nJulia also provides multiple functions that can be used to find specific characters or substring in a given string. The `contains` function checks if the string contains a specific substring or character. Similarly, the `occursin` function determines if the specified string or character occurs in the given string. These two functions differ only in the order of arguments.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> contains(\"JuliaLang is pretty cool!\", \"Julia\") true","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> occursin(\"Julia\", \"JuliaLang is pretty cool!\") true","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nAnother useful function is `endswith`, which checks if the given string ends with the given substring or character. It can be used, for example, to check that the file has a proper suffix.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> endswith(\"figure.png\", \"png\") true","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nSometimes, it is necessary to find indices of characters in the string based on some conditions. For such cases, Julia provides several find functions.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> str = \"JuliaLang is a pretty cool language!\" \"JuliaLang is a pretty cool language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> findall(isequal('a'), str) 5-element Vector{Int64}:   5   7  14  29  33","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> findfirst(isequal('a'), str) 5","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> findlast(isequal('a'), str) 33","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nThe first argument `isequal('a')` creates a function that checks if its argument equals the character `a`.\n\nAs we said before, strings are immutable and cannot be changed. However, we can easily create new strings. The `replace` function returns a new string with a substring of characters replaced with something else:\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> replace(\"Sherlock Holmes\", \"e\" => \"ee\") \"Sheerlock Holmees\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nIt is also possible to apply a function to a specific substring using the `replace` function. The following example shows how to change all `e` letters in the given string to uppercase.\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> replace(\"Sherlock Holmes\", \"e\" => uppercase) \"ShErlock HolmEs\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\nIt is even possible to replace a whole substring:\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"jldoctest julia> replace(\"Sherlock Holmes\", \"Holmes\" => \"Homeless\") \"Sherlock Homeless\" ```","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"warning: Exercise:\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Use the split function to split the following string","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\"Julia!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"into a vector of single-character strings.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Hint: we can say that an empty string \"\" separates the characters in the string.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"details: Solution:\n","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"To separate a string into separate single-character strings, we can use the split function and an empty string (\"\") as a delimiter.   jldoctest   julia> split(\"Julia!\", \"\")   6-element Vector{SubString{String}}:   \"J\"   \"u\"   \"l\"   \"i\"   \"a\"   \"!\"","category":"page"},{"location":"lecture_04/exercises/#Conway's-Game-of-Life","page":"Exercises","title":"Conway's Game of Life","text":"","category":"section"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"The Game of Life is a cellular automaton devised by the British mathematician John Horton Conway in 1970. It is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One only interacts with the Game of Life by creating an initial configuration.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"The universe of the Game of Life is an infinite, two-dimensional orthogonal grid of square cells, each of which is in one of two possible states: live or dead. Every cell interacts with its eight neighbours. The game evolves. At each time step, the following transitions occur:","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"Any live cell with exactly two or three live neighbours survives.\nAny dead cell with exactly three live neighbours becomes a live cell.\nAll other live cells die in the next generation. All other dead cells stay dead.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"The first generation must be initialized. Every new generation is created by applying the above rules simultaneously to every cell in the previous generations; births and deaths occur simultaneously. The moment when this happens is called a tick. Since every generation depends only on the previous one, this process is a Markov chain.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"The following few exercises will implement the Game of Life. We will consider finite universe with periodic boundary conditions.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise:\nWrite a function neighbours that return the number of live neighbours of a cell. The function should accept the world matrix of boolean values representing the state of all cells (true if the cell is alive and false otherwise) and index of the row and column of the cell.Hint: use the following properties of the mod1 function to implement periodic boundaries.mod1(1, 4)\nmod1(4, 4)\nmod1(5, 4)Bonus: implement a more general function which computes the number of alive cells in a neighbourhood of given size.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nOne way to define the neighbours function is to check all neighbours manually.function neighbours(world, row, col)\n    n, m = size(world)\n\n    # this implements periodic boundaries\n    down  = mod1(row + 1, n)\n    up    = mod1(row - 1, n)\n    left  = mod1(col - 1, m)\n    right = mod1(col + 1, m)\n\n    return ( world[up,   left] + world[up,  col]  + world[up,   right]\n        + world[row,  left] +                  + world[row,  right]\n        + world[down, left] + world[down, col] + world[down, right])\nendThe approach above can not define a general version of the neighbours function. In this case, we can use nested loops. First, we compute proper row indices by range combined with the mod1 function.rows = mod1.(row .+ (-r:r), size(world, 1))Column indexes can be computed similarly. Then we use nested loops to iterate through both rows and columns. Since the iteration includes the middle cell, we need to subtract its state.function neighbours(world, row, col; r = 1)\n    rows = mod1.(row .+ (-r:r), size(world, 1))\n    cols = mod1.(col .+ (-r:r), size(world, 2))\n\n    return sum(world[i, j] for i in rows, j in cols) - world[row, col]\nend","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise:\nAdd a new method to the neighbours function that for the world matrix returns a matrix containing numbers of living neighbours.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe created a function that computes the number of living neighbours in the exercise above. One way how to create a matrix with numbers of living neighbours is:function neighbours(world)\n    n, m = size(world)\n    return [neighbours(world, row, col) for row in 1:n, col in 1:m]\nendThis is an example of multiple dispatch. The function neighbours can have both one and three input arguments.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise:\nWrite a function willsurvive that returns true if the cell will survive based on the conditions described at the beginning of the section and false otherwise. This function should accept two arguments: state of the cell (true/false) and the number of living neighbours.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThis function can be written using the if-elseif-else statement. Since cell is a boolean value, we do not need to compare with one as in cell == 1.function willsurvive(cell, k)\n    if k == 3\n        return true\n    elseif k == 2 && cell\n        return true\n    else\n        return false\n    end\nendWe can write this function in a simpler form. We first realize that the short-circuit evaluation can merge the first two conditions. Since the function returns only true or false, we can write the function on one line.willsurvive(cell, k) = k == 3 || k == 2 && cell","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise:\nCombine these functions to write a function evolve! that evolves the given world matrix into a new generation.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe first compute the matrix with the numbers of living neighbours. Then we iterate over all elements of the world matrix and compute new states of all elements with the willsurvive function. Since we computed the number of living neighbours before iterating, we can rewrite the world matrix.function evolve!(world)\n    ks = neighbours(world)\n    for i in eachindex(world)\n        world[i] = willsurvive(world[i], ks[i])\n    end\n    return\nend","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"In the four exercises above, we defined functions sufficient to animate the Game of Life. Use the following code to initialize the world.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"world = zeros(Bool, 30, 30)\nrow, col = 15, 15\n\nworld[row, col] = 1\nworld[row, col + 1] = 1\nworld[row - 1, col + 6] = 1\nworld[row + 1, col + 1] = 1\nworld[row + 1, col + 5] = 1\nworld[row + 1, col + 6] = 1\nworld[row + 1, col + 7] = 1","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"We use the Plots package introduced in the previous lecture to create animations.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\n\nanim = @animate for i in 1:150\n    heatmap(world; axis = nothing, border = :none, cbar = false, ratio = :equal)\n    evolve!(world)\nend\ngif(anim, \"gameoflife.gif\"; fps = 10)","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"Many different types of patterns occur in the Game of Life. For example, the following initialization is called pulsar.","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"world = zeros(Bool, 17, 17)\nline = zeros(17)\nline[5:7] .= 1\nline[11:13] .= 1\n\nfor ind in [3,8,10,15]\n    world[ind, :] .= line\n    world[:, ind] .= line\nend","category":"page"},{"location":"lecture_04/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_05/otherpackages/#Distributions.jl","page":"Other useful packages","title":"Distributions.jl","text":"","category":"section"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using Distributions\nusing StatsPlots","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The Distributions package provides an extensive collection of probabilistic distributions and related functions. Each distribution is defined as a custom type, which allows creating instances of distributions.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using Distributions\nD = Normal(2, 0.5)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The example above creates the normal distribution with mean μ = 2 and standard deviation σ = 0.5. The Distributions package provides functions to compute mean, variance, or quantiles.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"mean(D)\nvar(D)\nquantile(D, 0.9)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The package also provides ways to evaluate probability or cumulative density functions.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"pdf(D, 2)\ncdf(D, 2)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"In combination with the StatsPlots package, it is possible to plot probability density functions.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using StatsPlots\nplot(\n    plot(D; title = \"pdf\"),\n    plot(D; func = cdf,  title = \"cdf\");\n    legend = false,\n    xlabel = \"x\",\n    ylabel = \"f(x)\",\n    ylims = (0,1),\n    linewidth = 2,\n    layout = (1,2),\n    size = (800, 400)\n)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The Distributions package also provides methods to fit a distribution to a given set of samples.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"x = rand(Normal(2, 0.5), 10000); # generate 10000 random numbers from Normal(2, 0.5)\nD = fit(Normal, x)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The fit function chooses a reasonable way to fit the distribution, which, in most cases, is the maximum likelihood estimation. However, this is not supported for all distributions. We can quickly check that the fit by using a histogram.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"histogram(x; normalize = :pdf, legend = false, opacity = 0.5)\nplot!(D; linewidth = 2, xlabel = \"x\", ylabel = \"pdf(x)\")","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"warning: Exercise:\nCreate a figure that shows the gamma distributions with the following parameters: (2, 2), (9, 0.5), (7.5, 1) and (0.5, 1).Hint: to plot cumulative probability functions, use the Plots ability to plot functions.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"details: Solution:\nThe easiest way to create multiple distributions is to use the broadcasting system.Ds = Gamma.([2, 9, 7.5, 0.5], [2, 0.5, 1, 1])\nnothing #hideSimilarly, we use broadcasting to create a vector of labels.labels = reshape(string.(\"Gamma\", params.(Ds)), 1, :)\nnothing #hideWe need to reshape the labels to become a row vector. The reason is that we want to plot multiple distributions, and the Plot package expects that labels will be a row vector. Now, we call the plot function to plot all distributions.plot(Ds;\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"pdf(x)\", (0, 0.5)),\n    labels = labels,\n    linewidth = 2,\n    legend = :topright,\n)A plot of the cumulative probability functions cannot be done in the same way. However, StatsPlots provides the func keyword argument that allows specifying which function should be plotted.plot(Ds;\n    func = cdf,\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"cdf(x)\", (0, 1.05)),\n    labels = labels,\n    linewidth = 2,\n    legend = :bottomright,\n)Another possibility is to use the Plots package directly. To do so, we need to define a function with one argument, which at a given point returns the value of the cumulative probability function. Such functions for all our distributions can be easily defined as anonymous functions.cdfs = [x -> cdf(D, x) for D in Ds]\nnothing # hideThe previous expression returns a vector of functions. Now we can use the plot function to create a curve for each element of the vector of cumulative probability functions. The example below creates these curves for x from 0 to 20.plot(cdfs, 0, 20;\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"cdf(x)\", (0, 1.05)),\n    labels = labels,\n    linewidth = 2,\n    legend = :bottomright,\n)\n\nsavefig(\"Gamma_cdf.svg\") # hide(Image: )","category":"page"},{"location":"lecture_05/otherpackages/#BSON.jl","page":"Other useful packages","title":"BSON.jl","text":"","category":"section"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"BSON is a package for working with the Binary JSON serialization format. It can be used as a general store for Julia's data structures. To save the data, BSON provides the bson function. The data can be passed to the function directly via keyword arguments","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using BSON\nBSON.bson(\"test2.bson\", a = [1+2im, 3+4im], b = \"Hello, World!\")","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"or as a dictionary","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"data = Dict(:a => [1+2im, 3+4im], :b => \"Hello, World!\")\nBSON.bson(\"test1.bson\", data)","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"To load the data, BSON provides the load function that accepts the path to the data.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"BSON.load(\"test1.bson\")\nBSON.load(\"test2.bson\")","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The package also provides an alternative way to saving and loading data using the @save and @load macro.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using BSON: @save, @load\n\na = [1+2im, 3+4im];\nb = \"Hello, World!\";\n\n@save \"test.bson\" a b # Same as above\n@load \"test.bson\" a b # Loads `a` and `b` back into the workspace","category":"page"},{"location":"lecture_05/otherpackages/#ProgressMeter.jl","page":"Other useful packages","title":"ProgressMeter.jl","text":"","category":"section"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The ProgressMeter package provides excellent utilities for printing progress bars for long computations. The package provides the @showprogress macro that prints the progress bar for for loops.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"julia> using ProgressMeter\n\njulia> @showprogress 1 \"Computing...\" for i in 1:50\n           sleep(0.1)\n       end\nComputing... 20%|███████▊                               |  ETA: 0:00:04","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The same syntax can also be used with the map, pmap or reduce functions. Progress bars can also be created manually, which allows additional formatting of the output. For example, it is possible to print and update information related to the computation by the showvalues keyword.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"julia> x, n = 1 , 10;\n\njulia> p = Progress(n);\n\njulia> for iter in 1:10\n           x *= 2\n           sleep(0.5)\n           ProgressMeter.next!(p; showvalues = [(:iter, iter), (:x, x)])\n       end\nProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\n  iter:  10\n  x:     1024","category":"page"},{"location":"lecture_05/otherpackages/#BenchmarkTools.jl","page":"Other useful packages","title":"BenchmarkTools.jl","text":"","category":"section"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The BenchmarkTools package provides a framework for writing and running groups of benchmarks as well as comparing benchmark results. The primary macro provided by BenchmarkTools is the @benchmark macro","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"using BenchmarkTools\n@benchmark sin(x) setup=(x=rand())","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"The setup expression is run once per sample and is not included in the timing results. Another handy macro provided by the package is the @btime macro. The output of this macro is similar to the built-in @time macro.","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"A = rand(3,3);\n@btime inv($A);","category":"page"},{"location":"lecture_05/otherpackages/","page":"Other useful packages","title":"Other useful packages","text":"We use $ to interpolate variable A into the benchmark expression. Any expression that is interpolated in such a way is \"pre-computed\" before the benchmarking begins.","category":"page"},{"location":"lecture_08/theory/#Introduction-to-continuous-optimization","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Optimization problems optimize (minimize or maximize) a given function on a given set. There are many applications:","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Maximize profit under market forecasts.\nGiven a set of points, find a visiting order which minimizes the distance. This application includes various tasks ranging from delivery services to snow ploughing. \nMake a prediction based on known data. Specific examples are whether a client gets a loan or whether an autonomous vehicle sees a pedestrian. Almost all tasks in machine learning minimize the difference between a prediction and a label.\nFind the optimal shape of a machine so that a criterion is maximized. Specific examples are designing planes with minimal drag or optimizing engines to maximize power under a reasonable oil consumption. ","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"These applications are very different from each other. They differ in their assumptions about the world, in their formulation and solution way.","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Profit maximization needs to model future uncertainty. The formulation will probably contain expectations and chance constraints, while the variables will be continuous. \nFinding the minimal way is often reformulated as finding the shortest path in a graph. Problems like this operate typically with binary variables and no uncertainty.  \nMachine learning requires loads of data and usually ignores any physical models. Due to the abundance of data, the objective function evaluations are lengthy, and specially designed optimization algorithms are used.\nTopology optimization is based on complicated physical models. Since these often come in a black-box form, additional information such as gradient is often not available. Moreover, the optimizer needs to consider conflicting criteria such as speed and consumption.","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"This short analysis implies that there is no single \"optimization topic\", and the theory of optimization contains many different subfields. In the following four lectures, we will study the field of continuous optimization, which assumes that all functions are (sub)differentiable and all variables are continuous. This includes most machine learning applications, to which we dedicate three lectures.","category":"page"},{"location":"lecture_08/theory/#Problem-definition","page":"Introduction to continuous optimization","title":"Problem definition","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"The goal of an optimization problem is to minimize or maximize a function f over a set X:","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    beginaligned\n    textminimizeqquad f(x) \n    textsubject toqquad xin X\n    endaligned","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Should we consider both minimization and maximization problems? No. Because","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    textmaximizeqquad f(x)","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"is equivalent to ","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    -textminimizeqquad -f(x)","category":"page"},{"location":"lecture_08/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"This trick has a neat consequence: All numerical and theoretical results are derived only for minimization problems. If we deal with a maximization problem, we convert it first to a minimization problem and then use known results.","category":"page"},{"location":"lecture_05/standardlibrary/#Useful-packages","page":"Standard library","title":"Useful packages","text":"","category":"section"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Julia provides a large package library. To add a package, we enter the package REPL by pressing ] and install a package by the keyword add.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"(@v1.6) pkg> add Plots","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Another option is to use the Pkg package to add it directly from the standard REPL.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"julia> using Pkg\n\njulia> Pkg.add(\"Plots\")","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"We return from the package REPL (@v1.6) pkg> to the standard REPL julia> by pressing escape.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Multiple standard packages are shipped together with Julia. These packages do not need to be installed. They include Pkg and all packages introduced on this page. However, we still need to load them to use them.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"julia> using Statistics","category":"page"},{"location":"lecture_05/standardlibrary/#Statistics","page":"Standard library","title":"Statistics","text":"","category":"section"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"The first package we mention is the Statistics package, which provides statistical analysis functions such as computation of mean, variance, or standard deviation.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"using Statistics\nx = rand(10);\nmean(x)\nvar(x)\nstd(x)","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"See the official documentation for more information. More statistics-related functions can be found in the StatsBase package. This package provides functions for computing scalar statistics, high-order moment computation, counting, ranking, covariances, sampling, and empirical density estimation. This course dedicates one lecture to statisctics.","category":"page"},{"location":"lecture_05/standardlibrary/#LinearAlgebra","page":"Standard library","title":"LinearAlgebra","text":"","category":"section"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Another package worth mentioning is the LinearAlgebra package, which provides a native implementation of many linear algebra operations. The package provides functions for computing matrix determinant, inversion, norm, eigenvalues, or eigenvectors.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"using LinearAlgebra\nA = [-4.0 -17.0; 2.0 2.0]\n\ndet(A)\ninv(A)\nnorm(A)\neigvals(A)\neigvecs(A)","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"The package also provides implementation of multiple matrix types that represent matrices with special symmetries and structures. As examples, we mention Symmetric, Hermitian or Diagonal matrices. These particular matrix types allow for fast computation due to using specialized algorithms. Matrices of these types can be constructed via their constructors.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"D = Diagonal([1,2,3])","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Another useful function provided by the package is the identity operator I representing the identity matrix. The identity operator I is defined as a constant and is an instance of UniformScaling. The size of this operator is generic and match the other matrix in the binary operations +, -, * and \\.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"D + I\nD - I","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"Note that for D+I and D-I, the matrix D must be square.","category":"page"},{"location":"lecture_05/standardlibrary/#Random","page":"Standard library","title":"Random","text":"","category":"section"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"The last package that we will describe in more detail is the Random package. This package provides advanced functionality for generating random numbers in Julia. The package allows setting the seed for the random generator using the seed! function. The seed! function is used to create a reproducible code that contains randomly generated values.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"using Random\nusing Random: seed!\n\nseed!(1234);\nrand(2)\nseed!(1234);\nrand(2)","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"The randperm function constructs a random permutation of a given length.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"randperm(4)","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"The shuffle function returns a randomly permuted copy of a given array.","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"v = [1,2,3,4]\nshuffle(v)","category":"page"},{"location":"lecture_05/standardlibrary/","page":"Standard library","title":"Standard library","text":"info: Other useful standard packages:\nThere are other useful standard packages in Julia, but there is not enough space to present them all.Test provides simple unit testing functionality. Unit testing is a process to determine if your code is correct by checking that the results are what you expect. It helps to ensure the code works after changes. Unit tests can also be used during the development phase to specify the expected behaviour when implemented. We will provide more details later.\nSparseArrays provides special types to store and work with sparse arrays.\nDistributed includes support for distributed computing.The section Standard Library in the official documentation provides more information.","category":"page"},{"location":"lecture_05/DataFrames/#DataFrames.jl","page":"DataFrames.jl","title":"DataFrames.jl","text":"","category":"section"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"DataFrames is a package that provides a set of tools for working with tabular data. Its design and functionality are similar to  pandas (in Python) and data.frame, data.table and dplyr (in R) or table (in Matlab). This makes it a great general-purpose data science tool, especially for people coming to Julia from other languages.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using CSV\nusing DataFrames","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The core of the package is the DataFrame structure that represents a data table. The simplest way of constructing a DataFrame is to pass column vectors using keyword arguments or pairs.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\ndf = DataFrame(A = 1:4, B = [\"M\", \"F\", \"F\", \"M\"], C = rand(4))","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Since each column is stored in a DataFrame as a separate vector, it is possible to combine columns of different element types. Columns can be accessed directly without copying.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.A","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Another way is to use the indexing syntax similar to the one for arrays.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df[!, :A]","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"We use ! to select all rows. This creates a pointer to the column. If we use :,  then we get a copy of a column. Since vectors are mutable structures and accessing a column of DataFrame via ! does not make a copy, it is possible to change elements of the DataFrame.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.A[1] = 5\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"On the other hand, the : creates a copy, which will not change the original DataFrame.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"col = df[:, :A]\ncol[1] = 4\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"info: Column names:\nDataFrames allow using symbols (like :A) and strings (like \"A\") for all column indexing operations. Using symbols is slightly faster and should be preferred. One exception is when the column names are generated using string manipulation.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The standard format for storing table data is the csv file format. The CSV package provides an interface for saving and loading csv files.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using CSV\nCSV.write(\"dataframe.csv\", df)\ntable = CSV.read(\"dataframe.csv\", DataFrame; header = true)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"See the package documentation for more information.","category":"page"},{"location":"lecture_05/DataFrames/#Adding-columns-and-rows","page":"DataFrames.jl","title":"Adding columns and rows","text":"","category":"section"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is common for tables to be created column by column or row by row. DataFrames provides an easy way to extend existing tables. To can add new columns to a DataFrame in a direct way.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.D = [:a, :b, :c, :d]\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Alternatively, we can use the insertcols! function. This function can insert multiple columns at once and also provides advanced options for column manipulation. For example, we can specify the column index into which the columns are to be inserted.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"insertcols!(df, 3, :B => rand(4), :B => 11:14; makeunique = true)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"New rows can be added to an existing DataFrame by the push! function. It is possible to append a new row in the form of a vector or a tuple of the correct length or in the form of a dictionary or DataFrame with the correct keys.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"push!(df, [10, \"F\", 0.1, 15, 0.235, :f])\npush!(df, (10, \"F\", 0.1, 15, 0.235, :f))\npush!(df, Dict(:B_1 => 0.1, :B_2 => 15, :A => 10, :D => :f, :B => \"F\", :C => 0.235))\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is also possible to start with an empty DataFrame and build the table incrementally.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\ndf_empty = DataFrame()\ndf_empty.A = 1:3\ndf_empty.B = [:a, :b, :c]\ndf_empty","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"However, this approach will not work if the DataFrame is created row by row. In this case, the DataFrame must be initialized with empty columns of appropriate element types.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df_empty = DataFrame(A = Int[], B = Symbol[])\npush!(df_empty, [1, :a])\npush!(df_empty, (2, :b))\npush!(df_empty, Dict(:A => 3, :B => :c))\ndf_empty","category":"page"},{"location":"lecture_05/DataFrames/#Renaming","page":"DataFrames.jl","title":"Renaming","text":"","category":"section"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Two functions can be used to rename columns. The names function returns column names as a vector of strings, while the propertynames function returns a vector of symbols.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"names(df)\npropertynames(df)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"We use the rename! function to change column names. This function can be used to rename all columns at once.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"rename!(df, [:a, :b, :c, :d, :e, :f])\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Another option is to rename only some of the columns specified by their names.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"rename!(df, :a => :A, :f => :F)\ndf","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is also possible to use a function to generate column names.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"myname(x) = string(\"column_\", uppercase(x))\nrename!(myname, df)\ndf","category":"page"},{"location":"lecture_05/DataFrames/#Working-with-DataFrames","page":"DataFrames.jl","title":"Working with DataFrames","text":"","category":"section"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\nusing RDatasets","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"In the next part of the lecture, we will use the RDatasets package. The package provides an easy way for Julia users to use many standard datasets available in the core of the R programming language. We will use the Iris dataset.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using RDatasets, DataFrames\niris = dataset(\"datasets\", \"iris\")\nfirst(iris, 6)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"We use the first function to print the first n = 6 rows of a table. Similarly, the last function shows the last n rows. When working with a new dataset, it is helpful to get a basic description. DataFrames provides the describe function that returns descriptive statistics for each column.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"describe(iris)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"We can use the indexing syntax to get a specific subset of a DataFrame.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"iris[2:4, [:SepalLength, :Species]]","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Additionally, DataFrames provides Not, Between, Cols and All selectors for more complex column selection scenarios.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"iris[2:4, Not([:SepalLength, :Species])]","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The Query package allows for advanced manipulation with DataFrame. The code below selects only rows with SepalLength >= 6 and SepalWidth >= 3.4. Then we create a new DataFrame, where for each of the selected rows, we add the Species, the sum of sepal length and width, and the sum of petal length and width.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using Query\n\ntable = @from row in iris begin\n    @where row.SepalLength >= 6 && row.SepalWidth >= 3.4\n    @select {\n        row.Species,\n        SepalSum = row.SepalLength + row.SepalWidth,\n        PetalSum = row.PetalLength + row.PetalWidth,\n    }\n    @collect DataFrame\nend","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"There are many topics related to DataFrames. However, there is not enough time to cover them all. We refer the reader to the excellent documentation with lots of examples.","category":"page"},{"location":"lecture_05/DataFrames/#Visualizing-using-StatsPlots","page":"DataFrames.jl","title":"Visualizing using StatsPlots","text":"","category":"section"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\nusing RDatasets\nusing StatsPlots\nusing Query\n\niris = dataset(\"datasets\", \"iris\")\nCore.eval(Main, :(using StatsPlots))","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The StatsPlots package provides recipes for plotting histograms, boxplots, and many other plots related to statistics. This package also provides the @df macro, which allows simple plotting of tabular data. As a simple example, we create a scatter plot of SepalLength and SepalWidth grouped by Species. Keyword arguments can be used in the same way as before.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using StatsPlots\n@df iris scatter(\n    :SepalLength,\n    :SepalWidth;\n    group = :Species,\n    xlabel = \"SepalLength\",\n    ylabel = \"SepalWidth\",\n    marker = ([:d :h :star7], 8),\n)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"As another example, we mention the marginalkde function for plotting marginal kernel density estimations. In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. The marginalkde function can be used together with @df macro.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using StatsPlots: marginalkde # hide\n@df iris marginalkde(\n    :SepalLength,\n    :SepalWidth;\n    xlabel = \"SepalLength\",\n    ylabel = \"SepalWidth\",\n)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Another example is the corrplot function, which shows the correlation between all variables.","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"@df iris corrplot(\n    cols(1:4);\n    grid = false,\n    nbins = 15,\n    fillcolor = :viridis,\n    markercolor = :viridis,\n)","category":"page"},{"location":"lecture_05/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Because it is shorter, we use cols(1:4) instead of the column names.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nusing StatsPlots\nusing RDatasets\nusing Statistics\nusing LinearAlgebra\nusing Query\n\nfunction log_reg(X, y, w; max_iter=100)\n    X_mult = [row*row' for row in eachrow(X)]\n    for i in 1:max_iter\n        y_hat = 1 ./(1 .+exp.(-X*w))\n        grad = X'*(y_hat.-y) / size(X,1)\n        hess = y_hat.*(1 .-y_hat).*X_mult |> mean\n        w -= hess \\ grad\n    end\n    return w\nend\n\niris = dataset(\"datasets\", \"iris\")\niris_reduced = @from i in iris begin\n    @where i.Species != \"setosa\"\n    @select {\n        i.PetalLength,\n        i.PetalWidth,\n        intercept = 1,\n        i.Species,\n        label = i.Species == \"virginica\",\n    }\n    @collect DataFrame\nend\n\nX = Matrix(iris_reduced[:, 1:3])\ny = iris_reduced.label\n\nw = log_reg(X, y, zeros(size(X,2)))\n\nσ(z) = 1/(1+exp(-z))","category":"page"},{"location":"lecture_09/exercises/#l8-exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 1:\nThe logistic regression on the iris dataset failed in 6 out of 100 samples. But the visualization shows the failure only in 5 cases. How is it possible?","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe use the iris_reduced dataframe and add the column prediction to it.df = iris_reduced\ndf.prediction = σ.(X*w) .>= 0.5\n\nnothing # hideNow we show all misclassified samples.sort(df[df.label .!= df.prediction, :], [:PetalLength, :PetalWidth])A quick look at the image shows that the point (4818) is misclassified, but the image shows it correctly. Let us show all such points.df[(df.PetalLength .== 4.8) .& (df.PetalWidth .== 1.8), :]As we can see, there are three samples with the same data. Two of them have label 1 and one label 0. Since the incorrectly classified sample was redrawn, it was not possible to see it.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 2: Disadvantages of the sigmoid function\nShow that Newton's method fails when started from the vector (123). Can you guess why it happened? What are the consequences for optimization? Is gradient descent going to suffer from the same problems?","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nFirst, we run the logistic regression as before, only with a different starting pointlog_reg(X, y, [1;2;3])ERROR: SingularException(1)This resulted in an error (or possibly in NaNs for older versions of Julia). When something fails, it may be a good idea to run a step-by-step analysis. In this case, we will run the first iteration of Newton's methodw = [1;2;3];\nX_mult = [row*row' for row in eachrow(X)];\ny_hat = 1 ./(1 .+exp.(-X*w))\ngrad = X'*(y_hat.-y) / size(X,1)\nhess = y_hat.*(1 .-y_hat).*X_mult |> mean\nw -= hess \\ gradStarting from the bottom, we can see that even though we started with relatively small w, the next iteration is four degrees of magnitude larger. This happened because the Hessian hess is much smaller than the gradient grad. This indicates that there is some kind of numerical instability. The prediction y_hat should lie in the interval 01 but it seems that it is almost always close to 1. Let us verify this by showing the extrema of y_hatextrema(y_hat)They are indeed too large.Now we explain the reason. We know that the prediction equals tohat y_i = sigma(w^top x_i)where sigma is the sigmoid function. Since the mimimum from w^top x_iminimum(X*[1;2;3])is large, all w^top x_i are large. But plotting the sigmoid funtionxs = -10:0.01:10\nplot(xs, σ, label=\"\", ylabel=\"Sigmoid function\")\n\nsavefig(\"sigmoid.svg\") # hide(Image: )it is clear that all w^top x_i hit the part of the sigmoid which is flat. This means that the derivative is almost zero, and the Hessian is \"even smaller\" zero. Then the ratio of the gradient and Hessian is huge.The gradient descent will probably run into the same difficulty. Since the gradient will be too small, it will take a huge number of iterations to escape the flat region of the sigmoid. This is a known problem of the sigmoid function. It is also the reason why it was replaced in neural networks by other activation functions.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 3 (theory)\nShow the details for the derivation of the loss function of the logistic regression.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nSince hat y equals the probability of predicting 1, we havehat y = frac11+e^-w^top xThen the cross-entropy loss reduces tobeginaligned\noperatornameloss(yhat y) = - ylog hat y - (1-y)log(1-hat y) \n= ylog(1+e^-w^top x) - (1-y)log(e^-w^top x) + (1-y)log(1+e^-w^top x) \n= log(1+e^-w^top x) + (1-y)w^top x\nendalignedThen it remains to sum this term over all samples.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 4 (theory)\nShow that if the Newton's method converged for the logistic regression, then it found a point globally minimizing the logistic loss.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe derived that the Hessian of the objective function for logistic regression isnabla^2 L(w) = frac 1n sum_i=1^nhat y_i(1-hat y_i)x_i x_i^topFor any vector a, we havea^top x_i x_i^top a = (x_i^top a)^top (x_i^top a) = x_i^top a^2 ge 0which implies that x_i x_i^top is a positive semidefinite matrix (it is known as rank-1 matrix as its rank is always 1 if x_i is a non-zero vector). Since y_i(1-hat y_i)ge 0, it follows that nabla^2 L(w) is a positive semidefinite matrix. If a Hessian of a function is positive semidefinite everywhere, the function is immediately convex. Since Newton's method found a stationary point, this points is a global minimum.","category":"page"},{"location":"lecture_02/tuples/#Tuples","page":"Tuples and named tuples","title":"Tuples","text":"","category":"section"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"A tuple is an immutable, ordered, fixed-sized group of elements. Therefore, it is impossible to add new elements or change any tuple element's values. Tuples are created using the following syntax:","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t = (1, 2.0, \"3\")\n(1, 2.0, \"3\")","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"It is possible to omit the brackets.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t = 1, 2.0, \"3\"\n(1, 2.0, \"3\")","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"The same syntax is used in function definitions to return multiple values at once. The tuple type consists of the types of all its elements.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> typeof(t)\nTuple{Int64, Float64, String}","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"In this case, we have a tuple that contains three elements: Int64, Float64, and String.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"To access elements of a tuple, we can use the same syntax as for arrays.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t[1] # the first element\n1\n\njulia> t[end] # the last element\n\"3\"\n\njulia> t[1:2] # the first two elements\n(1, 2.0)","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"A handy feature is the possibility to unpack a tuple over its values.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> a, b, c = t\n(1, 2.0, \"3\")\n\njulia> println(\"The values stored in the tuple are: $a, $b and $c\")\nThe values stored in the tuple are: 1, 2.0 and 3","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"Arrays can be unpacked similarly. However, tuples are usually used for storing a small number of values, while arrays are typically large. Recall that while tuples are immutable, arrays are mutable.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"warning: Exercise:\nCreate a tuple that contains the first four letters of the alphabet (these letters should be of type String). Then unpack this tuple into four variables a, b, c and d.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"details: Solution:\nSuch a tuple can be created easily using the standard syntax:julia> t = (\"a\", \"b\", \"c\", \"d\")\n(\"a\", \"b\", \"c\", \"d\")We can use the four variables and the = sign to unpack the tuple.julia> a, b, c, d = t\n(\"a\", \"b\", \"c\", \"d\")","category":"page"},{"location":"lecture_02/tuples/#Named-tuples","page":"Tuples and named tuples","title":"Named tuples","text":"","category":"section"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"Named tuples are similar to tuples, i.e., a named tuple is immutable, ordered, fixed-sized group of elements. The only difference is that each element consists of a name (identifier) and a value. Named tuples are created by the following syntax:","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t = (a = 1, b = 2.0, c = \"3\")\n(a = 1, b = 2.0, c = \"3\")","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"It is also possible to create a named tuple directly from variables.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> a = 1;\n\njulia> b = 2.0;\n\njulia> c = \"3\";\n\njulia> t = (; a, b, c)\n(a = 1, b = 2.0, c = \"3\")","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"Here the semicolon is mandatory because, without the semicolon, the result will be a tuple instead of a named tuple. Similarly to tuples, the elements of a named tuple can be accessed via square brackets. However, as opposed to tuples, it is impossible to access multiple elements at once.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t[1] # the first element\n1\n\njulia> t[end] # the last element\n\"3\"\n\njulia> t[1:2] # error\nERROR: MethodError: no method matching getindex(::@NamedTuple{a::Int64, b::Float64, c::String}, ::UnitRange{Int64})\n[...]","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"On the other hand, it is possible to get elements of a named tuple via their names or unpack elements directly to variables.","category":"page"},{"location":"lecture_02/tuples/","page":"Tuples and named tuples","title":"Tuples and named tuples","text":"julia> t.a\n1\n\njulia> t.c\n\"3\"\n\njulia> a, b, c = t\n(a = 1, b = 2.0, c = \"3\")\n\njulia> println(\"The values stored in the tuple are: a = $a, b = $b\")\nThe values stored in the tuple are: a = 1, b = 2.0","category":"page"},{"location":"lecture_13/ode/#Wave-equation","page":"Wave equation","title":"Wave equation","text":"","category":"section"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"Wave equation is one of the most important differential equation. It models wave propagation and has numerous applications in acoustics, electromagnetics or fluid dynamics.","category":"page"},{"location":"lecture_13/ode/#Statement","page":"Wave equation","title":"Statement","text":"","category":"section"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"We consider the simplest case of a one-dimensional wave equation, such as a string. The wave equation in tin0T has the form","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"fracpartial^2 y(tx)partial t^2 = c^2 fracpartial^2 y(tx)partial x^2","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The function y0Ttimes 0Ltomathbb R describes the displacement of the string. To obtain a complete formulation, we need to add boundary (in space) and initial (in time) conditions. Assuming that the string is fixed on its edges, the boundary conditions","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"y(cdot0) = y_0 quad y(cdotL) = y_L","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"are time-independent. The initial conditions are prescribed by functions","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"beginaligned\ny(0cdot) = f(cdot) \nfracpartial y(0cdot)partial t = g(cdot)\nendaligned","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"which vary in space. For consistency, we need f(0)=y_0 and f(L)=y_L.","category":"page"},{"location":"lecture_13/ode/#Solving-the-wave-equation","page":"Wave equation","title":"Solving the wave equation","text":"","category":"section"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The following few exercises show how to solve the wave equation via the finite differences technique. It discretizes both time and space into equidistant discretization. For a function h and a discretization stepsize Delta x, the approximation of the first derivative reads","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"fracpartialpartial xh(x) = frach(x+Delta x) - h(x)Delta x","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"A similar formula for the second derivatives reads","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"fracpartial^2partial x^2h(x) = frach(x+Delta x) - 2h(x) + h(x-Delta x)Delta x^2","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The following exercise derives the mathematical formulas needed for solving the wave equation.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"warning: Exercise:\nConsider equidistant discretizations with stepsizes Delta t and Delta x. Derive mathematical formulas for solving the one-dimensional wave equation on 0Ttimes 0L by applying finite differences in time and space. Do not write any code.Hint: Start with the initial time and compute the solution after each time step. Use the condition on f at the first time step, the condition on g at the second time step and the wave equation at further steps.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"details: Solution:\nThe wave equation needs to satisfy the boundary conditionsy(t0) = f(0)qquad y(tL) = f(L) qquadtext for all tin0Delta t2Delta tdotsTand the initial conditionsy(0x) = f(x)  qquadtext for all xinDelta x2Delta xdotsL-Delta xWe exclude xin 0L from the last equation because the boundary conditions already prescribe these values.Now we start increasing time. For the values at Delta t, we approximate the initial condition for the derivative by the finite difference and get y(Delta t x) = y(0 x) + Delta t g(x)At further times, we use the finite difference approximation of the second derivative to arrive atfracy(t+Delta tx) - 2y(tx) + y(t-Delta tx)Delta t^2 = c^2 fracy(tx+Delta x) - 2y(tx) + y(tx-Delta x)Delta x^2Since we already know the values at t and t - Delta t, we rearrange the previous formula to obtain the values at the next time. This yields the final formula:y(t + Delta tx) = fracc^2Delta t^2Delta x^2  Big(y(tx + Delta x) - 2y(tx) + y(tx - Delta x)Big) + 2y(tx) - y(t - Delta tx)","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The most challenging part is done: We have finished the discretization scheme. Now we need to code it. We will employ a structure storing the wave equation parameters. ","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"struct Wave\n    f\n    g\n    c\nend","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The first exercise solves the wave equation.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"warning: Exercise:\nWrite the function solve_wave(T, L, wave::Wave; n_t=100, n_x=100) that solves the wave equation.Hint: Follow the procedure from the previous exercise. Discretize time and space, initialize the solution, add the boundary conditions, add the initial conditions and finally, iterate over time.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"details: Solution:\nWe first discretize both time and space by the range function. Then we initialize the matrix y. We decide that the first dimension corresponds to time and the second one to space. We set the boundary conditions and fill y[:,1] with wave.f(0) and y[:,end] with wave.f(L). Since the wave at the initial moment equals to f, we set y[1,2:end-1] = wave.f.(xs[2:end-1]). Since the condition at t=Delta t amount toy(Delta t x) = y(0 x) + Delta t g(x)we write y[2,2:end-1] = y[1,2:end-1] + Δt*wave.g.(xs[2:end-1]). We must not forget to exclude the boundary points because the string position is attached there. For the remaining times, we use the formulay(t + Delta tx) = fracc^2Delta t^2Delta x^2  Big(y(tx + Delta x) - 2y(tx) + y(tx - Delta x)Big) + 2y(tx) - y(t - Delta tx)This gives rise to the following function.function solve_wave(T, L, wave::Wave; n_t=100, n_x=100)\n    ts = range(0, T; length=n_t)\n    xs = range(0, L; length=n_x)\n    Δt = ts[2] - ts[1]\n    Δx = xs[2] - xs[1]\n    y = zeros(n_t, n_x)\n    \n    # boundary conditions\n    y[:,1] .= wave.f(0)\n    y[:,end] .= wave.f(L)\n\n    # initial conditions\n    y[1,2:end-1] = wave.f.(xs[2:end-1])\n    y[2,2:end-1] = y[1,2:end-1] + Δt*wave.g.(xs[2:end-1])\n\n    # solution for t = 2Δt, 3Δt, ..., T\n    for t in 2:n_t-1, x in 2:n_x-1\n        ∂y_xx = (y[t, x+1] - 2*y[t, x] + y[t, x-1])/Δx^2\n        y[t+1, x] = c^2 * Δt^2 * ∂y_xx  + 2*y[t, x] - y[t-1, x]\n    end\n\n    return y\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"The best visualization of the wave equation is via animation. Each frame will be a plot of a row of y. We use the keyword arguments kwargs, where we store additional arguments for plotting. We run the for loop over all rows, create the animation via the @animate macro and save it into anim. To save the animation to the hard drive, we use the gif function.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"using Plots\n\nfunction plot_wave(y, file_name; fps = 60, kwargs...)\n    anim = @animate for (i, y_row) in enumerate(eachrow(y))\n        plot(\n            y_row;\n            title = \"t = $(i-1)Δt\",\n            xlabel = \"x\",\n            ylabel = \"y(t, x)\",\n            legend = false,\n            linewidth = 2,\n            kwargs...\n        )\n    end\n    gif(anim, file_name; fps, show_msg = false)\n    \n    return nothing\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"Now we can finally plot the solution.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"warning: Exercise:\nSolve the wave equation for L=frac32pi, T=240, c=002 and the initial conditionsbeginaligned\nf(x) = 2e^-(x-frac L2)^2 + fracxL \ng(x) = 0\nendalignedUse time discretization with stepsize Delta t=1 and the space discretization with number of points n_x=101 and n_x=7 steps. Plot two graphs.","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"details: Solution:\nFirst, we assign the parametersf(x,L) = 2*exp(-(x-L/2)^2) + x/L\ng(x) = 0\n\nL = 1.5*pi\nT = 240\nc = 0.02\n\nnothing # hideNow we create the wave structure, compute the solution and plot it for with different values of n_x.wave = Wave(x -> f(x,L), g, c)\n\ny1 = solve_wave(T, L, wave; n_t=241, n_x=101)\nplot_wave(y1, \"wave1.gif\"; ylims=(-2,3), label=\"\")\n\ny2 = solve_wave(T, L, wave; n_t=241, n_x=7)\nplot_wave(y2, \"wave2.gif\"; ylims=(-2,3), label=\"\")\n\nnothing # hide","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"(Image: )","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"(Image: )","category":"page"},{"location":"lecture_13/ode/","page":"Wave equation","title":"Wave equation","text":"If there are two waves in different phases (positions), please refresh the page. The waves should start from the same location and move at the same speed. This is an important property of any physical system: it is consistent. If we use a different discretization, their behaviour should be roughly similar. Of course, a finer spatial discretization results in smoother lines, but both waves have similar shapes and move at similar speeds. If we see that one moves significantly faster, there is a mistake in the code.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"using Plots\n\nf(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nf(x1,x2) = f([x1;x2])","category":"page"},{"location":"lecture_08/unconstrained/#Unconstrained-optimization","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"","category":"section"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Unconstrained optimization means that we optimize a function on the whole space X=mathbbR^n. Then the optimization problem reduces to","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"    textminimizeqquad f(x)","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"What do we look for when we minimize a function f over some X? The optimal point would be a global minimum, which is a point xin X which satisfies","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) le f(y) text for all yin X","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This point is often challenging to find. Sometimes we can find a local minimum, which is a global minimum on some small neighbourhood of x. However, as the following theorem suggests, we often need to lower our requirements even lower.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"todo: Theorem: Connection between optimization problems and gradients\nConsider a differentiable function f over X=mathbbR^n. If x is its local minimum, then nabla f(x)=0. Conversely, if f is convex, then every point x with nabla f(x)=0 is a global minimum of f.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Points with nabla f(x)=0 are known as stationary points. Optimization algorithms often try to find local minima or stationary points, hoping to minimize the function f. The reason is the following: To optimize f, we can evaluate it only at a limited number of points. Since evaluating f at a point conveys only information about the function value at this point or its small neighbourhood, we collect only local information about f. Therefore, unless f has a special structure, it is possible to obtain global results from only local evaluations. ","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"info: Take care:\nThis theorem does not hold if X is not the whole space. A simple counterexmple is minimization of f(x)=x on X=01.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Since the gradient is the direction of the steepest ascent, the straightforward idea is to move in the opposite direction. This gives rise to the gradient (or steepest) descent algorithm","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x^k+1 = x^k - alpha^knabla f(x^k)","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"where alpha_k0 is called stepsize. If this update converges, then x^k+1 and x^k are close to each other, and therefore nabla f(x^k)to 0. This means that this method converges to a stationary point.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The stepsize alpha^k0 is usually fixed and determined before the optimization is started. However, some methods use an automatic selection of the stepsize. One of the possibilities is the Armijo condition which looks for alpha^k satisfying","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x^k - alpha^knabla f(x^k)) le f(x^k) - c alpha^k nabla f(x^k)^2","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Here  cin(01) is a small constant, usually c=10^-4. Since the left-hand side is the function value at the new iterate x^k+1, the Armijo condition ensures that the sequence of function values is strictly decreasing. This prevents oscillations. Theoretical results ensure that there is some interval (0alpha_0) such that any alpha from this interval satisfies the Armijo condition. Therefore, to find some alpha satisfying the Armijo conditions, we start with some alpha_rm max and divide it by two until the condition is satisfied.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"info: Terminology:\nIn classical optimization, the usual terminology is:Variable is to be optimized. The example would be x.\nParameter is an external (fixed) parameter such as a material parameter. The example would be alpha.In machine learning, the usual terminology is:Parameter is to be optimized.\nHyperparameter is an external model parameter that is not optimized and needs to be tuned. The example is the steplength because the gradient descent finds a different solution for different steplength, but it is not changed during the optimization.The different terminology (and possibly the fact that there are adaptive schemes to select the steplength, which should make it a parameter instead of a hyperparameter) makes the notation confusing.","category":"page"},{"location":"lecture_08/unconstrained/#Gradient-descent","page":"Unconstrained optimization","title":"Gradient descent","text":"","category":"section"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"In this section, we will implement the gradient descent method.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"warning: Exercise: Gradient descent:\nImplement function optim, which takes as inputs function f, its gradient, starting point x^0 and fixed stepsize alpha and runs the gradient descent. Its output should be the first 100 iterations.This example is rather artificial because usually only the last iteration is returned and some stopping criterion is employed instead of the fixed number of iterations. We want to get all iterations to make visualizations.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"details: Solution:\nFirst we need to create an empty array into which we store the data. Then at every iteration we compute the gradient g(x), perform the update and save the new value of x.function optim(f, g, x, α; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    xs[:,1] = x\n    for i in 1:max_iter\n        x -= α*g(x)\n        xs[:,i+1] = x\n    end\n    return xs\nend\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The implementation does not use the values of f but only its gradient nabla f. If the algorithm converges x^k to bar x, then passing to the limit in the gradient update results in nabla f(bar x)=0. Therefore, as with most optimization methods, gradient descent looks for stationary points.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Before plotting the path taken by gradient descent, we create the create_anim function, which creates animations of path over the contour plot of f. From xlims and ylim, it creates discretizations xs and ys and then plots the contour plot as background. Since Animation requires updating a graph, we start with an empty graph, and we push a new image to the animation in every iteration. The final command gif saves the animation into file_name.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"using Random\n\nfunction create_anim(\n    f,\n    path,\n    xlims,\n    ylims,\n    file_name = joinpath(pwd(), randstring(12) * \".gif\");\n    xbounds = xlims,\n    ybounds = ylims,\n    fps = 15,\n)\n    xs = range(xlims...; length = 100)\n    ys = range(ylims...; length = 100)\n    plt = contourf(xs, ys, f; color = :jet)\n\n    # add constraints if provided\n    if !(xbounds == xlims && ybounds == ylims)\n        x_rect = [xbounds[1]; xbounds[2]; xbounds[2]; xbounds[1]; xbounds[1]]\n        y_rect = [ybounds[1]; ybounds[1]; ybounds[2]; ybounds[2]; ybounds[1]]\n        \n        plot!(x_rect, y_rect; line = (2, :dash, :red), label=\"\")\n    end\n\n    # add an empty plot\n    plot!(Float64[], Float64[]; line = (4, :arrow, :black), label = \"\")\n\n    # extract the last plot series\n    plt_path = plt.series_list[end]\n\n    # create the animation and save it\n    anim = Animation()\n    for x in eachcol(path)\n        push!(plt_path, x[1], x[2]) # add a new point\n        frame(anim)\n    end\n    gif(anim, file_name; fps = fps, show_msg = false)\n    return nothing\nend\n\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We now plot how gradient descent behaves.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"warning: Exercise: Gradient descent\nUse the implementation of the gradient descent to minimize the functionf(x) = sin(x_1 + x_2) + cos(x_1)^2from the starting point x^0=(0-1). Use the constant stepsize alpha=01. Store all iterations into matrix xs.Use the create_anim function to plot the iteration into a gif file.Use one line of code to evaluate the function values for all iterations xs and plot these function values.Hint: to evaluate all xs in one line, use iterate either via eachcol(xs) or eachrow(xs).","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"details: Solution:\nWe call optim from the previous exercise and then create the animation.x_gd = optim([], g, [0; -1], 0.1)\n\nxlims = (-3, 1)\nylims = (-2, 1)\ncreate_anim(f, x_gd, xlims, ylims, \"anim1.gif\")\n\nnothing # hideTo plot the function values, we need to iterate over all columns. We use [? for x in eachcol(x_gd)] and apply f(x) instead of ?. Another (more complicated) way is to iterate over indices instead of vectors and write [f(x_gs[:,i]) for i in 1:size(x_gd,2)].f_gd = [f(x) for x in eachcol(x_gd)]\n\nplot(f_gd, label=\"\", xlabel=\"Iteration\", ylabel=\"Function value\")\n\nsavefig(\"obj.svg\") # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: ) (Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The convergence looks very nice, and the function value decreases. Initially, the decrease is faster, but it slows down when the iterations get closer to the minimum.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"What happens if we choose a different stepsize? Let us try with two different values. First let us try alpha=001.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x_gd = optim([], g, [0; -1], 0.01)\n\ncreate_anim(f, x_gd, xlims, ylims, \"anim2.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"When the stepsize is reduced, the steps are shorter, and we would need to increase the number of iterations (and thus the computational time) to converge. When the stepsize is larger, say alpha=1, the situation is different.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x_gd = optim([], g, [0; -1], 1)\n\ncreate_anim(f, x_gd, xlims, ylims, \"anim3.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For a large stepsize, the algorithm gets close to the solution and then starts jumping around. If we further increase the stepsize, the algorithm will even diverge. Try it.","category":"page"},{"location":"lecture_08/unconstrained/#Adaptive-stepsize","page":"Unconstrained optimization","title":"Adaptive stepsize","text":"","category":"section"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The implementation of optim(f, g, x, α; max_iter=100) does not allow modifying the step selection. The simplest fix would be to include if conditions inside the function. However, this would result in a long function, which may be difficult to debug and modify. A more elegant solution is to create an abstract type.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"abstract type Step end","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For each possible step selection technique, we implement an optim_step method selecting the step. First, we create the gradient descent type GD as a subtype of Step by","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"struct GD <: Step\n    α::Float64\nend","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"It is a structure with parameter α. Then we create the optim_step function by","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"optim_step(s::GD, f, g, x) = -s.α*g(x)\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Due to the first input argument, it will be called only for the  GD stepsize. To access the parameter α, we need to retrieve it from the structure by s.α. Now we can modify the optim function by","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"function optim(f, g, x, s::Step; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    xs[:,1] = x\n    for i in 1:max_iter\n        x += optim_step(s, f, g, x)\n        xs[:,i+1] = x\n    end\n    return xs\nend\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The specification of the input s::Step allows for any subtype of the abstract type Step. Using this implentation results in","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"gd = GD(0.1)\nx_opt = optim(f, g, [0;-1], gd)\n\ncreate_anim(f, x_opt, xlims, ylims, \"anim4.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The result is the same as in the previous case. This is not surprising as the code does the same things; it is only written differently. The following exercise shows the power of defining the Step type.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"warning: Exercise: Armijo condition\nImplement the Armijo subtype of the Step type. It should have two parameters c from the definition and α_max which will be the initial value of alpha. The value alpha should be divided by two until the Armijo condition is satisfied.Then run the optimization with the Armijo stepsize selection and plot the animation.","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"details: Solution:\nWe define the type in the same way as for GD:struct Armijo <: Step\n    c::Float64\n    α_max::Float64\nendFor the search for the stepsize, we first save the values for the function value f(x) and the gradient nabla f(x). If we do not do this, it will be recomputed at every step. Then we initialize the value of alpha and run the while loop until the Armijo condition is satisfied. We add a termination condition α <= 1e-6 to prevent the loop from continuing indefinitely.function optim_step(s::Armijo, f, g, x)\n    fun = f(x)\n    grad = g(x)\n    α = s.α_max\n    while f(x .- α*grad) > fun - s.c*α*(grad'*grad)\n        α /= 2\n        if α <= 1e-6\n            warning(\"Armijo line search failed.\")\n            break\n        end\n    end\n    return -α*grad\nend\nnothing # hideThen we create the Armijo struct and run the optimization.gd = Armijo(1e-4, 1)\nx_opt = optim(f, g, [0;-1], gd)\n\ncreate_anim(f, x_opt, xlims, ylims, \"anim5.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Since the Armijo condition determines the optimal stepsize automatically, the convergence is much faster than for gradient descent. Moreover, it is not necessary to specify the stepsize. The price to pay is that every iteration needs to perform several function evaluations, which is not the case for standard gradient descent.","category":"page"},{"location":"lecture_07/pkg/#Package-management","page":"Package manager","title":"Package management","text":"","category":"section"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Julia provides a simple and intuitive built-in package manager that handles installing, updating and removing packages. The package manager offers an interactive Pkg REPL, which simplifies the package management process. We enter the Pkg REPL from the Julia REPL by pressing ]. To return to the Julia REPL, press backspace or ^C. After entering the Pkg REPL, a screen similar to the following one will appear:","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg>","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Registered packages can be installed by the add keyword.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> add JSON BSON","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"It is possible to install multiple packages by entering their names separated by spaces. The add keyword can also install unregistered packages by specifying the URL of a git repository.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> add https://github.com/JuliaLang/Example.jl","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"We can use both absolute and relative path to a local git repository.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> add /absolute/or/relative/path/MyPackage","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"The status keyword, abbreviated as st, can be used to list all installed packages.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.2.6\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master`\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"info: Adding specific version:\nThe syntax above installs the latest stable version of packages. In some cases, we may want to use an older or a not-yet-released package version. We can install such a specific version by appending the version number after the @ symbol.(@v1.6) pkg> add BSON@0.2.1\n\n(@v1.6) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.2.1\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master`\n  [682c06a0] JSON v0.21.1If a branch (or a certain commit) is not yet included in a registered version, we can explicitly track it by appending #branchname (or #commitSHA1) to the package name.(@v1.6) pkg> add BSON#master\n\n(@v1.6) pkg> add JSON#1231b521196de6697d682940b963167fbe4d5cd8\n\n(@v1.6) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.3.2 `https://github.com/JuliaIO/BSON.jl.git#master`\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master`\n  [682c06a0] JSON v0.21.1+ `https://github.com/JuliaIO/JSON.jl.git#1231b52`","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"We use the update keyword to update for registered and unregistered packages. If we do not provide a package name, all installed packages will be updated.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> update Example","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Sometimes it is helpful to disallow updating a package. This is done by the pin command.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> pin Example BSON\n\n(@v1.6) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.3.2 ⚲\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master` ⚲\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"The pin symbol ⚲ shows that the package is pinned. The keyword free removes the pin.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> free BSON\n\n(@v1.6) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.3.2\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master` ⚲\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"To remove a package, we use the rm or remove keyword.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> rm Example","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Like the help for functions, we can use ? in the Pkg REPL to list all its available commands.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(@v1.6) pkg> ?\n  Welcome to the Pkg REPL-mode. To return to the julia> prompt, either press backspace when\n  the input line is empty or press Ctrl+C.\n\n  Synopsis\n\n  pkg> cmd [opts] [args]\n\n  Multiple commands can be given on the same line by interleaving a ; between the commands.\n  Some commands have an alias, indicated below.\n\n  Commands\n\n  activate: set the primary environment the package manager manipulates\n\n  add: add packages to project\n\n  build: run the build script for packages\n[...]","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"compat: Non-interactive package manager:\nWe can also use the package manager in a non-interactive way from the Julia REPL by the Pkg package.using Pkg\nPkg.add([\"JSON\", \"BSON\"])\nPkg.add(url = \"https://github.com/JuliaLang/Example.jl\")","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"compat: JuliaHub:\nJuliaHub is a web service provided by Julia Computing that allows to explore the Julia ecosystem, build packages, and run code in the cloud. It allows for exploring packages, documentation, repositories and code written by other users.","category":"page"},{"location":"lecture_07/pkg/#Environments","page":"Package manager","title":"Environments","text":"","category":"section"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"So far, we have dealt with the basic package management: adding, updating, or removing packages. However, Julia package manager offers significant advantages over traditional package managers by organizing dependencies into environments. Environments should be familiar to people who use Python. The difference from Python is that Julia provides an effortless way to create and manage environments. Even though some utilities, such as Conda, simplify working with Python environments, Julia handles environments natively within Julia itself.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"You may have noticed the (v1.5) in the REPL prompt. It indicates the name of the active environment.  The active environment is the environment modified by Pkg commands such as add, rm, or update. We can set up a new environment by the activate command, followed by the absolute or relative path.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"julia> mkdir(\"./tutorial\") # create a folder named tutorial\n\"./tutorial\"\n\njulia> cd(\"./tutorial\") # change the working directory to tutorial\n\n(@v1.6) pkg> activate . # alternatively we can specify full path\n Activating new environment at `path/to/the/tutorial/Project.toml`\n\n(tutorial) pkg>","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"The example above creates an empty directory tutorial and activates a new environment inside it. The prompt in the package REPL changed from @v1.5 to tutorial. It indicates that tutorial is the active environment, and Pkg commands will modify it. Since it is a new environment, it has no installed packages.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(tutorial) pkg> status\nStatus `path/to/the/tutorial/Project.toml` (empty project)","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"The path printed by the status command (path/to/the/tutorial/Project.toml) is the location of the Project.toml file, where the package manager stores metadata for the environment.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Since tutorial is an environment, we can use the same commands as before.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(tutorial) pkg> add JSON BSON\n\n(tutorial) pkg> st\nStatus `path/to/the/tutorial/Project.toml`\n  [fbb218c0] BSON v0.2.6\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Since we added two new packages, this information is stored in the files Project.toml and Manifest.toml.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"julia> readdir(\"./tutorial\")\n2-element Vector{String}:\n \"Manifest.toml\"\n \"Project.toml\"","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"The Project.toml file describes the project on a high level. It contains the package/project dependencies and compatibility constraints. On the other hand, the Manifest.toml file is an absolute record of the state of packages used in the environment. It includes exact information about (direct and indirect) dependencies of the project. Given Project.toml and Manifest.toml, it is possible to instantiate the same package environment.","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"(tutorial) pkg> instantiate","category":"page"},{"location":"lecture_07/pkg/","page":"Package manager","title":"Package manager","text":"Different users may use different package versions. Since updated packages provide different functionality for some functions, instantiating is extremely useful for reproducing code across multiple computers.","category":"page"},{"location":"why/#Why-julia?","page":"Why Julia?","title":"Why julia?","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"There are many established programming languages like Python, Matlab, R, or C. When a new language is introduced, the natural question is why I should learn this new language. What are the advantages and disadvantages of this language? This section introduces significant advantages and disadvantages of Julia and compares it to Python, Matlab, R, and C.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"danger: Advantages:\nIntuitive and flexible syntax: Julia was designed to be easy to use and powerful at the same time. Julia provides a very intuitive syntax and supports many useful concepts from other languages such as generators from Python. More details and examples are provided in the separate section below.\nPerformance: Since Julia is a compiled language, code in Julia is generally faster than code written in pure Python or Matlab. More details and examples are provided in the separate section below.\nType system: Like Matlab or Python, it is not necessary to use type annotations for variable or function input arguments. However, since everything in Julia has its own type, it is possible to use type annotation. This allows the compiler to optimize the code, and it can also prevent mistakes.\nMultiple dispatch: Julia multiple dispatch means that one functions consist of multiple methods which may differ in the number of input arguments or their type. When a function is called, the most specific method definition matching the number and argument types is executed. This allows defining general functions such as convert for all conversion operations, instead of using specific function names like str2double typically used in Matlab.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"To be as objective as possible, we provide a list of Julia disadvantages.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"tip: Disadvantages:\nA limited number of packages: Even though Julia grows rapidly and there are many packages, it can not compete with the number of available packages in Python or R. However, Julia provides a simple way of interacting with other languages. If there is no adequate package in Julia, it is possible to use packages from other languages.\nSlow first run: Since Julia uses just-in-time compilation, the first call of every function is slower due to compilation. This slowdown can be significant if multiple functions are called for the first time. This includes creating a plot in a new Julia session because packages for plotting are large and use many functions. It results in a long time to the first plot (~20 s with Plots.jl).\nLimited number of job opportunities: Because Julia is a relatively new language, there is a limited number of job opportunities, especially compared to Python. On the other hand, there is a list of Julia users and Julia Computing customers on the official webpage of Julia Computing including Amazon, Google, IBM, Intel and many others.","category":"page"},{"location":"why/#Intuitive-and-flexible-syntax","page":"Why Julia?","title":"Intuitive and flexible syntax","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Julia provides very intuitive and yet flexible syntax, which allows users to write relatively complicated functions in a simple and readable way. As an example, we can compare the definition of the function that computes the Fibonacci number. A naive Matlab implementation of this function would be:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function f = fib(n)\n    if n < 2\n        f = n;\n    else\n        f = fib(n-1) + fib(n-2);\n    end\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We do not check whether the input argument is a non-negative integer for simplicity. Python would result in the following implementation:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"def fib(n):\n    return n if n<2 else fib(n-1) + fib(n-2)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Finally, an implementation in C would be close to:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"int fib(int n) {\n    return n < 2 ? n : fib(n-1) + fib(n-2);\n}","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We see that these three implementations are very different. Surprisingly, the implementation in C is the shortest one on par with python. The reason is that C allows using the ternary operator. Even though Matlab allows to write the if-else statement on one line, this would decrease the code readability. Julia can implement this function in a simple way.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"fib(n::Int) = n < 2 ? n : fib(n-1) + fib(n-2)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"At the same time, it is possible to use traditional multiline function declaration syntax.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function fib(n::Int)\n    if n < 2\n        return n\n    else\n        return fib(n-1) + fib(n-2)\n    end\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The annotation of the input argument type and the return keyword are optional and can be both omitted. Julia, therefore, supports different syntax for defining functions. This is very useful because it is possible to write simple functions on one line or use a multiline syntax for more complicated functions. Additionally, Julia authors took inspiration from other languages, and Julia provides many handy features known from other languages:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The syntax of matrix operations is inspired by Matlab.\nStatistical packages use similar syntax to R packages.\nIt is possible to use list comprehensions and generators like in Python.","category":"page"},{"location":"why/#Performance","page":"Why Julia?","title":"Performance","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"One of the most obvious advantages of Julia is its speed. Since Julia uses just-in-time compilation, it is possible to achieve the performance of C without using any special tricks or packages. It can be seen in the following figure, which shows a speed comparison of various languages for multiple micro-benchmarks. A full description of these micro-benchmarks can be found on the official Julia Micro-Benchmarks webpage.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"These micro-benchmarks test performance on a range of common code patterns, such as function calls, string parsing, sorting, numerical loops, random number generation, recursion, or array operations. It is important to say that the used benchmark codes are not optimized for maximal performance. Instead, the benchmarks are written to test the performance of identical algorithms and code patterns implemented in each language. The following figure shows a computational time increase against the C language for several benchmark functions. The time on the y axis is logarithmic.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"(Image: )","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"It is fair to say that sometimes other languages can use simple tricks to improve their performance. For example, the performance of Python can be enhanced by Numba: an open-source JIT compiler that translates a subset of Python and NumPy into fast machine code using the LLVM compiler. Since both Numba and Julia use the same compiler, it is interesting to compare the performance of Julia and Python+Numba.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"For the comparison consider the following example of estimating pi using the Monte Carlo sampling originally posted here. A naive implementation of such estimation in pure Python 3.8.5 (using NumPy for the random number generator) is as follows:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"import numpy as np\n\ndef estimate_pi(n):\n    n_circle = 0\n    for i in range(n):\n        x = 2*np.random.random() - 1\n        y = 2*np.random.random() - 1\n        if np.sqrt(x**2 + y**2) <= 1:\n           n_circle += 1\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"To track the computational time, we use the IPython 7.13.0 command shell in combination with the timeit package.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [2]: import timeit\n   ...: n = 10000000\n\nIn [3]: %timeit estimate_pi(n)\n18.3 s ± 990 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The average computation time is 18.3 seconds, which is a lot. The reason is that for loops in Python (and Matlab) are slow. One way to improve the performance is to use NumPy vectorized operations (it is a similar approach used often in Matlab to improve performance).","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"def estimate_pi_vec(n):\n    xy = 2*np.random.random((n, 2)) - 1\n    n_circle = (np.sqrt((xy**2).sum(axis = 1)) <= 1).sum()\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [5]: %timeit estimate_pi_vec(n)\n354 ms ± 21.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We use the same function to track the computational time, which amounts to 354 milliseconds. The vectorized version is 50 times faster than the pure Python implementation using the for loop. However, it requires rewriting the code and in many cases, which can often be very difficult or even impossible. Another approach is to use the Numba package mentioned above. The Numba package is straightforward to use by including one additional line of code before the function definition.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"import numba\n\n@numba.jit()\ndef estimate_pi_numba(n):\n    n_circle = 0\n    for i in range(n):\n        x = 2*np.random.random() - 1\n        y = 2*np.random.random() - 1\n        if np.sqrt(x**2 + y**2) <= 1:\n           n_circle += 1\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [7]: %timeit estimate_pi_numba(n)\n109 ms ± 2.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The result is quite impressive and the average computational time is only 109 milliseconds, which is more than 150 times faster than the pure Python implementation. However, Numba is not guaranteed to speed all computations.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"How fast is Julia? To answer this question, we use the same function definition as in the pure Python implementation.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function estimate_pi(n)\n    n_circle = 0\n    for i in 1:n\n        x = 2*rand() - 1\n        y = 2*rand() - 1\n        if sqrt(x^2 + y^2) <= 1\n           n_circle += 1\n        end\n    end\n    return 4*n_circle/n\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In Julia, we can use the BenchmarkTools package that allows simple benchmarking of the code. To track the computational time we use @benchmark macro.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"julia> using BenchmarkTools\n\njulia> n = 10000000\n10000000\n\njulia> @benchmark estimate_pi(n)\nBenchmarkTools.Trial: 56 samples with 1 evaluation.\n Range (min … max):  86.735 ms … 94.346 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     89.119 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   89.358 ms ±  1.659 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n                 ▁   ▃   █                                     \n  ▄▁▄▇▁▇▇▁▁▄▄▄▄▄▄█▄▄▁█▄▄▁█▇▇▄▁▁▁▄▄▁▁▇▇▁▇▁▇▄▁▄▁▁▁▁▄▄▁▇▁▁▁▁▄▄▁▄ ▁\n  86.7 ms         Histogram: frequency by time        92.7 ms <\n\n Memory estimate: 16 bytes, allocs estimate: 1.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We see that the average computation time is 89 milliseconds. Without any modifications, the Julia code is slightly faster than the Python implementation with Numba. Even though the performance gap is not large, the Numba package will only work on a small Python and NumPy functionalities subset. Of course, other packages such as Cython can be used to increase performance. But all these packages have the same problem as Numba and will not support all Python functionalities. Python was not designed to be compiled, which results in many limitations that can not be easily solved. On the other hand, Julia was designed to be fast and provide high-performance without taking any additional steps. Moreover, Julia performance is not restricted to a subset of the language as in the case of Numba and other similar packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<img class=\"docs-light-only\" src=\"https://raw.githubusercontent.com/JuliaTeachingCTU/JuliaCTUGraphics/main/logo/Julia-for-Optimization-and-Learning.svg\" alt=\"Julia for Optimization and Learning logo\">\n<img class=\"docs-dark-only\" src=\"https://raw.githubusercontent.com/JuliaTeachingCTU/JuliaCTUGraphics/main/logo/Julia-for-Optimization-and-Learning-dark.svg\" alt=\"Julia for Optimization and Learning logo\">","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Plots\nENV[\"GKSwstype\"] = \"100\"\ngr()","category":"page"},{"location":"","page":"Home","title":"Home","text":"Welcome to our course Julia for Optimization and Learning. This course consists of two parts:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Basics of Julia: Julia is a fast programming language for scientific computing. Designed and developed at MIT, it quickly keeps gaining popularity and scored rank 22 among programming languages in the PYPL rating (as of September 2021).\nApplications: The second part of the course will be dedicated to applications. The main emphasis will given to machine learning, but we will also go through statistics and differential equations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This course is taught at the Czech Technical University in Prague. It is part of the prg.ai minor, a study programme combining top courses from four faculties of two Prague universities.","category":"page"},{"location":"#What-will-we-emphasize?","page":"Home","title":"What will we emphasize?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main goals of the course are the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"You will learn the connections between theory and coding. There are many lectures which teach either only theory or only coding. We will show you both.\nYou will learn how to code efficiently. We will teach you to split the code into small parts which are simpler to debug or optimize. We will often show you several writing possibilities and comment on the differences.\nYou will learn about machine learning and neural networks. You will understand neural networks by writing a simple one from scratch. Then you will learn how to use packages to write simple code for complicated networks.\nYou will learn independence. The problem formulation of many exercises is very general, which simulates when no step-by-step procedure is provided.","category":"page"},{"location":"#What-will-you-learn?","page":"Home","title":"What will you learn?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Selected examples of what you will be able to write at the end of the course include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Efficient coding: The following plot can be created in twenty lines of code (Image: )\nNumerical techniques: You will learn many techniques to minimize functions (Image: )\nNeural networks: And apply techniques to train neural networks (Image: )\nFigure 1 contains digit 5 with probability 0.999683.\nFigure 2 contains digit 0 with probability 1.000000.\nFigure 3 contains digit 4 with probability 0.974734.\nConnection to Matlab, R or Python: Do you have a Matlab code which you need to run from Julia? No problem, write five lines of code to get (Image: )","category":"page"},{"location":"#Technical-details","page":"Home","title":"Technical details","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Scripts for each lecture is available at its own Github repository. For students attending the course at CTU, we list the requirements for completing the course in Czech and English.","category":"page"},{"location":"#Useful-materials","page":"Home","title":"Useful materials","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Official documentation\nCheatsheet for differences between Julia and Matlab and Python\nCheatsheet of basic functions\nCheatsheet of advanced functions\nThink Julia: How to Think Like a Computer Scientist\nFrom Zero to Julia!","category":"page"},{"location":"lecture_12/sparse/#Linear-regression-with-sparse-constraints","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"The standard regression problem reads","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"operatornameminimize_wqquad sum_i=1^n(w^top x_i - y_i)^2","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Often, a regularization term is added. There are two possibilities. The ridge regression adds the weighted squared l_2-norm penalization term to the objective:","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"operatornameminimize_wqquad sum_i=1^n(w^top x_i - y_i)^2 + fracmu2w_2^2","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"LASSO adds the weighted l_1-norm penalization term to the objective:","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"operatornameminimize_wqquad sum_i=1^n(w^top x_i - y_i)^2 + mu w_1","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Both approaches try to keep the norm of parameters w small to prevent overfitting. The first approach results in a simpler numerical method, while the second one induces sparsity. Before we start with both topics, we will briefly mention matrix decompositions which plays a crucial part in numerical computations.","category":"page"},{"location":"lecture_12/sparse/#matrix-eigen","page":"Linear regression with sparse constraints","title":"Theory of matrix eigendecomposition","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Consider a square matrix Ain mathbb R^ntimes n with real-valued entries. We there exist lambdainmathbb R and vinmathbb R^n such that","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Av = lambda v","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"we say that lambda is a eigenvalue of A and v is the corresponding eigenvector.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"For the rest of this section, we will assume that A is a symmetric matrix. Then these eigenvector are perpendicular to each other. We create the diagonal matrix Lambda with eigenvalues on diagonal and the matrix Q with columns consisting of the corresponding eigenvectors. Then we have","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"A = QLambda Q^top","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"and for any real number mu, we also have","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"A + mu I = Q(Lambda + mu I) Q^top","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Since the eigenvectors are perpendicular, Q is an orthonormal matrix and therefore Q^-1 = Q^top. This implies that we can easily invert the matrix A + mu I by","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"(A + mu I)^-1 = Q (Lambda + mu I)^-1 Q^top","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Because Lambda + mu I is a diagonal matrix, its inverse is simple to compute.","category":"page"},{"location":"lecture_12/sparse/#Theory-of-ridge-regression","page":"Linear regression with sparse constraints","title":"Theory of ridge regression","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"The optimality condition for the ridge regression reads","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"X^top (Xw - y) + mu w = 0","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Therefore, the optimal solution satisfies","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"w = (X^top X + mu I)^-1X^top y","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"For mu=0, we obtain the classical result for the linear regression. Since X^top X is symmetric, we can compute its eigendecomposition","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"X^top X = QLambda Q^top","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Then the formula for optimal weights simplifies into ","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"w = Q(Lambda+mu I)^-1 Q^top X^top y","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Since this formula uses only matrix-vector multiplication and an inversion of a diagonal matrix, we can employ it to fast compute the solution for multiple values of mu.","category":"page"},{"location":"lecture_12/sparse/#lasso","page":"Linear regression with sparse constraints","title":"Theory of LASSO","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Unlike ridge regression, LASSO does not have a closed-form solution. Since it is a structured convex problem, it can be solved the ADMM algorithm. It is a primal-dual algorithm, which employs the primal original variable w, the primal auxiliary variable z and the dual variable u with the iterative updates:","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"beginaligned\nw^k+1 = (X^top X + rho I)^-1(X^top y + rho z^k - rho u^k) \nz^k+1 = S_mu  rho(w^k+1 + u^k) \nu^k+1 = u^k + w^k+1 - z^k\nendaligned","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Here, rho  0 is an arbitrary number and","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"S_eta(z) = maxz - eta 0 - max-z -eta 0","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"is the so-called soft thresholding operator. Since these updates must be performed many times, it may be a good idea to perform the same factorization of the matrix X^top X + rho I as in the case of ridge regression.","category":"page"},{"location":"lecture_12/sparse/#Ridge-regression","page":"Linear regression with sparse constraints","title":"Ridge regression","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"We will randomly generate 10000 samples in mathbb R^1000.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"using LinearAlgebra\nusing Random\nusing Plots\n\nn = 10000\nm = 1000\n\nRandom.seed!(666)\nX = randn(n, m)\n\nnothing # hide","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"The real dependence depends only on the first two features and reads","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"y = 10x_1 + x_2","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"This is a natural problem for sparse models because most of the weights should be zero. We generate the labels but add noise to them.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"y = 10*X[:,1] + X[:,2] + randn(n)\n\nnothing # hide","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"The first exercise compares both approaches to solving the ridge regression.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"warning: Exercise:\nImplement the methods for the ridge_reg function. Verify that the result in the same result.Hints:The eigendecomposition can be found by eigen(A) or eigen(A).values.\nThe identity matrix is implemented by I in the LinearAlgebra package.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"details: Solution:\nThe simple implementation for the solution is the same as in the case of linear regression. We only need to add μ*I.ridge_reg(X, y, μ) = (X'*X + μ*I) \\ (X'*y)\n\nnothing # hideWe first compute the eigendecomposition and save it into eigen_dec. Then we extract the eigenvector and eigenvalues. We also transpose the matrix Q and save it into Q_inv so that we do not have to compute it repeatedly.eigen_dec = eigen(X'*X)\nQ = eigen_dec.vectors\nQ_inv = Matrix(Q')\nλ = eigen_dec.values\n\nnothing # hideThe more sophisticated way of solving the ridge regression contains only matrix-vector multiplication and the inversion of the diagonal matrix (Lambda + mu I)^-1. We need to properly add paranthesis, to start multiplication from the right and evade matrix-matrix multiplication, which would occur if we started from the left. Since the matrix Lambda + mu I is diagonal, its inverse is the digonal matrix formed from the inverted diagonal.ridge_reg(X, y, μ, Q, Q_inv, λ) = Q * ((Diagonal(1 ./ (λ .+ μ)) * ( Q_inv * (X'*y))))\n\nnothing # hideWhen we compare both solution, we see that they are the same.w1 = ridge_reg(X, y, 10)\nw2 = ridge_reg(X, y, 10, Q, Q_inv, λ)\n\nnorm(w1 - w2)","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"To test the speed, we use the BenchmarkTools package. The second option is significantly faster. The price to pay is the need to pre-compute the matrix decomposition.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"julia> using BenchmarkTools\n\njulia> @btime ridge_reg(X, y, 10);\n  114.182 ms (9 allocations: 22.91 MiB)\n\njulia> @btime ridge_reg(X, y, 10, Q, Q_inv, λ);\n  6.194 ms (5 allocations: 39.69 KiB)","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Now we create multiple values of mu and compute the ridge regression for all of them. Since the broadcasting would broadcast all matrices, we need to fix all but one by the Ref command.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"μs = range(0, 1000; length=50)\nws = hcat(ridge_reg.(Ref(X), Ref(y), μs, Ref(Q), Ref(Q_inv), Ref(λ))...)\n\nplot(μs, abs.(ws');\n    label=\"\",\n    yscale=:log10,\n    xlabel=\"mu\",\n    ylabel=\"weights: log scale\",\n)\n\nsavefig(\"Sparse1.svg\") # hide","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"(Image: )","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"The regularization seems to have a small effect on the solution.","category":"page"},{"location":"lecture_12/sparse/#Lasso","page":"Linear regression with sparse constraints","title":"Lasso","text":"","category":"section"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"For LASSO, we define the soft thresholding operator.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"S(x, η) = max(x-η, 0) - max(-x-η, 0)\n\nnothing # hide","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Then we define the iterative updates from ADMM. It is important that we allow to insert the initial values for w^0, z^0 and u^0. If they are not provided, they are initialized by zeros with the correct dimension. We should implement a proper termination condition but, for simplicity, we run ADMM for a fixed number of iterations.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"function lasso(X, y, μ, Q, Q_inv, λ;        \n        max_iter = 100,\n        ρ = 1e3,\n        w = zeros(size(X,2)),\n        u = zeros(size(X,2)),\n        z = zeros(size(X,2)),\n    )\n    \n    for i in 1:max_iter\n        w = Q * ( (Diagonal(1 ./ (λ .+ ρ)) * ( Q_inv * (X'*y + ρ*(z-u))))) \n        z = S.(w + u, μ / ρ)\n        u = u + w - z\n    end\n    return w, u, z  \nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"Finally, we compute the values for all regularization parameters mu. The second line in the loop says that if i=1, then run LASSO without the initial values, and if i1, then run it with the initial values from the previous iteration. SInce the visibility of w, u and z is only one iteration, we need to specify that they are global variables.","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"ws = zeros(size(X,2), length(μs))\n\nfor (i, μ) in enumerate(μs)\n    global w, u, z\n    w, u, z = i > 1 ? lasso(X, y, μ, Q, Q_inv, λ; w, u, z) : lasso(X, y, μ, Q, Q_inv, λ)\n    ws[:,i] = w\nend","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"When we plot the parameter values, we see that they are significantly smaller than for the ridge regression. This is precisely what we meant when we mentioned that l_1-norm regularization induces sparsity. ","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"plot(μs, abs.(ws');\n    label=\"\",\n    yscale=:log10,\n    xlabel=\"mu\",\n    ylabel=\"weights: log scale\",\n)","category":"page"},{"location":"lecture_12/sparse/","page":"Linear regression with sparse constraints","title":"Linear regression with sparse constraints","text":"info: Warm start:\nThe technique of starting from a previously computed value is called warm start or hor start. It is commonly used when some parameter changes only slightly. Then the solution changes only slightly and the previous solution provides is close to the new solution. Therefore, we initialize the algorithm from the old solution.","category":"page"},{"location":"lecture_09/logistic/#log-reg","page":"Logistic regression","title":"Logistic regression","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We continue with logistic regression, where the labels are discrete variables. Most regression models employ the sigmoid function","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"sigma(z) = frac11+e^-z = frace^z1+e^z","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"because its values are in the interval 01 and can be interpreted as probabilities.","category":"page"},{"location":"lecture_09/logistic/#Theory-of-logistic-regression","page":"Logistic regression","title":"Theory of logistic regression","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The name logistic regression is misleading because it is actually a classification problem. In its simplest form, it assumes binary labels yin01 and predicts the positive and negative classes with probabilities","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"beginaligned\nmathbbP(y=1mid x) = sigma(w^top x) = frac11+e^-w^top x \nmathbbP(y=0mid x) = 1 - sigma(w^top x) = frace^-w^top x1+e^-w^top x\nendaligned","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Denoting hat y = mathbbP(y=1mid x) the probabily of predicting 1, the loss function is the cross-entropy loss","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"operatornameloss(yhat y) = - ylog hat y - (1-y)log(1-hat y)","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"info: Cross-entropy loss:\nEven though the cross-entropy loss may seem overwhelming, it is quite simple. When a sample is of the positive class, we have y=1, and the cross-entropy loss reduces tooperatornameloss(1hat y) = - log hat ySince hat y lies in the interval (01) due to the sigmoid function, the cross-entropy is minimized when hat y = 1. Since we get similar results for y=0, the cross-entropy is minimal whenever the labels y equal to the predictions hat y.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Then is not difficult to show that then the logistic regression problems reads","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"operatornameminimize_wqquad frac1nsum_i=1^nleft(log(1+e^-w^top x_i) + (1-y_i)w^top x_i right)","category":"page"},{"location":"lecture_09/logistic/#soft-hard","page":"Logistic regression","title":"Soft and hard predictions","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The previous paragraph used the soft prediction, where the output was the probability hat y of the positive class. If we need to provide a hard prediction, we predict the positive class whenever hat yge frac 12 and the negative class whenever hat y  frac12.  Since","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"hat y = frac11+e^-w^top x ge frac12","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"is equivalent to","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"w^top x ge 0","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"the prediction function is again linear.","category":"page"},{"location":"lecture_09/logistic/#Numerical-method","page":"Logistic regression","title":"Numerical method","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The logistic regression can be optimized by Newton's method. Denoting the loss function L(w), the Newton's method performs updates","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"w^k+1 = w^k - nabla^2 L(w^k)^-1nabla L(w^k)","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The partial derivative of L with respect to one component equals to","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"beginaligned\nfracpartial Lpartial w_j(w) = frac1nsum_i=1^nleft(-frac11+e^-w^top x_ie^-w^top x_ix_ij + (1-y_i)x_ij right) \n= frac1nsum_i=1^nleft(-frac11+e^w^top x_ix_ij + (1-y_i)x_ij right)\nendaligned","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"where x_ij is the j-th component of x_i (it is also the (ij) entry of matrix X). The second partial derivative amounts to","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"fracpartial^2 Lpartial w_j partial w_k(w) = frac1nsum_i=1^n frac1(1+e^w^top x_i)^2e^w^top x_ix_ijx_ik = frac1nsum_i=1^n hat y_i(1-hat y_i)x_ijx_ik","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Now we will write it in a more compact notation (recall that x_i is a column vector). We have","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"beginaligned\nnabla L(w) = frac1n sum_i=1^n left((hat y_i-1)x_i + (1-y_i)x_i right) = frac1n sum_i=1^n (hat y_i-y_i)x_i  \nnabla^2 L(w) = frac 1n sum_i=1^nhat y_i(1-hat y_i)x_i x_i^top\nendaligned","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"If the fit is perfect, y_i=hat y_i, then the Jacobian nabla L(w) is zero. Then the optimizer minimized the objective and satisfied the optimality condition.","category":"page"},{"location":"lecture_09/logistic/#Loading-and-preparing-data","page":"Logistic regression","title":"Loading and preparing data","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The last part predicted a continuous variable. This part will be closer to the iris dataset spirit: It will predict one of two classes. We load the data as before.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using StatsPlots\nusing RDatasets\n\niris = dataset(\"datasets\", \"iris\")\n\nnothing # hide","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The data contain three classes. However, we considered only binary problems with two classes. We therefore cheat.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"warning: Exercise:\nCreate the iris_reduced dataframe in the following way:Label \"setosa\" will be deleted.\nLabel \"versicolor\" will be the negative class.\nLabel \"virginica\" will be the positive class.\nAdd the intercept column with ones as entries.For the features, consider only petal length and petal width.Hint: Use the Query package or do it manually via the !insertcols function.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"details: Solution:\nThe modification of the dataframe can be by the Query package.using Query\n\niris_reduced = @from i in iris begin\n    @where i.Species != \"setosa\"\n    @select {\n        i.PetalLength,\n        i.PetalWidth,\n        intercept = 1,\n        i.Species,\n        label = i.Species == \"virginica\",\n    }\n    @collect DataFrame\nend\n\nnothing # hideWe can also perform this procedure manually.iris_reduced2 = iris[iris.Species .!= \"setosa\", :]\niris_reduced2 = iris_reduced2[:,[3;4;5]]\n\ninsertcols!(iris_reduced2, 3, :intercept => 1)\ninsertcols!(iris_reduced2, 5, :label => iris_reduced2.Species .== \"virginica\")\n\nnothing # hideWe can check that both approaches give the same result.isequal(iris_reduced, iris_reduced2)","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Now we extract the data X and labels y. Since iris_reduced is a DataFrame, we need to convert it first into a Matrix. The matrix X is formed by the petal length, width and the intercept. ","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"X = Matrix(iris_reduced[:, 1:3])\ny = iris_reduced.label\n\nnothing # hide","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We again plot the data. Since we are interested in a different prediction than last time, we will plot them differently.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"warning: Exercise:\nSince X has two features (columns), it is simple to visualize. Use scatter plot to show the data. Use different colours for different classes. Try to produce a nice graph by including names of classes and axis labels (petal length and petal width).","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"details: Solution:\nWe make use of the iris_reduced variable. To plot the points in different colours, we use the keyword group = :Species.using Plots\n\n@df iris_reduced scatter(\n    :PetalLength,\n    :PetalWidth;\n    group = :Species,\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    legend = :topleft,\n)\n\nsavefig(\"iris1.svg\") # hide","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"(Image: )","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We see that the classes are almost perfectly separable. It would not be difficult to estimate the separating hyperplane by hand. However, we will do it automatically.","category":"page"},{"location":"lecture_09/logistic/#Training-the-classifier","page":"Logistic regression","title":"Training the classifier","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"warning: Exercise:\nWrite a function log_reg which takes as an input the dataset, the labels and the initial point. It should use Newton's method to find the optimal weights w. Print the results when started from zero.It would be possible to use the code optim(f, g, x, s::Step) from the previous lecture and define only the step function s for the Newton's method. However, sometimes it may be better to write simple functions separately instead of using more complex machinery.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"details: Solution:\nTo write the desired function, we need to implement the gradient and Hessian from derived in the theoretical lecture. First, we define the sigmoid function in σ. Then we need to create hat y. We may use for loop notation [σ(w'*x) for x in eachrow(X)]. However, in this case, it is simpler to use matrix operations σ.(X*w) to get the same result. The gradient can be written in the same way. Again, we use matrix notation. For the Hessian, we first create X_mult = [row*row' for row in eachrow(X)] which computes all products x_ix_i^top. This creates an array of length 100; each element of this array is a 2times 2 matrix. Since it is an array, we may multiply it by y_hat.*(1 .-y_hat). As mean from the Statistics package operates on any array, we can call it (or similarly sum). We may use mean(???) but we find the alternative  ??? |> mean more readable in this case. We use hess \\ grad, as explained in the previous lecture for Newton's method, to update the weights.using Statistics\n\nσ(z) = 1/(1+exp(-z))\n\nfunction log_reg(X, y, w; max_iter=100, tol=1e-6)\n    X_mult = [row*row' for row in eachrow(X)]\n    for i in 1:max_iter\n        y_hat = σ.(X*w)\n        grad = X'*(y_hat.-y) / size(X,1)\n        hess = y_hat.*(1 .-y_hat).*X_mult |> mean\n        w -= hess \\ grad\n    end\n    return w\nend\n\nnothing # hideThe definition of X_mult should be outside the for loop, as it needs to be computed only once. After the tough work, it remains to call it.w = log_reg(X, y, zeros(size(X,2)))\n\nnothing # hide","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The correct solution is","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"println(round.(w, digits=4)) # hide","category":"page"},{"location":"lecture_09/logistic/#Analyzing-the-solution","page":"Logistic regression","title":"Analyzing the solution","text":"","category":"section"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We can now show the solution. Since the intercept is the third component with x_3=1, the section on soft and hard predictions derived that the separating hyperplane takes the form","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"w_1x_1 + w_2x_2 + w_3 = 0","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"To express it as a function, we obtain","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"operatornamesepar(x_1) = x_2 = frac-w_1x_1 - w_3w_2","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Now we plot it.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"separ(x::Real, w) = (-w[3]-w[1]*x)/w[2]\n\nxlims = extrema(iris_reduced.PetalLength) .+ [-0.1, 0.1]\nylims = extrema(iris_reduced.PetalWidth) .+ [-0.1, 0.1]\n\n@df iris_reduced scatter(\n    :PetalLength,\n    :PetalWidth;\n    group = :Species,\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    legend = :topleft,\n    xlims,\n    ylims,\n)\n\nplot!(xlims, x -> separ(x,w); label = \"Separation\", line = (:black,3))\n\nsavefig(\"iris2.svg\") # hide","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"(Image: )","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Anything above the separating hyperplane is classified as virginica, while anything below it is versicolor.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"This is the optimal solution obtained by the logistic regression. Since the norm of the gradient","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using LinearAlgebra\n\ny_hat = σ.(X*w)\ngrad = X'*(y_hat.-y) / size(X,1)\nnorm(grad)","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"equals to zero, we found a stationary point. It can be shown that logistic regression is a convex problem, and, therefore, we found a global solution.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The picture shows that there are misclassified samples. The next exercise analyses them.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"warning: Exercise:\nCompute how many samples were correctly and incorrectly classified.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"details: Solution:\nSince hat y_i is the probability that a sample is of the positive class, we will predict that it is positive if this probability is greater than frac 12. Then it suffices to compare the predictions pred with the correct labels y.pred = y_hat .>= 0.5\n\"Correct number of predictions: \" * string(sum(pred .== y))\n\"Wrong   number of predictions: \" * string(sum(pred .!= y))\n\nnothing # hideThere is an alternative (but equivalent way). Since the separating hyperplane has form w^top x, we predict that a sample is positive whenever w^top xge 0. Write arguments on why these two approaches are equivalent.","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The correct answer is","category":"page"},{"location":"lecture_09/logistic/","page":"Logistic regression","title":"Logistic regression","text":"println(\"Correct number of predictions: \" * string(sum(pred .== y))) # hide\nprintln(\"Wrong   number of predictions: \" * string(sum(pred .!= y))) # hide","category":"page"},{"location":"lecture_10/theory/#Theory-of-neural-networks","page":"Theory of neural networks","title":"Theory of neural networks","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Neural networks appeared for the first time decades ago but were almost forgotten after a few years. Their resurgence in the last one or two decades is mainly due to available computational power. Their impressive list of applications include:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"One of the first applications was reading postal codes to automatize the sorting of letters. Since only ten black and white digits can appear at five predetermined locations, simple networks were used.\nA similar type of neural (convolutional) networks is used in autonomous vehicles to provide information about cars, pedestrians or traffic signs. These networks may also use bounding boxes to specify the position of the desired object.\nWhile the previous techniques used the 2D structure of the input (image), recurrent neural networks are used for series-type data (text, sound). The major application is automatic translators.\nAnother application includes generating new content. While practical applications such as artistic composition exist, these networks are often used to generate fake content (news, images).","category":"page"},{"location":"lecture_10/theory/#Neural-networks","page":"Theory of neural networks","title":"Neural networks","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The first three bullets from the previous paragraph are all used for classification. The idea is the same as for linear networks. For an input x with a label y, the classifier minimizes the loss between the prediction operatornamepredict(wx) and the label y. The operatornamepredict function has two parameters: w is to be trained (weights) while x is input (data). Having n samples (data points), the minimization problem reads","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornameminimize_wqquad frac1nsum_i=1^n operatornameloss(y_i operatornamepredict(wx_i))","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The previous lecture used the linear classifier operatornamepredict(wx)=w^top x and the cross-entropy loss for classification and the mean squared error for regression.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Neural networks use more complex function than linear for better prediction power. At the same time, this function must satisfy: ","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"It has good approximative quality.\nIt does not contain many parameters to learn (train).\nThe computation of derivatives (training) is simple.","category":"page"},{"location":"lecture_10/theory/#Layers","page":"Theory of neural networks","title":"Layers","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The previous bullets are elegantly achieved by representing the neural network via layers. The input x enters the first layers, the output of the first layer goes into the second layer and so on. Mathematically speaking, a network with M layers has the structure","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"hat y = operatornamepredict(wx) = (f_M circ dots circ f_1)(x)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where f_1dotsf_M are individual layers. Most of these layers depend on the weights w, but we omit this dependence for simplicity. On the other hand, only the first layer f_1 depends directly on the input x. Since two layers that are not next to each other (such as the first and the third layer) are not directly connected, this allows for the simple propagation of function values and derivatives.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/theory/#Dense-layer","page":"Theory of neural networks","title":"Dense layer","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The dense layer is the simplest layer which has the form","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"f_m(a) = l_m(W_ma + b_m)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where W_m is a matrix of appropriate dimensions, b_m is the bias (shift) and l_m is an activation function. The weights of the neural network, which need to be trained, would be w=(W_mb_m)_m in this case.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The activation function is usually written as l_mmathbbRtomathbbR and its operation on the vector W_mz + b_m is understood componentwise. Examples of activation functions include:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"beginaligned\ntextSigmoidl(z) = frac11+e^-z \ntextReLUl(z) = operatornamemax0z \ntextSoftplusl(z) = log(1+e^z) \ntextSwishl(z) = fracz1+e^-z \nendaligned","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"using Plots\n\nsigmoid(x) = 1 / (1 + exp(-x))\nReLU(x) = max(0, x)\nsoftplus(x) = log(1 + exp(x))\nswish(x) = x / (1 + exp(-x))\n\nx = -4:0.01:4\n\nplot(\n    plot(x, sigmoid; title = \"Sigmoid\"),\n    plot(x, ReLU; title = \"ReLU\"),\n    plot(x, softplus; title = \"Softplus\"),\n    plot(x, swish; title = \"Swish\");\n    linewidth = 2,\n    ylims = (-1, 4),\n    legend = false,\n)\n\nsavefig(\"Activation.svg\")","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/theory/#Softmax-layer","page":"Theory of neural networks","title":"Softmax layer","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The cross-entropy loss function (see below) requires that its input is a probability distribution. To achieve this, the softmax layer is applied directly before the loss function. Its formulation is","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornamesoftmax(a_1dotsa_K) = frac1sum_k=1^K e^a_k(e^a_1 dots e^a_K)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The exponential ensures that all outputs are positive. The normalization ensures that the sum of the outputs is one. Therefore, it is a probability distribution. When a dense layer precedes the softmax layer, it is used without any activation function (as, for example, ReLU would result in many probabilities being the same).","category":"page"},{"location":"lecture_10/theory/#One-hot-and-one-cold-representation","page":"Theory of neural networks","title":"One-hot and one-cold representation","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"One-hot and one-cold representations are directly connected with the softmax layer. The one-cold representation is \"the normal one\", while the one-hot representation is its probability distribution. For example, for the iris dataset, we encode virginica as (100), versicolor as (010) and setosa as (001).","category":"page"},{"location":"lecture_10/theory/#Other-layers","page":"Theory of neural networks","title":"Other layers","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"There are many other layers (convolutional, recurrent, pooling), which we will go through in the next lesson.","category":"page"},{"location":"lecture_10/theory/#Loss-functions","page":"Theory of neural networks","title":"Loss functions","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The most commonly used loss functions are:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Mean) squared error\noperatornameloss(yhat y) = (y-hat y)^2\nCross-entropy\noperatornameloss(yhat y) = - sum_k=1^K y_klog hat y_k\nBinary cross-entropy\noperatornameloss(yhat y) = - ylog hat y - (1-y)log(1- hat y)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Mean square error is usually used for regression problems while both cross-entropies for classification problem. The former for multi-class (K2) and the latter for binary (K=2) problems.","category":"page"},{"location":"lecture_10/theory/#Making-predictions","page":"Theory of neural networks","title":"Making predictions","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"For classification with K classes, the classifier predicts a probability distribution of K classes. The hard prediction is the label with the highest probability. Using the above terminology, the classifier output has the one-hot form, while the actual prediction has the one-cold form.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The most common metric for evaluating classifiers is the accuracy defined by","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornameaccuracy = frac 1nsum_i=1^n I(y_i = hat y_i)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where I is the characteristic (0/1) function which counts how often the argument is satisfied. With abuse of notation, we use both the label y_i and the prediction hat y_i in the one-cold representation. Therefore, accuracy measures the fraction of samples with correct predictions.","category":"page"},{"location":"lecture_10/theory/#Overfitting-and-regularization","page":"Theory of neural networks","title":"Overfitting and regularization","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"While large neural networks may fit arbitrarily precisely, this is usually not preferred as overfitting may occur. This is especially true for large networks with more parameters than samples.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"using Plots\nusing Random\n\nRandom.seed!(666)\n\nn = 10\nx = rand(n)\ny = x.^2 .+ 0.01*randn(n)\n\nscatter(x,y)\n\nX = zeros(n, n)\nfor i in 1:n\n    X[:,i] = x.^(i-1)\nend\n\nw = X \\ y\n\nf(x) = sum([w[i]*x^(i-1) for i in 1:n])\n\nx_plot = 0:0.001:1\n\nscatter(x, y, label=\"Data\", ylim=(-0.01,1.01), legend=:topleft)\nplot!(x_plot, f.(x_plot), label=\"Prediction\")\nplot!(x_plot, x_plot.^2, label=\"True dependence\")\n\nsavefig(\"Overfit.svg\")","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This figure shows data with quadratic dependence and a small added error. While the complex classifier (a polynomial of order 9) fits the data perfectly, the correct classifier (a polynomial of order 2) fits the data slightly worse, but it is much better at predicting unseen samples. The more complicated classifier overfits the data. ","category":"page"},{"location":"lecture_10/theory/#Preventing-overfitting","page":"Theory of neural networks","title":"Preventing overfitting","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Multiple techniques were developed to prevent overfitting.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Early stopping stops the algorithm before it finds an optimum. This goes against the spirit of optimization as the loss function is actually not optimized.\nRegularization adds a term to the objective funtion, usually the squared l_2 norm of weights\noperatornameminimizeqquad frac1nsum_i=1^n operatornameloss(y_i operatornamepredict(wx_i)) + fraclambda2w^2\nThe more complicated classifier from the figure above contains (among others) the term 20222x^9. Since the coefficient is huge, its l_2 norm would be huge as well. Regularization prevents such classifiers. Another possibility is the (non-differentiable) l_1 norm, which induces sparsity (many weights should be zero).\nSimple networks cannot approximate overly complicated functions, and they can also prevent overfitting.","category":"page"},{"location":"lecture_10/theory/#Train-test-split","page":"Theory of neural networks","title":"Train-test split","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"How should the classifier be evaluated? The figure above suggests that it is a bad idea to evaluate it on the same data where it was trained. The dataset is usually split into training and testing sets. The classifier is trained on the training and evaluated on the testing set. The classifier is not allowed to see the testing set during training. When the classifier contains many hyperparameters, which need to be tuned, the dataset is split into training, validation and testing sets. Then multiple classifiers are trained on the training set, the best values of hyperparameters are selected on the validation set, and the classifier performance is evaluated on the testing set.","category":"page"},{"location":"lecture_10/theory/#Additional-topics","page":"Theory of neural networks","title":"Additional topics","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The following result shows that even shallow neural networks (not many layers) can approximate any continuous function well. As the proof suggests (Exercise 5), the price to pay is that the network needs to be extremely wide (lots of hidden neurons).","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"compat: BONUS: Universal approximation of neural networks\nLet gabto mathbbR be a continuous function defined on an interval. Then for every varepsilon0, there is a neural network f such that f-g_inftyle varepsilon. Moreover, this network can be chosen as a chain of the following two layers:Dense layer with the ReLU activation function.\nDense layer with the identity activation function.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"A prerequisite for training neural networks is the efficient computation of derivatives. We derive this computation in the next box. Even though it looks complicated, it is just a simple application of the chain rule. It consists of forward and backward passes. The forward pass starts with the input, computes the values at each neuron and finishes with evaluating the loss function. The backward pass starts with the loss function, computes the partial derivatives in a backward way and chains them together to obtain the composite derivative.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This computation is highly efficient because the forward pass (computing function value) and the backward pass (computing derivatives) have the same complexity. This is in sharp contrast with the finite difference method, where the computation of derivatives is much more expensive.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"compat: BONUS: Computation of gradients\nFor simplicity, we denote f = operatornamepredict and considerL(w) = sum_i=1^n operatornameloss(y_i f(wx_i))If the classifier has only a single output (as in regression or binary classification), then the chain rule yieldsnabla L(w) = sum_i=1^n operatornameloss(y_i f(wx_i))nabla_w f(wx_i)The most difficult term to compute is nabla_w f(wx_i). All neural networks presented in this course have a layered structure. For an input x, the evalutation of f(wx) is initialized by a_0=x and then the iterative updatebeginaligned\nz_m = W_ma_m-1 + b_m \na_m = l_m(z_m)\nendalignedfor m=1dotsM is performed. The first equation z_m = W_ma_m-1 + b_m performs a linear mapping, while a_m = l_m(z_m) applies the activation function l_m to each component of z_m. The parameters of the network are (W_mb_m)_m. Since a_M=f(wx), the chain rule impliesbeginaligned\nnabla_W_m f = nabla_W_ma_M = nabla_z_Ma_Mnabla_z_M-1a_Mnabla_a_M-1z_M-1dots nabla_z_ma_mnabla_W_mz_m \nnabla_b_m f = nabla_b_ma_M = nabla_z_Ma_Mnabla_z_M-1a_Mnabla_a_M-1z_M-1dots nabla_z_ma_mnabla_b_mz_m\nendalignedCare needs to be taken with this expression; for example nabla_W_mz_m differentiates a vector with respect to a matrix. The computation of nabla_W_m f and nabla_b_m f is almost the same and only the last term differs.Now we need to compute the individual derivativesbeginaligned\nnabla_a_m-1 z_m = W_m \nnabla_z_m a_m = operatornamediag(l_m(z_m))\nendalignedThe derivative in l_m(z_m) is understood componentwise, and operatornamediag makes a diagonal matrix from the vector.Combining all these relations allow computing the derivative of the whole network.","category":"page"},{"location":"lecture_06/compositetypes/#Abstract-types","page":"Abstract and composite types","title":"Abstract types","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Julia does not allow abstract types to be instantiated. They can only be used to create a logical hierarchy of types. The following figure shows this hierarchy for numeric types introduced in the first lecture.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"(Image: )","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"All types depicted in blue are abstract types, and all green types are concrete types. For example, Int8, Int16, Int32, Int64 and Int128 are signed integer types, UInt8, UInt16, UInt32, UInt64 and UInt128 are unsigned integer types, while Float16, Float32 and Float64 are floating-point types. In many cases, the inputs must be of a specific type. An algorithm to find the greatest common denominator should work any integer types, but it should not work for any floating-point inputs. Abstract types specify these cases and provide a context into which concrete types can fit.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Abstract types are defined by abstract type followed by the type name. It is possible to specify a type to be a subtype of another abstract type. The definition of abstract numeric types would be:","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"abstract type Number end\nabstract type Real <: Number end\nabstract type AbstractFloat <: Real end\nabstract type AbstractIrrational <: Real end\nabstract type Integer <: Real end\nabstract type Signed <: Integer end\nabstract type Unsigned <: Integer end","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"When no supertype is specified, such as for Number, the default supertype is Any. The Any type is sometimes called the top type since all types are its subtypes. The bottom type is Union{}, and all types are supertypes of Union{}.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The <: operator can be used to check if the left operand is a subtype of the right operand.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Signed <: Integer\ntrue\n\njulia> Signed <: Number\ntrue\n\njulia> Signed <: AbstractFloat\nfalse","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Julia also provides the isa function, which checks if a variable is an instance of a type.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> isa(1, Int64) # equivalent to typeof(1) <: Int64\ntrue\n\njulia> isa(1, Integer) # equivalent to typeof(1) <: Integer\ntrue\n\njulia> isa(1, AbstractFloat) # equivalent to typeof(1) <: AbstractFloat\nfalse","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Other handy functions are isabstracttype and isconcretetype that check whether a type is abstract and concrete, respectively.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> isabstracttype(Real)\ntrue\n\njulia> isabstracttype(Float64)\nfalse\n\njulia> isconcretetype(Real)\nfalse\n\njulia> isconcretetype(Float64)\ntrue","category":"page"},{"location":"lecture_06/compositetypes/#Composite-types","page":"Abstract and composite types","title":"Composite types","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"A composite type is a collection of key-value pairs. In many languages, composite types are the only kind of user-definable type. Even though Julia allows defining other types, composite types are used the most. Their main goal is to collect all information about one object within one structure. We will soon define the Rectangle type containing information about the size and the bottom-left point position of a rectangle. Collecting this information into one structure makes it simple to pass all information about the rectangle as arguments and use it for further computation. Moreover, it is possible to use composite types in combination with multiple-dispatch and define specialized functions for custom types.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The struct keyword defines composite types. It is followed by the composite type name and field names, where the latter may be annotated with types.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"struct Rectangle\n    bottomleft::Vector{Float64}\n    width\n    height\nend","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"If the type annotation is omitted, Any is used, and such a field may contain any value. A Julia convention suggests making the first letter in custom type names uppercase. We can create a new instance of the above type by calling Rectangle as a function. Its input arguments represent the fields of the Rectangle type.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> r = Rectangle([1,2], 3, 4)\nRectangle([1.0, 2.0], 3, 4)\n\njulia> isa(r, Rectangle)\ntrue","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"A constructor is calling a type as a function. Two constructors are automatically generated when a type is created. One accepts any arguments and converts them to the field types, and the other accepts arguments that match the field types exactly. If all fields are Any, only one constructor is generated. Julia creates these two constructors to make it easier to add new definitions without replacing the default constructor. We can list all constructors by the methods function.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> methods(Rectangle)\n# 2 methods for type constructor:\n [1] Rectangle(bottomleft::Vector{Float64}, width, height)\n     @ none:2\n [2] Rectangle(bottomleft, width, height)\n     @ none:2","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The fields of composite types can be accessed via the dot notation similarly to named tuples or via the getproperty function.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> r.width\n3\n\njulia> getproperty(r, :width)\n3","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The fields can be then accessed anywhere, for example, within a function.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> area(r::Rectangle) = r.width * r.height\narea (generic function with 1 method)\n\njulia> function vertices(r::Rectangle)\n           x, y = r.bottomleft\n           w, h = r.width, r.height\n           return [[x, y], [x + w, y], [x + w, y + h], [x, y + h]]\n       end\nvertices (generic function with 1 method)\n\njulia> area(r)\n12\n\njulia> vertices(r)\n4-element Vector{Vector{Float64}}:\n [1.0, 2.0]\n [4.0, 2.0]\n [4.0, 6.0]\n [1.0, 6.0]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The convenient function fieldnames returns a tuple with names of all structure fields represented as symbols.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> fieldnames(Rectangle)\n(:bottomleft, :width, :height)\n\njulia> fieldnames(typeof(r))\n(:bottomleft, :width, :height)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"info: Comparison with Python:\nThe same object can be defined in Python in the following way:class Rectangle:\n    def __init__(self, bottomleft, width, height):\n        self.bottomleft = bottomleft\n        self.width = width\n        self.height = height\n\n    def area(self):\n        return self.width * self.height\n\n    def vertices(self):\n        x, y = self.bottomleft\n        w, h = self.width, self.height\n        return [[x, y], [x + w, y], [x + w, y + h], [x, y + h]]We can create an instance of this object and call the two functions defined in the class definition.In [2]: r = Rectangle([1.0, 2.0], 3, 4)\n\nIn [3]: r.area()\nOut[3]: 12\n\nIn [4]: r.vertices()\nOut[4]: [[1.0, 2.0], [4.0, 2.0], [4.0, 6.0], [1.0, 6.0]]The declaration of the Rectangle class is very similar to the one in Julia. The main difference is, that in Python methods are bounded to the class, while Julia defines functions outside of the composite types. This is very important since Julia uses multiple-dispatch. It means, that functions consist of methods, and Julia decides which method to use based on the number of input arguments and its types. Since all arguments are used for method selection, it would be inappropriate for functions to \"belong\" to some composite type. As a consequence, we can modify existing methods or add new ones without the necessity to change the composite type definition. This property significantly improves code extensibility and reusability.","category":"page"},{"location":"lecture_06/compositetypes/#Mutable-composite-types","page":"Abstract and composite types","title":"Mutable composite types","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Composite types declared with struct keyword are immutable and cannot be modified after being constructed.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> r.bottomleft = [2;2]\nERROR: setfield!: immutable struct of type Rectangle cannot be changed\n[...]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"However, immutability is not recursive. If an immutable object contains a mutable object, such as an array, elements of this mutable object can be modified. Even though Rectangle is an immutable type, its bottomleft field is a mutable array and can be changed.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> r.bottomleft[1] = 5\n5\n\njulia> r.bottomleft\n2-element Vector{Float64}:\n 5.0\n 2.0\n\njulia> area(r)\n12\n\njulia> vertices(r)\n4-element Vector{Vector{Float64}}:\n [5.0, 2.0]\n [8.0, 2.0]\n [8.0, 6.0]\n [5.0, 6.0]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"To allow changing their fields, we need to define composite types as mutable by adding the mutable keyword.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"mutable struct MutableRectangle\n    bottomleft::Vector{Float64}\n    width\n    height\nend","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"We can work with mutable and immutable types in the same way.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> mr = MutableRectangle([1,2], 3, 4)\nMutableRectangle([1.0, 2.0], 3, 4)\n\njulia> isa(mr, MutableRectangle)\ntrue","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Similarly to accessing field values, we can change them by the dot notation or the setproperty! function.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> mr.width = 1.5\n1.5\n\njulia> setproperty!(mr, :height, 2.5)\n2.5\n\njulia> mr\nMutableRectangle([1.0, 2.0], 1.5, 2.5)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"info: Type unions:\nThe area function defined earlier will only work for Rectangle but not for MutableRectangle types. To define it for both types, we need type unions. The Union keyword creates a supertype of its inputs.julia> const AbstractRectangle = Union{Rectangle, MutableRectangle}\nUnion{MutableRectangle, Rectangle}\n\njulia> Rectangle <: AbstractRectangle\ntrue\n\njulia> MutableRectangle <: AbstractRectangle\ntrueWe now create the perimeter(r::AbstractRectangle) function. Since we specify that its input is an AbstractRectangle, it will work for both mutable MutableRectangle and immutable Rectangle types.julia> perimeter(r::AbstractRectangle) = 2*(r.width + r.height)\nperimeter (generic function with 1 method)\n\njulia> perimeter(r)\n14\n\njulia> perimeter(mr)\n8.0","category":"page"},{"location":"lecture_06/compositetypes/#Parametric-types","page":"Abstract and composite types","title":"Parametric types","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"An important and powerful feature of the Julia type system is that it is parametric. Types can take parameters, and type declarations introduce a whole family of new types (one for each possible combination of parameter values). Parametric (abstract) types can be defined as follows:","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"abstract type AbstractPoint{T} end\n\nstruct Point{T <: Real} <: AbstractPoint{T}\n    x::T\n    y::T\nend","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The example above defines a parametric abstract type AbstractPoint and its parametric subtype Point. The declaration of the concrete type Point{T <: Real} has two fields of type T, where T can be any subtype of Real. This definition ensures that both fields are always of the same type. Note that Point{Float64} is a concrete type equivalent to replacing T in the definition of Point by Float64.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> isconcretetype(Point{Float64})\ntrue","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"This single declaration declares a concrete type for each type T that is a subtype of Real.  The Point type itself is also a valid type object, containing all instances Point{Float64}, Point{Int64}, etc., as subtypes.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Point{Float64} <: Point <: AbstractPoint\ntrue\n\njulia> Point{Int64} <: Point <: AbstractPoint\ntrue","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Concrete Point types with different T values are never subtypes of each other. Even though Float64 is a subtype of Real, Point{Float64} is not a subtype of  Point{Real}.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Point{Float64} <: Point{Real}\nfalse\n\njulia> Point{Float64} <: AbstractPoint{Float64}\ntrue\n\njulia> Point{Float64} <: AbstractPoint{Real}\nfalse","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"This behaviour has important consequences: while any instance of Point{Float64} may be represented as an instance of Point{Real}, these two types have different representations in memory:","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"An instance of Point{Float64} can be efficiently represented as a pair of 64-bit values;\nAn instance of Point{Real} must be able to hold any pair of Real values. Since instances of Real can have arbitrary size and structure, an instance of Point{Real} must be represented as a pair of pointers to individually allocated Real objects.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"This efficiency gain is magnified for arrays: Array{Float64} can be stored as a contiguous memory block of 64-bit floating-point values, whereas Array{Real} is an array of pointers to Real objects.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Since Point{Float64} is not a subtype of Point{Real}, the following method cannot be applied to arguments of type Point{Float64}.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> coordinates(p::Point{Real}) = (p.x, p.y)\n\njulia> coordinates(Point(1,2))\nERROR: MethodError: no method matching coordinates(::Point{Int64})\n[...]\n\njulia> coordinates(Point(1.0,2.0))\nERROR: MethodError: no method matching coordinates(::Point{Float64})\n[...]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The correct way to define a method that accepts all arguments of type Point{T} where T is a subtype of Real is as follows:","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> coordinates(p::Point{<:Real}) = (p.x, p.y)\ncoordinates (generic function with 1 method)\n\njulia> coordinates(Point(1,2))\n(1, 2)\n\njulia> coordinates(Point(1.0,2.0))\n(1.0, 2.0)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"It is also possible to define a function for all subtypes of some abstract type.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Base.show(io::IO, p::AbstractPoint) = print(io, coordinates(p))\n\njulia> Point(4, 2)\n(4, 2)\n\njulia> Point(0.2, 1.3)\n(0.2, 1.3)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"There are two ways how to instantiate the Point type.  The first one does not specify the T parameter and lets Julia automatically decide the appropriate type. The second one specifies the T parameter manually.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Point(1, 2)\n(1, 2)\n\njulia> Point{Float32}(1, 2)\n(1.0f0, 2.0f0)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The first way works only if the arguments have the same type.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Point(1, 2.0)\nERROR: MethodError: no method matching Point(::Int64, ::Float64)\n\nClosest candidates are:\n  Point(::T, !Matched::T) where T<:Real\n[...]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"This situation can be handled by defining custom constructors, as we will discuss in the next section.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"warning: Exercise:\nDefine a structure that represents 3D-points. Do not forget to define it as a subtype of the AbstractPoint type. Then add a new method to the coordinates function.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"details: Solution:\nThere are several possibilities for defining the structure. We define it as a structure with three fields. Another option is to use a tuple to store the point coordinates.struct Point3D{T <: Real} <: AbstractPoint{T}\n    x::T\n    y::T\n    z::T\nend\n\ncoordinates(p::Point3D) = (p.x, p.y, p.z)Since the show function was defined for the abstract type AbstractPoint and uses the coordinates function, the custom print is applied to Point3D without the need for further changes.julia> Point3D(1, 2, 3)\n(1, 2, 3)\n\njulia> Point3D{Float32}(1, 2, 3)\n(1.0f0, 2.0f0, 3.0f0)","category":"page"},{"location":"lecture_06/compositetypes/#Constructors","page":"Abstract and composite types","title":"Constructors","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Constructors are functions that create new instances of composite types. When a user defines a new composite type,  Julia creates the default constructors. Sometimes it is helpful to add additional constructors. In the example from the previous section, we may want to create an instance of Point from two numbers with different types. This can be achieved by defining the following constructor.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Point(x::Real, y::Real) = Point(promote(x, y)...)","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The promote function converts its arguments to the supertype that can represent both inputs. For example, promote(1, 2.3) results in the tuple (1.0, 2.3) because it is possible to represent Int64 by Float64, but not the other way round. We can test the new constructor on the example from the end of the previous section. As expected, the result has the type Point{Float64}.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> Point(1, 2.0)\n(1.0, 2.0)\n\njulia> typeof(Point(1, 2.0))\nPoint{Float64}","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The constructor defined above is the outer constructor because it is defined outside of the type definition. A constructor behaves like any other function in Julia and may have multiple methods. We can define new methods to add additional functionality to a constructor. On the other hand, outer constructors cannot construct self-referential objects or instances with some special properties. In such a case, we have to use inner constructors, which differ from outer constructors in two aspects:","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"They are declared inside the composite type declaration rather than outside of it.\nThey have access to the local function new that creates new instances of the composite type.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"For example, one may want to create a type with two real numbers, where the first number cannot be greater than the second one. The inner constructor can ensure this.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"struct OrderedPair{T <: Real}\n    x::T\n    y::T\n\n    function OrderedPair(x::Real, y::Real)\n        x > y && error(\"the first argument must be less than or equal to the second one\")\n        xp, yp = promote(x, y)\n        return new{typeof(xp)}(xp, yp)\n    end\nend","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"If an inner constructor method is provided, no default constructor method is constructed.  The example above ensures that any instance of the OrderedPair satisfies x <= y.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> OrderedPair(1,2)\nOrderedPair{Int64}(1, 2)\n\njulia> OrderedPair(2,1)\nERROR: the first argument must be less than or equal to the second one\n[...]","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Inner constructors have an additional advantage. Since outer constructors create the object by calling an appropriate inner constructor, even if we define any number of outer constructors, the resulting instances of the OrderedPair type will always satisfy x <= y.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"warning: Exercise:\nDefine a structure that represents ND-points and stores their coordinates as Tuple. Do not forget to define it as a subtype of the AbstractPoint type. Redefine the default inner constructor to create an instance of PointND from different types. Then add a new method to the coordinates function, and define function dim that returns the dimension of the point.Hints: use the new function in the definition of the new inner constructor.Bonus: Tuples with elements of the same type can be described by the special type NTuple{N, T}, where N is the number of elements and T their type.julia> NTuple{2, Int64} <: Tuple{Int64, Int64}\ntrue","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"details: Solution:\nIn this case, we can use an inner constructor with the optional number of input arguments. In the definition below, we use type annotation to set these arguments to be real numbers. Since we use the new function and our type is parametric, we have to specify N and type T.struct PointND{N, T <: Real} <: AbstractPoint{T}\n    x::NTuple{N, T}\n\n    function PointND(args::Real...)\n        vals = promote(args...)\n        return new{length(args), eltype(vals)}(vals)\n    end\nend\n\ncoordinates(p::PointND) = p.x\ndim(p::PointND{N}) where N = NNote that we use the parameter N in the definition of the dim function.Since the show function was defined for the abstract type AbstractPoint and uses the coordinates function, the custom printing function is immediately applied to the new type. Since we redefined the default constructors, we can create an instance of the PointND type from inputs of mixed types.julia> p = PointND(1, 2)\n(1, 2)\n\njulia> dim(p)\n2\n\njulia> p = PointND(1, 2.2, 3, 4.5)\n(1.0, 2.2, 3.0, 4.5)\n\njulia> dim(p)\n4","category":"page"},{"location":"lecture_06/compositetypes/#Default-field-values","page":"Abstract and composite types","title":"Default field values","text":"","category":"section"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"It may be beneficial to define custom types with default field values. Since a constructor is a function, one way to achieve this is to use optional or keyword arguments in its declaration. Another option is to use the @kwdef macro from Base that automatically defines keyword-based constructors.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"Base.@kwdef struct MyType\n    a::Int # required keyword\n    b::Float64 = 2.3\n    c::String = \"hello\"\nend","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The methods function shows that Julia created three constructors.  The @kwdef macro creates the first constructor; the other two constructors are the default constructors.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> methods(MyType)\n# 3 methods for type constructor:\n[1] MyType(; a, b, c) in Main at util.jl:478\n[2] MyType(a::Int64, b::Float64, c::String) in Main at none:2\n[3] MyType(a, b, c) in Main at none:2","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"A MyType instance can be created by the default constructors.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> MyType(1, 2.3, \"aaa\")\nMyType(1, 2.3, \"aaa\")","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"The other way is to use the constructor with predefined field values. Then all values have to be passed as keyword arguments. The fields without default values are mandatory keyword arguments: we have to specify them.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"julia> MyType(; a = 3)\nMyType(3, 2.3, \"hello\")\n\njulia> MyType(; a = 5, b = 4.5)\nMyType(5, 4.5, \"hello\")","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"info: Function-like objects (functors):\nMethods are associated with types; therefore, it is possible to make an arbitrary Julia object \"callable\" by adding methods to its type. Such \"callable\" objects are sometimes called functors. Using this technique to the MyType defined above, we can define a method that returns values of all its fields.julia> (m::MyType)() = (m.a, m.b, m.c)\n\njulia> m = MyType(; a = 5, b = 4.5)\nMyType(5, 4.5, \"hello\")\n\njulia> m()\n(5, 4.5, \"hello\")Moreover, we can use multiple-dispatch for functors. We show an example, where the functor has a different behaviour when it is called with a number and a string.(m::MyType)(x::Real) = m.a*x + m.b\n(m::MyType)(x::String) = \"$(m.c), $(x)\"These two methods give different results.julia> m(1)\n9.5\n\njulia> m(\"world\")\n\"hello, world\"","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"warning: Exercise:\nGaussian distribution is uniquely represented by its mean mu and variance sigma^20. Write a structure Gauss with the proper fields and an inner constructor that checks if the input parameters are correct. Initialization without arguments Gauss() should return the standardized normal distribution (mu = 0 and sigma = 1).  Define a functor that computes the probability density function at a given point defined byf_mu sigma(x) = frac1sigma sqrt 2pi  expleft -frac12 left( fracx - musigma right) ^2 rightVerify that the probability density function is defined correctly, i.e., its integral equals 1.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"details: Solution:\nOne possible way to define this structure is the @kwdef macro, where we specify the default parameters. We also define an inner constructor that promotes the inputs to a same type, and checks if the variance is positive.Base.@kwdef struct Gauss{T<:Real}\n    μ::T = 0\n    σ::T = 1\n\n    function Gauss(μ::Real, σ::Real)\n        σ^2 > 0 || error(\"the variance `σ^2` must be positive\")\n        pars = promote(μ, σ)\n        return new{eltype(pars)}(pars...)\n    end\nendWe specified the parameter T by eltype(pars) in the call of the new function. The probability density function can be defined as a functor in the following way:(d::Gauss)(x::Real) = exp(-1/2 * ((x - d.μ)/d.σ)^2)/(d.σ * sqrt(2*π))We use type annotation to ensure that all input arguments are real numbers.julia> gauss = Gauss()\nGauss{Int64}(0, 1)\n\njulia> gauss(0)\n0.3989422804014327The integral of the probability density function over the real line should equal one. We check it numerically by discretizing the integral into a finite sum.julia> step = 0.01\n0.01\n\njulia> x = -100:step:100;\n\njulia> sum(Gauss(), x) * step\n1.0000000000000002\n\njulia> sum(Gauss(0.1, 2.3), x) * step\n1.0We use sum with a function as the first input argument and apply it to each value of the second argument. This is possible because we defined a functor for Gauss. The result is the same as sum(Gauss().(x)). The difference is that the former, similarly to generators, does not allocate an array.","category":"page"},{"location":"lecture_06/compositetypes/","page":"Abstract and composite types","title":"Abstract and composite types","text":"compat: Plot recipes:\nThe previous exercise defined a new type representing the Gaussian distribution. We also defined a functor that computes the probability density function of this distribution. It makes sense to visualize the probability density function using the Plots package. Unfortunately, it is not possible to use Function plotting, i.e., the following will not work even though the Gauss type is callable.plot(x, Gauss())Using the system of Julia types, it is possible to obtain special behaviour for a certain type only by defining a new method for this type. For example, if we use the plot function, all input data and plot attributes are preprocessed to some standard format and then the final graph is created. Due to the Julia type system, we can easily change how this preprocessing happens and define special behaviour for custom types.For plotting, this is done by the @recipe macro from the RecipesBase package. The RecipesBase package provides the functionality related to creating custom plots and the Plots package uses this functionality. Moreover, since the RecipesBase package is much smaller, its first run is faster. The syntax is straightforward. In the function head, we define two inputs: our type and input x. In the function body, we define plot attributes in the same way as if we pass them into the plot function. Finally, we define the output of the function.using RecipesBase\n\n@recipe function f(d::Gauss, x = (d.μ - 4d.σ):0.1:(d.μ + 4d.σ))\n    seriestype  :=  :path\n    label --> \"Gauss(μ = $(d.μ), σ = $(d.σ))\"\n    xguide --> \"x\"\n    yguide --> \"f(x)\"\n    linewidth --> 2\n    return x, d.(x)\nendThe operators := and --> are specific for this package. Both set default values for plotting attributes. The difference is that the default values can be changed for --> but cannot be changed for :=.The recipe above is equivalent to calling the plot function.d = Gauss()\nplot(x, d.(x);\n    seriestype := :path,\n    label = \"Gauss(μ = $(d.μ), σ = $(d.σ))\",\n    xguide = \"x\",\n    yguide = \"f(x)\",\n    linewidth = 2\n)With the new plot recipe, we can plot the probability density function of the Gaussian distribution with different parameters.using Plots\n\nplot(Gauss())\nplot!(Gauss(4, 2); linewidth = 4, color = :red)\nplot!(Gauss(-3, 2); label = \"new label\", linestyle = :dash)(Image: )","category":"page"},{"location":"lecture_03/conditions/#Conditional-evalutions","page":"Conditional evaluations","title":"Conditional evalutions","text":"","category":"section"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"This lecture handles control flow. The first part focuses on if conditions and the second one of loops.","category":"page"},{"location":"lecture_03/conditions/#if-elseif-else-statement","page":"Conditional evaluations","title":"if-elseif-else statement","text":"","category":"section"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"In many cases, we have to decide what to do for different conditions. Julia supports the standard if-elseif-else syntax, which determines which part of the code will be evaluated. This depends on the logical expression value. For example, the following function compares two numerical values.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"function compare(x, y)\n    if x < y\n        println(\"x is less than y\")\n    elseif x > y\n        println(\"x is greater than y\")\n    else\n        println(\"x is equal to y\")\n    end\n    return\nend","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"If the expression x < y is true, the functions prints \"x is less than y\", otherwise, the expression x > y is evaluated, and if it is true, the functions prints \"x is greater than y\". If neither expression is true, the function prints the remaining option \"x is equal to y\".","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> compare(1, 2.3)\nx is less than y\n\njulia> compare(4.7, 2.3)\nx is greater than y\n\njulia> compare(2.3, 2.3)\nx is equal to y","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"info: Function declaration:\nSo far, we did not show how to define functions. However, the above example should show the basic syntax for defining functions. The return keyword specifies the function output. In this case, the function returns nothing since we only want to compare numbers. If we need to define a function that returns more than one variable, the following syntax is used.return x, y, zHere x, y, and z are some variables. We will discuss the function declaration in more detail in the next lesson.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The elseif and else keywords are optional. Moreover, it is possible to use as many elseif blocks as needed.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> x, y = 2, 1;\n\njulia> if x < y\n           println(\"x is less than y\")\n       elseif x > y\n           println(\"x is greater than y\")\n       end\nx is greater than y\n\njulia> if x < y\n           println(\"x is less than y\")\n       end","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The conditions in the if-elseif-else construction are evaluated until the first one is true. The associated block is then evaluated, and no other condition expressions or blocks are evaluated.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"In contrast to languages like Python or Matlab, the logical expression in the if-elseif-else statement must always return a boolean value. Otherwise, an error will occur.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> if 1\n           println(\"Hello\")\n       end\nERROR: TypeError: non-boolean (Int64) used in boolean context\n[...]","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The if blocks do not introduce a local scope, i.e., it is possible to introduce a new variable inside the if block and use this variable outside the block.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> x, y = 2, 1;\n\njulia> if x < y\n           z = y\n       else\n           z = x\n       end\n2\n\njulia> z\n2","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"However, it is necessary to ensure that the variable is always declared in all cases.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"function compare(x, y)\n    if x < y\n        z = y\n    elseif x > y\n        z = x\n    end\n    return z\nend","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The function defined above works only for numbers which are not equal.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> compare(1, 2.3)\n2.3\n\njulia> compare(4.7, 2.3)\n4.7\n\njulia> compare(2.3, 2.3)\nERROR: UndefVarError: `z` not defined\n[...]","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The if blocks always return a value equal to the last expression evaluated in the if block. In other words, it is possible to assign the value returned by the if block to a new variable.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"function compare(x, y)\n    z = if x < y\n        y\n    else\n        x\n    end\n    return z\nend","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"In the example above, the variable z equals y if the expressionx < y evaluates as true. Otherwise, the variable z equalsx.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> compare(1, 2.3)\n2.3\n\njulia> compare(4.7, 2.3)\n4.7\n\njulia> compare(2.3, 2.3)\n2.3","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"warning: Exercise:\nWrite the fact(n) function that computes the factorial of n. Use the following function declaration:function fact(n)\n    # some code\nendMake sure that the input argument is a non-negative integer. For negative input arguments and for arguments that can not be represented as an integer, the function should throw an error.Hint: use recursion, the isinteger function and the error function. The or operator is written by |.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"details: Solution:\nWe split the solution into three cases:If n is smaller than zero or not an integer, we throw an error.\nIf n is equal to zero, the function returns 1.\nIf n is a positive integer, we use recursion.function fact(n)\n    return if n < 0 | !isinteger(n)\n        error(\"argument must be non-negative integer\")\n    elseif n == 0\n        1\n    else\n        n * fact(n - 1)\n    end\nendSince the if block returns a value from the latest evaluated expression, it is possible to use it after the return keyword to define the function output. However, it is also possible to omit the return keyword since functions return the last evaluated expression if the return keyword is not used.julia> fact(4)\n24\n\njulia> fact(0)\n1\n\njulia> fact(-5)\nERROR: argument must be non-negative integer\n[...]\n\njulia> fact(1.4)\nERROR: argument must be non-negative integer\n[...]","category":"page"},{"location":"lecture_03/conditions/#Ternary-operator","page":"Conditional evaluations","title":"Ternary operator","text":"","category":"section"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The ternary operator ? is closely related to the if-else statement. It can instead be used to decide between two simple options. The syntax is the following:","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"a ? b : c","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"which can be read as \"if a is true, then evaluate b; otherwise, evaluate c\". The white spaces around ? and : are mandatory.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> x, y = 2, 1;\n\njulia> println(x < y ? \"x is less than y\" : \"x is greater than or equal to y\")\nx is greater than or equal to y","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"In this case, there are two possibilities:","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"if x < y is true, then the string \"x is less than y\" is returned,\nif x < y is false, then the string \"x is greater than or equal to y\" is returned.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"Since we wrapped the whole expression into the println function, the ternary operator output is printed.","category":"page"},{"location":"lecture_03/conditions/#Short-circuit-evaluation","page":"Conditional evaluations","title":"Short-circuit evaluation","text":"","category":"section"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"Julia provides the so-called short-circuit evaluation which is similar to the conditional evaluation. The behaviour exists in most imperative programming languages having the && and || boolean operators. In a series of boolean expressions connected by these operators, only the minimal number of expressions is evaluated  to determine the final boolean value of the entire chain:","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"In the expression a && b, the subexpression b is only evaluated if a evaluates true.\nIn the expression a || b, the subexpression b is only evaluated if a evaluates to false.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"To investigate this behavior, let's define the following two functions:","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"t(x) = (println(x); true)\nf(x) = (println(x); false)","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"The t function prints x and returns true. Similarly, the f function prints x and returns false. Using these two functions, we can easily determine which expressions are evaluated when using short-circuit evaluation.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> t(1) && println(2) # both expressions are evaluated\n1\n2\n\njulia> f(1) && println(2) # only the first expression is evaluated\n1\nfalse\n\njulia> t(1) || println(2) # only the first expression is evaluated\n1\ntrue\n\njulia> f(1) || println(2) # both expressions are evaluated\n1\n2","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"info: Short-circuit evaluation vs. bitwise boolean operators:\nBoolean operations without short-circuit evaluation can be done with the bitwise boolean operators & and | introduced in previous lecture. These are normal functions, which happen to support infix operator syntax, but always evaluate their arguments.julia> f(1) & t(2)\n1\n2\nfalse\n\njulia> f(1) && t(2)\n1\nfalse","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"When multiple && and || are chained together, && has a higher precedence than ||. For example, a || b && c && d || e is equivalent to a || (b && c && d) || e.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"julia> t(1) && t(2) || println(3) # the first two expressions are evaluated\n1\n2\ntrue\n\njulia> f(1) && t(2) || println(3) # the first and the last expressions are evaluated\n1\n3\n\njulia> f(1) && f(2) || println(3) # the first and the last expressions are evaluated\n1\n3\n\njulia> t(1) && f(2) || println(3) # all expressions are evaluated\n1\n2\n3\n\njulia> t(1) || t(2) && println(3) # the first expression is evaluated\n1\ntrue\n\njulia> f(1) || t(2) && println(3) # all expressions are evaluated\n1\n2\n3\n\njulia> f(1) || f(2) && println(3) # the first two expressions are evaluated\n1\n2\nfalse\n\njulia> t(1) || f(2) && println(3) # the first expression is evaluated\n1\ntrue","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"warning: Exercise:\nRewrite the factorial function from the exercises above. Use the short-circuit evaluation to check if the given number is a non-negative integer and the ternary operator for recursion.","category":"page"},{"location":"lecture_03/conditions/","page":"Conditional evaluations","title":"Conditional evaluations","text":"details: Solution:\nSince we want to check if the input number is a non-negative integer, we need to check two conditions. It can be done separately by the short-circuit evaluation.function fact(n)\n    isinteger(n) || error(\"argument must be non-negative integer\")\n    n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nendThis can be further simplified by combining the && and || operators.function fact(n)\n    isinteger(n) && n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nendSince && has higher precedence than ||, the error function is evaluated only if isinteger(n) && n >= 0 is violated. We can then check that this function works the same as the fact function from above.julia> fact(4)\n24\n\njulia> fact(0)\n1\n\njulia> fact(-5)\nERROR: argument must be non-negative integer\n[...]\n\njulia> fact(1.4)\nERROR: argument must be non-negative integer\n[...]","category":"page"},{"location":"installation/tutorial/#Creating-new-project","page":"Quickstart guide","title":"Creating new project","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"This section provides a step-by-step tutorial showing how to create a new project, add a new file, initialize a git repository, and publish the repository on Github.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"The first thing we have to do when creating a new project is to select a folder where we want to store the project. Open the file Explorer in the VS Code by pressing its icon in the activity bar and pressing the Open Folder button. Alternatively, use the keyboard shortcut Ctrl + K Ctrl + O.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"A system file explorer should open, so find and select the folder you want to use as a project folder. In our case, it is a Tutorial folder in Documents.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Now go to the project manager by pressing the appropriate button in the activity bar. Since we are creating our first project, the project manager tab should be empty. Press the Project Manager: Save Project button, type a project name in the pop-up bar, and then press Enter.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"It will add a new project to the project manager. In our case, it is a project called Tutorial.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Now go back to the file explorer. In the sidebar, under the project name, there should be an empty space. Press the New File button next to the project name and write a new file name with the .jl extension. Alternatively, use the keyboard shortcut Ctr + N to create a new file and then Ctrl + S to save the file.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"The new file will open in the editor to the right of the File Explorer sidebar. Type println(\"Hello, world.\") in the new file and press Ctrl + S to save the change. Now select the code and press Ctrl + Enter to execute the code. This shortcut runs the new Julia session and sends the code to the session. Congratulations, you have just created and run a Hello, world program in Julia.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/#Initialize-Git-repository","page":"Quickstart guide","title":"Initialize Git repository","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Now that we have created a new project, it is time to initialize the git repository to track the project's changes. Go to the Source Control bar by pressing the appropriate button in the activity bar. Then press the Initialize Repository button, which will create a new Git repository in the project folder.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"We can check if the Git repository is initialized in the system file explorer. Go to the project folder, and in the file explorer, in the top bar under the View tab, select the Hidden items option. Now you should see the .git folder in the project directory.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"With the initialized Git repository, we can start tracking our work changes. Note the number 1 in the control source icon. It indicates one change against the last version of the project.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Git provides the commit command to capture changes in the project. To create a new git commit, we must first select what changes we want to capture. In our case, it is trivial since there is only one change. In the source control under the Changes section, you should see the test.jl file. Press the Stage Changes button located on the file name's right (+ icon).","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"This moves the file under the Staged Changes section. The next step is to add a summary to the git commit. Type any message that describes changes made in the project. It is good to use short but descriptive messages since it will help navigate the project history. We use the Initial commit message. To finish the git commit, press the Commit button above the message bar or use the keyboard shortcut Ctrl + Enter in the message bar.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Now return to the file explorer bar and open the Timeline drop-down menu at the bottom. In the Timeline bar, you can see the currently open file history. In our case, we can see the history of the test.jl file: one git commit created by user  User Name and described by the Initial commit message. If you click on that git commit, it shows changes made to the current file. On the left-hand side, we can see the file's state before the git commit and on the right-hand side after the git commit. It allows us to see all the changes made in the file. We can see that we added one line of code.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/#Publish-on-GitHub","page":"Quickstart guide","title":"Publish on GitHub","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Now it's time to publish our work on GitHub. With GitHub, it's easy to share and collaborate on a project with multiple people. If you did not create a GitHub account in the previous section about Git installation, please do it now.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Firstly we have to create a new empty repository on GitHub. Press the + button in the GitHub website's top right corner and select the New repository option.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"Enter the desired repository name and select whether the repository should be private or public, and press Enter. In our case, we use the Tutorial.jl name for the repository since it is an easy way to show that the project is written in Julia.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"When the new repository is created, select the repository URL and copy it. We will need it in the next step.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"The next step is to add a new remote repository to the local Git repository. It can be done directly from the VS Code. Go to the Source Control bar by pressing the appropriate button in the activity bar. Then press the ... button to open the pop-up window and select the option Remote and then Add Remote....","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"In the pop-up window, enter the URL of the GitHub repository created in the previous steps and press enter.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"The next step is to choose a remote repository name. This name is used by Git to recognize what remote repository we want to work with, since it is possible to have multiple remote repositories linked with the local repository. If there is only one remote repository, the usual choice of the name is origin.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"The last step is to push local changes to the remote repository. To do that, press the Publich on GitHub button in the left bottom corner.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"And that's all. Now that you've published your first repository on GitHub, you can easily share your project with others.","category":"page"},{"location":"installation/tutorial/","page":"Quickstart guide","title":"Quickstart guide","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using RDatasets\nusing Plots\nusing Random\nusing Statistics\nusing LinearAlgebra\n\nfunction split(X, y::AbstractVector; dims=1, ratio_train=0.8, kwargs...)\n    n = length(y)\n    size(X, dims) == n || throw(DimensionMismatch(\"...\"))\n\n    n_train = round(Int, ratio_train*n)\n    i_rand = randperm(n)\n    i_train = i_rand[1:n_train]\n    i_test = i_rand[n_train+1:end]\n\n    return selectdim(X, dims, i_train), y[i_train], selectdim(X, dims, i_test), y[i_test]\nend\n\nfunction normalize(X_train, X_test; dims=1, kwargs...)\n    col_means = mean(X_train; dims)\n    col_std = std(X_train; dims)\n\n    return (X_train .- col_means) ./ col_std, (X_test .- col_means) ./ col_std\nend\n\nfunction onehot(y, classes)\n    y_onehot = falses(length(classes), length(y))\n    for (i, class) in enumerate(classes)\n        y_onehot[i, y .== class] .= 1\n    end\n    return y_onehot\nend\n\nonecold(y, classes) = [classes[argmax(y_col)] for y_col in eachcol(y)]\n\nfunction prepare_data(X, y; do_normal=true, do_onehot=true, kwargs...)\n    X_train, y_train, X_test, y_test = split(X, y; kwargs...)\n\n    if do_normal\n        X_train, X_test = normalize(X_train, X_test; kwargs...)\n    end\n\n    classes = unique(y)\n\n    if do_onehot\n        y_train = onehot(y_train, classes)\n        y_test = onehot(y_test, classes)\n    end\n\n    return X_train, y_train, X_test, y_test, classes\nend\n\n# SimpleNet\n\nstruct SimpleNet{T<:Real}\n    W1::Matrix{T}\n    b1::Vector{T}\n    W2::Matrix{T}\n    b2::Vector{T}\nend\n\nSimpleNet(n1, n2, n3) = SimpleNet(randn(n2, n1), randn(n2), randn(n3, n2), randn(n3))\n\nfunction (m::SimpleNet)(x)\n    z1 = m.W1*x .+ m.b1\n    a1 = max.(z1, 0)\n    z2 = m.W2*a1 .+ m.b2\n    return exp.(z2) ./ sum(exp.(z2), dims=1)\nend\n\nfunction grad(m::SimpleNet, x::AbstractVector, y; ϵ=1e-10)\n    z1 = m.W1*x .+ m.b1\n    a1 = max.(z1, 0)\n    z2 = m.W2*a1 .+ m.b2\n    a2 = exp.(z2) ./ sum(exp.(z2), dims=1)\n    l = -sum(y .* log.(a2 .+ ϵ))\n\n    e_z2 = exp.(z2)\n    l_part = (- e_z2 * e_z2' + Diagonal(e_z2 .* sum(e_z2))) / sum(e_z2)^2\n\n    l_a2 = - y ./ (a2 .+ ϵ)\n    l_z2 = l_part * l_a2\n    l_a1 = m.W2' * l_z2\n    l_z1 = l_a1 .* (a1 .> 0)\n    l_x = m.W1' * l_z1\n\n    l_W2 = l_z2 * a1'\n    l_b2 = l_z2\n    l_W1 = l_z1 * x'\n    l_b1 = l_z1\n\n    return l, l_W1, l_b1, l_W2, l_b2\nend\n\nmean_tuple(d::AbstractArray{<:Tuple}) = Tuple([mean([d[k][i] for k in 1:length(d)]) for i in 1:length(d[1])])\n\npredict(X) = m(X)\naccuracy(X, y) = mean(onecold(predict(X), classes) .== onecold(y, classes))","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"iris = dataset(\"datasets\", \"iris\")\n\nX = Matrix(iris[:, 1:4])\ny = iris.Species","category":"page"},{"location":"lecture_10/exercises/#l9-exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 1: Keyword arguments\nKeyword arguments (often denoted as kwargs but any name may be used) specify additional arguments which do not need to be used when the function is called. We recall the prepare_data function written earlier.function prepare_data(X, y; do_normal=true, do_onehot=true, kwargs...)\n    X_train, y_train, X_test, y_test = split(X, y; kwargs...)\n\n    if do_normal\n        X_train, X_test = normalize(X_train, X_test; kwargs...)\n    end\n\n    classes = unique(y)\n\n    if do_onehot\n        y_train = onehot(y_train, classes)\n        y_test = onehot(y_test, classes)\n    end\n\n    return X_train, y_train, X_test, y_test, classes\nend\nnothing # hideAll keyword arguments kwargs will be passed to the split and normalize functions. The benefit is that we do not need to specify the keyword arguments for split in prepare_data.Recall that split takes ratio_split as an optional argument. Write a one-line function ratio_train which gets the training and testing sets and computes the ratio of samples in the training set. Then call the prepare_data with:no normalization and the default split ratio;\nnormalization and the split ratio of 50/50;","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe ratio_train function reads:ratio_train(X_train, X_test) = size(X_train, 2) / (size(X_train,2) + size(X_test,2))\nnothing # hideThe first case uses the default ratio; hence we do not pass ratio_split. Since we do not want to use normalization, we need to pass do_normal=false.X_train, y_train, X_test, y_test, classes = prepare_data(X', y; dims=2, do_normal=false)\nprintln(\"Ratio train/test = \", ratio_train(X_train, X_test))The second case behaves the other way round. We use the default normalization; thus, we do not need to specify do_normal=true (even though it may be a good idea). We need to pass ratio_train=0.5.X_train, y_train, X_test, y_test, classes = prepare_data(X', y; dims=2, ratio_train=0.5)\nprintln(\"Ratio train/test = \", ratio_train(X_train, X_test))","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The goal of the following exercise is to show the prediction function graphically. For this reason, we will consider only two features. All the following exercises use the data with the fixed seed for reproducibility.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Random.seed!(666)\nX_train, y_train, X_test, y_test, classes = prepare_data(X[:,3:4]', y; dims = 2)\n\nnothing # hide","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 2: Showing the contours\nUse the same training procedure for 1000 iterations to train the classifier with the new data. Then plot a graph depicting which classes are predicted at subregions of -22times -22. Moreover, depict the testing data in this graph.Hint: use the heatmap function.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nThe procedure for training the network is the same as during the lecture.m = SimpleNet(size(X_train,1), 5, size(y_train,1))\n\nα = 1e-1\nmax_iter = 1000\nfor iter in 1:max_iter\n    grad_all = [grad(m, X_train[:,k], y_train[:,k]) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n\n    m.W1 .-= α*grad_mean[2]\n    m.b1 .-= α*grad_mean[3]\n    m.W2 .-= α*grad_mean[4]\n    m.b2 .-= α*grad_mean[5] \nend\n\nnothing # hideThe prediction function is m([x;y]). Since this creates a one-hot representation, we need to convert it into a one-cold representation. However, it is not possible to use onecold(m([x; y]), classes), which would result in one of the three string labels. We need to use onecold(m([x; y]), 1:3) to convert it to a real number. Then we call the heatmap function. Since we will later use plotting in a loop, we assign the graph to plt.colours = [:blue, :red, :green]\n\nxs = -2:0.01:2\nplt = heatmap(xs, xs, (x, y) -> onecold(m([x; y]), 1:3)[1];\n    color = colours,\n    opacity = 0.2,\n    axis = false,\n    ticks = false,\n    cbar = false,\n    legend = :topleft,\n)\n\nnothing # hideTo add the predictions of the testing set, we find the indices inds of samples from each class. Then we add them via the scatter! plot. We keep colours from the previous part to have the same colours. Since we plotted in a loop, we need to display the plot.for (i, class) in enumerate(classes)\n    inds = findall(onecold(y_test, classes) .== class)\n    scatter!(plt, X_test[1, inds], X_test[2, inds];\n        label = class,\n        marker=(8, 0.8, colours[i]),\n    )\nend\ndisplay(plt)\n\nsavefig(\"Separation.svg\") # hide","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 3: Overfitting\nThis exercise shows the well-known effect of overfitting. Since the model sees only the training set, it may fit it too perfectly (overfit it) and generalize poorly to the testing set of unseen examples.Consider the same data as in the previous exercise but train a network with 25 hidden neurons for 25000 iterations. Plot the loss function values on the training and testing sets. Then plot the same prediction visualization as in the previous exercise for both testing and training sets. Describe what went wrong.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nWe first specify the loss function.loss(X, y; ϵ = 1e-10) = mean(-sum(y .* log.(m(X) .+ ϵ); dims = 1))\nnothing # hideThen we train the network as before. The only change is that we need to save the training and testing objective.m = SimpleNet(size(X_train,1), 25, size(y_train,1))\n\nα = 1e-1\nmax_iter = 25000\nL_train = zeros(max_iter)\nL_test = zeros(max_iter)\nfor iter in 1:max_iter\n    grad_all = [grad(m, X_train[:,k], y_train[:,k]) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n    \n    m.W1 .-= α*grad_mean[2]\n    m.b1 .-= α*grad_mean[3]\n    m.W2 .-= α*grad_mean[4]\n    m.b2 .-= α*grad_mean[5] \n\n    L_train[iter] = loss(X_train, y_train)\n    L_test[iter] = loss(X_test, y_test)\nendThen we plot it. We ignore the first nine iterations, where the loss is large there. We see the classical procedure of overfitting. While the loss function on the training set decreases steadily, on the testing set, it decreases first, and after approximately 100 iterations, it starts increasing. This behaviour may be prevented by several techniques, which we discuss in the following lecture.plot(L_train[10:end], xlabel=\"Iteration\", label=\"Training loss\", legend=:topleft)\nplot!(L_test[10:end], label=\"Testing loss\")\n\nsavefig(\"Train_test.svg\") # hide(Image: )We create the contour plot in the same way as in the previous exercise.plt = heatmap(xs, xs, (x, y) -> onecold(m([x; y]), 1:3)[1];\n    color = colours,\n    opacity = 0.2,\n    axis = false,\n    ticks = false,\n    cbar = false,\n    legend = :topleft,\n)\n\nfor (i, class) in enumerate(classes)\n    inds = findall(onecold(y_test, classes) .== class)\n    scatter!(plt, X_test[1, inds], X_test[2, inds];\n        label = class,\n        marker=(8, 0.8, colours[i]),\n    )\nend\ndisplay(plt)\n\nsavefig(\"Separation2.svg\") # hide(Image: )plt = heatmap(xs, xs, (x, y) -> onecold(m([x; y]), 1:3)[1];\n    color = colours,\n    opacity = 0.2,\n    axis = false,\n    ticks = false,\n    cbar = false,\n    legend = :topleft,\n)\n\nfor (i, class) in enumerate(classes)\n    inds = findall(onecold(y_train, classes) .== class)\n    scatter!(plt, X_train[1, inds], X_train[2, inds];\n        label = class,\n        marker=(8, 0.8, colours[i]),\n    )\nend\ndisplay(plt)\n\nsavefig(\"Separation3.svg\") # hide(Image: )The separation on the testing set is quite good, but it could be better for the two bottommost green circles (iris virginica). The model predicted (in the background) the red colour (iris versicolor) there. This is wrong. The reason is clear from the picture depicting the training set. The classifier tried to perfectly fit the boundary between the green and red points, making an outward-pointing tip. This is precisely overfitting and the reason for the misclassification on the testing set.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: ) (Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 4: Generalization\nThe contour plots from Exercises 2 and 3 are strikingly different, especially in the top-left and bottom-right corners. Why is that?","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nSince the dataset does not contain any data in the top-left or bottom-right corners, it does not know what to predict. From its perspective, both separations are very good.info: Generalization:\nIf a classifier does not have any data in some region, it may predict anything there, including predictions with no sense.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 5: Universal approximation of neural networks\nProof the theorem about universal approximation of neural networks.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nSince piecewise linear functions are dense in the set of continuous functions, there is a piecewise linear function h such that h-g_inftyle varepsilon. Assume that h has kinks at x_1dotsx_n with function values h(x_i)=y_i for i=1dotsn. Definingd_i = fracy_i+1-y_ix_i+1-x_ithen h has the formh(x) = y_i + d_i(x-x_i) qquadtext for xin x_ix_i+1It is not difficult to show thath(x) = y_1 + sum_i=1^n(d_i-d_i-1)operatornamemaxx-x_i0where we defined d_0=0.Then h can be represented as the following network with two layers:Dense layer with n hidden neurons and ReLU activation function. Neuron i has weight 1 and bias -x_i.\nDense layer with 1 output neurons and identity activation function. Connection i has weight d_i-d_i-1 and the joint bias is y_1.This finishes the proof.","category":"page"},{"location":"lecture_13/diff_eq/#Julia-package","page":"Julia package","title":"Julia package","text":"","category":"section"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"To solve differential equations, we use the package DifferentialEquations, which consider ODEs in the form","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"dot u(t) = f(t u(t) p(t))","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"with the initial condition u(t_0)= u_0. While u is the solution, p describes external parameters.","category":"page"},{"location":"lecture_13/diff_eq/#Introduction","page":"Julia package","title":"Introduction","text":"","category":"section"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"We start with the following simple problem:","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"beginaligned\ndot u(t) = 098u \nu(0) = 1\nendaligned","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"This equation has the closed-form solution u(t) = e^098t. To solve it by DifferentialEquations, we first need to create the problem prob by supplying the function f, the initial point u_0 and the time interval t_0t_1 to the constructor ODEProblem.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"using DifferentialEquations\n\nf(u,p,t) = 0.98*u\n\nu0 = 1.0\ntspan = (0.0, 1.0)\n\nprob = ODEProblem(f, u0, tspan)\n\nnothing # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"Then we use the solve function to solve the equation.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"sol = solve(prob)","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The first line says that the solution was successful, which can be automatically checked by accessing the field sol.retcode. The second line specifies the interpolation method, and the following lines the solution. Even though the solution was evaluated at only five points, the interpolation allows plotting a smooth function.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"using Plots\n\nplot(sol; label=\"\")\n\nsavefig(\"intro.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The sol structure can be used to evaluate the solution u.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"sol(0.8)","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The following exercise shows how to specify the interpolation technique and compares the results.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"warning: Exercise:\nWhen calling the solve function, we can specify the interpolation way. Solve the ODE with linear interpolation (dense=false) and the Runge-Kutta method of the fourth order (RK4()). Plot the results and compare them with the default and original solutions.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"details: Solution:\nTo compute the additional solutions, we add the arguments as specified above.sol2 = solve(prob, dense=false)\nsol3 = solve(prob, RK4())\n\nnothing # hideWe create a discretization ts of the time interval and then plot the four functions.ts = range(tspan...; length = 100)\n\nplot(ts, t->exp(0.98*t), label=\"True solution\", legend=:topleft)\nplot!(ts, t->sol(t), label=\"Default\")\nplot!(ts, t->sol2(t), label=\"Linear\")\nplot!(ts, t->sol3(t), label=\"Runge-Kutta\")\n\nsavefig(\"Comparison.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"We see that all solutions are the same except for the linear approximation.","category":"page"},{"location":"lecture_13/diff_eq/#Lorenz-system","page":"Julia package","title":"Lorenz system","text":"","category":"section"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The Lorenz system is a prime example of the butterfly effect in the chaos theory. There, small changes in the initial conditions result in large changes in the solution. This effect was first described in 1961 during work on weather modelling.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The following equations describe the three-dimensional Lorenz system:","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"beginaligned\nfracpartial xpartial t = sigma (y - x) \nfracpartial ypartial t = x (rho - z) - y \nfracpartial zpartial t = x y - beta z\nendaligned","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"We first define the right-hand side of the system.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"function lorenz(u, p, t)\n    σ, ρ, β = p\n    x_t = σ*(u[2]-u[1])\n    y_t = u[1]*(ρ-u[3]) - u[2]\n    z_t = u[1]*u[2] - β*u[3]\n    return [x_t; y_t; z_t]\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The parameters are saved in a tuple or array p. Since the right-hand side of the Lorenz system is a vector, we need to return a vector as well. Now, we compute the solution in the same way as before.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"u0 = [1.0; 0.0; 0.0]\np = [10; 28; 8/3] \n\ntspan = (0.0, 100.0)\nprob = ODEProblem(lorenz, u0, tspan, p)\n\nsol = solve(prob)\n\nnothing # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"We plot the solution:","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"plot(sol)\n\nsavefig(\"lorenz0.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"Since this is a two-dimensional graph of all coordinates, we need to specify that we want to plot a 3D graph.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"plt1 = plot(sol, vars=(1,2,3), label=\"\")\n\nsavefig(\"lorenz1.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"We see the power of interpolation again. If we used linear interpolation, which amounts to connecting the points, we would obtain a much coarse graph.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"plot(sol, vars=(1,2,3), denseplot=false; label=\"\")\n\nsavefig(\"lorenz2.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"This graph shows the strength of the DifferentialEquations package. With a small computational effort, it can compute a good solution. Note that the last plotting call is equivalent to:","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"traj = hcat(sol.u...)\nplot(traj[1,:], traj[2,:], traj[3,:]; label=\"\")","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"In the introduction, we mentioned chaos theory. We will elaborate on this in the following exercise.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"warning: Exercise:\nUse the nextfloat function to perturb the first parameter of p by the smallest possible value. Then solve the Lorenz system again and compare the results by plotting the two trajectories next to each other.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"details: Solution:\nWe start with the smallest possible perturbation of the initial value.p0 = (nextfloat(p[1]), p[2:end]...) Then we plot the graphs as beforeprob0 = ODEProblem(lorenz, u0, tspan, p0)\nsol0 = solve(prob0)\n\nplt0 = plot(sol0, vars=(1,2,3), label=\"\")\n\nplot(plt1, plt0; layout=(1,2))\n\nsavefig(\"lorenz4.svg\") # hide","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The solutions look different. Comparing the terminal states of both solutions","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"hcat(sol(tspan[2]), sol0(tspan[2]))","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"shows that they are different by a large margin. This raises a natural question.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"warning: Exercise:\nCan we trust the solutions? Why?","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"details: Solution:\nUnfortunately, we cannot. Numerical methods always introduce some errors byRounding errors due to representing real numbers in machine precision.\nDiscretization errors for continuous systems when the finite difference method approximates the derivative.However, if the system itself is unstable and an extremely small perturbation results in big differences in solutions, the numerical method even enhances these errors. The solution could be trusted on some small interval but not after it.","category":"page"},{"location":"lecture_13/diff_eq/","page":"Julia package","title":"Julia package","text":"The following section shows a situation where we try to mitigate this possible effect by using mathematical formulas to compute the exact solution as long as possible. This aproach delays the necessary discretization and may bring better stability.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function bisection(f, a, b; tol=1e-6)\n    fa = f(a)\n    fb = f(b)\n    fa == 0 && return a\n    fb == 0 && return b\n    fa*fb > 0 && error(\"Wrong initial values for bisection\")\n    while b-a > tol\n        c = (a+b)/2\n        fc = f(c)\n        fc == 0 && return c\n        if fa*fc > 0\n            a = c\n            fa = fc\n        else\n            b = c\n            fb = fc\n        end\n    end\n    return (a+b)/2\nend","category":"page"},{"location":"lecture_13/optimal_control/#Optimal-control","page":"Optimal control","title":"Optimal control","text":"","category":"section"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Optimal control combines ordinary differential equations with optimization. It was extensively studied many decades ago when it was used to steer rockets in space.","category":"page"},{"location":"lecture_13/optimal_control/#Permanent-magnet-synchronous-motors","page":"Optimal control","title":"Permanent magnet synchronous motors","text":"","category":"section"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We will consider optimal steering of a PMSM (permanent magnet synchronous motor), which appears in electrical drives. It can be described via the linear equation:","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"dot x(t) = Ax(t) + q(t) + Bu(t)","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"where x(t) is the state, q(t) is the bias and u(t) is the control term. In the simplest case, we have","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"A = -beginpmatrix rho  0  0  rho endpmatrix - omega beginpmatrix 0  -1  1  0 endpmatrix qquad B = beginpmatrix 1  0  0  1endpmatrix qquad q(t) = beginpmatrix rhopsi_rm pm  0 endpmatrix","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"where rho=frac RL is the ratio of resistance and inductance, psi the flux and omega the rotor speed. Vector q does not depend on time. The state x(t) are the currents in the dq-reference frame, and the control u(t) is the provided voltage.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"From the theoretical part, we know that the trajectory of the ODE equals to","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\nx(t) = e^Atleft(x_0 + int_0^t e^-As(q+u(s))dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t e^-Asu(s)dsright)\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"This term contains the matrix exponential e^At. It can be shown that the eigendecomposition of A=QLambda Q^top is","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"A = frac 12beginpmatrix i  -i  1  1 endpmatrix beginpmatrix -rho - iomega  0 0  -rho+iomega endpmatrix beginpmatrix i  1  -i  1 endpmatrix","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We have divided the expression by 2 because the eigenvectors have a unit norm. Then it is simple to compute the matrix exponential.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ne^At = frac 12beginpmatrix i  -i  1  1 endpmatrix beginpmatrix e^-rho t - iomega t  0 0  e^-rho t+iomega t endpmatrix beginpmatrix i  1  -i  1 endpmatrix \n= dots = e^-rho tbeginpmatrix cosomega t  sinomega t  -sinomega t  cosomega tendpmatrix\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/#Computing-trajectories-with-no-control","page":"Optimal control","title":"Computing trajectories with no control","text":"","category":"section"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We start with no control term, therefore u(t)=0. Then the trajectory simplifies to:","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"x(t) = e^Atleft(x_0 + A^-1(I-e^-At)q right)","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Similarly to the wave equation, this system has multiple parameters. To prevent accidentally changing them, we save them in a structure.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"struct PMSM{T<:Real}\n    ρ::T\n    ω::T\n    A::Matrix{T}\n    invA::Matrix{T}\n\n    function PMSM(ρ, ω)\n        A = -ρ*[1 0; 0 1] -ω*[0 -1; 1 0]\n        return new{eltype(A)}(ρ, ω, A, inv(A))\n    end\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Besides rho, omega and A, we also store the inverse matrix A^-1 so that we do not have to recompute it. We now write the expA function, which computes the matrix exponential e^At.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function expA(p::PMSM, t)\n    ρ, ω = p.ρ, p.ω\n    return exp(-ρ*t)*[cos(ω*t) sin(ω*t); -sin(ω*t) cos(ω*t)]\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"For the rest of this section, we will work with the following parameter setting.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"ρ = 0.1\nω = 2\nx0 = [0;-0.5]\nq = [1;0]\n\nps = PMSM(ρ, ω)\n\nnothing # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The first exercise checks that we computed the matrix exponential correctly.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"warning: Exercise:\nVerify that the matrix exponential is computed correctly and that it is different from the elementwise exponential.Hint: The matrix exponential can also be computed directly by the exp function from the LinearAlgebra package.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"details: Solution:\nA simple way to verify is to fix some t and evaluate the expressions above.using LinearAlgebra\n\nt = 5\nexp0 = exp.(t*ps.A)\nexp1 = exp(t*ps.A)\nexp2 = expA(ps, t)\n\nnothing # hideWhile exp1 and exp2 must be identical, they must differ from exp0. Since there are rounding errors for different methods, the matrices will not be identical, and we need to check whether their norm is almost zero.norm(exp1 - exp0) >= 1e-10 || error(\"Matrices are wrong\")\nnorm(exp1 - exp2) <= 1e-10 || error(\"Matrices are wrong\")\n\nnothing # hideSince the computation resulted in no error (note the opposite sign for exp0), our computation seems to be correct.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Now we can finally plot the trajectories of the electric motor.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"warning: Exercise:\nWrite two function trajectory_fin_diff and trajectory_exact which compute the trajectory. The first one should use the finite difference method to discretize the time, while the second one should use the closed-form formula.Plot both trajectories on time interval 010 with time discretization step Delta t=001. Since x(t) is a two-dimensional vector, plot each component on one axis.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"details: Solution:\nBoth functions create an empty structure for the solution and then iterate over time. Since finite differences compute the solution at the next time, the loop is one iteration shorter. We compute the iteration based on the formulas derived above. The exact method does not need values at the previous point, which implies that numerical errors do not accumulate due to discretization errors.function trajectory_fin_diff(p::PMSM, x0, ts, q)\n    xs = zeros(length(x0), length(ts))\n    xs[:, 1] = x0\n\n    for i in 1:length(ts)-1\n        xs[:, i+1] = xs[:, i] + (ts[i+1]-ts[i])*(p.A * xs[:, i] + q)\n    end\n    return xs\nend\n\nfunction trajectory_exact(p::PMSM, x0, ts, q)\n    xs = zeros(length(x0), length(ts))\n\n    for (i, t) in enumerate(ts)\n        xs[:, i] = expA(p, t)*(x0 + p.invA * (I - expA(p, -t))*q)\n    end\n    return xs\nend\n\nnothing # hideFor plotting, we create the time discretization, compute both trajectories and then plot them.using Plots\n\nts = 0:0.01:10\n\nxs1 = trajectory_fin_diff(ps, x0, ts, q)\nxs2 = trajectory_exact(ps, x0, ts, q)\n\nplot(xs1[1,:], xs1[2,:], label=\"Finite differences\")\nplot!(xs2[1,:], xs2[2,:], label=\"True value\")\n\nsavefig(\"Comparison1.svg\") # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The trajectories are different. Something is wrong. However, when we use the time discretization Delta t=00001, the solutions are suddenly equal.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"ts = 0:0.0001:10\n\nxs1 = trajectory_fin_diff(ps, x0, ts, q)\nxs2 = trajectory_exact(ps, x0, ts, q)\n\nplot(xs1[1,:], xs1[2,:], label=\"Finite differences\")\nplot!(xs2[1,:], xs2[2,:], label=\"True value\")\n\nsavefig(\"Comparison2.svg\") # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Can you guess why this happened? The problem is that the finite difference method performs a first-order approximation of the non-linear function x(t). Since the trajectory always \"bends leftwards\", the finite differences follow this bending with a delay. The error accumulates over time and is quite large at the end.","category":"page"},{"location":"lecture_13/optimal_control/#Solving-the-optimal-control-problem","page":"Optimal control","title":"Solving the optimal control problem","text":"","category":"section"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The goal is to apply such voltage so that the system reaches the desired position x_rm tar from an initial position x_0 in minimal possible time. With maximal possible allowed voltage U_rm max this amounts to solving","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ntextminimizeqquad tau \ntextsubject toqquad dot x(t) = Ax(t) + q + u(t) qquad tin0tau \nu(t)le U_rm maxqquad tin0tau \nx(0) = x_0 x(tau)=x_rm tar\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Discretizing the problem and solving it using non-linear programming would result in many variables (their number would also be unknown due to the minimal time tau) and is not feasible. Instead, we analyze the problem and try to simplify it. It can be shown that for any terminal state x_rm tar, there is some p_0 such that the optimal control u(t) has form:","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\np(t) = e^-A^top tp_0 \nu(t) = U_rm maxfracp(t)p(t)\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"compat: BONUS: Connection with optimization\nThis part hints at the derivation of the previous result and the connection to constrained optimization. Optimal control forms the Hamiltonian (similar to the Langrangian)H = tau + p(t)^top (Ax(t) + q + u(t))Since the constraint is time-dependent, the adjoint variable (multiplier) p(t) must also depend on time. Differentiating the Hamiltonian with respect to the x(t) and setting the derivative to -dot p(t) (instead of zero as in nonlinear optimization) results in-dot p(t) = A^top p(t)which has the solutionp(t) = e^-A^top tp_0This is the first condition written above. The second condition can be obtained by maximizing the Hamiltonian with respect to u and arguing that the constraint u(t)=U_rm max will always be satisfied (this goes beyond the content of this lecture).","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"It is not difficult to show","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"e^-Ata^-A^top t = e^2rho tI","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We intend to compute the trajectory. The most difficult part is the integral from  e^-Asu(s). Since","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ne^-Asu(s) = U_rm maxfrace^-Ase^-A^top sp_0e^-A^top sp_0 = U_rm maxfrace^-Ase^-A^top sp_0sqrtp_0^top e^-Ase^-A^top sp_0 =  U_rm maxfrace^2rho sp_0sqrtp_0^top e^2rho sI p_0 = U_rm maxe^rho sfracp_0p_0\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"the trajectory equals to ","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\nx(t) = e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t e^-Asu(s)dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t U_rm maxe^rho sfracp_0p_0 dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + fracU_rm maxrho(e^rho t-1)fracp_0p_0 right)\nendaligned","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"When we know p_0, we can use this formula to compute the optimal trajectory with control. To compute p_0, we rearrange the previous equation to","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho t-1) fracp_0p_0 = e^-Atx(t) - x_0 - A^-1(I-e^-At)q","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We take the norm of both sides to arrive at","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho t-1) = e^-tAx(t) - x_0 - A^-1(I-e^-At)q","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Since this relation needs to hold for all tin0tau, we set t=tau and use the target relation x(tau)=x_rm tar:","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho tau-1) = e^-tau Ax_rm tar - x_0 - A^-1(I-e^-Atau)q","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Since this is one equation for one variable, we can compute the optimal time tau from it.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"warning: Exercise:\nSolve the optimal time for x_rm tar= (025 -05) with the maximum voltage U_rm max = 01.Hint: To solve the equation above for t, use the bisection method.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"details: Solution:\nTo solve the equation above, we need to find a zero point of f(t) = e^-Atx_rm tar - x_0 - A^-1(I-e^-At)q - fracU_rm maxrho(e^rho t-1)The graph of the function (plot it) shows a single zero point (for this parameter setting). It can be found by evaluating it at many points at selecting the point with the value closest to zero. A more formal approach is to use the bisection method.U_max = 0.1\nx_t = [0.25;-0.5]\n\nf(t) = norm(expA(ps, -t)*x_t - x0 - ps.invA*(I-expA(ps, -t))*q) - U_max/ps.ρ*(exp(ps.ρ*t)-1)\n\nτ = bisection(f, minimum(ts), maximum(ts))\n\nnothing # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"To compute the optimal control and optimal trajectory, we rewrite one of the formulas derived above.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function trajectory_control(p::PMSM, x0, ts, q, U_max, p0)\n    xs = zeros(length(x0), length(ts))\n\n    for (i, t) in enumerate(ts)\n        eAt  = expA(p, t)\n        emAt = expA(p, -t)\n        xs[:, i] = eAt*(x0 + p.invA * (I - emAt)*q + U_max/ρ*(exp(ρ*t) - 1)*p0)\n    end\n    return xs\nend\n\nnothing # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"To compute the optimal trajectory, we compute p_0 by the formula derived above. Then we plot the trajectory and the target point.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"p0 = ps.ρ/(U_max*(exp(ps.ρ*τ)-1))*(expA(ps, -τ)*x_t - x0 - ps.invA*(I-expA(ps, -τ))*q)\np0 /= norm(p0)\n\nts = range(0, τ; length=100)\n\ntraj = trajectory_control(ps, x0, ts, q, U_max, p0)\n\nplot(traj[1,:], traj[2,:], label=\"Optimal trajectory\")\nscatter!([x0[1]], [x0[2]], label=\"Starting point\")\nscatter!([x_t[1]], [x_t[2]], label=\"Target point\")\n\nsavefig(\"Optimal.svg\") # hide","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We confirm that the optimal trajectory leads from the starting to the target point.","category":"page"},{"location":"lecture_13/optimal_control/","page":"Optimal control","title":"Optimal control","text":"compat: BONUS: Plotting all optimal trajectories\nThe optimal trajectory depends on the normed vector p_0. All such vectors form a unit circle in mathbb R^2. Therefore, they can be parameterized by an angle alphain02pi. We plot eight possible optimal trajectories, each corresponding to a different target x_rm tar, with uniformly distributed alpha. Since we plot in a loop, we need to initialize an empty plot and then display it.ts = 0:0.01:10\n\nplt = plot()\nfor α = 0:π/4:2*π\n    trj = trajectory_control(ps, x0, ts, q, U_max, [sin(α); cos(α)])\n    plot!(plt, trj[1,:], trj[2,:], label=\"\")\nend\ndisplay(plt)\nsavefig(\"Trajectories.svg\") # hide(Image: )","category":"page"},{"location":"installation/git/#Git","page":"Git","title":"Git","text":"","category":"section"},{"location":"installation/git/","page":"Git","title":"Git","text":"Git is a distributed version control system for tracking changes in any set of text files. It is designed for coordinating work among cooperating programmers during software development. The Julia package system is based on Git, and the whole Julia project is hosted on GitHub. GitHub is a service that provides internet hosting for software development and version control using Git. This section offers a basic tutorial on installing and setting Git on Windows 10.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"Git installer can be download from the official download page.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"Download the proper installer, run it and follow the instructions.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"There is no need to change the default settings. However, we recommend changing the default editor used by Git to Visual Studio Code.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"After setting the editor used by Git, finish the installation with default settings.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"info: GitHub Account:\nCreate a GitHub account on the official GitHub page. Do not forget to verify your email address.","category":"page"},{"location":"installation/git/#User-settings","page":"Git","title":"User settings","text":"","category":"section"},{"location":"installation/git/","page":"Git","title":"Git","text":"Before using Git, we need to make the necessary settings. Type cmd into the search bar and open the Command Prompt.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"In the Command Prompt type the following two commands","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"git config --global user.name \"USERNAME\"git config --global user.email \"USEREMAIL\"","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"and press Enter. Do not forget to change USERNAME and USEREMAIL to the ones registered at GitHub.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"The commands above set the user name and email for Git. Because Git is designed for collaboration between multiple people, this information is used to track who made which changes.","category":"page"},{"location":"lecture_02/arrays/#Vectors","page":"Arrays","title":"Vectors","text":"","category":"section"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"A vector is a particular case of an array with only one dimension. It is represented as a list of ordered data with the same type (Int64, Float64, Any,...). A vector in Julia can be constructed directly using square brackets and a comma (or semicolon) as separators.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1, 2, 3, 4, 5, 6, 7, 8] # or equivalently v = [1; 2; 3; 4; ...]\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The number of dimensions and the type of elements can be obtained from the output of the typeof function.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(v)\nVector{Int64} (alias for Array{Int64, 1})","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The general description of an array in Julia is as follows: Array{T,N} denotes N-dimensional dense array with elements of type T. From this description, we can immediately see that vector v has one dimension and contains elements of type Int64. Another way to get this information is to use the ndims and eltype functions.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> ndims(v)\n1\n\njulia> eltype(v)\nInt64","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"We can also check the size and the length of a vector using the size and length functions.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> size(v)\n(8,)\n\njulia> length(v)\n8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The size function returns a tuple containing the array size along all dimensions. The length function returns a total number of elements.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Elements of a vector can be accessed via square brackets. Contrary to other programming languages like C or Python, and similarly to Matlab, arrays are indexed from 1. For example, the third element of vector v can be accessed via the following syntax:","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[3]\n3","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"There are also special keywords to access the first and last element of a vector.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[begin] # the first element\n1\n\njulia> v[end] # the last element\n8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Multiple elements can be accessed at once. The only difference is that instead of only one index, we use a vector of multiple indices. For example, to access the second and third element of vector v, we can do:","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[[2, 3]]\n2-element Vector{Int64}:\n 2\n 3","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to select multiple indices using the range function. It always accepts the starting point as a first argument, and then the keyword argument stop or length. The user can also set the step length using the keyword argument step. If the keywords length, stop, and step are all specified, they must agree. For example, to generate integers from 1 to 10 with step length 2, the following code can be used:","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> range(1; stop = 10, step = 2) # or equivalently range(1, 10; step = 2)\n1:2:9","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Ranges can also be constructed using the shorter syntax start:step:stop, where the step can be omitted if it equals 1. The previous example can be equivalently rewritten as","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> 1:2:10\n1:2:9","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"This shorter syntax is handy for accessing array elements.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[1:3] # the first three elements\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> v[1:2:end] # select all elements with odd index\n4-element Vector{Int64}:\n 1\n 3\n 5\n 7\n\njulia> v[:] # all elements\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"New elements can be appended to the vector using the append! function. Notice the ! symbol in the function name. This is Julia's convention for naming functions that modify their input arguments (usually the first one). In this case, the append! function appends one or more elements to the end of the given vector.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1,2,3]\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> append!(v, 4)\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\njulia> append!(v, [5,6])\n6-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> append!(v, 7:8)\n8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"As has already been said, the elements of a vector share the same type. In this case, we have a vector with elements of type Int64. If we try to append a value that is not representable as Int64, it will result in an error.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> append!(v, 3.0)\n9-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 3\n\njulia> append!(v, 3.1415)\nERROR: InexactError: Int64(3.1415)\n[...]","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"In the first case, it is possible to append a floating-point number since it can be represented as an integer. We can use the isinteger function to test whether the number is numerically equal to some integer.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> isinteger(3.0)\ntrue","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"In the second case, we cannot convert the given number to Int64 without losing precision, thus the error. The vector v can store only values of type Int64 or values that can be safely converted to Int64 (such as Int32). To avoid these errors, we can initialize the type of elements when creating a vector. It can be done using a type name followed by a square bracket.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = Float64[1, 2, 3]\n3-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n\njulia> append!(v, 3.1415)\n4-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n 3.1415","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Since arrays in Julia are mutable objects, it is possible to change their values. This can be done by assigning a new value to an element.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1, 2, 3, 4]\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\njulia> v[2] = 4\n4\n\njulia> v\n4-element Vector{Int64}:\n 1\n 4\n 3\n 4","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to assign one value to multiple array elements at once. However, in this case, we have to use dot syntax, which Julia uses for element-wise operations.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[3:4] .= 11\n2-element view(::Vector{Int64}, 3:4) with eltype Int64:\n 11\n 11\n\njulia> v\n4-element Vector{Int64}:\n  1\n  4\n 11\n 11","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"warning: Exercise:\nCreate a vector of positive integers that contains all odd numbers smaller than 10. Then change the first element to 4 and the last two elements to 1.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"details: Solution:\nSuch a vector can be either created manually byjulia> v = [1,3,5,7,9]\n5-element Vector{Int64}:\n 1\n 3\n 5\n 7\n 9or we can use the range function to create a range with given properties and then use the collect function to create a vector. Another possibility is to use the Vector type to convert the range into a vector.julia> collect(1:2:9)\n5-element Vector{Int64}:\n 1\n 3\n 5\n 7\n 9\n\njulia> Vector(1:2:9)\n5-element Vector{Int64}:\n 1\n 3\n 5\n 7\n 9The values stored in the vector can be changed using the .= sign and proper indices. Do not forget to add the dot before the = sign to perform the element-wise operation.julia> v[1] = 4\n4\n\njulia> v[end-1:end] .= 1\n2-element view(::Vector{Int64}, 4:5) with eltype Int64:\n 1\n 1\n\njulia> v\n5-element Vector{Int64}:\n 4\n 3\n 5\n 1\n 1","category":"page"},{"location":"lecture_02/arrays/#Matrices","page":"Arrays","title":"Matrices","text":"","category":"section"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"A matrix is a special case of an array with precisely two dimensions. In Julia, we can construct a matrix by the square brackets similarly to vectors. Matrices are built row by row. Elements in rows are separated by spaces, and rows are separated by semicolons.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> M = [1  2  3  4; 5  6  7  8]\n2×4 Matrix{Int64}:\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The same functions can obtain the basic information about matrices as for vectors.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(M)\nMatrix{Int64} (alias for Array{Int64, 2})\n\njulia> eltype(M)\nInt64\n\njulia> ndims(M)\n2\n\njulia> size(M)\n(2, 4)\n\njulia> length(M)\n8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Accessing matrix elements can be also done in the same way as for vectors.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> M[1] # the first element, equivalent to m[begin]\n1\n\njulia> M[2] # the the second element element\n5\n\njulia> M[end-1] # the second to last element\n4","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Note that the second element is 5. The reason is that Julia is column-oriented. Element at a specific position in a matrix can be accessed by the following syntax matrix[row_index, column_index]. The following code returns the second element in the first row.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> M[1, 2]\n2","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to access multiple elements at once","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> M[1, [2, 3]] # the second and third element in the first row\n2-element Vector{Int64}:\n 2\n 3\n\njulia> M[1:3] # the first three elements according to linear indexing\n3-element Vector{Int64}:\n 1\n 5\n 2\n\njulia> M[:, 1:3] # the first three columns\n2×3 Matrix{Int64}:\n 1  2  3\n 5  6  7\n\njulia> M[1, :] # the first row\n4-element Vector{Int64}:\n 1\n 2\n 3\n 4\n\njulia> M[:] # all elements\n8-element Vector{Int64}:\n 1\n 5\n 2\n 6\n 3\n 7\n 4\n 8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"It is impossible to append new elements into arrays directly, except for vectors. However, arrays with matching sizes along a dimension can be concatenated in this dimension. For example, we can horizontally concatenate the matrix m using the hcat function.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> hcat(M, M)\n2×8 Matrix{Int64}:\n 1  2  3  4  1  2  3  4\n 5  6  7  8  5  6  7  8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"For concatenating vertically, we use the vcat function.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> vcat(M, M)\n4×4 Matrix{Int64}:\n 1  2  3  4\n 5  6  7  8\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The general function cat concatenates arrays along the dimension specified by the dims keyword argument.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> cat(M, M; dims = 2) # equivalent to hcat(m, m)\n2×8 Matrix{Int64}:\n 1  2  3  4  1  2  3  4\n 5  6  7  8  5  6  7  8\n\njulia> cat(M, M; dims = 1) # equivalent to vcat(m, m)\n4×4 Matrix{Int64}:\n 1  2  3  4\n 5  6  7  8\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"If the sizes of arrays do not match, an error occurs.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [11, 12]\n2-element Vector{Int64}:\n 11\n 12\n\njulia> hcat(M, v)\n2×5 Matrix{Int64}:\n 1  2  3  4  11\n 5  6  7  8  12\n\njulia> vcat(M, v)\nERROR: DimensionMismatch: number of columns of each array must match (got (4, 1))\n[...]","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"warning: Exercise:\nCreate two vectors: vector of all odd positive integers smaller than 10 and vector of all even positive integers smaller than or equal to 10. Then concatenate these two vectors horizontally and fill the third row with 4.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"details: Solution:\nFirst, we have to create the two vectors. We can do it manually, or we can use ranges and the collect function as in the exercise in the previous section.julia> v1 = collect(1:2:9)\n5-element Vector{Int64}:\n 1\n 3\n 5\n 7\n 9\n\njulia> v2 = collect(2:2:10)\n5-element Vector{Int64}:\n  2\n  4\n  6\n  8\n 10Then we use the hcat function to concatenate these two vectors horizontally.julia> M = hcat(v1, v2)\n5×2 Matrix{Int64}:\n 1   2\n 3   4\n 5   6\n 7   8\n 9  10Finally, we select all elements in the third row and assign the new value to them.julia> M[3,:] .= 4\n2-element view(::Matrix{Int64}, 3, :) with eltype Int64:\n 4\n 4\n\njulia> M\n5×2 Matrix{Int64}:\n 1   2\n 3   4\n 4   4\n 7   8\n 9  10","category":"page"},{"location":"lecture_02/arrays/#N-dimensional-arrays","page":"Arrays","title":"N-dimensional arrays","text":"","category":"section"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"In many cases, it is useful to use arrays with more dimensions to store data. As an example, we can mention RGB images, which are typically stored in 3-dimensional arrays. In Julia, there is no straightforward way to create N-dimensional arrays. The typical way to make such an array is to create an empty array of appropriate size and then fill it manually or using a loop. In this lecture, we will focus only on the basics of creating arrays. The lecture focused on loops will explain this topic in more details.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"compat: New features in Julia 1.7\nStarting with Julia 1.7, it is possible to create multidimensional arrays in a similar way to matrices and vectors. Repeated semicolons can be used inside array concatenation expressions to separate dimensions of an array, with the number of semicolons specifying the dimension.julia> [1; 2; 3]\n3-element Vector{Int64}:\n1\n2\n3\n\njulia> [1;; 2;; 3]\n1×3 Matrix{Int64}:\n1  2  3\n\njulia> [1;;; 2;;; 3]\n1×1×3 Array{Int64, 3}:\n[:, :, 1] =\n1\n\n[:, :, 2] =\n2\n\n[:, :, 3] =\n3","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"There are several ways to initialize an array. The simplest and most common is using the zeros function. By default, this function creates an array of given size filled with zeros of type Float64.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = zeros(3, 5, 2) # equivalent to A = zeros((3, 5, 2))\n3×5×2 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The element type can be changed by passing the type as a first argument.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> B = zeros(Int64, 3, 5, 2)  # equivalent to B = zeros(Int64, (3, 5, 2))\n3×5×2 Array{Int64, 3}:\n[:, :, 1] =\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n\n[:, :, 2] =\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"As in the case of vectors and matrices, we can use the same functions to obtain basic information about arrays.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(A)\nArray{Float64, 3}\n\njulia> eltype(A)\nFloat64\n\njulia> ndims(A)\n3\n\njulia> size(A)\n(3, 5, 2)\n\njulia> length(A)\n30","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Assigning a new value to the element of an array is also the same.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> B[1] = 1 # assign 1 to the first element\n1\n\njulia> B[1, 2, 2] = 2 # assign 2 to the element at position (1,2,2)\n2\n\njulia> B[2,:,1] .= 4\n5-element view(::Array{Int64, 3}, 2, :, 1) with eltype Int64:\n 4\n 4\n 4\n 4\n 4\n\njulia> B\n3×5×2 Array{Int64, 3}:\n[:, :, 1] =\n 1  0  0  0  0\n 4  4  4  4  4\n 0  0  0  0  0\n\n[:, :, 2] =\n 0  2  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Other useful functions can be used to initialize an array. The ones function is similar to the zeros function, but instead of an array filled with zeros, it creates an array filled with ones.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> ones(Float32, 2, 3, 1)\n2×3×1 Array{Float32, 3}:\n[:, :, 1] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Function fill creates an array of given size filled with the given value.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> fill(1.234, 2, 3, 1)\n2×3×1 Array{Float64, 3}:\n[:, :, 1] =\n 1.234  1.234  1.234\n 1.234  1.234  1.234","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"warning: Exercise:\nCreate three matrices with the following properties:Matrix A is of size 2x3, and all its elements equal 0.\nMatrix B is of size 2x3x1, and all its elements equal 1.\nMatrix C is of size 2x3, and all its elements equal 2.Concatenate these three matrices along the third dimension.Hint: use the cat function and the keyword dims.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"details: Solution:\nMatrix A can be created using the zeros function, and similarly, matrix B using the ones function. To create a matrix C, we can use the fill function.julia> A = zeros(2, 3)\n2×3 Matrix{Float64}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\njulia> B = ones(2, 3, 1)\n2×3×1 Array{Float64, 3}:\n[:, :, 1] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n\njulia> C = fill(2, 2, 3)\n2×3 Matrix{Int64}:\n 2  2  2\n 2  2  2Now we can use the cat function with dims = 3 to concatenate the matrices along the third dimension.julia> cat(A, B, C; dims = 3)\n2×3×3 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\n[:, :, 2] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n\n[:, :, 3] =\n 2.0  2.0  2.0\n 2.0  2.0  2.0","category":"page"},{"location":"lecture_02/arrays/#Broadcasting","page":"Arrays","title":"Broadcasting","text":"","category":"section"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"In Julia, broadcasting maps a function or an operation (which are the same in Julia) over an array (or any other iterable object) element by element. Since it is equivalent to writing a for loop, there is no speed gain, but its conciseness may be useful. Julia's core idea is to write functions that take single values as inputs and use broadcasting whenever needed. The exception is when a function must explicitly work on arrays such as sorting, computing means, or matrix operations.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The broadcasting notation for operators consists of adding a dot . before the operator such as .*, .+ or ./).","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a = [1,2,3] # column vector\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> a .-= 4 # from each element of vector subtracts 4\n3-element Vector{Int64}:\n -3\n -2\n -1","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Without the dot, we get an error since we cannot subtract a number from a vector.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a -= 1\nERROR: MethodError: no method matching -(::Vector{Int64}, ::Int64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n[...]","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The same syntax can be applied to any function in Julia. It is beneficial for basic operations. For example, we can compute the absolute value of all elements by","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> abs.(a)\n3-element Vector{Int64}:\n 3\n 2\n 1","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"With broadcasting, it is effortless to compute complex mathematical formulas. For example, if we want to evaluate the following formulas:","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"sum_i = 1^3 fracexpsqrta_i - 12","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"we can use the following code","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> sum(exp.(sqrt.(abs.(a .- 1)))./2)\n8.577270075873834","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Broadcasting can also be used for matrix multiplication. Consider the following two vectors.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a = [1,2,3] # column vector\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> b = [4,5,6] # column vector\n3-element Vector{Int64}:\n 4\n 5\n 6","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Since we have two column vectors, the matrix multiplication will not work.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a * b\nERROR: MethodError: no method matching *(::Vector{Int64}, ::Vector{Int64})\n[...]","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"It makes perfect sense from a mathematical perspective, and the * operator behaves how we would mathematically expect. If we want to use matrix multiplication, we have to transpose one of the vectors.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a' * b\n32\n\njulia> a * b'\n3×3 Matrix{Int64}:\n  4   5   6\n  8  10  12\n 12  15  18","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Nonetheless, it is often useful to write operations in an element-wise manner in programming. In such cases, broadcasting is helpful.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> a .* b\n3-element Vector{Int64}:\n  4\n 10\n 18","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"warning: Exercise:\nConstruct a matrix whose elements are given by the following formulaA_i j = frac12exp(B_i j + 1)^2 quad i in 1 2  j in  1 2 3where the matrix B is defined byB = [\n    -1  0  2;\n    2  -3  1;\n]","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"details: Solution:\nEach element of the matrix A depends on only one element of the matrix B. In other words, matrix A can be created in an element-wise manner from matrix B, i.e. we can use broadcasting.julia> A = exp.((B .+ 1) .^ 2) ./ 2\n2×3 Matrix{Float64}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991We use a dot before each operation since we want to perform all operations element-wise. In this case, we can use the @. macro, which automatically adds a dot before each operator and each function.julia> A = @. exp((B + 1) ^ 2) / 2\n2×3 Matrix{Float64}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991Just for the comparison, the same matrix can be created as follows using for loop.julia> A = zeros(2, 3);\n\njulia> for i in 1:length(A)\n           A[i] = exp((B[i] + 1)^2)/2\n       end\n\njulia> A\n2×3 Matrix{Float64}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991","category":"page"},{"location":"lecture_02/arrays/#Views","page":"Arrays","title":"Views","text":"","category":"section"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"As in other programming languages, arrays are pointers to memory location. Thus we need to pay attention to how we handle them. If we create an array A and assign it to a variable B, the original array elements can be modified by changing B.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6]\n2×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n\njulia> B = A\n2×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n\njulia> B[2] = 42\n42","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"We can check that both arrays are equal even though we modified only array B.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> A == B\ntrue","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The reason is that Julia, by default, does not create a copy of an array when assigning to a variable. This behavior is advantageous because it saves memory. However, it also may have undesirable effects. If we want to make a copy of an array, we have to use the copy function.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> C = copy(A)\n2×3 Matrix{Int64}:\n  1  2  3\n 42  5  6\n\njulia> C[4] = 10\n10\n\njulia> A == C\nfalse","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Different behaviour occurs when accessing elements. Every time we access multiple array elements at once, a new array is created.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> D = A[1:2, 1:2]\n2×2 Matrix{Int64}:\n  1  2\n 42  5\n\njulia> D[1] = 15\n15","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"In this case, we modified array D, while array A remains unchanged.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> D == A[1:2, 1:2]\nfalse","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Even if we want to select a subarray, it may be useful to create only a link to the original array and not create a new array. This can be achieved by the view function or the @view macro.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> E = view(A, 1:2, 1:2)\n2×2 view(::Matrix{Int64}, 1:2, 1:2) with eltype Int64:\n  1  2\n 42  5\n\njulia> E = @view A[1:2, 1:2]\n2×2 view(::Matrix{Int64}, 1:2, 1:2) with eltype Int64:\n  1  2\n 42  5\n\njulia> E[4] = 78\n78","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"If we change only the array D, this change is propagated to A.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> E == A[1:2, 1:2]\ntrue","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The function view creates the special type SubArray.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(E)\nSubArray{Int64, 2, Matrix{Int64}, Tuple{UnitRange{Int64}, UnitRange{Int64}}, false}","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"Since SubArray is a subtype of AbstractArray, we can apply any function defined for AbstractArrays to SubArray. In other words, (almost) all functions that work for arrays will also work for subarrays.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6]\n2×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n\njulia> A_view = @view A[:, :]\n2×3 view(::Matrix{Int64}, :, :) with eltype Int64:\n 1  2  3\n 4  5  6\n\njulia> sum(A)\n21\n\njulia> sum(A_view)\n21\n\njulia> minimum(A; dims = 1)\n1×3 Matrix{Int64}:\n 1  2  3\n\njulia> minimum(A_view; dims = 1)\n1×3 Matrix{Int64}:\n 1  2  3","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"This means that we can use arrays and subarrays interchangeably without the necessity of changing existing code. Of course, there are some limitations, but we will talk about them later.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"The @view macro can only be applied directly to a reference expression. We do not want to use views throughout the whole expression in many cases. In such a case, we can add the @view macro before each array-slicing operation.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6];\n\njulia> sum(exp.(sqrt.(abs.(@view(A[1, :]) .- @view(A[2, :]))))./2)\n8.478350511051136","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"However, the resulting expression is long and difficult to read. To simplify this task, Julia provides the @views macro that converts every array-slicing operation in the given expression to return a view.","category":"page"},{"location":"lecture_02/arrays/","page":"Arrays","title":"Arrays","text":"julia> @views sum(exp.(sqrt.(abs.(A[1, :] .- A[2, :])))./2)\n8.478350511051136","category":"page"},{"location":"installation/vscode/#Julia","page":"Julia + Visual Studio Code","title":"Julia","text":"","category":"section"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"Julia can be installed from the official download page. The appropriate version is the 64-bits version for the Windows operating system in most cases. In case of difficulties, we refer to platform-specific instructions.","category":"page"},{"location":"installation/vscode/#Visual-Studio-Code","page":"Julia + Visual Studio Code","title":"Visual Studio Code","text":"","category":"section"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"It is possible to write Julia codes in any text editor, and run them directly from the terminal. However, it is usually better to use an IDE that provides additional features such as syntax highlighting, or code suggestions. We recommend using Visual Studio Code, a free source-code editor made by Microsoft. It supports many programming languages (Julia, Python, LaTex, ...) via extensions. The editor is available at the official download page.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"Download the proper installer, run it and follow the instructions","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"There is no need to change the default settings. On the installer's last window, select the Launch Visual Studio Code option and press the Finish button.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"If the installation was successful, the VS Code should open in a new window.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/#Extensions","page":"Julia + Visual Studio Code","title":"Extensions","text":"","category":"section"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"To use the VS Code as an IDE for Julia, we have to install the Julia extension. It can be done directly from the VS Code. Open the Extension MarketPlace by pressing the button in the Activity bar (the left bar). Type julia in the search bar and select the Julia extension. Then press the Install button to install the extension.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"After the installation, press Ctrl + Shift + P to open the command palette. Type Julia: Start REPL into the command palette and press enter.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"The panel with the terminal and new Julia session should open.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"info: Configuring the Julia extension:\nIf you installed Julia into a standard location on Mac or Windows, or if the Julia binary is on your PATH, the Julia VS Code extension automatically finds your Julia installation. If the VS Code extension does not find your Julia installation automatically, or you want to use a different Julia installation than the default one, you need to configure the extension using the following steps: Open VS Code settings.(Image: )Type Julia: Executable Path in the search box.\nSet the Julia: Executable Path to the full path of Julia executable that the extension should use. The format of the path should follow your platform specific conventions.(Image: )","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"There are other useful extensions. We recommend installing the Project Manager extension that provides additional features to manage projects.","category":"page"},{"location":"installation/vscode/","page":"Julia + Visual Studio Code","title":"Julia + Visual Studio Code","text":"(Image: )","category":"page"},{"location":"lecture_09/theory/#Introduction-to-regression-and-classification","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"Regression and classification are a part of machine learning which predicts certain variables based on labelled data. Both regression and classification operate on several premises:","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"We differentiate between datapoints x and labels y. While data points are relatively simple to obtain, labels y are relatively hard to obtain.\nWe consider some parameterized function operatornamepredict(wx) and try to find an unknown variable w to correctly predict the labels from samples (data points)","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"operatornamepredict(wx) approx y","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"We have a labelled datasets with n samples x_1dotsx_n and labels y_1dotsy_n.\nWe use the labelled dataset to train the weights w.\nWhen an unlabelled sample arrives, we use the prediction function to predict its label.","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"The MNIST dataset contains n=50000 images of grayscale digits. Each image x_i from the dataset has the size 28times 28 and was manually labelled by y_iin0dots9. When the weights w of a prediction function operatornamepredict(wx) are trained on this dataset, the prediction function can predict which digit appears on images it has never seen before. This is an example where the images x are relatively simple to obtain, but the labels y are hard to obtain due to the need to do it manually.","category":"page"},{"location":"lecture_09/theory/#Regression-and-classification","page":"Introduction to regression and classification","title":"Regression and classification","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"The difference between regression and classification is simple:","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"Regression predicts a continuous variable y (such as height based on weight).\nClassification predict a variable y with a finite number of states (such as cat/dog/none from images).","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"The body-mass index is used to measure fitness. It has a simple formula","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"operatornameBMI = fracwh^2","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"where w is the weight and h is the height. If we do not know the formula, we may estimate it from data. We denote x=(wh) the samples and y=operatornameBMI the labels. Then regression considers the following data.","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"x^1 x^2 y\n94 1.8 29.0\n50 1.59 19.8\n70 1.7 24.2\n110 1.7 38.1","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"The upper index denotes components while the lower index denotes samples. Sometimes it is not necessary to determine the exact BMI value but only whether a person is healthy, which is defined as any BMI value in the interval 185 25. When we assign label 0 to underweight people, label 1 to normal people and label 2 to overweight people, then classification considers the following data.","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"x^1 x^2 y\n94 1.8 2\n50 1.59 1\n70 1.7 1\n110 1.7 2","category":"page"},{"location":"lecture_09/theory/#Mathematical-formulation","page":"Introduction to regression and classification","title":"Mathematical formulation","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"Recall that the samples are denoted x_i while the labels y_i. Having n datapoints in the dataset, the training procedure finds weights w by solving","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"operatornameminimize_wqquad frac 1n sum_i=1^noperatornamelossbig(y_i operatornamepredict(wx_i)big)","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"This minimizes the average discrepancy between labels and predictions. We need to specify the prediction function operatornamepredict and the loss function operatornameloss. This lecture considers linear predictions","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"operatornamepredict(wx) = w^top x","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"while non-linear predictions are considered in the following lecture.","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"info: Linear classifiers:\nWe realize thatw^top x + b = (w b)^top beginpmatrixx  1endpmatrixThat means that if we add 1 to each sample x_i, it is sufficient to consider the classifier in the form w^top x without the bias (shift, intercept) b. This allows for simpler implementation.","category":"page"},{"location":"lecture_09/theory/","page":"Introduction to regression and classification","title":"Introduction to regression and classification","text":"compat: BONUS: Data transformation\nLinear models have many advantages, such as simplicity or guaranteed convergence for optimization methods. Sometimes it is possible to transform non-linear dependences into linear ones. For example, the body-mass indexoperatornameBMI = fracwh^2is equivalent to the linear dependencelog operatornameBMI = log w - 2log hin logarithmic variables. We show the same table as for regression but with logarithmic variable values.log x^1 log x^2 log y\n4.54 0.59 3.37\n3.91 0.46 2.99\n4.25 0.53 3.19\n4.25 0.53 3.64It is not difficult to see the simple linear relation with coefficients 1 and -2, namely log y = log x^1 - 2log x^2","category":"page"},{"location":"lecture_02/dictionaries/#Dictionaries","page":"Dictionaries","title":"Dictionaries","text":"","category":"section"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"Dictionaries are mutable, unordered (random order) collections of pairs of keys and values. The syntax for creating a dictionary is:","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> d = Dict(\"a\" => [1, 2, 3], \"b\" => 1)\nDict{String, Any} with 2 entries:\n  \"b\" => 1\n  \"a\" => [1, 2, 3]","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"Another possibility is to use symbols instead of strings as keys.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> d = Dict(:a => [1, 2, 3], :b => 1)\nDict{Symbol, Any} with 2 entries:\n  :a => [1, 2, 3]\n  :b => 1","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"It is possible to use almost any type as a key in a dictionary. Dictionary's elements can be accessed via square brackets and a key.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> d[:a]\n3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"If the key does not exist in the dictionary, an error will occur if we try to access it.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> d[:c]\nERROR: KeyError: key :c not found\n[...]\n\njulia> haskey(d, :c)\nfalse","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"The haskey function checks whether the dictionary has the :c key. To avoid such errors, we can use the get function that accepts three arguments: a dictionary, key, and a default value for this key, which is returned if the key does not exist in the dictionary.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> get(d, :c, 42)\n42","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"There is also an in-place version of the get function. The get! function adds the default value to the dictionary if the key does not exist.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> get!(d, :c, 42)\n42\n\njulia> get!(d, :d, [\"hello\", \"world\"])\n2-element Vector{String}:\n \"hello\"\n \"world\"\n\njulia> d\nDict{Symbol, Any} with 4 entries:\n  :a => [1, 2, 3]\n  :b => 1\n  :d => [\"hello\", \"world\"]\n  :c => 42","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"Unwanted keys from the dictionary can be removed by the delete! function.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> delete!(d, :d)\nDict{Symbol, Any} with 3 entries:\n  :a => [1, 2, 3]\n  :b => 1\n  :c => 42\n\njulia> haskey(d, :d)\nfalse","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"An alternative is the pop! function, which removes the key from the dictionary, and returns the value corresponding to it.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> pop!(d, :c)\n42\n\njulia> haskey(d, :c)\nfalse","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"Optionally, it is possible to add a default value for a given key to the pop! function, which is returned if the key does not exist in the given dictionary.","category":"page"},{"location":"lecture_02/dictionaries/","page":"Dictionaries","title":"Dictionaries","text":"julia> haskey(d, :c)\nfalse\n\njulia> pop!(d, :c, 444)\n444","category":"page"},{"location":"lecture_04/scope/#Scope-of-variables","page":"Scope of variables","title":"Scope of variables","text":"","category":"section"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"The scope of a variable is the region of a code where the variable is visible. There are two main scopes in Julia: global and local. The global scope can contain multiple local scope blocks. Local scope blocks can be nested. There is also a distinction in Julia between constructs which introduce a hard scope and those which only introduce a soft scope. This affects whether shadowing a global variable by the same name is allowed.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"The following table shows constructs that introduce scope blocks.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"Construct Scope type Allowed within local\nmodule, baremodule global ✗\nstruct local (soft) ✗\nmacro local (hard) ✗\nfor, while, try local (soft) ✔\nlet, functions, comprehensions, generators local (hard) ✔","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"This table contains several constructs which we have not introduced yet. Modules and structures will be discussed later in the course. The rest is described in the official documentation.","category":"page"},{"location":"lecture_04/scope/#Local-scope","page":"Scope of variables","title":"Local scope","text":"","category":"section"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"A function declaration introduces a new (hard) local scope. It means that all variables defined inside a function body can be accessed and modified inside the function body. Moreover, it is impossible to access these variables from outside the function.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> function f()\n           z = 42\n           return\n       end\nf (generic function with 1 method)\n\njulia> f()\n\njulia> z\nERROR: UndefVarError: `z` not defined","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"Thanks to this property, we can use the names most suitable for our variables (i, x, y, etc.) without the risk of clashing with declarations elsewhere. It is possible to specify a global variable inside a function by the global keyword.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> function f()\n           global z = 42\n           return\n       end\nf (generic function with 1 method)\n\njulia> f()\n\njulia> z\n42","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"However, this is not recommended.  If we need a variable defined inside a function, we should probably return that variable as an output of the function","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> function f()\n           z = 42\n           return z\n       end\nf (generic function with 1 method)\n\njulia> z = f()\n42\n\njulia> z\n42","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"In the example above, the z variable in the function is local, and the z variable outside of the function is global. These two variables are not the same.","category":"page"},{"location":"lecture_04/scope/#Global-scope","page":"Scope of variables","title":"Global scope","text":"","category":"section"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"Each module introduces a new global scope, separate from the global scope of all other modules. The interactive prompt (aka REPL) is in the global scope of the module Main.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> module A\n           a = 1 # a global in A's scope\n           b = 2 # b global in A's scope\n       end\nA\n\njulia> a # errors as Main's global scope is separate from A's\nERROR: UndefVarError: `a` not defined","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"Modules can introduce variables of other modules into their scope through the using (or import)  keyword. Variables can be accessed by the dot-notation.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> using .A: b # make variable b from module A available\n\njulia> A.a\n1\n\njulia> b\n2","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"While variables can be read externally, they can only be changed within the module they belong to.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> b = 4\nERROR: cannot assign a value to imported variable b\n[...]","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"Global scope variables can be accessed anywhere inside the global scope, even in the local scopes defined in that global scope. In the following example, we define a variable c in the Main global scope, and then we define a function foo (that introduces a new local scope inside the Main global scope), and inside this function, we use the variable c,","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"julia> c = 10\n10\n\njulia> foo(x) = x + c\nfoo (generic function with 1 method)\n\njulia> foo(1)\n11","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"However, it is not recommended to use global variables in this way. The reason is that global variables can change their type and value at any time, and therefore they cannot be properly optimized by the compiler. We can see the performance drop in a simple test.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"x = rand(10);\ny = rand(10);\nf_global() = x .+ y\nf_local(x, y) = x .+ y\n\nhcat(f_global(), f_local(x, y))","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"In the example above, we defined two functions that do the same thing. The first function has no arguments and returns a sum of two global variables, x and y. The second function also returns a sum of variables x and y. However, in this case, these variables are local since they are introduced as the inputs to the function. If we use the @time macro, we can measure the time needed to call these two functions.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"@time f_global();\n@time f_local(x, y);","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"The second function is faster and also needs fewer allocations. The reason is that when we call the f_local function for the first time, the function is optimized for the given arguments. Each time a function is called for the first time with new types of arguments, it is compiled. This can be seen in the following example: the first call is slower due to the compilation.","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"a, b = 1:10, 11:20;\n\n@time f_local(a, b);\n@time f_local(a, b);","category":"page"},{"location":"lecture_04/scope/","page":"Scope of variables","title":"Scope of variables","text":"On the other hand, the f_global function cannot be optimized because it contains two global variables, and these two variables can change at any time.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using Plots\nusing MLDatasets\n# using ImageInspector\n\nCore.eval(Main, :(using Flux)) # hide\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nX_train = MNIST(Float32, :train)[:][1]\n\n# imageplot(1 .- X_train, 1:15; nrows = 3, size=(800,480))\n\n# savefig(\"mnist_intro.svg\")","category":"page"},{"location":"lecture_11/nn/#More-complex-networks","page":"More complex networks","title":"More complex networks","text":"","category":"section"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"This lecture shows how to train more complex networks using stochastic gradient descent. We will use the MNIST dataset containing 60000 images of digits 0-9. Each image is represented by 28 pixels in each dimension.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"(Image: )","category":"page"},{"location":"lecture_11/nn/#Preparing-data","page":"More complex networks","title":"Preparing data","text":"","category":"section"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"During the last lecture, we implemented everything from scratch. This lecture will introduce the package Flux (and Optimisers) which automizes most of the things needed for neural networks.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"It creates many layers, including convolutional layers.\nIt creates the model by chaining layers together.\nIt efficiently represents model parameters.\nIt automatically computes gradients and trains the model by updating the parameters.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"This functionality requires inputs in a specific format.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"Images must be stored in Float32 instead of the commonly used Float64 to speed up operations.\nConvolutional layers require that the input has dimension n_xtimes n_ytimes n_ctimes n_s, where (n_xn_y) is the number of pixels in each dimension, n_c is the number of channels (1 for grayscale, and 3 for coloured images) and n_s is the number of samples.\nIn general, samples are always stored in the last dimension.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"We use the package MLDatasets to load the data.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using MLDatasets\n\nT = Float32\nX_train, y_train = MLDatasets.MNIST(T, :train)[:]\nX_test, y_test = MLDatasets.MNIST(T, :test)[:]\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The first two exercises visualize the data and transform it into the correct input shape required by Flux.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nPlot the first 15 images of the digit 0 from the training set.Hint: The ImageInspector package written earlier provides the function imageplot(X_train, inds; nrows=3), where inds are the desired indices.Hint: To find the correct indices, use the function findall.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nThe unique elements in y_train show that it represents the digits.unique(y_train)Then we use the findall function to find the indices of the first 15 images of the digit zero.inds = findall(y_train .== 0)[1:15]\n\nnothing # hideWe use the imageplot function to plot the images. To invert the colours, we need to call it with 1 .- X_train instead of X_train.using Plots\nusing ImageInspector\n\nimageplot(1 .- X_train, inds; nrows=3, size=(800,480))","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"(Image: )","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nWrite function reshape_data, which reshapes X_train and X_test into the correct size required by Flux.Hint: The function should work only on inputs with the correct size. This can be achieved by specifying the correct input type X::AbstractArray{<:Real, 3}.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nAs we have never worked with MLDatasets, we do not know in which format the loading function returns the data.typeof(X_train)The variable X_train stores a three-dimensional array of images.size(X_train)Its size shows that the first two dimensions are the number of pixels and the last dimension are the samples. Since the images are grayscale, the dimension representing channels is missing. We need to add it.function reshape_data(X::AbstractArray{<:Real, 3})\n    s = size(X)\n    return reshape(X, s[1], s[2], 1, s[3])\nend\n\nnothing # hideWe specify that the input array has three dimensions via X::AbstractArray{T, 3}. This may prevent surprises when called with different input size.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"We write now the function load_data, which loads the data and transform it into the correct shape. The keyword argument onehot specifies whether the labels should be converted into their one-hot representation. The dataset keyword specifies which dataset to load. It can be any dataset from the MLDatasets package, or we can even use datasets outside of this package provided that we define the traindata and testdata functions for it.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using Flux\nusing Flux: onehotbatch, onecold\n\nfunction load_data(dataset; T=Float32, onehot=false, classes=0:9)\n    X_train, y_train = dataset(T, :train)[:]\n    X_test, y_test = dataset(T, :test)[:]\n\n    X_train = reshape_data(X_train)\n    X_test = reshape_data(X_test)\n\n    if onehot\n        y_train = onehotbatch(y_train, classes)\n        y_test = onehotbatch(y_test, classes)\n    end\n\n    return X_train, y_train, X_test, y_test\nend\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"Now we use this function to load the data and modify them into the correct form.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"X_train, y_train, X_test, y_test = load_data(MLDatasets.MNIST; T=T, onehot=true)\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The previous example mentioned that load_data is rather general. The next exercise makes it work for datasets with coloured images.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nTry to load the CIFAR10 dataset via the load_data function and fix the error in one line of code.Hint: Use dataset = MLDatasets.CIFAR10.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nWe first load the data in the same way as before.load_data(MLDatasets.CIFAR10; T=T, onehot=true)│  MethodError: no method matching reshape_data(::Array{Float32,4})\n│  Closest candidates are:\n│    reshape_data(::AbstractArray{T,3} where T) where TIt results in an error which states that the reshape_function functon is not defined for inputs with 4 dimensions. We did not implement it because MNIST contains grayscale images, which leads to arrays with 3 dimensions. To fix the problem, it suffices to add a method to the reshape_data function.reshape_data(X::AbstractArray{<:Real, 4}) = X\n\nnothing # hideNow we can load the data.typeof(load_data(MLDatasets.CIFAR10; T=T, onehot=true))Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}We see that it correctly returned a tuple of four items.","category":"page"},{"location":"lecture_11/nn/#Training-and-storing-the-network","page":"More complex networks","title":"Training and storing the network","text":"","category":"section"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"We recall that machine learning minimizes the discrepancy between the predictions operatornamepredict(w x_i) and labels y_i. Mathematically, this amount to minimizing the following objective function.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"L(w) = frac1nsum_i=1^n operatornameloss(y_i operatornamepredict(w x_i))","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The gradient descent works with the derivative nabla L(w), which contains the mean over all samples. Since the MNIST training set size is 50000, evaluating one full gradient is costly. For this reasons, the gradient is approximated by a mean over a small number of samples. This small set is called a minibatch, and this accelerated method stochastic gradient descent.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The following exercise splits the dataset into minibatches. While we can do it manually, Flux provides a simple way to do so.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nUse the help of the function DataLoader to split the dataset into minibatches.Hint: It needs to be imported from Flux via using Flux.Data: DataLoader.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nWe first load the function DataLoader.using Flux.Data: DataLoaderThe in-built help shows us how to call this function. It also includes multiple examples.help?> DataLoader\nsearch:\n\nDataLoader(data; batchsize=1, shuffle=false, partial=true)We use the following code to split the dataset into minibatches. We need to include both X_train and y_train to perform the partition for the data and the labels.batchsize = 32\nbatches = DataLoader((X_train, y_train); batchsize, shuffle = true)\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"compat: BONUS: Manually splitting the dataset\nWe can do the same procedure manually. To create minibatches, we create a random partition of all indices randperm(size(y, 2)) and use function partition to create an iterator, which creates the minibatches in the form of tuples (Xy).using Base.Iterators: partition\nusing Random\n\nbatches = map(partition(randperm(size(y, 2)), batchsize)) do inds\n    return (X[:, :, :, inds], y[:, inds])\nendThis procedure is equivalent to the map function.[(X[:, :, :, inds], y[:, inds]) for inds in partition(randperm(size(y, 2)), batchsize)]The type of batches is a one-dimensional array (vector) of tuples.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"To build the objective L, we first specify the prediction function operatornamepredict. We keep the usual convention and denote it by model m. It is a composition of seven layers:","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"Two convolutional layers extract low-level features from the images.\nTwo pooling layers reduce the size of the previous layer.\nOne flatten layer converts multi-dimensional arrays into one-dimensional vectors.\nOne dense layer is usually applied at the end of the chain.\nOne softmax layer is usually the last one and results in probabilities.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using Random\nusing Flux: flatten\n\nRandom.seed!(666)\nm = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The objective function L then applies the cross-entropy loss to the predictions and labels. For us to be able to use Flux.Optimise.train! function to easily train a neural network, we will define the loss operatornameL as","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using Flux: crossentropy\n\nL(model, X, y) = crossentropy(model(X), y)\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"We now write the function train_model! to train the neural network m. Since this function modifies the input model m, its name should contain the exclamation mark. Besides the loss function L, data X and labels y, it also contains as keyword arguments optimizer the optimizer opt, the minibatch size batchsize, the number of epochs n_epochs, and the file name file_name to which the model should be saved.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"info: Optimiser and optimiser state:\nNote that we have to initialize the optimiser state opt_state. For a simple gradient descent Descent(learning_rate), there is no internal state of the optimiser and internal parameters. However, when using different parametrized optimisers such as Adam, the internal state of opt_state is updated in each iteration, just as the parameters of the model. Therefore, if we want to save a model and continue its training later on, we need to save both the model (or its parameters) and the optimiser state.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using BSON\n\nfunction train_model!(m, L, X, y;\n        opt = Descent(0.1),\n        batchsize = 128,\n        n_epochs = 10,\n        file_name = \"\")\n\n    opt_state = Flux.setup(opt, m)\n    batches = DataLoader((X, y); batchsize, shuffle = true)\n\n    for _ in 1:n_epochs\n        Flux.train!(L, m, batches, opt_state)\n    end\n\n    !isempty(file_name) && BSON.bson(file_name, m=m, opt_state=opt_state)\n\n    return\nend\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The function train_model! first splits the datasets into minibatches batches and then uses the optimizer for n_epochs epochs. In one epoch, the model m evaluates all samples exactly once. Therefore, the optimizer performs the same number of gradient updates as the number of minibatches during one epoch. On the other hand, the standard gradient descent makes only one gradient update during one epoch. The default optimizer is the stochastic gradient descent with stepsize 01. Since we do not need an index in the loop, we use _. Finally, if file_name is non-empty, the function saves the trained model m.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nTrain the model for one epoch and save it to MNIST_simple.bson. Print the accuracy on the testing set.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nTo train the model, it suffices to call the previously written function.file_name = \"mnist_simple.bson\"\ntrain_model!(m, L, X_train, y_train; n_epochs=1, file_name=file_name)\n\nnothing # hideThe accuracy has been computed many times during the course.using Statistics\n\naccuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n\n\"Test accuracy = \" * string(accuracy(X_test, y_test))\n\nnothing # hideWe defined accuracy in a different way than before. Can you spot the difference and explain why they are equivalent?","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"println(\"Test accuracy = \", accuracy(X_test, y_test)) # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The accuracy is over 93%, which is not bad for training for one epoch only. Let us recall that training for one epoch means that the classifier evaluates each sample only once. To obtain better accuracy, we need to train the model for more epochs. Since that may take some time, it is not good to train the same model repeatedly. The following exercise determines automatically whether the trained model already exists. If not, it trains it.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"warning: Exercise:\nWrite a function train_or_load!(file_name, m, args...; ???) checking whether the file file_name exists.If it exists, it loads it and then copies its parameters into m using the function Flux.loadparams!.\nIf it does not exist, it trains it using train_model!.In both cases, the model m should be modified inside the train_or_load! function. Pay special attention to the optional arguments ???.Use this function to load the model from data/mnist.bson and evaluate the performance at the testing set.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"details: Solution:\nThe optional arguments should contain kwargs..., which will be passed to train_model!. Besides that, we include force which enforces that the model is trained even if it already exists.First, we should check whether the directory exists !isdir(dirname(file_name)) and if not, we create it mkpath(dirname(file_name)). Then we check whether the file exists (or whether we want to enforce the training). If yes, we train the model, which already modifies m. If not, we BSON.load the model and copy the loaded parameters into m by Flux.loadparams!(m, Flux.params(m_loaded)). We cannot load directly into m instead of m_loaded because that would create a local copy of m and the function would not modify the external m.function train_or_load!(file_name, m, args...; force=false, kwargs...)\n\n    !isdir(dirname(file_name)) && mkpath(dirname(file_name))\n\n    if force || !isfile(file_name)\n        train_model!(m, args...; file_name=file_name, kwargs...)\n    else\n        m_weights = BSON.load(file_name)[:m]\n        Flux.loadparams!(m, Flux.params(m_weights))\n    end\nend\n\nnothing # hideTo load the model, we should use joinpath to be compatible with all operating systems. The accuracy is evaluated as before.file_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m, L, X_train, y_train)\n\n\"Test accuracy = \" * string(accuracy(X_test, y_test))\n\nnothing # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"println(\"Test accuracy = \" * string(accuracy(X_test, y_test))) # hide","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"The externally trained model has an accuracy of more than 98% (it has the same architecture as the one defined above, but it was trained for 50 epochs.). Even though there are perfect models (with accuracy 100%) on MNIST, we are happy with this result. We will perform further analysis of the network in the exercises.","category":"page"},{"location":"lecture_11/nn/","page":"More complex networks","title":"More complex networks","text":"using Plots\n\nplot_image(x::AbstractArray{T, 2}) where T = plot(Gray.(1 .-x'), axis=false, ticks=false)\n\nfunction plot_image(x::AbstractArray{T, 3}) where T\n    size(x,3) == 1 || error(\"Image is not grayscale.\")\n    plot_image(x[:,:,1])\nend\n\nii = [1;2;54]\n\np1 = plot_image(X_train[:,:,:,ii[1]])\np2 = plot_image(X_train[:,:,:,ii[2]])\np3 = plot_image(X_train[:,:,:,ii[3]])\n\nplot(p1, p2, p3; layout=(1,3), size=(900,300))\n\nsavefig(\"nn_intro.svg\")\n\nm_val = m(X_train[:,:,:,ii])\np = maximum(m_val, dims=1)\ny_hat = onecold(m_val, 0:9)","category":"page"},{"location":"lecture_06/currencies/#Bank-account","page":"Generic programming","title":"Bank account","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"This section aims to show the real power of the Julia type system in combination with multiple-dispatch. We will present it through an example, where the goal is to create a structure that represents a bank account with the following properties:","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The structure has two fields: owner and transaction.\nIt is possible to make transactions in different currencies.\nAll transactions are stored in the currency in which they were made.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Before creating such a structure, we first define an abstract type Currency and its two concrete subtypes.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"abstract type Currency end\n\nstruct Euro <: Currency\n    value::Float64\nend\n\nstruct Dollar <: Currency\n    value::Float64\nend","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Since Euro and Dollar are concrete types, we can create their instances and use isa to check that these instances are subtypes of Currency.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Euro(1)\nEuro(1.0)\n\njulia> isa(Dollar(2), Currency) # equivalent to typeof(Dollar(2)) <: Currency\ntrue","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"As Currency is an abstract type, we cannot create its instance. However, abstract types allow us to define generic functions that work for all their subtypes. We do so and define the BankAccount composite type.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"struct BankAccount{C<:Currency}\n    owner::String\n    transaction::Vector{Currency}\n\n    function BankAccount(owner::String, C::Type{<:Currency})\n        return new{C}(owner, Currency[C(0)])\n    end\nend","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We will explain this type after creating its instance with the euro currency.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> b = BankAccount(\"Paul\", Euro)\nBankAccount{Euro}(\"Paul\", Currency[Euro(0.0)])","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"First, we observe that we use the Euro type (and not its instance) to instantiate the BankAccount type. The reason is the definition of the inner constructor for BankAccount, where the type annotation is ::Type{<:Currency}. This is in contrast with ::Currency. The former requires that the argument is a type, while the latter needs an instance.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Second, BankAccount is a parametric type, as can be seen from BankAccount{Euro}. In our example, this parameter plays the role of the primary account currency.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Third, due to the line Currency[C(0)] in the inner constructor, transactions are stored in a vector of type Vector{Currency}. The expression C(0) creates an instance of the currency C with zero value. The Currency type combined with the square brackets creates a vector that may contain instances of any subtypes of Currency. It is, therefore, possible to push a new transaction in a different currency to the transaction field.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> push!(b.transaction, Dollar(2))\n2-element Vector{Currency}:\n Euro(0.0)\n Dollar(2.0)\n\njulia> b\nBankAccount{Euro}(\"Paul\", Currency[Euro(0.0), Dollar(2.0)])","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"It is crucial to use Currency in Currency[C(0)]. Without it, we would create an array of type C only. We would not be able to add transactions in different currencies to this array as Julia could not convert the different currencies to C.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> w = [Euro(0)]\n1-element Vector{Euro}:\n Euro(0.0)\n\njulia> push!(w, Dollar(2))\nERROR: MethodError: Cannot `convert` an object of type Dollar to an object of type Euro\n[...]","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We used only the abstract type Currency to define the BankAccount type. This allows us to write a generic code that not constrained to one concrete type. We created an instance of BankAccount and added a new transaction. However, we cannot calculate an account balance (the sum of all transactions), and we cannot convert money from one currency to another. In the rest of the lecture, we will fix this, and we will also define basic arithmetic operations such as + or -.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"info: Avoid containers with abstract type parameters:\nIt is generally not good to use containers with abstract element type as we did for storing transactions. We used it in the example above because we do not want to convert all transactions to a common currency. When we create an array from different types, the promotion system converts these types to their smallest supertype for efficient memory storage.julia> [Int32(123), 1, 1.5, 1.234f0]\n4-element Vector{Float64}:\n 123.0\n   1.0\n   1.5\n   1.2339999675750732The smallest supertype is Float64, and the result is Array{Float64, 1}. When we do not want to convert the variables, we must manually specify the resulting array supertype.julia> Real[Int32(123), 1, 1.5, 1.234f0]\n4-element Vector{Real}:\n 123\n   1\n   1.5\n   1.234f0In this case, the types of all elements are preserved.","category":"page"},{"location":"lecture_06/currencies/#Custom-print","page":"Generic programming","title":"Custom print","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Each currency has its symbol, such as € for the euro. We will redefine the show function to print the currency in a prettier way. First, we define a new function symbol that returns the used currency symbol.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"symbol(T::Type{<:Currency}) = string(nameof(T))\nsymbol(::Type{Euro}) = \"€\"","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We defined one method for all subtypes of Currency and one method for the Euro type. With the symbol function, we can define nicer printing by adding a new method to the show function from Base. It is possible to define a custom show function for different output formats. For example, it is possible to define different formating for HTML output. The example below shows only basic usage; for more information, see the official documentation.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.show(io::IO, c::C) where {C <: Currency} = print(io, c.value, \" \", symbol(C))","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The show function has two input arguments. The first one is of type IO that specifies where the output will be printed (for example, in the REPL). The second argument is an instance of some currency. We used the where keyword in the function definition to get the currency type C, which we pass to the symbol function. Alternatively, we can use the typeof function.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.show(io::IO, c::Currency) = print(io, c.value, \" \", symbol(typeof(c)))","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We can check that the printing of currencies is prettier than before.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Euro(1)\n1.0 €\n\njulia> Euro(1.5)\n1.5 €","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"There is one big difference with Python, where we can create a class and define methods inside the class. If we wanted to add a new method, we have to would modify the class. In Julia, we can add or alter methods any time without the necessity to change the class.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"warning: Exercise:\nDefine a new method for the symbol function for Dollar.Hint: the dollar symbol $ has a special meaning in Julia. Do not forget to use the \\ symbol when using the dollar symbol in a string.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"details: Solution:\nWhen adding a new method to the symbol function, we have to remember that we used the currency type for dispatch, i.e., we have to use ::Type{Dollar} instead of ::Dollar in the type annotation.symbol(::Type{Dollar}) = \"\\$\"Now we can check that everything works well.julia> Dollar(1)\n1.0 $\n\njulia> Dollar(1.5)\n1.5 $","category":"page"},{"location":"lecture_06/currencies/#Conversion","page":"Generic programming","title":"Conversion","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"In the previous section, we have defined two currencies. A natural question is how to convert one currency to the other.  In the real world, the exchange operation between currencies is not transitive. However, we assume that the exchange rate is transitive and there are no exchange costs.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The simplest way to define conversions between the currencies is to define the conversion function for each pair of currencies. This can be done efficiently only for two currencies.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"dollar2euro(c::Dollar) = Euro(0.83 * c.value)\neuro2dollar(c::Euro) = Dollar(c.value / 0.83)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We can check that the result is correct.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> eur = dollar2euro(Dollar(1.3))\n1.079 €\n\njulia> euro2dollar(eur)\n1.3 $","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Even though this is a way to write code, there is a more general way. We start with a conversion rate between two types.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"rate(::Type{Euro}, ::Type{Dollar}) = 0.83","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Transitivity implies that if one exchange rate is r_1 rightarrow 2, the opposite exchange rate equals r_2 rightarrow 1 = r_1 rightarrow 2^-1. We create a generic function to define the exchange rate in the opposite direction.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"rate(T::Type{<:Currency}, ::Type{Euro}) = 1 / rate(Euro, T)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"If we use only the two methods above, it computes the exchange rate between Dollar and Euro.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Euro, Dollar)\n0.83\n\njulia> rate(Dollar, Euro)\n1.2048192771084338","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"However, the definition is not complete because the rate function does not work if we use the same currencies.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Euro, Euro)\nERROR: StackOverflowError:\n[...]\n\njulia> rate(Dollar, Dollar)\nERROR: MethodError: no method matching rate(::Type{Dollar}, ::Type{Dollar})\n[...]","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"To solve this issue, we have to add two new methods. The first one defines that the exchange rate between the same currency is 1.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"rate(::Type{T}, ::Type{T}) where {T<:Currency} = 1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"This method solves the issue for the Dollar to Dollar conversion.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Dollar, Dollar)\n1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"However, it does not solve the problem with Euro to Euro conversion.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Euro, Euro)\nERROR: StackOverflowError:\n[...]","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The reason is that methods are selected based on the input arguments. There is a simple rule:  the most specific method definition matching the number and types of the arguments will be executed. We use the methods function to list all methods defined for the rate function.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> methods(rate)\n# 3 methods for generic function \"rate\":\n[1] rate(::Type{Euro}, ::Type{Dollar}) in Main at none:1\n[2] rate(T::Type{var\"#s37\"} where var\"#s37\"<:Currency, ::Type{Euro}) in Main at none:1\n[3] rate(::Type{T}, ::Type{T}) where T<:Currency in Main at none:1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"There are three methods. Since two of them can be selected when converting from euro to euro, we need to specify one more method.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"rate(::Type{Euro}, ::Type{Euro}) = 1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"This method solves the issue, as can be seen in the example below.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Euro, Euro)\n1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The transitivity also implies that instead of converting the C1 currency directly to the C2 currency, we can convert it to some C and then convert C to C2. In our case, we use the Euro as the intermediate currency. When adding a new currency, it suffices to specify its exchange rate only to the euro.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"rate(T::Type{<:Currency}, C::Type{<:Currency}) = rate(Euro, C) * rate(T, Euro)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"To test the rate function, we add a new currency.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"struct Pound <: Currency\n    value::Float64\nend\n\nsymbol(::Type{Pound}) = \"£\"\nrate(::Type{Euro}, ::Type{Pound}) = 1.13","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We can quickly test that the rate function works in all possible cases correctly in the following way.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> rate(Pound, Pound) # 1\n1\n\njulia> rate(Euro, Pound) # 1.13\n1.13\n\njulia> rate(Pound, Euro) # 1/1.13 = 0.8849557522123894\n0.8849557522123894\n\njulia> rate(Dollar, Pound) # 1.13 * 1/0.83 = 1.36144578313253\n1.3614457831325302\n\njulia> rate(Pound, Dollar) # 0.83 * 1/1.13 = 0.7345132743362832\n0.7345132743362832","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We have defined the rate function with all necessary methods. To convert currency types, we need to extend the convert function from Base by the following two methods:","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.convert(::Type{T}, c::T) where {T<:Currency} = c\nBase.convert(::Type{T}, c::C) where {T<:Currency, C<:Currency} = T(c.value * rate(T, C))","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The first method is unnecessary because the rate function returns 1, and the second method could be used instead.  However, when converting to the same type, the result is usually the same object and not a new instance. We, therefore, defined the first method to follow this convention. Finally, we test that the conversion function indeed converts its input to a different type.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> eur = convert(Euro, Dollar(1.3))\n1.079 €\n\njulia> pnd = convert(Pound, eur)\n0.9548672566371682 £\n\njulia> dlr = convert(Dollar, pnd)\n1.3 $","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"warning: Exercise:\nThe printing style is not ideal because we are usually not interested in more than the first two digits after the decimal point. Redefine the method in the show function to print currencies so that the result is rounded to 2 digits after the decimal point.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"details: Solution:\nAny real number can be rounded to 2 digits after the decimal point by the round function with the keyword argument digits = 2. Then we can use an almost identical definition of the method as before.function Base.show(io::IO, c::T) where {T <: Currency}\n    val = round(c.value; digits = 2)\n    return print(io, val, \" \", symbol(T))\nendThe same code as before this example gives the following results.julia> eur = convert(Euro, Dollar(1.3))\n1.08 €\n\njulia> pnd = convert(Pound, eur)\n0.95 £\n\njulia> dlr = convert(Dollar, pnd)\n1.3 $We realize that the rounding is done only for printing, while the original value remains unchanged.","category":"page"},{"location":"lecture_06/currencies/#Promotion","page":"Generic programming","title":"Promotion","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Before defining basic arithmetic operations for currencies, we have to decide how to work with money in different currencies. Imagine that we want to add 1€ and 1$. Should the result be euro or dollar? For such a situation, Julia provides a promotion system that allows defining simple rules for promoting custom types. The promotion system can be modified by defining custom methods for the promote_rule function. For example, the following definition means that the euro has precedence against all other currencies.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.promote_rule(::Type{Euro}, ::Type{<:Currency}) = Euro","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"One does not need to define both methods. The symmetry is implied by the way promote_rule is used in the promotion process. Since we have three different currencies, we also define the promotion type for the pair Dollar and Pound.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.promote_rule(::Type{Dollar}, ::Type{Pound}) = Dollar","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The promote_rule function is used as a building block for the promote_type function, which returns the promoted type of inputs.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> promote_type(Euro, Dollar)\nEuro\n\njulia> promote_type(Pound, Dollar)\nDollar\n\njulia> promote_type(Pound, Dollar, Euro)\nEuro","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"When we have instances instead of types, we can use the promote function to convert them to their representation in the promoted type.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> promote(Euro(2), Dollar(2.4))\n(2.0 €, 1.99 €)\n\njulia> promote(Pound(1.3), Euro(2))\n(1.47 €, 2.0 €)\n\njulia> promote(Pound(1.3), Dollar(2.4), Euro(2))\n(1.47 €, 1.99 €, 2.0 €)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"warning: Exercise:\nDefine a new currency CzechCrown representing Czech crowns. The exchange rate to euro is 0.038, and all other currencies should take precedence over the Czech crown.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"details: Solution:\nWe define first the new type CzechCrown.struct CzechCrown <: Currency\n    value::Float64\nendWe must add new methods for the symbol and rate functions.symbol(::Type{CzechCrown}) = \"Kč\"\nrate(::Type{Euro}, ::Type{CzechCrown}) = 0.038We also must add promotion rules for the dollar and pound.Base.promote_rule(::Type{CzechCrown}, ::Type{Dollar}) = Dollar\nBase.promote_rule(::Type{CzechCrown}, ::Type{Pound}) = PoundFinally, we can test the functionality.julia> CzechCrown(2.8)\n2.8 Kč\n\njulia> dl = convert(Dollar, CzechCrown(64))\n2.93 $\n\njulia> convert(CzechCrown, dl)\n64.0 Kč\n\njulia> promote(Pound(1.3), Dollar(2.4), Euro(2), CzechCrown(2.8))\n(1.47 €, 1.99 €, 2.0 €, 0.11 €)","category":"page"},{"location":"lecture_06/currencies/#Basic-arithmetic-operations","page":"Generic programming","title":"Basic arithmetic operations","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Now we are ready to define basic arithmetic operations. As usual, we can do this by adding a new method to standard functions. We start with the addition, where there are two cases to consider. The first one is the summation of two different currencies. In this case, we use the promote function to convert these two currencies to their promote type.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.:+(x::Currency, y::Currency) = +(promote(x, y)...)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The second one is the summation of the same currency. In this case, we know the resulting currency, and we can sum the value fields.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.:+(x::T, y::T) where {T <: Currency} = T(x.value + y.value)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Note that the first function calls the second one. We have finished with addition, and now we can sum money in different currencies.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Dollar(1.3) + CzechCrown(4.5)\n1.51 $\n\njulia> CzechCrown(4.5) + Euro(3.2) + Pound(3.6) + Dollar(12)\n17.4 €","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Moreover, we can use, for example, the sum function without any additional changes.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> sum([CzechCrown(4.5), Euro(3.2), Pound(3.6), Dollar(12)])\n17.4 €","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Also, the broadcasting works natively for arrays of currencies.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> CzechCrown.([4.5, 2.4, 16.7, 18.3]) .+ Pound.([1.2, 2.6, 0.6, 1.8])\n4-element Vector{Pound}:\n 1.35 £\n 2.68 £\n 1.16 £\n 2.42 £","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"However, there is a problem if we want to sum a vector of currencies with one currency. In such a case, an error will occur.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> CzechCrown.([4.5, 2.4, 16.7, 18.3]) .+ Dollar(12)\nERROR: MethodError: no method matching length(::Main.Dollar)\n[...]","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The reason is that Julia assumes that custom structures are iterable. But in our case, all subtypes of the Currency type represent scalar values. This situation can be easily fixed by defining a new method to the broadcastable function from Base.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.broadcastable(c::Currency) = Ref(c)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"This function should return either an object or some representation of an object that supports the axes, ndims, and indexing functions. To create such a representation of all subtypes of the Currency type, we use the Ref function, which creates an object referring to the given currency instance and supports all necessary operations.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> c_ref = Ref(Euro(1))\nBase.RefValue{Euro}(1.0 €)\n\njulia> axes(c_ref)\n()\n\njulia> ndims(c_ref)\n0\n\njulia> c_ref[]\n1.0 €","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Now we can test if the broadcasting works as expected.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> CzechCrown.([4.5, 2.4, 16.7, 18.3]) .+ Dollar(12)\n4-element Vector{Dollar}:\n 12.21 $\n 12.11 $\n 12.76 $\n 12.84 $","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"warning: Exercise:\nIn the section above, we defined the addition for all subtypes of Currency. We also told the broadcasting system in Julia to treat all subtypes of the Currency as scalars. Follow the same pattern and define the following operations: -, *, /.Hint: Define only operations that make sense. For example, it makes sense to multiply 1 € by 2 to get 2 €. But it does not make sense to multiply 1 € by 2 €.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"details: Solution:\nThe - operation can be defined exactly as the addition.Base.:-(x::Currency, y::Currency) = -(promote(x, y)...)\nBase.:-(x::T, y::T) where {T <: Currency} = T(x.value - y.value)In the example below, we can see that everything works as intended.julia> Dollar(1.3) - CzechCrown(4.5)\n1.09 $\n\njulia> CzechCrown.([4.5, 2.4, 16.7, 18.3]) .- Dollar(12)\n4-element Vector{Dollar}:\n -11.79 $\n -11.89 $\n -11.24 $\n -11.16 $The situation with the multiplication is different as it makes sense to multiply 1 € by 2 but not by 2 €. We have to define a method for multiplying any Currency subtype by a real number. We have to define the multiplication both from the right and the left.Base.:*(a::Real, x::T) where {T <: Currency} = T(a * x.value)\nBase.:*(x::T, a::Real) where {T <: Currency} = T(a * x.value)As in the previous cases, everything works as expected, and broadcasting is supported without any additional steps.julia> 2 * Dollar(1.3) * 0.5\n1.3 $\n\njulia> 2 .* CzechCrown.([4.5, 2.4, 16.7, 18.3]) .* 0.5\n4-element Vector{CzechCrown}:\n 4.5 Kč\n 2.4 Kč\n 16.7 Kč\n 18.3 KčFinally, we can define division. In this case, it makes sense to divide a currency by a real number.Base.:/(x::T, a::Real) where {T <: Currency} = T(x.value / a)But it also makes sense to define the division of one amount of money by another amount of money in different currencies. In this case, a result is a real number representing their ratio.Base.:/(x::Currency, y::Currency) = /(promote(x, y)...)\nBase.:/(x::T, y::T) where {T <: Currency} = x.value / y.valueThe result is as follows.julia> Dollar(1.3) / 2\n0.65 $\n\njulia> 2 .* CzechCrown.([1, 2, 3, 4]) ./ CzechCrown(1)\n4-element Vector{Float64}:\n 2.0\n 4.0\n 6.0\n 8.0","category":"page"},{"location":"lecture_06/currencies/#Currency-comparison","page":"Generic programming","title":"Currency comparison","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The last thing we should define is comparison operators. To provide full functionality, we have to add new methods to two functions. The first one is the value equality operator ==. By default, it uses the following definition ==(x, y) = x === y. The === operator determines whether x and y are identical, in the sense that no program could distinguish them.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Dollar(1) == Euro(0.83)\nfalse\n\njulia> Dollar(1) != Euro(0.83)\ntrue","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The result does not match the expected behaviour since 0.83 € is equal to 1 $ with the given exchange rate. The reason is that we want to compare values stored in the structures and not the structures themselves. To allow this kind of comparison, we can define new methods to the == function as follows:","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.:(==)(x::Currency, y::Currency) = ==(promote(x, y)...)\nBase.:(==)(x::T, y::T) where {T <: Currency} = ==(x.value, y.value)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Again, the first function (for different currencies) calls the second function (for the same currencies). With these two methods defined, the comparison works as expected.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Dollar(1) == Euro(0.83)\ntrue\n\njulia> Dollar(1) != Euro(0.83)\nfalse","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The second function to extend is the isless function. In this case, the logic is the same as before: We want to compare values stored in the structure.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Base.isless(x::Currency, y::Currency) = isless(promote(x, y)...)\nBase.isless(x::T, y::T) where {T <: Currency} = isless(x.value, y.value)","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"As can be seen below, all operations work as intended.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> Dollar(1) < Euro(0.83)\nfalse\n\njulia> Dollar(1) > Euro(0.83)\nfalse\n\njulia> Dollar(1) <= Euro(0.83)\ntrue\n\njulia> Dollar(1) >= Euro(0.83)\ntrue","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Other functions based only on comparison will work for all subtypes of Currency without any additional changes. Examples include extrema, argmin or sort functions.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> vals = Currency[CzechCrown(100), Euro(0.83),  Pound(3.6), Dollar(1.2)]\n4-element Vector{Currency}:\n 100.0 Kč\n 0.83 €\n 3.6 £\n 1.2 $\n\njulia> extrema(vals)\n(0.83 €, 3.6 £)\n\njulia> argmin(vals)\n2\n\njulia> sort(vals)\n4-element Vector{Currency}:\n 0.83 €\n 1.2 $\n 100.0 Kč\n 3.6 £","category":"page"},{"location":"lecture_06/currencies/#Back-to-the-bank-account","page":"Generic programming","title":"Back to the bank account","text":"","category":"section"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"In the previous sections, we defined all the functions and types needed for the BankAccount type and performed basic arithmetic and other operations on currencies.  For a bank account, we are primarily interested in its balance. Since we store all transactions in a vector, the account balance can be computed as a sum of the transaction field.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"balance(b::BankAccount{C}) where {C} = convert(C, sum(b.transaction))","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"We convert the balance to the primary currency of the account.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> b = BankAccount(\"Paul\", CzechCrown)\nBankAccount{CzechCrown}(\"Paul\", Currency[0.0 Kč])\n\njulia> balance(b)\n0.0 Kč","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Another thing that we can define is custom pretty-printing.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"function Base.show(io::IO, b::BankAccount{C}) where {C<:Currency}\n    println(io, \"Bank Account:\")\n    println(io, \"  - Owner: \", b.owner)\n    println(io, \"  - Primary currency: \", nameof(C))\n    println(io, \"  - Balance: \", balance(b))\n    print(io,   \"  - Number of transactions: \", length(b.transaction))\nend","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The previous method definition results in the following output.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> b\nBank Account:\n  - Owner: Paul\n  - Primary currency: CzechCrown\n  - Balance: 0.0 Kč\n  - Number of transactions: 1","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The last function that we define is the function that adds a new transaction into the given bank account. Even though it can be defined like any other function, we decided to use a special syntax. Since methods are associated with types, making any arbitrary Julia object \"callable\" is possible by adding methods to its type. Such \"callable\" objects are sometimes called \"functors\".","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"function (b::BankAccount{T})(c::Currency) where {T}\n    balance(b) + c >= T(0) || throw(ArgumentError(\"insufficient bank account balance.\"))\n    push!(b.transaction, c)\n    return\nend","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"The first thing in the function above is the check whether there is a sufficient account balance. If not, the function will throw an error. Otherwise, the function will push a new element to the transaction field.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> b(Dollar(10))\n\njulia> b(-2*balance(b))\nERROR: ArgumentError: insufficient bank account balance.\n[...]\n\njulia> b(Pound(10))\n\njulia> b(Euro(23.6))\n\njulia> b(CzechCrown(152))\n\njulia> b\nBank Account:\n  - Owner: Paul\n  - Primary currency: CzechCrown\n  - Balance: 1288.84 Kč\n  - Number of transactions: 5","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"Note that all transactions are stored in their original currency, as can be seen if we print the transaction field.","category":"page"},{"location":"lecture_06/currencies/","page":"Generic programming","title":"Generic programming","text":"julia> b.transaction\n5-element Vector{Currency}:\n 0.0 Kč\n 10.0 $\n 10.0 £\n 23.6 €\n 152.0 Kč","category":"page"},{"location":"lecture_03/exercises/#Julia-set","page":"Exercises","title":"Julia set","text":"","category":"section"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"So far, we used only the standard library shipped with Julia. However, the standard library provides only basic functionality. If we want to get additional functions, we have to use extra packages. There is a Plots package for creating plots. Packages can be installed via Pkg REPL. To enter the Pkg REPL from the Julia REPL, press ] and install the package by","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(@v1.6) pkg> add Plots","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"We need to use the using keyword to load the package. For example, we can use the Plots package to visualize the sin and cos functions.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nx = 0:0.01π:2π\n\nplot(x, sin.(x); label = \"sinus\", linewidth = 2)\nplot!(x, cos.(x); label = \"cosinus\", linewidth = 2)\n\nsavefig(\"sin.svg\") # hide","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"There will be a whole section dedicated to the Plots package. However, we need some basic functionality to visualize the outputs of the following exercises.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 1:\nEvery programmer should be able to rewrite pseudocode to actual code. The goal of this exercise is to rewrite the following pseudocode:(Image: )This pseudocode describes how to compute the Julia set for the following functionf_c(z) = z^2 + cwhere c in mathbbC is a complex parameter. To test the resulting code, try the following settings of input parametersx is a vector of 1500 evenly spaced numbers from -1.5 to 1.5.\ny is a vector of 1000 evenly spaced numbers from -1 to 1.\nc = - 04 + 061 cdot i\nR = 2\nN = 1000Use this code given below to plot the heatmap of the matrix A.using Plots\nheatmap(A;\n    c=:viridis,\n    clims=(0, 0.15),\n    cbar=:none,\n    axis=:none,\n    ticks=:none\n)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nFirstly, we have to define all input parameters.c = - 0.4 + 0.61im\nR = 2\nN = 1000\nL = 1500\nK = 1000The second step is to define the vectors x and y. Since we know that these vectors contain evenly spaced numbers, and we also know the starting point, the stopping point, and the length of the vectors, we can use the range function.x = range(-1.5, 1.5; length = L)\ny = range(-1.0, 1.0; length = K)The next step is to define the A matrix of zeros by the zeros function.A = zeros(K, L)Now, we rewrite the for loops from the pseudocode. It is possible to rewrite the pseudocode in an almost identical way. However, in many cases, the code can be simplified. For example, we can use the shorter syntax for writing nested for loops.for k in 1:K, l in 1:L\n    z = x[l] + y[k]*im\n    for n in 0:N\n        if abs(z) > R^2 - R\n            A[k, l] = n/N\n            break\n        end\n        z = z^2 + c\n    end\nendFinally, we visualize the heatmap of the matrix A.using Plots\nheatmap(A;\n    c = :viridis,\n    clims = (0, 0.15),\n    cbar = :none,\n    axis = :none,\n    ticks = :none,\n)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 2:\nIn the previous exercise, we rewrote pseudocode to an actual Julia code. This exercise will improve the central part of the code: the inner loop. Write a function which replaces the inner loop in the code from the exercise above. Use the following function definitionfunction juliaset(z, c, R, N)\n    ???\n    return ???\nendwhere z c in mathbbC, R in mathbbR and N in mathbbN. Use the while loop to replace the for loop in the original pseudocode. Visualize the resulting matrix by the same code as in the previous exercise.Hint: recall that the function should return 0 if n > N and n/N otherwise.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"details: Solution:\nAs suggested in the exercise description, we will use the while loop. Using the while loop, we have to define a stopping condition. In this case, we have two conditions:maximal number of iterations is N + 1,\nthe absolute value of z needs to be smaller or equal to R^2 - R.These two conditions can be merged into n <= N && abs(z) <= R^2 - R. Inside the while loop, we only have to update n and z.function juliaset(z, c, R, N)\n    n = 0\n    while n <= N && abs(z) <= R^2 - R\n        n += 1\n        z = z^2 + c\n    end\n    return n > N ? 0 : n/N\nendWe use the ternary operator to decide which value is returned. Now we need to define all input parameters as in the previous exercise.c = - 0.4 + 0.61im\nR = 2\nN = 1000\nx = range(-1.5, 1.5; length = 1500)\ny = range(-1.0, 1.0; length = 1000)We can use a nested for loops to create A. However, a simpler way is to use the list comprehension or broadcasting to vectorize the juliaset function.A1 = [juliaset(xl + yk*im, c, R, N) for yk in y, xl in x]\nA2 = juliaset.(x' .+ y .* im, c, R, N)Both A1 and A2 are the same. In the second case, we have to pay attention to use the correct form of the input. We use the transposition of x. Finally, we can call the same code to create the same plot.using Plots\nheatmap(A1;\n    c = :viridis,\n    clims = (0, 0.15),\n    cbar = :none,\n    axis = :none,\n    ticks = :none,\n    size = (800, 600),\n)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"warning: Exercise 3:\nTry different values of variable c to create different plots. For inspiration, check the Wikipedia page about Julia set.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"c = 0285 + 001 cdot i","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"c = - 0835 - 02321 cdot i","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"c = -08 + 0156 cdot i","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"c = -070176 + 03842 cdot i","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/#Animation","page":"Exercises","title":"Animation","text":"","category":"section"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"danger: Warning:\nIt takes a lot of time to create the animation below, especially when using the default GR backend for the Plots package. The plotting time can be reduced by using a different backend such as the PyPlot backend.using Plots, PyPlot\npyplot()The PyPlot package must be installed first. An alternative way is to use the Makie package instead of the Plots package.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"We will now create an animation of the Julia sets for c defined as follows","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"c_k = 07885 exp  k cdot i  qquad k in left fracpi2 frac3pi2 right ","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Firstly, we create the vector of all values c by combining the range function and broadcasting.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"cs = 0.7885 .* exp.(range(π/2, 3π/2; length = 500) .* im)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Note that we use the length keyword to specify the length of cs. To create an animation, it suffices to use the for loop in combination with the @animate macro.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"anim = @animate for c in cs\n    A = juliaset.(x' .+ y .* im, c, R, N)\n    heatmap(A;\n        c = :viridis,\n        clims = (0, 0.15),\n        cbar = :none,\n        axis = :none,\n        ticks = :none,\n        size = (800, 600),\n    )\nend\ngif(anim, \"juliaset.gif\", fps = 20) # save animation as a gif","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"The code inside the loop is the same as in the previous exercise.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_05/interaction/#Interaction-with-other-languages","page":"Interaction with other languages","title":"Interaction with other languages","text":"","category":"section"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"One of the most significant advantages of Julia is its speed. As we discussed in  the section Why julia?, Julia is fast out-of-box without the necessity to do any additional steps. As a result, Julia solves the so-called Two-Language problem:","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Users are programming in a high-level language such as R and Python, but the performance-critical parts of the code have to be rewritten in C/Fortran for performance.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Since Julia is fast enough, most of the libraries are written in pure Julia, and there is no need to use C/Fortran for performance. However, there are many high-quality, mature libraries for numerical computing already written in C and Fortran. It would be a shame if it will not be possible to use them in Julia.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"To allow easy use of this existing code, Julia makes it simple and efficient to call C and Fortran functions. Julia has a no boilerplate philosophy: functions can be called directly from Julia without any glue code generation or compilation – even from the interactive prompt. This is accomplished just by making an appropriate call with the ccall syntax, which looks like an ordinary function call. Moreover, it is possible to pass Julia functions to native C functions that accept function pointer arguments. This section will show one example of the interaction between Julia and C. Extensive description of all provided functionality can be found in the official manual.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The following example is taken from the official manual. Consider the situation that we want to use the qsort function from the standard C library. The qsort function sorts an array and is declared as follows.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"void qsort(void *base, size_t nitems, size_t size,\n           int (*compare)(const void*, const void*))","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The base is the pointer to the first element of the array to be sorted. The nitems is the number of elements in the array pointed by base.  The size is the size in bytes of each element in the array. Finally, the compare is the function that compares two elements. The compare function should return a negative integer if the first argument is less than the second, a positive integer if the first argument is greater than the second, and otherwise zero. Such a Julia function can be defined as follows.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"mycompare(a, b)::Cint = sign(a - b)","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Since the qsort function expects that the return type of the compare function is C int, we annotate the return type to be Cint. In order to pass this function to C, we obtain its address using the macro @cfunction.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"mycompare_c = @cfunction(mycompare, Cint, (Ref{Cdouble}, Ref{Cdouble}))","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The @cfunction macro requires three arguments: the Julia function, the return type, and the tuple of the input argument types. Finally, we can use the ccall function to call the qsort function.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"julia> A = [1.3, -2.7, 4.4, 3.1];\n\njulia> ccall(:qsort, Cvoid, (Ptr{Cdouble}, Csize_t, Csize_t, Ptr{Cvoid}),\n             A, length(A), sizeof(eltype(A)), mycompare_c)\n\njulia> A\n4-element Vector{Float64}:\n -2.7\n  1.3\n  3.1\n  4.4","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Besides C and Fortran that can be called directly using ccall function, it is possible to interact with other languages using third-party packages. The following table shows an overview of those packages.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Language Calling from Julia Calling Julia\nC++ Cxx.jl package ???\nPython PyCall.jl PyJulia\nR RCall.jl JuliaCall\nMathematica MathLink.jl ExternalEvaluate\nMATLAB MATLAB.jl Mex.jl\nJava JavaCall.jl JuliaCaller","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Moreover, other Julia packages provide Julia interface for some well-known libraries from other languages. As an example, we can mention ScikitLear.jl, which provides an interface for the scikit-learn library from Python or the RDatasets.jl that provides an easy way to load famous R datasets.","category":"page"},{"location":"lecture_05/interaction/#RCall.jl","page":"Interaction with other languages","title":"RCall.jl","text":"","category":"section"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The RCall.jl package provides an interface for calling R functions from Julia and passing data between these two languages. The package provides an interactive REPL for the R language that can be accessed from the Julia REPL by typing the $ symbol. Consequently, it is possible to easily switch between these languages and use functionality provided by both languages simultaneously.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"julia> using RCall, RDatasets\n\njulia> mtcars = dataset(\"datasets\", \"mtcars\");\n\nR> library(ggplot2)\n\nR> ggplot($mtcars, aes(x = WT, y = MPG)) + geom_point()","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"(Image: )","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The package also provides string syntax that allows non-interactive usage. The previous example can be rewritten as follows.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"using RCall, RDatasets\nmtcars = dataset(\"datasets\", \"mtcars\");\n\nR\"\"\"\nlibrary(ggplot2)\nggplot($mtcars, aes(x = WT, y = MPG)) + geom_point()\n\"\"\"","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Note that we use multiline string syntax, but it is also possible to use standard string syntax. This multiline string syntax is very useful, especially when we want to perform multiple operations in R at once and then just return the result to Julia.","category":"page"},{"location":"lecture_05/interaction/#MATLAB.jl","page":"Interaction with other languages","title":"MATLAB.jl","text":"","category":"section"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The MATLAB.jl provides an easy interface for calling Matlab functions and passing data between Julia and Matlab. Consider the situation that you wrote a Matlab function that uses some special functionality that is not available in Julia. MATLAB.jl package provides an interface to call this function directly from Julia, as can be seen in the following example.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"using MATLAB, BSON\n\nX = BSON.load(\"data.bson\")[:X]\nmxcall(:MakeVideo, 0, X, \"video.gif\")","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"The mxcall function accepts the name of the function as the first argument and the number of the output variables of that function as the second argument. All other inputs to the mxcall function are the input arguments of the Matlab function. The result is the following animation.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"(Image: )","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"Like the RCall.jl package, the MATLAB.jl package also provides string syntax that allows for Matlab syntax. The previous example can be rewritten as follows.","category":"page"},{"location":"lecture_05/interaction/","page":"Interaction with other languages","title":"Interaction with other languages","text":"using MATLAB, BSON\n\nX = BSON.load(\"data.bson\")[:X]\nmat\"\"\"\nMakeVideo($(X), 30, \"Video2.gif\");\n\"\"\"","category":"page"},{"location":"lecture_11/iris/#Introduction-to-Flux","page":"Introduction to Flux","title":"Introduction to Flux","text":"","category":"section"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Flux is a library for using neural networks. This part will present the basics of Flux on the Iris dataset from the previous lecture. We include the auxiliary functions from the previous lesson into the utilities.jl file, which we include by","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"include(\"utilities.jl\")\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We set the seed and load the data in the same way as during the last lecture.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using RDatasets\nusing Random\n\nRandom.seed!(666)\n\niris = dataset(\"datasets\", \"iris\")\n\nX = Matrix(iris[:, 1:4])\ny = iris.Species\n\nX_train, y_train, X_test, y_test, classes = prepare_data(X', y; dims=2)\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/#Creating-the-network","page":"Introduction to Flux","title":"Creating the network","text":"","category":"section"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We recall that machine learning minimizes the discrepancy between the predictions operatornamepredict(w x_i) and labels y_i. Mathematically, this amount to minimizing the following objective function.  ","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"L(w) = frac1nsum_i=1^n operatornameloss(y_i operatornamepredict(w x_i))","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To build the objective L, we first specify the prediction function operatornamepredict, which we denote by model m.  We start by creating the same network by the function Chain. Its inputs are the individual layers. Dense layers are created by Dense with the correct number of input and output neurons. We also need to specify the activation functions.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Flux\n\nn_hidden = 5\nm = Chain(\n    Dense(size(X_train,1) => n_hidden, relu),\n    Dense(n_hidden => size(y_train,1), identity),\n    softmax,\n)\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Since identity is the default argument, it is possible to remove it in the second layer. However, we recommend keeping it for clarity.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We can evaluate the whole dataset.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"m(X_train)","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Because there are 3 classes and 120 samples in the training set, it returns an array of size 3times 120. Each column corresponds to one sample and forms a vector of probabilities due to the last layer of softmax.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We access the neural network parameters by using params(m). We can select the second layer of m by m[2]. Since the second layer has 5 input and 3 output neurons, its parameters are a matrix of size 3times 5 and a vector of length 3. The parameters params(m[2]) are a tuple of the matrix and the vector. This also implies that the parameters are initialized randomly, and we do not need to take care of it. We can also easily modify any parameters.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Flux: params\n\nparams(m[2])[2] .= [-1;0;1]\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/#Training-the-network","page":"Introduction to Flux","title":"Training the network","text":"","category":"section"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To train the network, we need to define the objective function L. Since we already defined operatornamepredict, it suffices to define the loss function operatornameloss. Since we work with a multi-class problem, the loss function is usually the cross-entropy.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Flux: crossentropy\n\nL(ŷ, y) = crossentropy(ŷ, y)\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"The loss function should be defined between predicted haty and true label y. Therefore, we can evaluate the objective function by","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"L(m(X_train), y_train)","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"where ŷ = m(x).","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"This computes the objective function on the whole training set. Since Flux is (unlike our implementation from the last lecture) smart, there is no need to take care of individual samples.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"info: Notation:\nWhile the standard definition of cross-entropy is operatornameloss(yhat y), Flux uses operatornameloss(hat yy).","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Since we have the model and the loss function, the only remaining thing is the gradient. Flux again provides a smart way to compute it.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"grads = Flux.gradient(m -> L(m(X_train), y_train), m)\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"The function gradient takes as inputs a function to differentiate, and arguments that specify the parameters we want to differentiate with respect to. Since the argument is the model m itself, the gradient is taken with respect to the parameters of m. The L function needs to be evaluated at the correct points m(X_train) (predictions) and y_train (true labels).","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"The grads structure is a tuple holding a named tuple with the :layers key. Each layer then holds the parameters of the model, in this case, the weights W, bias b, and optionally parameters of the activation function sigma.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"julia> grads[1][:layers][2]\n(weight = Float32[0.30140522 0.007785671 … -0.070617765 0.014230583; 0.06814249 -0.07018863 … 0.17996183 -0.20995824; -0.36954764 0.062402964 … -0.10934405 0.19572766], bias = Float32[0.0154182855, 0.022615476, -0.03803377], σ = nothing)","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Now, we train the classifiers for 250 iterations. In each iteration, we compute the gradient with respect to all network parameters and perform the gradient descent with stepsize 01. Since Flux@0.14, there's been a change from implicit definition to explicit definition of optimisers. Since now, we need to use Flux.setup(optimiser, model) to create an optimiser that would optimise over the model's parameters.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"opt = Descent(0.1)\nopt_state = Flux.setup(opt, m)\nmax_iter = 250\n\nacc_train = zeros(max_iter)\nacc_test = zeros(max_iter)\nfor i in 1:max_iter\n    gs = Flux.gradient(m -> L(m(X_train), y_train), m)\n    Flux.update!(opt_state, m, gs[1])\n    acc_train[i] = accuracy(X_train, y_train)\n    acc_test[i] = accuracy(X_test, y_test)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Both the accuracy on the training and testing set keeps increasing as the training progresses. This is a good check that we are not over-fitting.","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Plots\n\nplot(acc_train, xlabel=\"Iteration\", ylabel=\"Accuracy\", label=\"train\", ylim=(-0.01,1.01))\nplot!(acc_test, xlabel=\"Iteration\", label=\"test\", ylim=(-0.01,1.01))\n\nsavefig(\"Iris_train_test_acc.svg\") # hide","category":"page"},{"location":"lecture_11/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"(Image: )","category":"page"},{"location":"lecture_13/theory/#Differential-equations","page":"Differential equations","title":"Differential equations","text":"","category":"section"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Differential equations describe many natural phenomena. Newton's law of motion","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"F = fracpartialpartial tmv","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"is a simple but important example of an ordinary differential equation. Besides applications in physics and engineering, differential equations appear in almost any (smoothly) evolving system. Examples include economics (Black-Scholes formula) or biology (population growth). There are whole fields dedicated to solving a single equation, such as the wave or heat equations. The basic distinction is:","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Ordinary differential equations (ODEs) depend only on time.\nPartial differential equations (PDEs) depend on space and may depend on time. The spatial variable is usually 1D, 2D or 3D.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"There are many extensions; let us name systems of differential equations, stochastic differential equations or differential algebraic equations (system of differential and non-differential equations).","category":"page"},{"location":"lecture_13/theory/#Ordinary-differential-equations","page":"Differential equations","title":"Ordinary differential equations","text":"","category":"section"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Ordinary differential equations take the form","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = f(t y(t))","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"on some interval tin 0T. To obtain a correct definition, the initial value y(0)=y_0 needs to be provided. A solution is a (sufficiently smooth) function y(t) such that the above formula is satisfied (almost) everywhere on 0T. Mild conditions ensure its existence and uniqueness.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"todo: Picard–Lindelöf theorem\nSuppose f is uniformly Lipschitz continuous in y (the Lipschitz constant is independent of t) and continuous in t. Then for some value varepsilon  0, there exists a unique solution y(t) to the initial value problem on the interval t_0-varepsilon t_0+varepsilon.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"However, it may happen that even simple equations do not have a unique solution.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"info: Uniqueness:\nThe uniqueness of solution is not guaranteed even for simple equations. Equationbeginaligned\ndot y(t) = y^frac 23(t) \ny(0) = 0\nendalignedhas at least two solution: y_1(t)=0 and y_2(t)=(frac t3)^3. This is possible because the right-hand side of the ODE has an infinite derivative at zero, and the Lipschitz continuity assumption of the Picard–Lindelöf theorem is not satisfied.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"The theory of partial differential equations is complicated because they employ a special definition of derivative (weak derivative), and the solution is defined on special spaces (Sobolev spaces).","category":"page"},{"location":"lecture_13/theory/#Linear-ordinary-differential-equations","page":"Differential equations","title":"Linear ordinary differential equations","text":"","category":"section"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Linear ordinary equations","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = Ay(t) + b(t)","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"form an important subclass of differential equations. They admit a \"closed-form\" solution. This closed form employs the matrix exponential defined by","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"e^A = sum_k=0^infty fracA^kk","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"where A^k is the standard multiplication of matrices. This is a generalization from scalars to matrices and has similar properties. For example, the derivative of the matrix exponential is the same object due to","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"fracpartialpartial Ae^A = sum_k=1^infty frackA^k-1k = sum_k=1^infty fracA^k-1(k-1) = e^A","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Then the solution of the linear equation above equals to","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"y(t) = e^Atleft(y_0 + int_0^t e^-Asb(s)dsright)","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"Indeed, the derivative of the previous term equals to","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = Ae^Atleft(y_0 + int_0^t e^-Asb(s)dsright) + e^Ate^-Atb(t) = Ay(t) + b(t)","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"because e^Ate^-At is the identity matrix (similarly to e^xe^-x=1). The matrix exponential can be computed using matrix decompositions.","category":"page"},{"location":"lecture_13/theory/","page":"Differential equations","title":"Differential equations","text":"info: Matrix decompositions in solving linear ODEs\nThe lecture on statistics showed the eigendecomposition for square matrices Ainmathbb R^ntimes n. The eigendecompositionA = QLambda Q^-1exists whenever A has n eigenvalues, which may even be even complex. Then the matrix exponential equals toe^At = e^Q(Lambda t) Q^-1 = Qe^Lambda t Q^-1Because Lambda is a diagonal matrix, its exponential equals to a diagonal matrix with entries(e^Lambda t)_ij = begincases e^Lambda_ii ttextif i=j  0textotherwiseendcasesSince we need to compute the matrix exponential multiple times, similarly to LASSO, using the eigendecomposition saves computational times.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"abstract type Step end\n\nstruct GD <: Step\n    α::Real\nend\n\noptim_step(s::GD, f, g, x) = -s.α*g(x)\n\nfunction optim(f, g, x, s::Step; max_iter=100)\n    for i in 1:max_iter\n        x += optim_step(s, f, g, x)\n    end\n    return x\nend","category":"page"},{"location":"lecture_09/linear/#Linear-regression","page":"Linear regression","title":"Linear regression","text":"","category":"section"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"We start with linear regression, where the labels are continuous variables.","category":"page"},{"location":"lecture_09/linear/#Theory-of-linear-regression","page":"Linear regression","title":"Theory of linear regression","text":"","category":"section"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"Linear regression uses the linear prediction function operatornamepredict(wx) = w^top x and the mean square error operatornameloss(y hat y) = (y - hat y)^2 as the loss function. When we have a dataset with n data points (samples) x_i and labels y_i, linear regression may be written as the following optimization problem. ","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"operatornameminimize_wqquad frac 1nsum_i=1^n (w^top x_i - y_i)^2","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"The objective function is minimal if the predictions w^top x_i equal to the labels y_i for all samples i=1dotsn.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"Some algorithms use the sum instead of the mean in the objective function. These approaches are equivalent. For the former case, it is simpler to work in the matrix notation, where we form a matrix X whose rows are the samples x_i. It is not difficult to show that the previous problem is equivalent to","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"operatornameminimize_wqquad Xw - y^2","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"where the norm is the l_2 norm. Since this is a convex quadratic problem, it is equivalent to its optimality conditions. Setting the derivative to zero yields","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"2X^top (Xw-y) = 0","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"From here, we obtain the closed-form solution to the linear regression","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"w = (X^top X)^-1X^top y","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"info: Closed-form solution:\nLinear regression is probably the only machine learning model with a closed-form solution. All other models must be solved by iterative algorithms such as gradient descent. In some cases, it may be advantageous to use iterative algorithms even for linear regression. For example, this includes the case of a large number of features m because then X^top X is an mtimes m matrix that may be difficult to invert.","category":"page"},{"location":"lecture_09/linear/#UCI-repository","page":"Linear regression","title":"UCI repository","text":"","category":"section"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"Training a machine learning model requires data. Neural networks require lots of data. Since collecting data is difficult, there are many datasets at the UCI Machine Learning Repository. We will use the iris (kosatec in Czech) dataset which predicts one of the three types of iris based on sepal (kališní lístek in Czech) and petal (okvětní lístek in Czech) widths and lengths.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"If you do not see any differences between these three species, machine learning to the rescue!","category":"page"},{"location":"lecture_09/linear/#Loading-and-preparing-data","page":"Linear regression","title":"Loading and preparing data","text":"","category":"section"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"To experiment with machine learning models, we use the RDatasets package, which stores many machine learning datasets, and we load the data by","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"using Plots\nusing StatsPlots\nusing RDatasets\n\niris = dataset(\"datasets\", \"iris\")\n\niris[1:5,:] # hide","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"Printing the first five entries of the data shows that they are saved in DataFrame, and the columns (features) are sepal length, sepal width, petal length and petal width.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"When designing a classification method, a good practice is to perform at least a basic analysis of the data. That may include checking for NaNs, infinite values, obvious errors, standard deviations of features or others. Here, we only plot the data. ","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"warning: Exercise:\nWe will simplify the goal and estimate the dependence of petal width on petal length. Create the data X (do not forget to add the bias) and the labels y.Make a graph of the dependence of petal width on petal length.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"details: Solution:\nSince the petal length and width are the third and fourth columns, we assign them to X and y, respectively. We can use iris[:, 4] or iris[:, :PetalWidth] instead of iris.PetalWidth, but the first possibility is vulnerable to errors. We need to concatenate X it with a vector of ones to add the bias.y = iris.PetalWidth\nX = hcat(iris.PetalLength, ones(length(y)))\n\nnothing # hideThe best visualization is by the scatter plot. We use the version from the StatsPlots package but the one from the Plots package would be naturally sufficient.@df iris scatter(\n    :PetalLength,\n    :PetalWidth;\n    label=\"\",\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\"\n)    \n\nsavefig(\"iris_lin1.svg\") # hide\n\nnothing # hide","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"The figure shows a positive correlation between length and width. This is natural as bigger petals mean both longer and wider petals. We will quantify this dependence by linear regression.","category":"page"},{"location":"lecture_09/linear/#Training-the-classifier","page":"Linear regression","title":"Training the classifier","text":"","category":"section"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"warning: Exercise:\nUse the closed-form formula to get the coefficients w for the linear regression. Then use the optim method derived in the previous lecture to solve the optimization problem via gradient descent. The results should be identical.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"details: Solution:\nThe closed-form expression is (X^top X)^-1X^top y. In the exercises to the previous lecture, we explained that writing (X'*X) \\ (X'*y) is better than inv(X'*X)*X'*y because the former does not compute the matrix inverse. As a side-note, can you guess the difference between inv(X'*X)*X'*y and inv(X'*X)*(X'*y)?w = (X'*X) \\ (X'*y)\n\nnothing # hideFor the gradient descent, we first realize that the formula for the derivate is X^top (Xw-y). Defining the derivative function in g, we call the optim method in the same way as in the last lecture. Since we use the sum and not mean in the objective, we need to use a much smaller stepsize.g(w) = X'*(X*w-y)\nw2 = optim([], g, zeros(size(X,2)), GD(1e-4); max_iter=10000)\n\nnothing # hideThe difference between the solutions isusing LinearAlgebra\n\nnorm(w-w2)which is acceptable.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"The correct solution is","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"w # hide","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"Now we can estimate the petal width if only petal length is known.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"warning: Exercise:\nWrite the dependence on the petal width on the petal length. Plot it in the previous graph.","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"details: Solution:\nThe desired dependence istextwidth approx -036 + 042*textlengthBefore plotting the prediction, we save it into f_pred.f_pred(x::Real, w) = w[1]*x + w[2]\n\nnothing # hideThen we create the limits x_lim and finally plot the prediction function.x_lims = extrema(iris.PetalLength) .+ [-0.1, 0.1]\n\n@df iris scatter(\n    :PetalLength,\n    :PetalWidth;\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    label = \"\",\n    legend = :topleft,\n)\n\nplot!(x_lims, x -> f_pred(x,w); label = \"Prediction\", line = (:black,3))\n\nsavefig(\"iris_lin2.svg\") # hide","category":"page"},{"location":"lecture_09/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_11/theory/#Theory-of-neural-networks","page":"Theory of neural networks","title":"Theory of neural networks","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"In the previous lecture, we presented an introduction to neural networks. We also showed how to train neural networks using gradient descent. This lecture is going to show more layers and a more sophisticated way of training.","category":"page"},{"location":"lecture_11/theory/#Convolutional-layers","page":"Theory of neural networks","title":"Convolutional layers","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The last lecture concentrated on the dense layer. Even though it is widely used due to its simplicity, it suffers from several disadvantages, especially in visual recognition. These disadvantages include:","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Large number of parameters. For an image with 500times 500times 3 pixels and the output layer of only 1000 neurons, the dense layer would contain 750 million parameters. This is too much to optimize.\nNo structural information. Dense layers assign a weight to every pixel and then add the weighted values. This means that information from the top-leftmost and bottom-rightmost pixels of the image will be combined. Since a combination of these two pixels should carry no meaningful information, redundant computation is performed.","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Convolutional layers were designed to alleviate these issues.","category":"page"},{"location":"lecture_11/theory/#Motivation","page":"Theory of neural networks","title":"Motivation","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"To understand the convolutional layers, we need to go back to the definition of convolution. Having a function f and  a kernel g, their convolution is defined by","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(x) = int_-infty^infty f(x - t)g(t) dt","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Let us consider the simplest case when","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"g(t) = begincases frac12varepsilon textif tin-varepsilonvarepsilon  0 textotherwise endcases","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Then ","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(x) = int_-infty^infty f(x - t)g(t) dt = frac12varepsilonint_-varepsilon^varepsilonf(x - t)dt","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Then (fast g)(x) does not take the value of f at x but integrates f over a small neighbourhood of x. Applying this kernel results in a smoothening of f.  ","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"In image processing, the image f is not represented by a function but by a collection of pixels. The kernel g is represented by a small matrix. For the commonly used 3times 3 kernel matrix, the convolution has the form","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(xy) = sum_i=-1^1sum_j=1^1 f(x+iy+j)g(ij)","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The following kernels","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"K_1 = beginpmatrix 0  0  0  0  1  0  0  0  0 endpmatrix qquad\nK_2 = frac 19beginpmatrix 1  1  1  1  1  1  1  1  1 endpmatrix qquad\nK_3 = beginpmatrix -1  -1  -1  -1  8  -1  -1  -1  -1 endpmatrix","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"perform identity, image smoothening and edge detection, respectively.","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_11/theory/#Formulas","page":"Theory of neural networks","title":"Formulas","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Traditional techniques for image processing use multiple fixed kernels and combine their results. The idea of convolutional layers is to remove all human-made assumptions about which kernels to choose and learn the kernels' parameters based purely on data. Even though it gives superb results, it also removes any insight or interpretation humans may make. ","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The input of a convolutional layer has dimension I_1times J_1times C_1, where I_1times J_1 is the size of the image and C_1 is the number of channels (1 for grayscale, 3 for coloured, anything for hidden layers). Its input is also the kernel K. The output of the convolutional layer has dimension I_2times J_2times C_2 and its value at some (i_0j_0c_0) equals to","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"textoutput(i_0j_0c_0) = lleft(sum_c=1^Csum_i=-a^asum_j=-b^b Big( K_c_0(ijc) textinput(i_0+ij_0+jc) + b(c)Big)right)","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"After the linear operation inside, an activation function l is applied. Without it, the whole network would a product of linear function and, therefore, linear function (written in a complicated form).","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The natural question is the interpretation of the linear operator and the number of parameters:","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The kernel matrix K contains (2a+1)(2b+1)C_1C_2 parameters. What does it mean? First, there is a separate kernel for each output channels. Second, the kernel also averages (more precisely, computes a linear combination) over all input channels. However, the coefficients of this linear combination do not depend on the position (i_0j_0). \nThe bias b has dimension C_2. Again, it does not depend on the position (i_0j_0).","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The important thing to realize is that the number of parameters does not depend on the size of the image or the hidden layers. For example, even for an input image 500times 500times 3, the convolutional layer contains only 448 parameters for 3times 3 kernel and 16 output channels (do the computations).","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This results in fixing the two issues mentioned above.","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The number of parameters of convolutional layers stays relatively small.\nUsing kernels means that only local information from neighbouring pixels is propagated to subsequent layers.","category":"page"},{"location":"lecture_11/theory/#Network-structure","page":"Theory of neural networks","title":"Network structure","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"When an input is an image, the usual structure of the neural network is the following:","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Convolutional layer followed by a pooling layer.\nThis is repeated many times.\nFlatten layer (it reshapes the three-dimensional tensor into a vector).\nDense (fully connected) layer.\nSoftmax layer.\nCross-entropy loss function.","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"compat: BONUS: Additional layers\nPractical convolutional layers involve additional complexities such as layers with even size (we showed only even sizes), padding (should zeros be added or should the output image be smaller) or stride (should there be any distance between convolutions). This goes, however, beyond the lecture.Recurrent layerRecurrent layers are designed to handle one-dimensional data. They are similar to convolutional layers with J_1=J_2=C_1=C_2=1. Unlike convolutional layers, they store additional hidden variables. The most-known representative is the long short-term memory (LSTM) cell.Pooling layerThe goal of pooling layers is to reduce the size of the network. They take a small (such as 2times 2) window and perform a simple operation on this window (such as maximum or mean). Since the pooled windows do not overlap, this reduces the size of each dimension in half. Pooling layers do not have any trainable parameters. Skip connectionsFrom the previous lecture, we know that the gradient is computed via the chain rulenabla f = nabla f_Mnabla f_M-1dotsnabla f_1Since the formula contains multiplication, if any of the gradients is too small, then the whole gradient will be too small. Specifically, the deeper the network, the higher the chance that the initial point will be in a point with a small gradient and the training will progress slowly. This phenomenon is called vanishing gradients.To solve the issue with vanishing gradients, skip connections are sometimes added. Even though it is not a layer, we include it here. They do precisely what their name suggests: They skip one or more layers. This makes the network more flexible: Due to its deep structure, it can approximate complicated functions, and due to its shallow structure (because of skip connections), the initial training can be fast.","category":"page"},{"location":"lecture_11/theory/#Stochastic-gradient-descent","page":"Theory of neural networks","title":"Stochastic gradient descent","text":"","category":"section"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"We recall that machine learning problems minimize the loss function","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"L(w) = frac1nsum_i=1^n operatornameloss(y_i f(w x_i))","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Its gradient equals to","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"nabla L(w) = frac1nsum_i=1^n operatornameloss(y_i f(w x_i))nabla_w f(w x_i)","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"If the dataset contains many samples (n is large), then it takes long time to compute the gradient. Therefore, the full gradient is replaced by its stochastic (random) approximation","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"frac1Isum_iin I operatornameloss(y_i f(w x_i))nabla_w f(w x_i)","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Here, the minibatchI is a small (32 64 dots) subset of all samples 1dotsn. Sometimes the gradient descent is replaced by other options such as ADAM or RMSprop, which in some way consider the history of gradients.","category":"page"},{"location":"lecture_11/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This technique is called stochastic gradient descent. During one epoch (the time when the optimizer evaluates each sample once), it performs many gradient updates (unlike the standard gradient descent, which performs only one update). Even though these updates are imprecise, numerical experiments show that stochastic gradient descent is much faster than standard gradient descent. The probable reason is that the entire dataset contains lots of duplicate information, and the full gradient performs unnecessary computation, which slows it down.  ","category":"page"},{"location":"lecture_04/methods/#Methods","page":"Methods","title":"Methods","text":"","category":"section"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"So far, we defined all functions (with some exceptions) without annotating the types of input arguments. When the type annotation is omitted, the default behaviour in Julia is to allow values to be of any type. One can write many useful functions without stating the types. When additional expressiveness is needed, it is easy to introduce type annotations into previously untyped code.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"In Julia, one function consists of multiple methods. A prime example is the convert function. When a user calls a function, the process of choosing which method to execute is called dispatch. The dispatch system in Julia decides which method to execute based on:","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"the number of function arguments;\nthe types of function arguments.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Using all function arguments to choose which method should be invoked is known as multiple dispatch.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"As an example of multiple dispatch, we define the product function that computes the product of two numbers.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(x, y) = x * y\nproduct (generic function with 1 method)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"In the REPL, we can see that the product function has only one method. In this case, we defined the method for any two input arguments without type specification.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product(2.4, 3.1)\n7.4399999999999995","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"The methods function lists all methods for a function.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> methods(product)\n# 1 method for generic function \"product\" from Main:\n [1] product(x, y)\n     @ none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Because we did not specify types of input arguments, the product function accepts arguments of all types. For some inputs, such as symbols, the * operator will not work.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(:a, :b)\nERROR: MethodError: no method matching *(::Symbol, ::Symbol)\n[...]","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"We can avoid such errors by specifying types of input arguments. Since we want to create a function that computes the product of two numbers, it makes sense to allow input arguments to be only numbers.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"product(x::Number, y::Number) = x * y\nproduct(x, y) = throw(ArgumentError(\"product is defined for numbers only.\"))","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"The second line redefined the original definition of the product function. It now throws an error if product is called with non-numeric inputs.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> methods(product)\n# 2 methods for generic function \"product\" from Main:\n [1] product(x::Number, y::Number)\n     @ none:1\n [2] product(x, y)\n     @ none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Now, we have a function with two methods, that returns a product if the input arguments are numbers, and throws an error otherwise.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product(:a, :b)\nERROR: ArgumentError: product is defined for numbers only.\n[...]\n\njulia> product(\"a\", \"b\")\nERROR: ArgumentError: product is defined for numbers only.\n[...]","category":"page"},{"location":"lecture_04/methods/#Type-hierarchy","page":"Methods","title":"Type hierarchy","text":"","category":"section"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"It is always better to use abstract types like Number or Real instead of concrete types like Float64, Float32, or Int64. The reason is that if we use an abstract type, the function will work for all its subtypes. To find a supertype for a specific type, we can use the supertype function from the InteractiveUtils package.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> using InteractiveUtils: supertype\n\njulia> supertype(Float64)\nAbstractFloat","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"The problem with the supertype function is that it does not return the whole supertype hierarchy, but only the closest larger supertype. For Float64 the closest larger supertype is AbstractFloat. However, as in the example above, we do not want to use this supertype, since then the function will only work for floating point numbers.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"warning: Exercise:\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Create a function supertypes_tree which prints the whole tree of all supertypes. If the input type T satisfies the following condition T === Any, then the function should do nothing. Use the following function declaration:","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"   function supertypes_tree(T::Type, level::Int = 0)\n      # code\n   end\n   ```\n\n   The optional argument `level` sets the printing indentation level.\n\n   **Hints:**\n   - Use the `supertype` function in combination with recursion.\n   - Use the `repeat` function and string with white space `\"    \"` to create a proper indentation.\n\n!!! details \"Solution:\"\n   The `supertypes_tree` function can be defined by:\n\n   ```jldoctest methods; output = false\n   function supertypes_tree(T::Type, level::Int = 0)\n      isequal(T, Any) && return\n      println(repeat(\"   \", level), T)\n      supertypes_tree(supertype(T), level + 1)\n      return\n   end\n\n   # output\n   supertypes_tree (generic function with 2 methods)\n   ```\n\n   The first line checks if the given input type is `Any`. If yes, then the function returns nothing. Otherwise, the function prints the type with a proper indentation provided by `repeat(\"   \", level)`, i.e., four white-spaces repeated `level`-times. The third line calls the `supertypes_tree` function recursively for the supertype of the input type `T` and the level of indentation `level + 1`.\n\nNow we can use the `supertypes_tree` function to get the whole supertype hierarchy for `Float64`.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia julia> supertypes_tree(Float64) Float64    AbstractFloat       Real          Number","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nWe can check the type hierarchy by the `<:` operator for comparing types: If `T1 <: T2` is true, then `T1` is a subtype (or the same type) of `T2`.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods julia> Float64 <: AbstractFloat <: Real <: Number true","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nSimilarly to the `supertype` function, there is the `subtypes` function that returns all subtypes for the given type.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia julia> using InteractiveUtils: subtypes","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> subtypes(Number) 2-element Vector{Any}:  Complex  Real","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nThis function suffers from a similar disadvantage as the `supertype` function: It is impossible to get the whole hierarchy of all subtypes using only this function.\n\n!!! warning \"Exercise:\"\n   Create a function `subtypes_tree` which prints the whole tree of all subtypes for the given type. Use the following function declaration:\n\n   ```@meta\n   DocTestSetup = quote\n      using InteractiveUtils: subtypes\n   end\n   ```\n\n   ```julia\n   function subtypes_tree(T::Type, level::Int = 0)\n      # code\n   end\n   ```\n\n   The optional argument `level` sets the printing indentation level.\n\n   **Hints:**\n   - Use the `subtypes` function in combination with recursion.\n   - Use the `repeat` function and string with white space `\"    \"` to create a proper indentation.\n\n!!! details \"Solution:\"\n   The `subtypes_tree` function is similar to `supertypes_tree`. The only differences are that we do not need to check for the top level of `Any`, and that we need to call the vectorized version `subtypes_tree.` because `subtypes(T)` returns an array.\n\n   ```jldoctest methods; output = false\n   function subtypes_tree(T::Type, level::Int = 0)\n      println(repeat(\"   \", level), T)\n      subtypes_tree.(subtypes(T), level + 1)\n      return\n   end\n\n   # output\n   subtypes_tree (generic function with 2 methods)\n   ```\n\nNow we can use the `subtypes_tree` function to get the whole subtypes hierarchy for the `Number` type.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia julia> subtypes_tree(Number) Number    Complex    Real       AbstractFloat          BigFloat          Float16          Float32          Float64       AbstractIrrational          Irrational       Integer          Bool          Signed             BigInt             Int128             Int16             Int32             Int64             Int8          Unsigned             UInt128             UInt16             UInt32             UInt64             UInt8       Rational","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nThis tree shows the whole structure of Julia numerical types. If we want to define a function that accepts all numeric types, we should use inputs of type `Number`. However, many operations are restricted to only real numbers. In such a case, we want to use the `Real` type instead of `Number`.\n\n\n## Multiple dispatch\n\nNow we can go back to our example with the `product` function. The problem with this function is that it is too restrictive because the product of two strings is a legitimate operation that should return their concatenation. We should define a method for strings. To use the proper type, we can use the `supertypes_tree` function for the `String` type.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods julia> supertypes_tree(String) String    AbstractString","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nWe see that the *largest* supertype for `String` is `AbstractString`. This leads to\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods; output = false product(x::AbstractString, y::AbstractString) = x * y product(x, y) = throw(ArgumentError(\"product is defined for numbers and strings only.\"))","category":"page"},{"location":"lecture_04/methods/#output","page":"Methods","title":"output","text":"","category":"section"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"product (generic function with 3 methods)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nWe also redefined the original definition of the `product` function to throw an appropriate error.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods julia> product(1, 4.5) 4.5","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(\"a\", \"b\") \"ab\"","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> product(:a, :b) ERROR: ArgumentError: product is defined for numbers and strings only. [...]","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nSometimes, it may be complicated to guess which method is used for concrete inputs. In such a case, there is a useful macro `@which` that returns the method that is called for given arguments.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods julia> using InteractiveUtils: @which","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> @which product(1, 4.5) product(x::Number, y::Number)      @ Main none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> @which product(\"a\", :a) product(x, y)      @ Main none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> @which product(\"a\", \"b\") product(x::AbstractString, y::AbstractString)      @ Main none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nThe previous example with the `product` function shows how methods in Julia works. However, it is a good practice to use type annotation only if we want to have a specialized function or if we want to define a function, which does different things for different types of input arguments.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods; output = false g(x::Real) = x + 1 g(x::String) = repeat(x, 4)","category":"page"},{"location":"lecture_04/methods/#output-2","page":"Methods","title":"output","text":"","category":"section"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"g (generic function with 2 methods)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nFor example, the `g` function returns `x + 1` if the input `x` is a real number or repeats four times the input argument if it is a string. Otherwise, it will throw a method error.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods julia> g(1.2) 2.2","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> g(\"a\") \"aaaa\"","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> g(:a) ERROR: MethodError: no method matching g(::Symbol)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Closest candidates are:   g(!Matched::String)    @ Main none:1   g(!Matched::Real)    @ Main none:1 [...]","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\n!!! info \"Do not overuse type annotation:\"\n   The `product` function should be defined without the type annotation. It is a good practice not to restrict input argument types unless necessary. The reason is that, in this case, there is no benefit of using the type annotation. It is better to define the function `product_new` by:\n\n   ```jldoctest methods; output = false\n   product_new(x, y) = x * y\n\n   # output\n   product_new (generic function with 1 method)\n   ```\n\n   Then we can apply this function to the same inputs as the original `product` function, and we will get the same results\n\n   ```jldoctest methods\n   julia> product(1, 4.5)\n   4.5\n\n   julia> product_new(1, 4.5)\n   4.5\n\n   julia> product(\"a\", \"b\")\n   \"ab\"\n\n   julia> product_new(\"a\", \"b\")\n   \"ab\"\n   ```\n\n   with only one exception\n\n   ```jldoctest methods\n   julia> product(\"a\", :a)\n   ERROR: ArgumentError: product is defined for numbers and strings only.\n   [...]\n\n   julia> product_new(\"a\", :a)\n   ERROR: MethodError: no method matching *(::String, ::Symbol)\n   [...]\n   ```\n\n   Here we get a different error. However, the error returned by the `product_new` function is more useful because it tells us what the real problem is. We can see that it is impossible to use the `*` operator to multiply a `String` and a `Symbol`. We can decide if this is the desired behaviour, and if not, we can define a method for the `*` operator that will fix it.\n\nWe show a simple example when the multiple dispatch is useful.\n\n!!! warning \"Exercise:\"\n   We define the abstract type `Student` and specific types `Master` and `Doctoral`. The latter two are defined as structures containing one and three fields, respectively.\n\n   ```@example methods\n   abstract type Student end\n\n   struct Master <: Student\n      salary\n   end\n\n   struct Doctoral <: Student\n      salary\n      exam_mid::Bool\n      exam_english::Bool\n   end\n\n   nothing # hide\n   ```\n\n   We can check that the `subtypes_tree` works correctly on any type, including the type `Student` which we defined.\n\n   ```julia\n   julia> subtypes_tree(Student)\n   Student\n      Doctoral\n      Master\n   ```\n\n   We create instances of two students by providing values for the struct fields.\n\n   ```@example methods\n   s1 = Master(5000)\n   s2 = Doctoral(30000, 1, 0)\n\n   nothing # hide\n   ```\n\n   Write the `salary_yearly` function which computes the yearly salary for both student types. The monthly salary is computed from the base salary (which can be accessed via `s1.salary`). Monthly bonus for doctoral students is 2000 for the mid exam and 1000 for the English exam.\n\n!!! details \"Solution:\"\n   Julia prefers to write many simple functions. We write `salary_yearly` based on the not-yet-defined `salary_monthly` function.\n\n   ```@example methods\n   salary_yearly(s::Student) = 12*salary_monthly(s)\n\n   nothing # hide\n   ```\n\n   We specified that the input to `salary_yearly` is any `Student`. Since `Student` is an abstract type, we can call `salary_yearly` with both `Master` and `Doctoral` student. Now we need to define the `salary_monthly` function. Since the salary is computed in different ways for both students, we write two methods.\n\n   ```@example methods\n   salary_monthly(s::Master) = s.salary\n   salary_monthly(s::Doctoral) = s.salary + s.exam_mid*2000 + s.exam_english*1000\n\n   nothing # hide\n   ```\n\n   Both methods have the same name (they are the same function) but have different inputs. While the first one is used for `Master` students, the second one for `Doctoral` students. Now we print the salary.\n\n   ```@example methods\n   println(\"The yearly salary is $(salary_yearly(s1)).\")\n   println(\"The yearly salary is $(salary_yearly(s2)).\")\n\n   nothing # hide\n   ```\n\n## Method ambiguities\n\nIt is possible to define a set of function methods with no most specific method applicable to some combinations of arguments.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods_amb; output = false f(x::Float64, y) = x * y f(x, y::Float64) = x + y","category":"page"},{"location":"lecture_04/methods/#output-3","page":"Methods","title":"output","text":"","category":"section"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"f (generic function with 2 methods)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nHere, `f` has two methods. The first method applies if the first argument is of type `Float64`, and the second method applies if the second argument is of type `Float64`.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods_amb julia> f(2.0, 3) 6.0","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"julia> f(2, 3.0) 5.0","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nBoth methods can be used if both arguments are of type `Float64`. The problem is that neither method is more specific than the other. This results in `MethodError`.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods_amb julia> f(2.0, 3.0) ERROR: MethodError: f(::Float64, ::Float64) is ambiguous.","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Candidates:   f(x, y::Float64)     @ Main none:1   f(x::Float64, y)     @ Main none:1","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"Possible fix, define   f(::Float64, ::Float64) [...]","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nWe can avoid method ambiguities by specifying an appropriate method for the intersection case.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods_amb julia> f(x::Float64, y::Float64) = x - y f (generic function with 3 methods)","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"\nNow `f` has three methods.\n","category":"page"},{"location":"lecture_04/methods/","page":"Methods","title":"Methods","text":"jldoctest methods_amb julia> f(2.0, 3.0) -1.0 ```","category":"page"},{"location":"lecture_12/monte/#Monte-Carlo-sampling","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"","category":"section"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The three previous lectures presented data analysis from an optimization viewpoint. We considered the dataset as fixed and then derived an optimization problem of minimizing the discrepancy between predictions and labels. This lecture returns to linear models. It presents a statistical viewpoint, which considers the data and the labels as random realizations (samples) of random variables. The family of methods using random sampling from the same random variable to obtain numerical results is called the Monte Carlo methods.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"We will also present several topics on the curse of dimensionality, where behaviour in a large dimension is entirely different from the one in a small dimension. Since we humans cannot properly comprehend more than three dimensions, some of the results may be counter-intuitive.","category":"page"},{"location":"lecture_12/monte/#Gamma-function","page":"Monte Carlo sampling","title":"Gamma function","text":"","category":"section"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"One of the most commonly used functions in statistical analysis is the Gamma-function defined by","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"Gamma(z) = int_0^infty x^z-1e^-zdx","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"It can be evaluated only approximately except for positive integers k, for which it holds","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"Gamma(k) = (k-1)","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"It is implemented in the SpecialFunctions package.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"using SpecialFunctions\nusing Plots\n\nplot(0:0.1:10, gamma;\n    xlabel=\"x\",\n    ylabel=\"gamma(x): log scale\",\n    label=\"\",\n    yscale=:log10,\n)","category":"page"},{"location":"lecture_12/monte/#Volume-of-m-dimensional-ball","page":"Monte Carlo sampling","title":"Volume of m-dimensional ball","text":"","category":"section"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"Machine learning datasets contain many features. Even simple datasets such as MNIST live in 28times 28=784 dimensions. However, we humans are unable to think in more than three dimensions. Working with more-dimensional spaces can bring many surprises. This section computes the volume of m-dimensional balls. Before we start, try to guess the volume of the unit balls in mathbb R^10 and mathbb R^100. ","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"warning: Exercise:\nUse the formula to compute the volume of a m-dimensional ball. Plot the dependence of the volume on the dimension m=1dots100.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"details: Solution:\nThe formula can be easily transferred to a function.volume_true(m, R) = π^(m/2) *R^2 / gamma(m/2 + 1)\n\nnothing # hideThen we create the plot. We use the log-scaling of the y-axis.plot(1:100, m -> volume_true.(m, 1);\n    xlabel=\"dimension\",\n    ylabel=\"unit ball volume: log scale\",\n    label=\"\",\n    yscale=:log10,\n)\n\nsavefig(\"dimension1.svg\") # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"This result may be surprising. While the volume of the 10-dimensional ball is approximately 255, the volume of the 100-dimensional ball is almost 0.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The following exercise uses the Monte Carlo sampling to estimate this volume. We will sample points in the hypercube -11^m and then compute the unit ball volume by realizing that the volume of the ball divided by the volume of the box equals the fraction of sampled points inside the ball.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"warning: Exercise:\nWrite the function volume_monte_carlo, which estimates the volume of the m-dimensional ball based on n randomly sampled points.Hint: function rand(m,n) creates a mtimes n matrix, which can be understood as n randomly sampled points in 01^m. Transform them to -11^m.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"details: Solution:\nTo transform the random variable from 01 to -11, we need to multiply it by two and subtract one. Then we compute the norm of each sampled point. The estimated volume is computed as the fraction of the points whose norm is smaller than one multiplied by the hypercube volume. The latter equals to 2^m.using Random\nusing Statistics\n\nfunction volume_monte_carlo(m::Int; n::Int=10000)\n    X = 2*rand(m, n).-1\n    X_norm_sq = sum(X.^2; dims=1)\n    return 2^m*mean(X_norm_sq .<= 1)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The next figure shows the estimated volume from nin 10 1000 100000 samples for the unit ball in dimension m=1dots15.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"ms = 1:15\nns = Int64.([1e1; 1e3; 1e5])\n\nRandom.seed!(666)\n\nplt = plot(ms, m -> volume_true(m, 1);\n    xlabel=\"dimension\",\n    ylabel=\"unit ball volume\",\n    legend=:topleft,\n    label=\"True\",\n    line=(4,:black),\n)\n\nfor n in ns\n    plot!(plt, ms, m -> volume_monte_carlo.(m; n=n); label=\"n = $n\")\nend\n\ndisplay(plt)\n\nsavefig(\"dimension2.svg\") # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"It is not surprising that with increasing dimension, we need a much larger number of samples to obtain good estimates. This number grows exponentially with the dimension. This phenomenon explains why machine learning models with large feature spaces need lots of data. Moreover, the number of samples should increase with the complexity of the input and the network. ","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"info: Generating from the uniform distribution:\nWhile we wrote our function for generating from the uniform distribution, we can also use the Distributions package.using Distributions\n\nrand(Uniform(-1, 1), 10, 5)\nnothing # hideWe will discuss this topic more in the following section.","category":"page"},{"location":"lecture_12/monte/#Sampling-from-distributions","page":"Monte Carlo sampling","title":"Sampling from distributions","text":"","category":"section"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"This section shows how to generate from various distributions. We use the Distributions package to create the normal distribution with three sets of parameters.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"using Distributions\n\nd1 = Normal()\nd2 = Normal(1, 1)\nd3 = Normal(0, 0.01)\n\nf1(x) = pdf(d1, x)\nf2(x) = pdf(d2, x)\nf3(x) = pdf(d3, x)\n\nnothing # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"We create the plot_histogram function, which plots the histogram of xs and its density f. We use the normalize keyword to obtain probabilities in the histogram.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"function plot_histogram(xs, f; kwargs...)\n    plt = histogram(xs;\n        label=\"Sampled density\",\n        xlabel = \"x\",\n        ylabel = \"pdf(x)\",\n        nbins = 85,\n        normalize = :pdf,\n        opacity = 0.5,\n        kwargs...\n    )\n\n    plot!(plt, range(minimum(xs), maximum(xs); length=100), f;\n        label=\"True density\",\n        line=(4,:black),\n    )\n\n    return plt\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The Distributions package allows to easily generate random samples from most distributions by rand(d, n). Do not confuse the call rand(d, n) with rand(m, n). The former employs the Distribution package and generates n samples from distribution d, while the latter employs Base and generates mtimes n samples from 01. ","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"plot_histogram(rand(d1, 1000000), f1)\n\nsavefig(\"density0.svg\") # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"When the sampled point number is high enough, the sampled histogram is a good approximation of its density function.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"We may work with a distribution d for which we know the density f, but there is no sampling function. Then we can use the rejection sampling technique, which assumes the knowledge of:","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"the interval x_rm min x_rm max containing the support of f.\nthe upper bound  f_rm max for the density f.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The rejection sampling technique first randomly samples a trial point xin x_rm min x_rm max and a scalar pin 0f_rm max. It accepts x if p le f(x) and rejects it otherwise. This technique ensures that a point is accepted with a probability proportional to its density function value.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"warning: Exercise:\nImplement the rejection_sampling function. It should generate n trial points and return all accepted points.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"details: Solution:\nWhile it is possible to generate the random points one by one, we prefer to generate them all at once and discard the rejected samples. The function follows precisely the steps summarized before this exercise.function rejection_sampling(f, f_max, x_min, x_max; n=1000000)\n    xs = x_min .+ (x_max - x_min)*rand(n)\n    ps = f_max*rand(n)\n    return xs[f.(xs) .>= ps]\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"We will now use the rejection sampling technique to generate the random samples from the three distributions from above. Since the density f of the normal distribution achieves its maximum at the mean, we specify f_max = f(d.μ).","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"xlims = (-10, 10)\n\nfor (f, d) in zip((f1, f2, f3), (d1, d2, d3))\n    Random.seed!(666)\n    xs = rejection_sampling(f, f(d.μ), xlims...)\n\n    pl = plot_histogram(xs, f)\n    display(pl)\n    savefig(\"density\" * string(f) * \".svg\") # hide\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"(Image: )","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"While the rejection sampling provides a good approximation for the first two distributions, it performs subpar for the last distribution. The reason is that the rejection sampling is sensitive to the choice of the interval x_rm min x_rm max. Because we chose the interval -1010 and f_3 has negligible values outside of the interval -0101,  most trial points got rejected. It is not difficult to verify that from the 1000000 trial points, only approximately 1200 got accepted. The small number of accepted points makes for the poor approximation. If we generated from a narrower interval, the results would be much better.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"compat: BONUS: Using rejection sampling to compute expected value\nThis exercise computes the expected valuemathbb E_3 cos(100X) = int_-infty^infty cos(100 x) f_3(x) dxwhere we consider the expectation mathbb E with respect to d_3sim  N(0 001) with density f_3. The first possibility to compute the expectation is to discretize the integral.h(x) = cos(100*x)\n\nΔx = 0.001\nxs = range(xlims...; step=Δx)\ne0 = Δx * sum(f3.(xs) .* h.(xs))\n\nnothing # hideThe second possibility is to approximate the integral bymathbb E_3 cos(100X) approx frac 1nsum_i=1^n cos(x_i)where x_i are sampled from d_3. We do this in expectation1, and expectation2, where the formed generates from the Distributions package while the latter uses our rejection sampling. We use the method of the mean function, which takes a function as its first argument.expectation1(h, d; n = 1000000) = mean(h, rand(d, n))\n\nfunction expectation2(h, f, f_max, xlims; n=1000000)\n    return mean(h, rejection_sampling(f, f_max, xlims...; n))\nend\n\nnothing # hideIf it is difficult to sample from d_3, we can use a trick to sample from some other distribution. This is based on the following formula:mathbb E_3 h(x) = int_-infty^infty h(x) f_3(x) dx = int_-infty^infty h(x) fracf_3(x)f_1(x)f_1(x) dx = mathbb E_1 frach(x)f_3(x)f_1(x)This gives rise to another implementation of the same thing.function expectation3(h, f, d_gen; n=1000000)\n    g(x) = h(x)*f(x)/pdf(d_gen, x)\n    return mean(g, rand(d_gen, n))\nend\n\nnothing # hideWe run these three approaches for 20 repetitions.n = 100000\nn_rep = 20\n\nRandom.seed!(666)\ne1 = [expectation1(h, d3; n=n) for _ in 1:n_rep]\ne2 = [expectation2(h, f3, f3(d3.μ), xlims; n=n) for _ in 1:n_rep]\ne3 = [expectation3(h, f3, d1; n=n) for _ in 1:n_rep]\n\nnothing # hideFinally, we plot the results. Sampling from the package gives the best results because it generates the full amount of points, while the rejection sampling rejects many points. scatter([1], [e0]; label=\"Integral discretization\", legend=:topleft)\nscatter!(2*ones(n_rep), e1; label=\"Generating from Distributions.jl\")\nscatter!(3*ones(n_rep), e2; label=\"Generating from rejection sampling\")\nscatter!(4*ones(n_rep), e3; label=\"Generating from other distribution\")This exercise considered the computation of a one-dimensional integral. It is important to realize that even for such a simple case, it is necessary to sample a sufficiently large number of points. Even when we sampled 100000 points, there is still some variance in the results, as the last three columns show.","category":"page"},{"location":"lecture_12/monte/#How-many-samples-do-we-need?","page":"Monte Carlo sampling","title":"How many samples do we need?","text":"","category":"section"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"Previous sections showed that we need many samples to obtain a good approximation of a desired quantity. The natural question is, how exactly many samples do we need? Even though many results estimate such errors, unfortunately, the answer depends on the application. This section will present two examples. The first one shows the distance of sampled points in a more-dimensional space, while the second one computes quantiles.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"warning: Exercise:\nSample n=1000 points in the unit cube in the m=9-dimensional space. What is the minimum distance of these points? Before implementing the exercise, try to guess the answer.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"details: Solution:\nWe first sample the points.n = 1000\nm = 9\n\nRandom.seed!(666)\nxs = rand(m, n)\n\nnothing # hideThen we save the pairwise of points in dist1. Since this variable contains zeros on the diagonal, and since lower and upper diagonal are the same, we select only the upper part of the matrix and save it into dist2.using LinearAlgebra\n\ndist1 = [norm(x-y) for x in eachcol(xs), y in eachcol(xs)]\ndist2 = [dist1[i,j] for i in 1:n for j in i+1:n]\n\nnothing # hideThis approach has the disadvantage that it allocates an ntimes n matrix.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"The minimum of these distances is roughly 02, while the maximum is 22. The minimum is surprisingly high and shows that sampling even 1000 points in mathbb R^9 forms a very sparse structure. The maximum distance is far away from the distance of two corners of the hypercube, which equals sqrtm=3.","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"extrema(dist2)","category":"page"},{"location":"lecture_12/monte/","page":"Monte Carlo sampling","title":"Monte Carlo sampling","text":"compat: BONUS: Approximating the quantiles\nQuantiles form an important concept in statistics. Its definition is slightly complicated; we will consider only absolutely continuous random variables: one-dimensional variables X with continuous density f. Then the quantile at a level alphain01 is the unique point x such that mathbb P(Xle x) = int_-infty^x f(x)dx = alpha The quantile at level alpha=05 is the mean. Quantiles play an important role in estimates, where they form upper and lower bounds for confidence intervals. They are also used in hypothesis testing.This part will investigate how quantiles on a finite sample differ from the true quantile. We will consider two ways of computing the quantile. Both of them sample n points from some distribution d. The first one follows the statistical definition and selects the index of the nalpha smallest observation by the partialsort function. The second one uses the function quantile, which performs some interpolation.quantile_sampled1(d, n::Int, α) = partialsort(rand(d, n), floor(Int, α*n))\nquantile_sampled2(d, n::Int, α) = quantile(rand(d, n), α)\n\nnothing # hideWe defined the vectorized version. This is not efficient because for every n, the samples will be randomly generated again.quantile_sampled1(d, ns::AbstractVector, α) = quantile_sampled1.(d, ns, α)\nquantile_sampled2(d, ns::AbstractVector, α) = quantile_sampled2.(d, ns, α)\n\nnothing # hideWe generate the quantile for alpha = 099 and repeat it 20 times.α = 0.99\nn_rep = 20\nns = round.(Int, 10 .^ (1:0.05:5))\n\nRandom.seed!(666)\nqs1 = hcat([quantile_sampled1(d1, ns, α) for _ in 1:n_rep]...)\nRandom.seed!(666)\nqs2 = hcat([quantile_sampled2(d1, ns, α) for _ in 1:n_rep]...)\n\nnothing # hideWe initialize the plot with the line for the true quantile. Since this will be part of both plots, we create just one and use deepcopy to create the other one. plt1 = plot([0.9*minimum(ns); 1.1*maximum(ns)], quantile(d1, α)*ones(2);\n    xlabel=\"n: log scale\",\n    ylabel=\"sampled quantile\",\n    xscale=:log10,\n    label=\"True quantile\",\n    line=(4,:black),\n    ylims=(0,3.5),\n)\nplt2 = deepcopy(plt1)\n\nnothing # hideNow we add the sampled quantiles and the mean over all repetitions. Since we work with two plots, we specify into which plot we want to add the new data. It would be better to create a function for plotting and call it for qs1 and qs2, but we wanted to show how to work two plots simultaneously.for i in 1:size(qs1,1)\n    scatter!(plt1, ns[i]*ones(size(qs1,2)), qs1[i,:];\n        label=\"\",\n        color=:blue,\n        markersize = 2,\n    )\n    scatter!(plt2, ns[i]*ones(size(qs2,2)), qs2[i,:];\n        label=\"\",\n        color=:blue,\n        markersize = 2,\n    )\nend\n\nplot!(plt1, ns, mean(qs1; dims=2);\n    label=\"Sampled mean\",\n    line=(4,:red),\n)\nplot!(plt2, ns, mean(qs2; dims=2);\n    label=\"Sampled mean\",\n    line=(4,:red),\n)\n\ndisplay(plt1)\ndisplay(plt2)\nsavefig(plt1, \"quantile1.svg\") # hide\nsavefig(plt2, \"quantile2.svg\") # hide(Image: ) (Image: )Both sampled estimates give a lower estimate than the true quantile. In statistical methodology, these estimates are biased. We observe that the interpolated estimate is closer to the true value and that computing the quantile even on 10000 points gives an uncertainty interval of approximately 025.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"using Plots\nusing Random\n\nfunction create_anim(\n    f,\n    path,\n    xlims,\n    ylims,\n    file_name = joinpath(pwd(), randstring(12) * \".gif\");\n    xbounds = xlims,\n    ybounds = ylims,\n    fps = 15,\n)\n    xs = range(xlims...; length = 100)\n    ys = range(ylims...; length = 100)\n    plt = contourf(xs, ys, f; color = :jet)\n\n    # add constraints if provided\n    if !(xbounds == xlims && ybounds == ylims)\n        x_rect = [xbounds[1]; xbounds[2]; xbounds[2]; xbounds[1]; xbounds[1]]\n        y_rect = [ybounds[1]; ybounds[1]; ybounds[2]; ybounds[2]; ybounds[1]]\n        \n        plot!(x_rect, y_rect; line = (2, :dash, :red), label=\"\")\n    end\n\n    # add an empty plot\n    plot!(Float64[], Float64[]; line = (4, :arrow, :black), label = \"\")\n\n    # extract the last plot series\n    plt_path = plt.series_list[end]\n\n    # create the animation and save it\n    anim = Animation()\n    for x in eachcol(path)\n        push!(plt_path, x[1], x[2]) # add a new point\n        frame(anim)\n    end\n    gif(anim, file_name; fps = fps, show_msg = false)\n    return nothing\nend\n\nf(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nf(x1,x2) = f([x1;x2])","category":"page"},{"location":"lecture_08/constrained/#lagrangian","page":"Constrained optimization","title":"Constrained optimization","text":"","category":"section"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The usual formulation of constrained optimization is","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"tagP\nbeginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad g_i(x) le 0 i=1dotsI \nh_j(x) = 0 j=1dotsJ\nendaligned","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Functions g_i generate inequality constraints, while functions h_j generate equality constraints. Box constraints such as xin01 are the simplest case of the former. This optimization problem is also called the primal formulation. It is closely connected with the Lagrangian","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"L(xlambdamu) = f(x)  + sum_i=1^I lambda_i g_i(x) + sum_j=1^J mu_j h_j(x)","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Namely, it is simple to show that the primal formulation (P) is equivalent to","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"operatorname*minimize_xquad operatorname*maximize_lambdage 0muquad L(xlambdamu)","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The dual problem then switches the minimization and maximization to arrive at","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"tagD operatorname*maximize_lambdage 0mu quadoperatorname*minimize_xquad L(xlambdamu)","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Even though the primal and dual formulations are not generally equivalent, they are often used interchangeably.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"info: Linear programming:\nThe linear programbeginaligned\ntextminimizeqquad c^top x \ntextsubject toqquad Ax=b \nxge 0\nendalignedis equivalent tobeginaligned\ntextmaximizeqquad b^top mu \ntextsubject toqquad A^top mule c\nendalignedWe can observe several things:Primal and dual problems switch minimization and maximization.\nPrimal and dual problems switch variables and constraints.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"For the unconstrained optimization, we showed that each local minimum satisfies the optimality condition nabla f(x)=0. This condition does not have to hold for constrained optimization, where the optimality conditions are of a more complex form.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"todo: Theorem: Karush-Kuhn-Tucker conditions\nLet f, g_i and h_j be differentiable function and let a constraint qualification hold. If x is a local minimum of the primal problem (P), then there are lambdage 0 and mu such that    beginaligned\n    textOptimality  nabla_x L(xlambdamu) = 0 \n    textFeasibility  nabla_lambda L(xlambdamu)le 0 nabla_mu L(xlambdamu) = 0 \n    textComplementarity  lambda^top g(x) = 0\n    endalignedIf f and g are convex and h is linear, then every stationary point is a global minimum of (P).","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"When there are no constraints, the Lagrangian L reduces to the objective f, and the optimality conditions are equivalent. Therefore, the optimality conditions for constrained optimization generalize those for unconstrained optimization.","category":"page"},{"location":"lecture_08/constrained/#Numerical-method","page":"Constrained optimization","title":"Numerical method","text":"","category":"section"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We present only the simplest method for constraint optimization. Projected gradients","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ny^k+1 = x^k - alpha^knabla f(x^k) \nx^k+1 = P_X(y^k+1)\nendaligned","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"compute the gradient as for standard gradient descent, and then project the point onto the feasible set. Since the projection needs to be simple to calculate, projected gradients are used for simple X such as boxes or balls. ","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We will use projected gradients to solve","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ntextminimizeqquad sin(x_1 + x_2) + cos(x_1)^2 \ntextsubject toqquad x_1 x_2in -11\nendaligned","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The implementation of projected gradients is the same as gradient descent but it needs projection function P as input. For reasons of plotting, it returns both x and y.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"function optim(f, g, P, x, α; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    ys = zeros(length(x), max_iter)\n    xs[:,1] = x\n    for i in 1:max_iter\n        ys[:,i] = xs[:,i] - α*g(xs[:,i])\n        xs[:,i+1] = P(ys[:,i])\n    end\n    return xs, ys\nend\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The projection function P computes the projection on [x_min, x_max]. Since it is a box, the projection is computed componentwise:","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"P(x, x_min, x_max) = min.(max.(x, x_min), x_max)\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Now we can call projected gradients from the same starting point as before.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"x_min = [-1; -1]\nx_max = [0; 0]\n\nxs, ys = optim(f, g, x -> P(x,x_min,x_max), [0;-1], 0.1)\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We use the keyword arguments xbounds and ybounds to plot the feasible region in the animation. First, we plot only the iterations xs.","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"xlims = (-3, 1)\nylims = (-2, 1)\n\ncreate_anim(f, xs, xlims, ylims, \"anim6.gif\";\n    xbounds=(x_min[1], x_max[1]),\n    ybounds=(x_min[2], x_max[2]),\n)\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"To plot the path, we need to merge them by following one point from xs by a point from ys and so on. Since xs and ys have different number of entries, we can do it via","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"xys = hcat(reshape([xs[:,1:end-1]; ys][:], 2, :), xs[:,end])\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"It is probably not the nicest thing to do, but it is Saturday evening, I am tired, and it works. Sorry :) The animation can now be created in the same way as before. ","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"create_anim(f, xys, xlims, ylims, \"anim7.gif\";\n    xbounds=(x_min[1], x_max[1]),\n    ybounds=(x_min[2], x_max[2]),\n)\n\nnothing # hide","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_08/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The animation shows that projected gradients converge to the global minimum. Most of the iterations are outside of the feasible region, but they are projected back to the boundary. One can use the optimality conditions to verify that the gradient of the objective and the active constraint have the same direction.","category":"page"},{"location":"lecture_10/nn/#Neural-networks","page":"Neural networks","title":"Neural networks","text":"","category":"section"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"During this lecture, we will train a better classifier for the iris dataset. From the previous lecture, it will differ in several points:","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"It will use a neural network instead of the linear classifier.\nIt will use all features and not only two.\nIt will use all classes and not only two.","category":"page"},{"location":"lecture_10/nn/#Prepare-data","page":"Neural networks","title":"Prepare data","text":"","category":"section"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"We start by loading the iris dataset in the same way as in the last lecture.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"using RDatasets\n\niris = dataset(\"datasets\", \"iris\")\n\nX = Matrix(iris[:, 1:4])\ny = iris.Species\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The first exercise splits the dataset into the training and testing sets. Recall that the training set is used to train the classifier, while its performance is evaluated on the testing set. Since the classifier does not see the testing set samples during training, the same performance on the training and testing sets indicates no overfitting.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite the split function, which randomly splits the dataset and the labels into training and testing sets. Its input should be the dataset X and the labels y. It should have four outputs. Include 80% of data in the training set and 20% of data in the testing set by default.Hints:Use the randperm function from the Random package.\nWhile y can be assumed to a vector, X is a matrix or a more-dimensional array. Then it is beneficial to use the selectdim function to select subindices along the correct dimension.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nThe function split has two required arguments and two optional arguments. The first optional argument is the dimension dims along which the split is done. The second optional argument is the fraction of the training set. We first check whether the inputs have the same sizes along the correct dimension. Then we determine the number of samples n_train in the training set, create a random permutation i_rand and select the correct number of indices. Finally, we return the data and labels in the training and testing sets.using Random\n\nfunction split(X, y::AbstractVector; dims=1, ratio_train=0.8, kwargs...)\n    n = length(y)\n    size(X, dims) == n || throw(DimensionMismatch(\"...\"))\n\n    n_train = round(Int, ratio_train*n)\n    i_rand = randperm(n)\n    i_train = i_rand[1:n_train]\n    i_test = i_rand[n_train+1:end]\n\n    return selectdim(X, dims, i_train), y[i_train], selectdim(X, dims, i_test), y[i_test]\nend\n\nnothing # hideWe can verify its functionality by calling this function.X_train, y_train, X_test, y_test = split(X, y)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The following exercise normalizes the data. In the previous lecture, we have already normalized the training set. We compute the normalizing constants (mean and standard deviation) for each feature and then apply them to the data. Since the normalization needs to be done before training, and since the testing set is not available during training, the normalizing constants can be computed only from the training set. This also means that the features on the training set have zero mean and unit variance, but features on the testing set may have different mean and variance.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite the normalize functions as described above. It should have two inputs and two outputs. The keyword argument dims should also be included.Hint: check the help for the mean function.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nTo compute the mean of X along dimension dims, we can check the help for the mean function to realize that the correct command is mean(X; dims). This is equivalent to mean(X; dims=dims). We do the same for the standard deviation. To normalize, we need to subtract the mean and divide by the standard deviation. Since col_means has the same number of dimensions as X_train, we can use X_train .- col_mean to broadcast col_mean along the dimension mean was computed. We need to use the same normalizing constant for the training and testing sets due to the reasons mentioned above.using Statistics\n\nfunction normalize(X_train, X_test; dims=1, kwargs...)\n    col_mean = mean(X_train; dims)\n    col_std = std(X_train; dims)\n\n    return (X_train .- col_mean) ./ col_std, (X_test .- col_mean) ./ col_std\nend\n\nnothing # hideTo obtain the normalized datasets, we run the normalize function.X_train, X_test = normalize(X_train, X_test)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The following exercise modifies the labels into a standard form for machine learning.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite the onehot function that converts the labels y into their one-hot representation. The samples should be along the second dimension. Write the onecold function that converts the one-hot representation into the one-cold (original) representation. Both these functions need to have two arguments; the second one is classes, which equals unique(y).Write a check that both functions work correctly.Hints:The one-hot representation for a label has the size equalling to the number of classes. All entries besides one are zeros.\nSince the one-hot representation represents probabilities, the prediction is the class with the highest probability.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nThe onehot function first creates an array y_onehot, where the first dimension is the number of classes, and the second dimension the number of samples. Since all but one entries of each column will be zeros, we initialize it by zeros. Then we run a for loop to fill one into each column. We perform the for loop over all classes, but it is also possible to perform it over all columns.function onehot(y, classes)\n    y_onehot = falses(length(classes), length(y))\n    for (i, class) in enumerate(classes)\n        y_onehot[i, y .== class] .= 1\n    end\n    return y_onehot\nend\nnothing # hideThe onecold function finds the index of its maximum value. We repeat this for every column  y_col.onecold(y, classes) = [classes[argmax(y_col)] for y_col in eachcol(y)]\n\nnothing # hideFunctions onehot and onecold should be inverse to each other. That means that if we call them in succession, we obtain the original input.classes = unique(y)\n\nisequal(onecold(onehot(y, classes), classes), y)","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Preparing the data is spread over many lines. It is better to combine them into the function prepare_data.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"function prepare_data(X, y; do_normal=true, do_onehot=true, kwargs...)\n    X_train, y_train, X_test, y_test = split(X, y; kwargs...)\n\n    if do_normal\n        X_train, X_test = normalize(X_train, X_test; kwargs...)\n    end\n\n    classes = unique(y)\n\n    if do_onehot\n        y_train = onehot(y_train, classes)\n        y_test = onehot(y_test, classes)\n    end\n\n    return X_train, y_train, X_test, y_test, classes\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The standard data representation in linear and logistic regression is that each row (first dimension) is one sample. However, neural networks work with more-dimensional data (three dimensions represent each image). The convention changed, and the last dimension represents the samples. For this reason, we need to transpose the matrix X and use the keyword argument dims=2 to split the dataset along the second dimension. Then the whole procedure for data preprocessing can be summarized in a few lines of code. We specify the seed to obtain the same train-test split.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Random.seed!(666)\n\niris = dataset(\"datasets\", \"iris\")\n\nX = Matrix(iris[:, 1:4])\ny = iris.Species\n\nX_train, y_train, X_test, y_test, classes = prepare_data(X', y; dims=2)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Writing function prepare_data as above has other advantages; we will show them in the exercises. The following example shows that specifying the dimension to split along works as intended.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"using LinearAlgebra\n\nRandom.seed!(666)\naux1 = prepare_data(X, y; dims=1)\nRandom.seed!(666)\naux2 = prepare_data(X', y; dims=2)\n\nnorm(aux1[1] - aux2[1]')","category":"page"},{"location":"lecture_10/nn/#Create-the-network","page":"Neural networks","title":"Create the network","text":"","category":"section"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"We will now construct a simple neural network SimpleNet with the following three layers:","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The first layer is a dense layer with the ReLU activation function.\nThe second layer is a dense layer with the identity activation function.\nThe third layer is the softmax.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Its parameters will be stored in the following structure.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"struct SimpleNet{T<:Real}\n    W1::Matrix{T}\n    b1::Vector{T}\n    W2::Matrix{T}\n    b2::Vector{T}\nend","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"We will start with initializing the weights stored in the SimpleNet structure.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite an outer constructor for SimpleNet. Its inputs should be three integers representing the input size of the three layers. All matrices should be initialized based on the normal distribution.Hint: think about the representation of the dense layer.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nSince a dense layer computes Wx+b, the size of W should be the layer output size times the layer input size. The bias b should be of the size of the layer output.SimpleNet(n1, n2, n3) = SimpleNet(randn(n2, n1), randn(n2), randn(n3, n2), randn(n3))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Out neural network will have five hidden neurons. Therefore, we need to initialize it with the following code.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Random.seed!(666)\n\nm = SimpleNet(size(X_train,1), 5, size(y_train,1))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The following exercise computes the network prediction for samples. For a calling simplicity, we will write it as a functor.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite a functor function (m::SimpleNet)(x) which computes the prediction (forward pass) of the neural network SimpleNet.Bonus: try to make the functor work for both vectors (one sample) and matrices (multiple samples) x.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nThe dense layer is a linear function z1 = W1*x .+ b1 followed by an activation function. If we assume that x is a vector, then + would work the same as .+ because both W1*x and b are of the same dimension. However, if we want x to be a matrix (each column corresponds to one sample), we need to write .+ because W1*x is a matrix and the vector b needs to be broadcasted to be of the same size. The activation function is the ReLU function which needs to be applied componentwise. The procedure for the second layer is the same, but we need to finish it with the softmax function. If x is a matrix, then z2 is a matrix, and we specify that we want to normalize along the first dimension. If we assume only vector inputs, then specifying the dimension is not necessary.function (m::SimpleNet)(x)\n    z1 = m.W1*x .+ m.b1\n    a1 = max.(z1, 0)\n    z2 = m.W2*a1 .+ m.b2\n    return exp.(z2) ./ sum(exp.(z2), dims=1)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"It is simple now to evaluate the first two samples one the training set.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"m(X_train[:,1:2]) ","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Due to the softmax layer, they sum to one and form a probability distribution describing the probability of each class.","category":"page"},{"location":"lecture_10/nn/#Train-the-network","page":"Neural networks","title":"Train the network","text":"","category":"section"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"To train the network, we need to compute the gradients. It is rather complicated. However, when going through the code, it becomes clear that it is just a different form of the chain rule derived in the theoretical part.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"function grad(m::SimpleNet, x::AbstractVector, y; ϵ=1e-10)\n    z1 = m.W1*x .+ m.b1\n    a1 = max.(z1, 0)\n    z2 = m.W2*a1 .+ m.b2\n    a2 = exp.(z2) ./ sum(exp.(z2), dims=1)\n    l = -sum(y .* log.(a2 .+ ϵ))\n\n    e_z2 = exp.(z2)\n    l_part = (- e_z2 * e_z2' + Diagonal(e_z2 .* sum(e_z2))) / sum(e_z2)^2\n\n    l_a2 = - y ./ (a2 .+ ϵ)\n    l_z2 = l_part * l_a2\n    l_a1 = m.W2' * l_z2\n    l_z1 = l_a1 .* (a1 .> 0)\n    l_x = m.W1' * l_z1\n\n    l_W2 = l_z2 * a1'\n    l_b2 = l_z2\n    l_W1 = l_z1 * x'\n    l_b1 = l_z1\n\n    return l, l_W1, l_b1, l_W2, l_b2\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The function returns the function value l and derivatives with respect to all four variables.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"info: That's it? I thought neural networks are magic...\nWell, for a network with two layers and a loss, we can compute the function value and its derivative in only 16 lines of code.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"info: Simple implementation:\nThe previous function grad can compute the gradient for only one sample. Since the objective in training a neural network is a mean over all samples, this mean needs to be included externally. This is NOT the correct way of writing function. However, we decided to present it in the current way to keep the presentation (relatively) simple. When such a simplification is included in the code, we should include a check such as x::AbstractVector to prevent unexpected errors. When we compute gradients of multiple samples, we obtain an array. Each element is a tuple with five elements from the grad function.g_all = [grad(m, X_train[:,k], y_train[:,k]) for k in 1:size(X_train,2)]\n\ntypeof(g_all)To compute the mean over all samples, we need to use the following obscure function.mean_tuple(d::AbstractArray{<:Tuple}) = Tuple([mean([d[k][i] for k in 1:length(d)]) for i in 1:length(d[1])])\n\nnothing # hideWe see that it produces an averaged output of the grad function, where the average is taken with respect to all its inputs.g_mean = mean_tuple(g_all)\n\ntypeof(g_mean)","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"Having the gradient at hand, we can finally train the network.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nTrain the network with a gradient descent with stepsize alpha=01 for 200 iterations. Save the objective value at each iteration and plot the results.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nNow the process is simple. We compute the gradient grad_all, then its mean grad_mean via the already written function mean_tuple. The first value of the tuple grad_mean is the objective; the remaining are the gradients. Thus, we save the first value to an array and use the remaining one to update the weights.α = 1e-1\nmax_iter = 200\nL = zeros(max_iter)\nfor iter in 1:max_iter\n    grad_all = [grad(m, X_train[:,k], y_train[:,k]) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n\n    L[iter] = grad_mean[1]\n\n    m.W1 .-= α*grad_mean[2]\n    m.b1 .-= α*grad_mean[3]\n    m.W2 .-= α*grad_mean[4]\n    m.b2 .-= α*grad_mean[5]\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"using Plots # hide\nplot(L, xlabel=\"Iteration\", ylabel=\"Loss function\", label=\"\", title=\"Loss function on the training set\") # hide\nsavefig(\"loss.svg\") # hide\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/nn/#Prediction","page":"Neural networks","title":"Prediction","text":"","category":"section"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"We have trained our first network. We saw that the loss function keeps decreasing, which indicates a good training procedure. Now we will evaluate the performance.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"warning: Exercise:\nWrite a function which predict the labels for samples. Show the accuracy on both training and testing sets.","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"details: Solution:\nThe predicted probabilities are obtained by using the model m. The prediction (highest predicted probability) is obtained by converting the one-hot into the one-cold representation. Finally, the accuracy computes in how many cases the prediction equals to the label.predict(X) = m(X)\naccuracy(X, y) = mean(onecold(predict(X), classes) .== onecold(y, classes))\n\nprintln(\"Train accuracy = \", accuracy(X_train, y_train))\nprintln(\"Test accuracy = \", accuracy(X_test, y_test))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"The correct answer is","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"println(\"Train accuracy = \", accuracy(X_train, y_train)) # hide\nprintln(\"Test accuracy = \", accuracy(X_test, y_test)) # hide","category":"page"},{"location":"lecture_10/nn/","page":"Neural networks","title":"Neural networks","text":"We see that the testing accuracy is smaller than the training one. This is quite a common phenomenon which is named overfitting. The problem is that the algorithm sees only the data from the training set. If it fits this data \"too perfectly\", it cannot generalize into unseen samples (the testing set).","category":"page"},{"location":"lecture_07/develop/#development","page":"Package development","title":"Package development","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The cool thing about Julia is the simplicity of creating packages and sharing them with others. This section contains a step-by-step tutorial on how to build a package from scratch. Moreover, we will use this package later in the course.","category":"page"},{"location":"lecture_07/develop/#Pkg-templates","page":"Package development","title":"Pkg templates","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We first generate an empty package PackageName by the built-in function generate in the Pkg REPL.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(@v1.7) pkg> generate PackageName\n Generating  project PackageName:\n    PackageName/Project.toml\n    PackageName/src/PackageName.jl","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"This way generates the new package in the working directory. However, we may also specify an absolute or relative path to generate it elsewhere. The generate function creates a new folder (with the name matching the package name) with the following content.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"├── Project.toml\n└── src\n    └── PackageName.jl","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The new package consists of the Project.toml file and the src folder with one .jl file. The src/PackageName.jl file contains a module PackageName. The package, the .jl file, and the module share the same name. Since we will modify multiple files during this lecture, we will often specify which file we work with.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/PackageName.jl\nmodule PackageName\n\ngreet() = print(\"Hello World!\")\n\nend # module","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since the generate function creates an empty package, the Project.toml contains only information describing the package name, its unique UUID, version, and author list.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"name = \"PackageName\"\nuuid = \"fa38fd22-11d6-48c8-ae38-ef06258216d8\"\nauthors = [\"Author Name\"]\nversion = \"0.1.0\"","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since the Project.toml file src/*.jl files are sufficient for determining a  package, packages are modules with their own environment.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The built-in generate function provides only basic functionality for generating packages. Even though it is sufficient in many cases, the PkgTemplates package offers a straightforward and customizable way for creating packages.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"warning: Exercise:\nThe goal of this exercise is to create a new package by the PkgTemplates package. Install PkgTemplates and then use the following code to generate a new package template.using PkgTemplates\n\ntemplate = Template(;\n    user = \"GithubUserName\",            # github user name\n    authors = [\"Author1\", \"Author2\"],   # list of authors\n    dir = \"/Path/To/Dir/\",              # dir in which the package will be created\n    julia = v\"1.7\",                     # compat version of Julia\n    plugins = [\n        !CompatHelper,                  # disable CompatHelper\n        !TagBot,                        # disable TagBot\n        Readme(; inline_badges = true), # added readme file with badges\n        Tests(; project = true),        # added Project.toml file for unit tests\n        Git(; manifest = false),        # add manifest.toml to .gitignore\n        License(; name = \"MIT\")         # addedMIT licence\n    ],\n)Do not forget to change user, authors and dir.In the rest of the lecture, we will write code to visualize grayscale and colour images. Come up with a proper package name and use the following code to generate a new package.template(\"PackageName\")For naming conventions, see the official package naming guidelines. Finally, create the folder examples in the main package folder.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"details: Solution:\nThere is no best way to choose the correct package name. We decided to use ImageInspector and create the package by the following code:template(\"ImageInspector\")After creating the ImageInspector package, we can add the examples folder manually or use the mkdir function to create it. For the latter, we use the joinpath function to specify the correct path.mkdir(joinpath(\"/Path/To/Dir/\", \"ImageInspector\", \"examples\"))The generated folder contains more files than the folder generated by the built-in generate function.├── .git\n├── .gitignore\n├── LICENSE\n├── Manifest.toml\n├── Project.toml\n├── README.md\n├── examples\n├── src\n│   └── ImageInspector.jl\n└── test\n    ├── Manifest.toml\n    ├── Project.toml\n    └── runtests.jl","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"compat: Interactive package generation:\nPkgTemplate provides an interactive way to generate a new package. The template can be created interactively by the following command:Template(; interactive=true)The exercise above used a simple template. However, PkgTemplates provides many additional features to simplify the package generation process. Some plugins add documentation or integration with GitHub features. See the official PkgTemplates documentation for more information.","category":"page"},{"location":"lecture_07/develop/#Development-mode","page":"Package development","title":"Development mode","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"In the previous section, we created a new empty package. In this section, we will fill the package with content. Before we continue, open the main folder of the ImageInspector package in a new VS Code window. One can access it from File -> Open folder.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The content of the ImageInspector folder can be divided into four parts:","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Root folder contains information about the package and git.\nFolder src contains the package source code.\nFolder tests contains the testing scripts for verifying the code correctness.\nFolder examples is used to run examples.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The first three are standard, while we added the last folder manually. We can add more folders, such as data.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We first activate a new environment in the examples folder.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(ImageInspector) pkg> activate ./examples\n\n(examples) pkg>","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Then we use the dev (or develop) command to tell Julia that the ImageInspector folder is a package, and we want to start its development. The important thing to realize is that the working directory is .../ImageInspector, while the working environment is .../ImageInspector/examples. Since the dot in dev . specifies the working directory, this command will add the package from the working directory into the working environment.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> pwd()\n.../ImageInspector\n\n(examples) pkg> dev . # or dev /absolute/or/relative/path/ImageInspector/\n\n(examples) pkg> st\nStatus `.../ImageInspector/examples/Project.toml`\n  [5c9991e7] ImageInspector v0.1.0 `..`","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Like the add command, the dev command allows us to load the package by using or import. The difference between add and dev is that the dev command tracks the package current state and not a concrete git commit in some branch.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"warning: Default Julia enviroment in VS Code:\nThe VS Code allows setting a default Julia environment that is activated when Julia REPL is opened. We can do this by pressing Julia env: located at the bottom info bar and selecting the desired environment.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We now create a script /examples/example.jl for testing the package functionality. In the rest of the lecture, we will use relative paths from the main folder of the ImageInspector package to specify the code location.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /examples/example.jl\nusing ImageInspector","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Julia can load a package only once per Julia session. If we load a package by the using or import commands and then make changes in the code, these changes will not be reloaded. This holds even if we try to reload the package by running using or import again. For example, we add the greet function to the ImageInspector package.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/ImageInspector.jl\nmodule ImageInspector\n\nexport greet\n\ngreet() = print(\"Hello World!\")\n\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since we have already loaded the package, this change is not reloaded. If we call the greet function, we get the UndefVarError error.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> greet()\nERROR: UndefVarError: greet not defined","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"In this case, we have to restart Julia. There are two ways how to exit Julia interactive session: using keyword shortcut ctrl + D or using the exit() function. Even though we can use the greet() function after the restart, we will not do it yet. The reason is that we would have to restart Julia again after making any changes to the package. Since this is not a convenient way to code, we will use the Revise package. Even though it provides lots of convenient features, we will present only its basic use. First, we install it.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(examples) pkg> add Revise","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"If we develop a package and load the Revise package first, all package changes will be reloaded without restarting Julia.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /examples/example.jl\nusing Revise # this must come before `using ImageInspector`\nusing ImageInspector\n\ngreet()","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Hello World!","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We now add the greet2 function.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/ImageInspector.jl\nmodule ImageInspector\n\nexport greet, greet2\n\ngreet() = print(\"Hello World!\")\ngreet2() = print(\"Hello World!!!!\")\n\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since we are using the Revise package, it should be possible to call the greet2 function without restarting Julia session.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> greet2()\nHello World!!!!","category":"page"},{"location":"lecture_07/develop/#Adding-content-1","page":"Package development","title":"Adding content 1","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"This section adds content to the package.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"warning: Exercise:\nThis exercise defines the image function that converts a matrix of real numbers to a matrix of Gray points. Real numbers can be converted to Gray points by the Gray constructor from the Colors package. Use the following code to test the function.# /examples/example.jl\nusing Revise # this must come before `using ImageInspector`\nusing ImageInspector, MLDatasets, Plots\n\nX = MLDatasets.FashionMNIST(Float64, :train)[:][1];\nx = selectdim(X, ndims(X), 1)\n\nplot(image(x); axis = nothing, border = :none)Hint: Each Julia package contains its environment for tracking package dependencies. Use proper commands in the Pkg REPL to add Colors as a dependency of the ImageInspector package. Do not forget to add MLDatasets and Plots to the examples environment.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"details: Solution:\nFirst, we need to install all necessary packages. Since we set the examples environment as the default one for this project, we first install MLDatasets and Plots.(examples) pkg> add MLDatasets PlotsSince we want to add the image function to the ImageInspector package, we have to install the Colors package. However, we do not want to add it to examples but to ImageInspector. Printing the working directory by pwd(), we realize that we are in the correct folder and activate the working environment by activate . The dot represents the current working directory.julia> pwd()\n\".../ImageInspector\"\n\n(examples) pkg> activate .\nActivating environment at `/path/ImageInspector/Project.toml`Now we use add Colors to install the Colors package.(ImageInspector) pkg> add ColorsSince we want to work in examples, we change the environment back.(ImageInspector) pkg> activate ./examples\n\n(examples)With the Colors package installed, we have to add using Colors into the ImageInspector module. Then we can define the image function and export it.# /src/ImageInspector.jl\nmodule ImageInspector\n\nusing Colors\n\nexport image\n\nimage(x::AbstractMatrix{<:Real}) = Gray.(x)\n\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(Image: )","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The previous exercise used the MLDatasets package that provides many well-known datasets used in machine learning. One of them is the FashionMNIST dataset of gray images of clothes. However, the resulting image is rotated 90 degrees. The reason is that images in the FashionMNIST dataset are stored in the width x height format, but the Plots package assumes the height x width format. We solve this issue by redefining the image function.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"function image(x::AbstractMatrix{T}; flip = true) where {T <: Real}\n    xx = flip ? PermutedDimsArray(x, (2, 1)) : x\n    return Gray.(xx)\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"In the definition of image, we use PermutedDimsArray that creates a permuted view without making a copy. There is also the permutedims function that does the same but creates a copy. Now we plot both images.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /examples/example.jl\nplot(\n    plot(image(x; flip = true); title = \"flip = true\"),\n    plot(image(x; flip = false); title = \"flip = false\");\n    axis = nothing,\n    border = :none,\n)","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(Image: )","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The image function also used AbstractMatrix to specify that the input must be a matrix. In general, we can specify the types of multi-dimensional input arrays in multiple ways:","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"AbstractArray specifies that the input must be an array.\nAbstractArray{T} specifies that the input must be an array with elements of type T.\nAbstractArray{T, N} specifies that the input must be an array of dimension N with elements of type T.\nAbstractMatrix or AbstractMatrix{T} is equivalent to  AbstractArray with N=2.\nAbstractVector or AbstractVector{T} is equivalent to  AbstractArray with N=1.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We will now extend the image function to three-dimensional inputs. The third dimension represents the colour channels.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"warning: Exercise:\nWrite a method for the image function that converts a 3D array of real numbers to its image representation. Assume that the third dimension represents the colour channels. Three channels should be converted to an RGB point extracting the RGB channels and RGB.(r, g, b). If the size of the third dimension is:1 the function should return a grayscale image,\n3 the function should return a colour image,\notherwise, the function should throw an error.Use the following code to test the image function.# /examples/example.jl\nX1 = MLDatasets.FashionMNIST(Float64, :train)[:][1];\nX2 = MLDatasets.CIFAR10(Float64, :train)[:][1];\n\nx1 = selectdim(X1, ndims(X1), 1)\nx2 = selectdim(X2, ndims(X2), 1)\n\nplot(\n    plot(image(x1)),\n    plot(image(x2));\n    axis = nothing,\n    border = :none\n)Hint: use the eachslice function to split the array along the third dimension and the dropdims function to drop a dimension slice.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"details: Solution:\nThe functionality depends on the size of the third dimension.If the size of the third dimension is 1, we use the dropdims to remove the third dimension. Then we call the image method from the previous exercise.\nIf the dimension size is 3, we use PermutedDimsArray if flip is true. We can extract the three channels manually, or we can use the eachslice function.\nOtherwise, we throw an ArgumentError.Altogether, the new method can be defined as follows.# /src/ImageInspector.jl\nfunction image(x::AbstractArray{T,3}; flip = true) where {T <: Real}\n    s = size(x, 3)\n    if s == 1\n        return image(dropdims(x; dims = 3); flip)\n    elseif s == 3\n        xx = flip ? PermutedDimsArray(x, (2, 1, 3)) : x\n        r, g, b = eachslice(xx; dims=3)\n        return RGB.(r, g, b)\n    else\n        throw(ArgumentError(\"unsupported size of the third dimension $(s) ∉ [1,3].\"))\n    end\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(Image: )","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Multiple images are usually stored in multi-dimensional arrays. For example, grayscale images are stored as 3D or 4D arrays, where the last dimension represents individual images. Similarly, colour images are stored as a 4D array.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"warning: Exercise:\nAdd new methods for the image function with the following properties:New methods should accept two arguments:\nx: 3D or 4D array of real numbers that represents images,\ninds: one or more image indices to extract and convert to Gray/RGB representation.\nIf only one index is provided, the method should return a single image in its representation.\nIf more indices are provided, the method should return an array of images.Use the following code to test the image function.# /examples/example.jl\nX = MLDatasets.FashionMNIST(Float64, :train)[:][1];\n\nplot(plot.(image(X, [1,2]))...; axis = nothing, border = :none)","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"details: Solution:\nWe have four possible combinations of the input arguments:3D array and one index,\n3D array and multiple indices,\n4D array and one index,\n4D array and multiple indices.We should, therefore, define a method for each combination of input arguments. We can do this in the following way:# /src/ImageInspector.jl\nimage(x::AbstractArray{T,3}, inds; flip = true) where {T <: Real} = [image(x[:,:,i]; flip) for i in inds]\nimage(x::AbstractArray{T,4}, inds; flip = true) where {T <: Real} = [image(x[:,:,:,i]; flip) for i in inds]\nimage(x::AbstractArray{T,3}, ind::Int; flip = true) where {T <: Real} = image(x, [ind]; flip)[1]\nimage(x::AbstractArray{T,4}, ind::Int; flip = true) where {T <: Real} = image(x, [ind]; flip)[1]Since x[:,:,i] creates a new copy, it can be replaced by selectdim(x, 3, i), which creates a view.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(Image: )","category":"page"},{"location":"lecture_07/develop/#unit-testing","page":"Package development","title":"Unit testing","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The previous section added the image function with multiple methods. We also manually tested if these methods work correctly. Even though this practice works for small projects, it is not optimal for code testing and should be automized by unit testing. The Test package from the standard library provides utility functions to simplify writing unit tests. Its core is the @test macro that tests if an expression evaluates as true.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"using Test\n\n@test 1 == 1\n@test 1 == 3","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"It is possible to pass additional arguments to the @test macro.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"@test π ≈ 3.14 atol=0.01","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"If we go back to our package, we can start writing tests for the methods of the image function. All tests should be located in the /test folder with its own environment. First, we have to import all necessary packages: Test, ImageInspector and Colors. Since we used PkgTemplates to generate the package, the test folder and the environment are both already generated. Moreover, the environment already contains the Test package. We do not have to add the ImageInspector package because it is added automatically. For simplicity, we use the environment from the examples folder.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /test/runtests.jl\nusing ImageInspector\nusing Test\nusing ImageInspector.Colors","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We import Colors from the ImageInspector to use the same version. Now we define inputs and expected outputs for the image function.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /test/runtests.jl\nx = [0.1 0.2; 0.3 0.4];\nimg = Gray.(x);\nimg_flipped = Gray.(x');","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since the input to the image function is a matrix, we test the first method of the image function that creates grayscale images.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> @test image(x) == img_flipped\nTest Passed\n\njulia> @test image(x; flip = false) == img\nTest Passed\n\njulia> @test image(x; flip = true) == img_flipped\nTest Passed","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Since all tests passed correctly, the message Test Passed is printed after each test. It is a good idea to group tests logically by the @testset macro.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /test/runtests.jl\njulia> @testset \"image function\" begin\n           @test image(x) == img_flipped\n           @test image(x; flip = false) == img\n           @test image(x; flip = true) == img_flipped\n       end\nTest Summary:  | Pass  Total\nimage function |    3      3","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We use the begin ... end block to specify which tests should be grouped. Moreover, it is possible to combine the @testset macro and the for loop to perform multiple tests at once. For example, we may want to test the image function for different input images.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /test/runtests.jl\nx1 = [0.1 0.2];\nx2 = [0.1 0.2; 0.3 0.4];\nx3 = [0.1 0.2 0.3; 0.4 0.5 0.6];\nx4 = [0.1 0.2; 0.3 0.4; 0.5 0.6];\nx5 = [0.1, 0.2];","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"In such a case, we use nested test sets to group all tests. This approach has the advantage that each iteration of the loop is treated as a separate test set.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> @testset \"image function\" begin\n           @testset \"size(x) = $(size(x))\" for x in [x1, x2, x3, x4, x5]\n               img = Gray.(x);\n               img_flipped = Gray.(x');\n               @test image(x) == img_flipped\n               @test image(x; flip = false) == img\n               @test image(x; flip = true) == img_flipped\n           end\n       end\nsize(x) = (2,): Error During Test\n[...]\nTest Summary:      | Pass  Error  Total\nimage function     |   12      3     15\n  size(x) = (1, 2) |    3             3\n  size(x) = (2, 2) |    3             3\n  size(x) = (2, 3) |    3             3\n  size(x) = (3, 2) |    3             3\n  size(x) = (2,)   |           3      3\nERROR: Some tests did not pass: 12 passed, 0 failed, 3 errored, 0 broken.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Not all tests passed. The reason is that the variable x5 is a vector. From the list of all methods defined for the image function, we see that there is no method for a vector.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> methods(image)\n# 6 methods for generic function \"image\":\n[1] image(x::AbstractArray{var\"#s1\",2} where var\"#s1\"<:Real) in ImageInspector at [...]\n[2] image(x::AbstractArray{T,3}; flip) where T<:Real in ImageInspector at [...]\n[3] image(x::AbstractArray{T,3}, ind::Int64; flip) where T<:Real in ImageInspector at [...]\n[4] image(x::AbstractArray{T,3}, inds; flip) where T<:Real in ImageInspector at [...]\n[5] image(x::AbstractArray{T,4}, ind::Int64; flip) where T<:Real in ImageInspector at [...]\n[6] image(x::AbstractArray{T,4}, inds; flip) where T<:Real in ImageInspector at [...]","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"If we pass a vector as an argument, the MethodError will appear. The Test package provides the @test_throw macro to test if the expression throws the correct exception.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"julia> @test_throws MethodError image(x5)\nTest Passed\n      Thrown: MethodError","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The final testing file should be similar to the following one.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /test/runtests.jl\nusing ImageInspector\nusing ImageInspector.Colors\nusing Test\n\n@testset \"ImageInspector.jl\" begin\n    x1 = [0.1 0.2]\n    x2 = [0.1 0.2; 0.3 0.4]\n    x3 = [0.1 0.2 0.3; 0.4 0.5 0.6]\n    x4 = [0.1 0.2; 0.3 0.4; 0.5 0.6]\n    x5 = [0.1, 0.2]\n\n    @testset \"size(x) = $(size(x))\" for x in [x1, x2, x3, x4]\n        img = Gray.(x);\n        img_flipped = Gray.(x');\n        @test image(x) == img_flipped\n        @test image(x; flip = false) == img\n        @test image(x; flip = true) == img_flipped\n    end\n\n    @test_throws MethodError image(x5)\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"There is Project.toml and Manifest.toml files in the test folder. Creating a different environment has the advantage that it may contain packages needed only for testing. We can run tests directly from the Pkg REPL by the test command.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(examples) pkg> test ImageInspector\n    Testing ImageInspector\nStatus `.../Project.toml`\n  [...]\nStatus `.../Manifest.toml`\n  [...]\nTest Summary:     | Pass  Total\nImageInspector.jl |   13     13\n    Testing ImageInspector tests passed","category":"page"},{"location":"lecture_07/develop/#Writing-documentation","page":"Package development","title":"Writing documentation","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"Writing documentation is a good coding practice. It helps others to understand your code. It may even help the author after working on the code after an extended break. The most used documentation type is the docstring, a multiline string describing the functionality.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/ImageInspector.jl\n\"\"\"\n    image(x::AbstractMatrix{T}; flip = true)\n\nConverts a matrix of real numbers to a matrix of `Gray` points. If the keyword argument\n`flip` is true, the matrix is transposed.\n\n# Example\n\n```julia-repl\njulia> x = [0.1 0.25; 0.4 0.6]\n2×2 Matrix{Float64}:\n 0.1  0.25\n 0.4  0.6\n\njulia> image(x)\n2×2 Array{Gray{Float64},2} with eltype Gray{Float64}:\n Gray{Float64}(0.1)   Gray{Float64}(0.4)\n Gray{Float64}(0.25)  Gray{Float64}(0.6)\n\njulia> image(x; flip = false)\n2×2 Array{Gray{Float64},2} with eltype Gray{Float64}:\n Gray{Float64}(0.1)  Gray{Float64}(0.25)\n Gray{Float64}(0.4)  Gray{Float64}(0.6)\n```\n\"\"\"\nfunction image(x::AbstractMatrix{T}; flip = true) where {T <: Real}\n    xx = flip ? PermutedDimsArray(x, (2, 1)) : x\n    return Gray.(xx)\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We first wrote a function header, and then we used one tab as an indentation. Then we wrote a short description of the function. Finally, we wrote usage examples. To get a well-looking format of the docstring, we use markdown # Example to represents a title. We use the julia-repl block to write code. Now we type the function name into the Julia help.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"help?> image\nsearch: image imag\n\n  image(x::AbstractMatrix{T}; flip = true)\n\n  Converts a matrix of real numbers to a matrix of `Gray` points. If the keyword argument\n  `flip` is true, the matrix is transposed.\n\n  Example\n  ≡≡≡≡≡≡≡≡≡\n\n  julia> x = [0.1 0.25; 0.4 0.6]\n  2×2 Matrix{Float64}:\n   0.1  0.25\n   0.4  0.6\n\n  julia> image(x)\n  2×2 Array{Gray{Float64},2} with eltype Gray{Float64}:\n   Gray{Float64}(0.1)   Gray{Float64}(0.4)\n   Gray{Float64}(0.25)  Gray{Float64}(0.6)\n\n  julia> image(x; flip = false)\n  2×2 Array{Gray{Float64},2} with eltype Gray{Float64}:\n   Gray{Float64}(0.1)  Gray{Float64}(0.25)\n   Gray{Float64}(0.4)  Gray{Float64}(0.6)","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"info: Creating reports:\nReports may be written externally in Latex. However, when we want to show some code, it may be advantageous to write them directly in Julia and export them to Jupyter notebooks. The Literate package allows combining Julia code with the Markdown syntax in a script. We mention the following code, which should be read with the soft wrapping on, as an example:# # ImageInspector\n\n# ImageInspector is a small package for educational purposes. Its main goal is not presenting functionality, but presenting package structure. This is its short documentation created in the package [Literate](https://fredrikekre.github.io/Literate.jl/v2) which uses the [Markdown](https://www.markdownguide.org/cheat-sheet) syntax.\n\n# To use the package, we need to load first the required packages.\n\nusing ImageInspector\nusing Plots\n\n# ## Grayscale images\n\n# As a test example, we create the real matrix `img1` representing a circle. We first discretize the domain $[-1,1]$ in `xs`. We assign black colour whenever $x^2 + y^2 \\le 1$. Since the white colour is represented by `[1; 1; 1]` and the black colour by `[0; 0; 0]`, we can do it by the following code:\n\nxs = -1:0.001:1\nimg1 = [x^2+y^2>1 for x in xs, y in xs];\n\n# This is a two-dimensional matrix, which represents a grayscale image. We convert it to an image by calling `image` and then we plot it.\n\nplot(image(img1); axis = nothing, border = :none)\nThe Markdown syntax starts with #. Among others, it allows to use:Links such as [Literate](https://fredrikekre.github.io/Literate.jl/v2).\nVariables or latex syntax such as $[-1,1]$.Exporting the script into a notebook is simple.julia> Literate.notebook(\"report.jl\"; execute=false)The resulting notebook can be found at our Github. All required data are in the report folder.","category":"page"},{"location":"lecture_07/develop/#Adding-content-2","page":"Package development","title":"Adding content 2","text":"","category":"section"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We will add more functions to the ImageInspector package. To plot multiple images at once, we will define two functions. The first one computes an optimal grid size for a given number of images.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/ImageInspector.jl\nfunction gridsize(n::Int; nrows::Int = -1, ncols::Int = - 1)\n    if nrows < 1\n        if ncols < 1\n            nrows = round(Int, sqrt(n))\n            ncols = ceil(Int, n / nrows)\n        else\n            nrows = ceil(Int, n / ncols)\n        end\n    else\n        ncols = ceil(Int, n / nrows)\n    end\n    return nrows, ncols\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"The second function consists of two methods and converts an array of real numbers to one big image of the appropriate colour type.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /src/ImageInspector.jl\nimagegrid(x, ind::Int; flip = true, kwargs...) = image(x, ind; flip)\n\nfunction imagegrid(x, inds; flip = true, sep = 1, kwargs...)\n    imgs = image(x, inds; flip)\n    n = length(imgs)\n    nrows, ncols = gridsize(n; kwargs...)\n\n    h, w = size(imgs[1])\n    A = fill(\n        eltype(imgs[1])(1), # white color in proper color type\n        nrows*h + (nrows + 1)*sep, # height of the reculting image\n        ncols*w + (ncols + 1)*sep, # width of the reculting image\n    )\n\n    for i in 1:nrows, j in 1:ncols\n        k = j + (i - 1) * ncols\n        k > n && break\n\n        rows = (1:h) .+ (i - 1)*h .+ i*sep\n        cols = (1:w) .+ (j - 1)*w .+ j*sep\n        A[rows, cols] = imgs[k]\n    end\n    return A\nend","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"We use the sep keyword argument to specify the separator width between images. With all functions defined, we can test them.","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"# /examples/example.jl\nX = MLDatasets.FashionMNIST(Float64, :train)[:][1];\n\nplot(imagegrid(X, 1:10; nrows = 2, sep = 2); axis = nothing, border = :none)","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"(Image: )","category":"page"},{"location":"lecture_07/develop/","page":"Package development","title":"Package development","text":"compat: Optional dependencies:\nWe used the same settings for the plot function in all previous examples. Therefore, it makes sense to write an auxiliary function setting attributes for the plot function. However, this function will depend on the Plots package, and if we add Plots to ImageInspector, it will significantly slow the loading time. The Requires package prevents explicit dependencies (and long load times) by allowing conditional code loading. In our case, we first add Requires to the ImageInspector.julia> pwd()\n\".../ImageInspector\"\n\n(examples) pkg> activate .\nActivating environment at `/path/ImageInspector/Project.toml`\n\n(ImageInspector) pkg> add Requires\n[...]\n\n(ImageInspector) pkg> activate\n\n(examples)Then we create a new file /src/imageplot.jl with the following content:# /src/imageplot.jl\nusing .Plots\n\nexport imageplot\n\nimageplot(x; flip = true, kwargs...) =  imageplot(image(x; flip); kwargs...)\n\nfunction imageplot(x, ind; flip = true, nrows = -1, ncols = -1, sep = 1, kwargs...)\n    img = imagegrid(x, ind; flip, nrows, ncols, sep)\n    return imageplot(img; kwargs...)\nend\n\nfunction imageplot(\n    x::AbstractMatrix{<:Color};\n    legend = false,\n    axis = nothing,\n    border = :none,\n    kwargs...\n)\n    return plot(x; legend, axis, border, kwargs...)\nendWe only defined a wrapper function for the plot function and exported this function. We use a relative path to the Plots package. Then we specify on which package the code depends by defining the __init__() function in the /src/ImageInspector.jl file.# /src/ImageInspector.jl\nusing Requires\n\nfunction __init__()\n    @require Plots=\"91a5bcdd-55d7-5caf-9e0b-520d859cae80\" include(\"imageplot.jl\")\nendThe __init__ function has to contain the @require macro followed by the package name and its unique UUID (can be found in the JuliaRegistries for public packages) and the code that should be included.Now we can start a new Julia session and test if the loading works properly. If we do not load Plots, the imageplot function will not be available, as can be seen below.julia> x = MLDatasets.CIFAR10(Float64, :train)[1:10][1]\n\njulia> imageplot(x, 1:10; nrows = 2, sep = 2)\nERROR: UndefVarError: imageplot not definedAfter loading the Plots package, the imageplot function will start working.julia> using Plots\n\njulia> imageplot(x, 1:10; nrows = 2, sep = 1)(Image: )","category":"page"}]
}
