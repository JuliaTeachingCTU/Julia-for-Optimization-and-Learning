var documenterSearchIndex = {"docs":
[{"location":"lecture_07/unconstrained/#Unconstrained-optimization","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Unconstrained optimization means that we optimize a function on the whole space X=mathbbR^n.","category":"page"},{"location":"lecture_07/unconstrained/#Theory-of-Unconstrained-optimization","page":"Unconstrained optimization","title":"Theory of Unconstrained optimization","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"What do we look for when we minimize a function f over some X? The optimal point would be a global minimum, which is a point xin X which satisfies","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) le f(y) text for all yin X","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This point is often very difficult to find. Sometimes we are able to find a local minimum, which is a global minimum on some small neighbourhood of x.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">Theorem: Connection between optimization problems and gradients</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Consider a differentiable function f over X=mathbbR^n. If x is its local minimum, then nabla f(x)=0. Conversely, if f is convex, then every point x with nabla f(x)=0 is a global minimum of f.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Points with nabla f(x)=0 are known as stationary points. Optimization algorithms often try to find them with the hope that they minimize the function f.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"info-body\">\n<header class = \"info-header\">Take care</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This theorem does not hold if X is not the whole space.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Most of optimizaton algorithms do not search for a global minimum but they instead apply some iterative procedure which looks for a stationary point. That means they try to find a point, where the gradient equals to zero. But what is the gradient? For a function fmathbbRto mathbbR, its gradient is defined by","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) = lim_hto 0fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For a mapping  fmathbbR^nto mathbbR^m, its Jacobian is a matrix nabla f(x) of size mtimes n of partial derivatives","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(nabla f(x))_ij = fracpartial f_ipartial x_j(x) = lim_hto 0fracf_i(x_1dotsx_j-1x_j+hx_j+1dotsx_n)-f(x_1dotsx_n)h","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"info-body\">\n<header class = \"info-header\">Confusion</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Gradient nabla f(x) of a function fmathbbR^ntomathbbR should be of size  1times n but it is commonly considered as ntimes 1.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Functions to optimize are usually complex. Then the definition cannot be used to compute the gradient. Instead, the objective function f is rewritten as a composition of simpler functions, these simpler functions are differentiated and the chain rule is applied to get nabla f.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">Theorem: Chain</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Consider two differentiable functions fmathbbR^mtomathbbR^s and gmathbbR^ntomathbbR^m. Then its composition h(x) = f(g(x)) is differentiable with Jacobian","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"nabla h(x) = nabla f(g(x))nabla g(x)","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/unconstrained/#Visualization-of-gradients","page":"Unconstrained optimization","title":"Visualization of gradients","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For the numerical experiments, we will consider the following function","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) = sin(x_1 + x_2) + cos(x_1)^2","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"on domain -31times -21.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Contour plot</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Write a function g(x) which computes the derivative of f at a point  x.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Plot the contours of f on the given domain. Use the optional argument color = :jet for better visualization.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Function f(x) takes as an input a vector of two dimensions and returns a scalar. Therefore, the gradient is a two-dimensional vector, which we create by [?; ?]. Its components are computed from the chain rule.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Since sometimes it is better to use notation f(x) and sometimes f(x_1x_2), we overload the function f","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x1,x2) = f([x1;x2])\n\nf([0; 0])\nf(0, 0)\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"println(f([0; 0])) # hide\nprintln(f(0, 0)) # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We use the Plots package for plotting. We create the discretization xs and ys of both axis and then call the contourf function.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"using Plots\n\nxs = range(-3, 1, length = 40)\nys = range(-2, 1, length = 40)\n\ncontourf(xs, ys, f, color = :jet)\n\nsavefig(\"grad1.svg\") # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/#comp-grad","page":"Unconstrained optimization","title":"Computation of gradients","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The simplest way to compute the gradients is to use a finite difference approximation. It replaces the limit in","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) = lim_hto 0fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"by fixing some h and approximates the gradient by","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) approx fracf(x+h)-f(x)h","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Finite difference approximation</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Write a function finite_difference which computes the approximation of f(x) by finite differences. The inputs are a function fmathbb Rtomathbb R and a point xinmathbbR. It should have an optional input hinmathbbR, for which you need to choose a reasonable value.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We just need to rewrite the formula above. Since the argument h is optional, it should be after ;. Its good default value is anything between 10^-10 and 10^-5. We specify x::Real as a sanity check for the case when a function of more variables is passed as input.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"finite_difference(f, x::Real; h=1e-8) = (f(x+h) - f(x)) / h\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This way of computing the gradient has two disadvantages:","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"It is slow. For a function of n variables, we need to evaluate the function at least n+1 times to get the whole gradient.\nIt is not precise. We will show this in the next example.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Finite difference approximation</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Fix a point x=(-2-1). For a proper discretization of hin 10^-15 10^-1 compute the finite difference approximation of the partial derivative of f with respect to the second variable.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Plot the dependence of this approximation on h. Add the true derivative computed from g.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"To compute the partial derivative with respect to the second argument, we need to fix the first argument and vary only the second one. We create an autonomous function y -> f(-2, y) and another function fin_diff which for an input h computes the finite difference.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x = [-2; -1]\nfin_diff(h) = finite_difference(y -> f(-2, y), -1; h=h)\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The true gradient is computed by g(x). It returns a vector of length two. Since we need only the partial derivative with respect to the second component, we select it by adding  [2].","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"true_grad = g(x)[2]\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Now we create the discretization of h in hs. When the orders of magnitude are so different, logarithmic scale should be used. For this reason, we create a uniform discretization of the interval -15-1 and then use it as an exponent.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"hs = 10. .^ (-15:0.01:-1)\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"There are many possibilities of how to create the plot. Probably the simplest one is to plot the function fin_diff and then add the true gradient (which does not depend on h and is, therefore, a horizontal line) via hline!","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"plot(hs, fin_diff,\n    xlabel = \"h\",\n    ylabel = \"Partial gradient wrt y\",\n    label = [\"Approximation\" \"True gradient\"],\n    xscale = :log10,\n)\n\nhline!([true_grad]; label =  \"True gradient\")\n\nsavefig(\"grad2.svg\") # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Another possibility is to use only one call for the plot function. The x axis is hs, while for the y axis we need to concatenate the true gradient true_grad and its finite difference approximation fin_diff.(hs) by hcat. It is also possible to use [? ?] but not [?, ?] or [?; ?] (try it). To get the same shape of the arrays, we need to repeat true_grad from a scalar to a vector of the same length as fin_diff. Since repeat requires the input to be an array, we need to create it by [true_grad].","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"data = hcat(fin_diff.(hs), repeat([true_grad], length(hs)))\nplot(hs, data,\n    xlabel = \"h\",\n    ylabel = \"Partial gradient wrt y\",\n    label = [\"Approximation\" \"True gradient\"],\n    xscale = :log10,\n)\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We see that the approximation is good if the value h is not too small or too large. It cannot be too large because the definition of the gradient considers the limit to zero. It cannot be too small because then the numerical errors kick in. This is connected with machine precision, which is most vulnerable to subtraction of two numbers of almost the same value. A simple example shows","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(x + h)^2 - x^2 = 2xh + h^2","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"but the numerical implementation","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x = 1;\nh = 1e-13;\n(x+h)^2 - x^2\n2*x*h + h^2","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"gives an error already on the third decimal point.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Finally, we show how the gradients look like.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Direction of gradients</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Plot the contours of f and its gradient at (-2-1).","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We use the same functions as before. Since we want to add a line, we use plot! instead of plot. We specify its parameters in an optional argument line = (:arrow, 4, :black). These parameters add the pointed arrow, the thickness and the colour of the line. Since we do not want any legend, we use label = \"\".","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x = [-2; -1]\nα = 0.25\nx_grad = [x x.+α.*g(x)]\n\ncontourf(xs, ys, f; color = :jet)\nplot!(x_grad[1, :], x_grad[2, :];\n    line = (:arrow, 4, :black),\n    label = \"\",\n)\n\nsavefig(\"grad3.svg\") # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The gradient is perpendicular to the contour lines. This makes perfect sense. Since the gradient is the direction of steepest ascent, and since the contours have constant values, it needs to be like this. Try this with different values of x.","category":"page"},{"location":"lecture_07/unconstrained/#Numerical-methods","page":"Unconstrained optimization","title":"Numerical methods","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This part introduces the most basic optimization algorithm called gradient (or steepest) descent.","category":"page"},{"location":"lecture_07/unconstrained/#Gradient-descent","page":"Unconstrained optimization","title":"Gradient descent","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We learnt that the gradient is the direction of steepest descent. The straightforward idea is to move in the opposite direction. This gives rise to the gradient descent algorithm","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x^k+1 = x^k - alpha^knabla f(x^k)","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The stepsize alpha^k0 can be tuned as a hyperparameter.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"info-body\">\n<header class = \"info-header\">Terminology</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"In classical optimization, the usual terminology is:","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Variable is to be optimized.\nParameter is external (fixed) such as material parameters.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"In machine learning, the usual terminology is:","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Parameter is to be optimized.\nHyperparameter is an external model parameter which is not optimized and needs to be tuned. The example is the steplength because the gradient descent finds a different solution for different steplength but it is not changed during the optimization.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The different terminology (and the fact that there are adaptive schemes to select the steplenght which should make it a parameter instead of a hyperparameter) makes the notation confusing.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Gradient descent</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Implement function optim which takes as inputs function f, its gradient, starting point x^0 and fixed stepsize alpha and runs the gradient descent. Its output should be the first 100 iterations.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"This example is rather artificial because usually only the last iteration is returned and some stopping criterion is employed instead of the fixed number of iterations. We want to get all iterations to make visualizations.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"First we need to create an empty array into which we store the iterates. Then at every iteration we compute the gradient g(x), perform the update and save the new value of x.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"function optim(f, g, x, α; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    xs[:,1] = x\n    for i in 1:max_iter\n        x -= α*g(x)\n        xs[:,i+1] = x\n    end\n    return xs\nend\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p>\n</details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The implementation does not use the values of f but only its gradient nabla f. Moreover, if the algorithm converges x^k to bar x, then passing to the limit in the gradient update results in nabla f(bar x)=0. Therefore, as most optimization methods, gradient descent looks for stationary points.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Before plotting the path taken by gradient descent, we create create_anim function which creates animations of path over the contour plot of f. From xlims and ylim, it creates discretizations xs and ys and then plots the contour plot as background. Since Animation requires updating a graph, we start with an empty graph and in a for loop over path, we push the new image to the animation. The final commands gif saves the animation into file_name.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"function create_anim(f, path, xlims, ylims; file_name = \"\", fps=15)\n    xs = range(xlims...; length = 100)\n    ys = range(ylims...; length = 100)\n    plt = contourf(xs, ys, f, color = :jet, axis = false, ticks = false, cbar = false)\n\n    # adds an empty plot to plt\n    plot!(Float64[], Float64[]; line = (4, :black), label = \"\")\n\n    # extracts last plot series\n    plt_path = plt.series_list[end]\n\n    # creates the  animation\n    anim = Animation()\n    for x in eachcol(path)\n        push!(plt_path, x[1], x[2]) # add new point to plt_grad\n        frame(anim)\n    end\n    gif(anim, file_name; fps = fps, show_msg = false)\n    return nothing\nend\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We now plot how gradient descent behaves.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Gradient descent</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Use the implementation of the gradient descent to minimize the function","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x) = sin(x_1 + x_2) + cos(x_1)^2","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"from the starting point x^0=(0-1) and constant stepsize alpha=01. Store all iterations into matrix xs.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Plot how the iterations evolve. You need to save the animation with the gif extension.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Use one line of code to evaluate the function values for all iterations xs (hint: you need to iterate via eachcol(xs) or eachrow(xs) depending on how you represent xs). Plot these values.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We call optim written in the previous exercise and then create the animation.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x_gd = optim([], g, [0; -1], 0.1)\n\nxlims = (-3, 1)\nylims = (-2, 1)\ncreate_anim(f, x_gd, xlims, ylims; file_name = \"anim1.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"To plot the function values, we need to iterate over all columns. We use [? for x in eachcol(x_gd)] and apply f(x) instead of ?. Another (more complicated) way is to iterate over indices instead of vectors and write [f(x_gs[:,i]) for i in 1:size(x_gd,2)].","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f_gd = [f(x) for x in eachcol(x_gd)]\n\nplot(f_gd, label=\"\", xlabel=\"Iteration\", ylabel=\"Function value\")\n\nsavefig(\"obj.svg\") # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The convergence looks very nice, and the function value decreases. First, the decrease is faster, but when the iterations get closer to the minimum, it slows down.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"What happens if we choose a different stepsize though? Let us try with two different values. First let us try alpha=001.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x_gd = optim([], g, [0; -1], 0.01)\n\ncreate_anim(f, x_gd, xlims, ylims; file_name = \"anim2.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We see that when the stepsize is reduced, the steps are shorter and we would need to increase the number of iterations (and thus time) to converge. When the stepsize is larger, say alpha=1, the situation is different.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"x_gd = optim([], g, [0; -1], 1)\n\ncreate_anim(f, x_gd, xlims, ylims; file_name = \"anim3.gif\")\n\nsavefig(\"numer4.svg\") # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For a large stepsize, the algorithm gets close to the solution and then starts jumping around. If we further increase the stepsize, it will even diverge to infinity. Try it.","category":"page"},{"location":"lecture_07/unconstrained/#Adaptive-stepsize","page":"Unconstrained optimization","title":"Adaptive stepsize","text":"","category":"section"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"To handle this numerical instability, safeguards are introduced. One of the possibilities is the Armijo condition which automatically selects the stepsize. It looks for alpha^k which satisfies","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"f(x^k - alpha^knabla f(x^k)) le f(x^k) - c alpha^k nabla f(x^k)^2","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Here  cin(01) is a small constant, usually c=10^-4. Since the left-hand side is the function value at the new iterate x^k+1, the Armijo condition ensures that the sequence of function values is strictly decreasing. This prevents oscillations.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The implementation of optim(f, g, x, α; max_iter=100) from the exercise above is rather stupid because it does not allow to modify the selection of the step. The simplest fix would be to include if conditions inside the function. However, this would result in a long function, which may be difficult to debug and modify. A more elegant solution is to create an abstract class","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"abstract type Step end","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"and for each possible step selection method implement a optim_step method, which selects the step. First, we create the gradient descent class GD as a subclass of Step by","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"struct GD <: Step\n    α::Real\nend","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"It is a structure with parameter α. Then we create the optim_step function by","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"optim_step(s::GD, f, g, x) = -s.α*g(x)\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Due to the first input argument, it will be called only for the  GD stepsize. To access the parameter α, we need to retrieve it from the structure by s.α. Now we can modify the optim function by","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"function optim(f, g, x, s::Step; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    xs[:,1] = x\n    for i in 1:max_iter\n        x += optim_step(s, f, g, x)\n        xs[:,i+1] = x\n    end\n    return xs\nend\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"The specification of the input s::Step allows for any subclass of the abstract class Step. Using this implentation results in","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"gd = GD(0.1)\nx_opt = optim(f, g, [-1;0], gd)\n\ncreate_anim(f, x_opt, xlims, ylims; file_name = \"anim4.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We obtained the same results as in the previous case. This is not surprising as the code does exactly the same things; it is only written differently. The next exercise shows the power of defining the Step class.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Armijo condition</header><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Implement the Armijo subclass of the Step class. It should have two parameters c from the definition and α_max which will be the initial value of alpha. The value alpha should be divided by two until the Armijo condition is satisfied.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Then run the optimization with the Armijo selection of the stepsize and plot the animation.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"We define the class in the same way as for GD:","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"struct Armijo <: Step\n    c::Real\n    α_max::Real\nend","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"For the search for the stepsize, we first save the values for the function value f(x) and the gradient nabla f(x). If we do not do this, it will be recomputed at every step. Then we initialize the value of alpha and run the while loop until the Armijo condition is satisfied. We added a termination condition (also a safe check) α <= 1e-6 to prevent the loop for continuing indefinitely.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"function optim_step(s::Armijo, f, g, x)\n    fun = f(x)\n    grad = g(x)\n    α = s.α_max\n    while f(x .- α*grad) > fun - s.c*α*(grad'*grad)\n        α /= 2\n        if α <= 1e-6\n            warning(\"Armijo line search failed.\")\n            break\n        end\n    end\n    return -α*grad\nend\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Then we create the Armijo object and run the optimization again.","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"gd = Armijo(1e-4, 1)\nx_opt = optim(f, g, [0;-1], gd)\n\ncreate_anim(f, x_opt, xlims, ylims; file_name = \"anim5.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"</p></details>","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/unconstrained/","page":"Unconstrained optimization","title":"Unconstrained optimization","text":"Since the Armijo condition determines the optimal stepsize automatically, the convergence is much faster than for gradient descent. Moreover, it is not necessary to specify the stepsize (which may cause small convergence of even divergence for gradient descent). The price to pay is that every iteration needs to perform several function evalutions, which is not the case for standard gradient descent.","category":"page"},{"location":"lecture_01/operators/#Arithmetic-operators","page":"Elementary Functions","title":"Arithmetic operators","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Basic arithmetic operations are defined in Julia standard libraries, and all these operators are supported on all primitive numeric types","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Expression Name Description\nx + y binary plus performs addition\nx - y binary minus performs subtraction\nx * y times performs multiplication\nx / y divide performs division\nx ÷ y integer divide x / y, truncated to an integer\nx \\ y inverse divide equivalent to y / x\nx ^ y power raises x to the yth power\nx % y remainder equivalent to rem(x,y)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Here are some simple examples using arithmetic operators","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> 1 + 2\n3\n\njulia> 2*3\n6\n\njulia> 4/3\n1.3333333333333333","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"All of these operators can also be applied directly to any variable that represents a numeric value","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 1;\n\njulia> y = 3;\n\njulia> (x + 2)/(y - 1) - 4*(x - 2)^2\n-2.5","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Note that we use a semicolon after some expressions. In the REPL, if we evaluate any expression, its result is printed. If we use the semicolon, the print is omitted. It is similar behavior as in Matlab, but in Julia, the print is automatic only in the REPL.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"A numeric literal placed directly before an identifier or parentheses is treated as a multiplication (except with higher precedence than other binary operations)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> 2(3 + 4) # equivalent to 2*(3 + 4)\n14","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"What is the value and type of y given by the following expression","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"y = frac(x + 2)^2 - 4(x - 2)^p - 2","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"where x = 4 and p = 5.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"First, we define variables x and p","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 4\n4\n\njulia> p = 5\n5","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"then we can use the combination of basic arithmetic operators to compute the value of y","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> y = ((x + 2)^2 - 4)/(x - 2)^(p - 2)\n4.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"The type of y can be determined using the typeof function","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> typeof(y)\nFloat64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Note that the resulting type of y is Float64 even though the result can be represented as an integer. The reason is that we divide two integers","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> typeof((x + 2)^2 - 4)\nInt64\n\njulia> typeof((x - 2)^(p - 2))\nInt64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Because this operation generally does not result in an integer, dividing two integers always returns a floating-point number. If we want to get an integer, we can use the integer division operator ÷ (can be typed as \\div<tab>)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> y_int = ((x + 2)^2 - 4)÷(x - 2)^(p - 2)\n4\n\njulia> typeof(y_int)\nInt64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></details>","category":"page"},{"location":"lecture_01/operators/#Promotion-system","page":"Elementary Functions","title":"Promotion system","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"As said in the section about variables, there are many numeric types in Julia. To ensure that the correct type is always used, Julia has a promotion system that converts input values of mixed types to a type that can correctly represent all values. The promotion of mixed type variables can be done manually using the promote function. As an example, we can mention the promotion of multiple numeric types","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 1.0 # Float64\n1.0\n\njulia> y = 2 # Int64\n2\n\njulia> xp, yp = promote(x, y)\n(1.0, 2.0)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In this case, the resulting type of variables xp and yp is Float64 as can be checked using the typeof function","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> typeof(xp)\nFloat64\n\njulia> typeof(yp)\nFloat64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Even though strictly, not all Int64 values can be represented exactly as Float64 values. The promotion system generally tries to return a type that approximates most values of either input type without excessively widening.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Note that the promote function will accept any number of input arguments","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> promote(1, 2f0, true, 4.5, Int32(1))\n(1.0, 2.0, 1.0, 4.5, 1.0)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"The resulting type of promotion can be determined by the promotion_type function. This function is similar to the promote function and will accept any number of input arguments, but the inputs have to be types and not values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> promote_type(Float64, Int64, Bool, Int32)\nFloat64","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Although this may seem complicated, type promotion is done automatically in most cases, and the user does not have to worry about it. To demonstrate the promotion system in practice, consider the following example: we sum the value of type Int64 with the value of type Float32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 1 # Int64\n1\n\njulia> y = 2f0 # Float32\n2.0f0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Since the \"smallest\" type that can represent both values correctly is Float32, the result is of type Float32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> z = x + y\n3.0f0\n\njulia> typeof(z)\nFloat32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"What type can represent the following values correctly","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"x = 1\ny = 2f0\nz = true\nw = Int32(1)","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"To get the correct promotion type, we can use a combination of the promote and typeof function","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> xp, yp, zp, wp = promote(x, y, z, w)\n(1.0f0, 2.0f0, 1.0f0, 1.0f0)\n\njulia> typeof(xp)\nFloat32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"of  the promote_type and typeof function","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> promote_type(typeof(x), typeof(y), typeof(z), typeof(w))\nFloat32","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></details>","category":"page"},{"location":"lecture_01/operators/#Updating-operators","page":"Elementary Functions","title":"Updating operators","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Every binary arithmetic operator also has an updating version that assigns the operation's result back into its left operand. The updating version of the binary operator is formed by placing a = symbol immediately after the operator. For example, writing x += 3 is equivalent to writing x = x + 3","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 1\n1\n\njulia> x += 3 # x = x + 3\n4\n\njulia> x *= 4 # x = x * 4\n16\n\njulia> x /= 2 # x = x / 2\n8.0\n\njulia> x \\= 16 # x = x \\ 16 = 16 / x\n2.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Compute the value of y given by the following expression","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"y = frac(x + 4)^frac32(x + 1)^p - 1","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"where x = 5 and p = 3. Then multiply the result by 8, add 3, divide by 3, and subtract 1. What are all the intermediate results and the final result?","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"First, we calculate the value of y","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 5;\n\njulia> p = 3;\n\njulia> y = (x + 4)^(3/2)/(x + 1)^(p - 1)\n0.75","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Then we can use the update operators to get all the intermediate results as well as the final result","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> y *= 8\n6.0\n\njulia> y += 3\n9.0\n\njulia> y /= 3\n3.0\n\njulia> y -= 1\n2.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></details>","category":"page"},{"location":"lecture_01/operators/#Numeric-comparison","page":"Elementary Functions","title":"Numeric comparison","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In addition to arithmetic and updating operators, basic comparison operators are also defined in Julia's standard libraries.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Operator Name\n== equality\n!=, ≠ inequality\n< less than\n<=, ≤ less than or equal to\n> greater than\n>=, ≥ greater than or equal to\n& bitwise and\n| bitwise or","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"All these operators always return a boolean value (true or false), as can be seen in the following example","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> 1 == 1\ntrue\n\njulia> 1 == 1.0\ntrue\n\njulia> -1 <= 1\ntrue\n\njulia> -1 ≥ 1\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In most programming languages, comparison operators are strictly binary, i.e., they can be used to compare only two values at a time. As an example, we can use a comparison of three numbers in Matlab","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":">> 3 > 2 > 1\n\nans =\n\n  logical\n\n   0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Even though the condition holds, the result is false (logical 0). The correct way to write such a condition in Matlab is as follows","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":">> 3 > 2 & 2 > 1\n\nans =\n\n  logical\n\n   1","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In Julia (and Python, for example), both ways of writing conditions are correct and lead to the same result","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> 3 > 2 > 1\ntrue\n\njulia> 3 > 2 & 2 > 1\ntrue","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In fact, comparison operators can be arbitrarily chained as in the following example","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> 1 < 2 <= 2 < 3 == 3 > 2 >= 1 == 1 < 3 != 5\ntrue","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"In general, the user should always try to write code that is easy to read. So writing expressions as in the example above is possible, however, the user always should consider if it is necessary.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Comparison of special values such as NaN can lead to unexpected behavior","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> NaN == NaN\nfalse\n\njulia> NaN != NaN\ntrue\n\njulia> NaN < NaN\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"To avoid unexpected result, Julia provides additional functions to compare numbers for special values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Function Tests if\nisequal(x, y) x and y are identical\nisfinite(x) x is a finite number\nisinf(x) x is infinite\nisnan(x) x is not a number","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Function isequal considers NaNs equal to each other","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> isequal(NaN, NaN)\ntrue\n\njulia> !isequal(NaN, NaN)\nfalse","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Note that we use the following operator ! to negate the output of the isequal function in the example above. This operator is called boolean not and can be used to negate boolean values","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> !true\nfalse\n\njulia> !false\ntrue","category":"page"},{"location":"lecture_01/operators/#Rounding-functions","page":"Elementary Functions","title":"Rounding functions","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Julia provides several functions for rounding numbers, as can be seen in the following table","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Function Description\nround(x) round x to the nearest integer\nfloor(x) round x towards -Inf\nceil(x) round x towards +Inf\ntrunc(x) round x towards zero","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"All these functions can be used without a specified output type. In such a case, the output will have the same type as the input variable","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 3141.5926\n3141.5926\n\njulia> round(x)\n3142.0\n\njulia> floor(x)\n3141.0\n\njulia> ceil(x)\n3142.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"However, in many cases, it makes sense to convert the rounded value to a different type. For example, if the rounded value can be represented as an integer, it makes sense to convert the rounded value to an integer. The output type (only subtypes of Integer with exception of Bool) can be passed as the first argument to all rounding functions from the table above","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> round(Int64, x)\n3142\n\njulia> floor(Int32, x)\n3141\n\njulia> ceil(Int16, x)\n3142","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"All rounding functions also support additional keyword arguments:","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"If the digits keyword argument is provided, it rounds to the specified number of digits after the decimal place (or before if negative) in the base specified by the base keyword argument.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> round(x; digits = 3)\n3141.593","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"If the sigdigits keyword argument is provided, it rounds to the specified number of significant digits in the base specified by the base keyword argument.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> round(x; sigdigits = 3)\n3140.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Use rounding functions to solve the following tasks:","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Round 1252.1518 to the nearest larger integer and convert the resulting value to Int64.\nRound 1252.1518 to the nearest smaller integer and convert the resulting value to Int16.\nRound 1252.1518 to 2 digits after the decimal point.\nRound 1252.1518 to 3 significant digits.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"The ceil function rounds numbers to the nearest larger value, and since we want the result to be of type Int64, we have to pass this type as a first argument","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x = 1252.1518\n1252.1518\n\njulia> ceil(Int64, x)\n1253","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Similarly, the floor function rounds numbers to the nearest smaller value","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> floor(Int16, x)\n1252","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"The number of digits after the decimal point can be controlled using the digits keyword","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> round(x; digits = 2)\n1252.15","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"and the number of significant digits using the sigdigits keyword","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> round(x; sigdigits = 3)\n1250.0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></details>","category":"page"},{"location":"lecture_01/operators/#Numerical-Conversions","page":"Elementary Functions","title":"Numerical Conversions","text":"","category":"section"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"As shown in the previous section, the numerical conversion can be done using rounding functions with a specified type of output variable. However, it only works for converting floating-point numbers to integers. Julia also provides a more general way how to perform a conversion between different (not only numerical): the notation T(x) or convert(T,x) converts x to a value of type T.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"If T is a floating-point type, the result is the nearest representable value, which could be positive or negative infinity","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> convert(Float32, 1.234)\n1.234f0\n\njulia> Float32(1.234)\n1.234f0","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"If T is an integer type, an InexactError is raised if x is not representable by T","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> convert(Int64, 1.0)\n1\n\njulia> Int64(1.0)\n1\n\njulia> convert(Int64, 1.234)\nERROR: InexactError: Int64(1.234)\n[...]\n\njulia> Int64(1.234)\nERROR: InexactError: Int64(1.234)\n[...]","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Conversion to other types works in a similar way.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Use the proper numeric conversion to get the correct result (not approximate) of summing the following two numbers","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"x = 1//3\ny = 0.5","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Hint: rational numbers can be summed without approximation.","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"Firstly, we can try just to sum the given numbers","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x + y\n0.8333333333333333","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"The result of such an operation is a floating-point number. However, in this specific case, we have a rational number and floating-point number that can also be represented as a rational number. So the exact result can be obtained by converting the variable y to a rational number","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"julia> x + Rational(y)\n5//6","category":"page"},{"location":"lecture_01/operators/","page":"Elementary Functions","title":"Elementary Functions","text":"</p></details>","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"using Plots","category":"page"},{"location":"lecture_07/theory/#Introduction-to-continuous-optimization","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"","category":"section"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Optimization problems optimize (minimize or maximize) a given function on a given set. There are many applications:","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Maximize profit under market forecasts.\nGiven a set of points, find a visiting order which minimizes the distance. This includes various tasks ranging from delivery services to snow ploughing. \nMake a prediction based on known data. Specific examples are whether a client gets a loan, or whether an autonomous vehicle sees a pedestrian. Almost all tasks in machine learning minimize the difference between a prediction and a label.\nFind the optimal shape of a machine so that a criterion is maximized. This includes designing planes with minimal drag, or optimizing engines to maximize power under a reasonable oil consumption. ","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"These applications are very different from each other. They differ in their assumptions about the world, or in the form in which they are written and subsequently solved.","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Profit maximization will need to model future uncertainty. The formulation will probably contain expectations and chance constraints. The variables will be usually continuous. \nFinding the minimal way is often reformulated as finding the shortest way in a graph. Problems like this operate typically with only binary variables and with no uncertainty.  \nMachine learning requires loads of data and usually ignores any physical models. Due to the abundance of data, the evaluation of the objective function is lengthy, and special algorithms for speed-ups need to be used.\nTopology optimization is usually based on complicated physical models. Since these are in a black-box form, additional information such as gradient is often not available. Moreover, conflicting criteria (such as speed and consumption) need to be considered. ","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"This short analysis implies that there is not a single \"optimization topic\". The theory of optimization contains many different subfields. In the following four lectures, we will study the field of continuous optimization, which assumes that all functions are (sub)differentiable, and all variables are continuous. This includes most machine learning applications, to which we dedicate three lectures.","category":"page"},{"location":"lecture_07/theory/#Problem-definition","page":"Introduction to continuous optimization","title":"Problem definition","text":"","category":"section"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"The goal of an optimization problem is to minimize or maximize a function f over a set X:","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    beginaligned\n    textminimizeqquad f(x) \n    textsubject toqquad xin X\n    endaligned","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Should we consider both minimization and maximization problems? No. Because","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    textmaximizeqquad f(x)","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"is equivalent to ","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"    -textminimizeqquad -f(x)","category":"page"},{"location":"lecture_07/theory/","page":"Introduction to continuous optimization","title":"Introduction to continuous optimization","text":"Therefore, it suffices to consider minimization problems.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nusing StatsPlots\nusing RDatasets\nusing Statistics\nusing LinearAlgebra\n\nfunction log_reg(X, y, w; max_iter=100)\n    X_mult = [row*row' for row in eachrow(X)]\n    for i in 1:max_iter\n        y_hat = 1 ./(1 .+exp.(-X*w))\n        grad = X'*(y_hat.-y) / size(X,1)\n        hess = y_hat.*(1 .-y_hat).*X_mult |> mean\n        w -= hess \\ grad\n    end\n    return w\nend\n\niris = dataset(\"datasets\", \"iris\")\niris_reduced = iris[iris.Species .!= \"setosa\", :]\n\nX = hcat(Matrix(iris_reduced[:, 3:4]), ones(size(iris_reduced,1)))\ny = iris_reduced.Species .== \"virginica\"\n\nw = log_reg(X, y, zeros(size(X,2)))","category":"page"},{"location":"lecture_08/exercises/#Exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"homework-body\">\n<header class = \"homework-header\">Homework: Data normalization</header><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Data are often normalized. Each feature subtracts its mean and then divides the result by its standard deviation. The normalized features have zero mean and unit standard deviation. This may help in several cases:","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"When each feature has a different order of magnitude (such as millimetres and kilometres). Then the gradient would ignore the feature with the smaller values.\nWhen problems such as vanishing gradients are present (we will elaborate on this in Exercise 4).","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Write function normalize which takes as an input a dataset and normalizes it. Then train the same classifier as in the lecture \"logistic regression\". Use the original and normalized dataset. Which differences did you observe when","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"the logistic regression is optimized via gradient descent?\nthe logistic regression is optimized via Newton's method?","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Do you have any intuition as to why?","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Write a short report (in Latex) summarizing your findings.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 1</header><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"The logistic regression on the iris dataset failed in 6 out of 100 samples. But the visualization shows the failure only in 5 cases. How is it possible?","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"We use the same code as before and find indices of the misclassified samples","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"y_hat = 1 ./(1 .+exp.(-X*w))\npred = y_hat .>= 0.5\nii = findall(pred .!= y)\n\nnothing # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Then we show the values of the data and labels at these indices. We sort the rows by sortslices. You cannot use sort as it would not sort rows, but it would perform the sorting operator on every column independently.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"aux = hcat(X[ii,:], y[ii])\nsortslices(aux, dims=1)","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"A short look at the image shows that the point (48 18) is misclassified but the image shows it correctly. Let us show all such points","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"ii = findall((X[:,1].==4.8) .& (X[:,2].==1.8))\naux = hcat(X[ii,:], y[ii])","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"As we can see, there are three samples with the same data. Two of them have label 1 and one label 0. Since the incorrectly classified sample was redrawn, it was not possible to see it.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 2: Why not use sigmoid</header><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Show that Newton's method fails when started from the vector (123). Can you guess why it happened? What are the consequences for optimization? Is gradient descent going to suffer from the same problems?","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"First, we run the logistic regression as before, only with a different starting point","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"log_reg(X, y, [1;2;3])","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"This resulted in NaNs. When something fails, it may be a good idea to run a step-by-step analysis. In this case, we will run the first iteration of Newton's method","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"w = [1;2;3];\nX_mult = [row*row' for row in eachrow(X)];\ny_hat = 1 ./(1 .+exp.(-X*w))\ngrad = X'*(y_hat.-y) / size(X,1)\nhess = y_hat.*(1 .-y_hat).*X_mult |> mean\nw -= hess \\ grad","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Starting from the bottom, we can see that even though we started with relatively small w, the next iteration is four degrees of magnitude larger. This happened because the Hessian hess is much smaller than the gradient grad. This indicates that there is some kind of numerical instability. The prediction y_hat should lie in the interval 01 but it seems that it is almost always close to 1. Let us verify this by showing the extrema of y_hat","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"extrema(y_hat)","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"They are indeed too large.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Now we explain the reason. We know that the prediction equals to","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"hat y_i = sigma(w^top x_i)","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"where sigma is the sigmoid function. Since the mimimum from w^top x_i","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"minimum(X*[1;2;3])","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"is large, all w^top x_i are large. But plotting the sigmoid funtion","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"σ(z) = 1/(1+exp(-z))\nxs = -10:0.01:10\nplot(xs, σ, label=\"\", ylabel=\"Sigmoid function\")\n\nsavefig(\"sigmoid.svg\") # hide","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"it is clear that all w^top x_i hit the part of the sigmoid which is flat. This means that the derivative is almost zero and the Hessian is \"even smaller\" zero. Then the ratio of the gradient and Hessian is huge as we observed above.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"The gradient descent will probably run into the same difficulty. Since the gradient will be too small, it will take a very large number of iterations to escape the flat region of the sigmoid. This is a known problem of the sigmoid function. It is also the reason why it was replaced in neural networks by other activation functions.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 3 (theory)</header><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Show the details for the derivation of the loss function of the logistic regression.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Since hat y equals the probability of predicting 1, we have","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"hat y = frac11+e^-w^top x","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Then the cross-entropy loss reduces to","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\noperatornameloss(yhat y) = - ylog hat y - (1-y)log(1-hat y) \n= ylog(1+e^-w^top x) - (1-y)log(e^-w^top x) + (1-y)log(1+e^-w^top x) \n= log(1+e^-w^top x) + (1-y)w^top x\nendaligned","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Then it remains to sum this term over all samples.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 4 (theory)</header><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"Show that if the Newton's method converged for the logistic regression, then it found a point globally minimizing the logistic loss. ","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"We derived that the Hessian of the objective function for logistic regression is","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"nabla^2 L(w) = frac 1n sum_i=1^nhat y_i(1-hat y_i)x_i x_i^top","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"For any vector a, we have","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"a^top x_i x_i^top a = (x_i^top a)^top (x_i^top a) = x_i^top a^2 ge 0","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"which implies that x_i x_i^top is a positive semidefinite matrix (it is known as rank-1 matrix as its rank is always 1 if x_i is a non-zero vector). Since y_i(1-hat y_i)ge 0, it follows that nabla^2 L(w) is a positive semidefinite matrix. If a Hessian of a function is positive semidefinite everywhere, the function is immediately convex. Since the Newton's method found a stationary point, this points is a global minimum.","category":"page"},{"location":"lecture_08/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_01/variables/#Variables","page":"Variables","title":"Variables","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In Julia (as in other languages), a variable is a name that refers to a value. Contrary to languages like C or C++ and similar to Python or MATLAB, variables can be created without the type specification, i.e., a variable can be declared simply by using the = sign","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 2\n2","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable is inferred automatically and can be checked using the typeof function","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> typeof(x)\nInt64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In this case, the variable x is of type Int64, which is a type that represents signed integers. Since x is a number, we can apply basic mathematical operations to it","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> y = x + 1\n3\n\njulia> typeof(y)\nInt64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable x is preserved because the sum of two integers is also an integer. We can also reuse the name of the variable and assign a new value to it","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 4\n4","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The type of the variable x is still Int64, but it is also possible to assign a value of a different type to x","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 3.1415\n3.1415\n\njulia> typeof(x)\nFloat64","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In this case, the variable x is of type Float64, which is a type that represents floating-point numbers.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Create the following three variables:","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Variable x with value 1.234.\nVariable y with value 1//2.\nVariable z with value x + y*im.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"What are the types of these three variables?","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"All three variables can be declared simply by assigning the value to the given variable name","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> x = 1.234\n1.234\n\njulia> y = 1//2\n1//2\n\njulia> z = x + y*im\n1.234 + 0.5im","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"and types can be checked using the typeof function","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> typeof(x)\nFloat64\n\njulia> typeof(y)\nRational{Int64}\n\njulia> typeof(z)\nComplex{Float64}","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"</p></details>","category":"page"},{"location":"lecture_01/variables/#Primitive-numeric-types","page":"Variables","title":"Primitive numeric types","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"There is a vast amount of types in Julia. In fact, every object in Julia has its type. As an example, we can mention the hierarchy of primitive numeric types","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"(Image: )","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"All types shown in blue are abstract types, i.e., it is impossible to create an instance of such a type. Abstract types are useful for creating logical type hierarchy. Types highlighted in green are concrete types. In many cases, it is useful to have the choice to choose which type to use. As an example, we can see floating-point numbers. There are four concrete types for floating-point numbers. If we want to maximize the precision of some calculations, we can use BigFloat. Using BigFloat increases precision but also increases computational time. On the other hand, if we want to speed up the code, we can use the type with lower precision, such as Float32. However, in most cases, the user does not have to take care of types and use the default type.","category":"page"},{"location":"lecture_01/variables/#Variable-Names","page":"Variables","title":"Variable Names","text":"","category":"section"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Julia provides an extremely flexible system for naming variables. Variable names are case-sensitive and have no semantic meaning, i.e., the language will not treat variables differently based on their names.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> I_am_float = 3.1415\n3.1415\n\njulia> CALL_ME_RATIONAL = 1//3\n1//3\n\njulia> MyString = \"MyVariable\"\n\"MyVariable\"","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Here I_am_float contains a floating-point number, CALL_ME_RATIONAL is a rational number (can be used if the exact accuracy is needed) and MyString contains a string (a piece of text).","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Moreover, in the Julia REPL and several other Julia editing environments, it is possible to use many Unicode (UTF-8 encoding) math symbols by typing the backslashed LaTeX symbol name followed by tab. It is also possible to use many other non-math symbols. For example, the variable name δ can be entered by typing \\delta<tab>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> δ = 1\n1","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"or pizza symbol 🍕 can be entered by typing \\:pizza:<tab>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> 🍕 = \"It's time for pizza!!!\"\n\"It's time for pizza!!!\"","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The list of all Unicode characters that can be entered via tab completion of LaTeX-like abbreviations in the Julia REPL is provided in the official manual.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Julia will even let the user redefine built-in constants and functions if needed (although this is not recommended to avoid potential confusions)","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> π = 2\n2\n\njulia> π\n2","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"However, if the user tries to use a variable name that corresponds to a built-in constant or function already in use, Julia will throw an error","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> π\nπ = 3.1415926535897...\n\njulia> π = 2\nERROR: cannot assign a value to variable MathConstants.π from module Main\n[...]","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"The only explicitly disallowed names for variables are the names of built-in reserved keywords listed in the following table","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Reserved words:     \nbaremodule begin break catch const continue\ndo else elseif end export false\nfinally for function global if import\nlet local macro module quote return\nstruct true try using while ","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"julia> struct = 3\nERROR: syntax: unexpected \"=\"\n[...]","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"In many cases, it is beneficial to have the choice to use special symbols as variable names. It may increase the code's readability, especially when the user needs to implement some mathematical algorithms, where it is common to use the greek alphabet. However, excessive use of special symbols can confuse.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"<div class = \"info-body\">\n<header class = \"info-header\">Stylistic Conventions:</header><p>","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"While there are almost no restrictions on valid names in Julia, it is useful to adopt the following conventions:","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"Names of variables are in lower case.\nWord separation can be indicated by underscores (_), but the use of underscores is discouraged unless the name would be hard to read otherwise.\nDo not overuse special symbols, i.e., avoid using symbols like 🍕 as variable names.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"For more information about stylistic conventions, see the official style guide or Blue Style.","category":"page"},{"location":"lecture_01/variables/","page":"Variables","title":"Variables","text":"</p></div>","category":"page"},{"location":"lecture_02/conditions/#if-elseif-else-statement","page":"Conditional Evaluation","title":"if-elseif-else statement","text":"","category":"section"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In many cases, we have to decide what to do, based on some conditions. Julia supports the standard if-elseif-else syntax, which allows you to decide which part of the code will be evaluated depending on the logical expression's value. For example, the following function compares two numerical values","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function compare(x, y)\n    if x < y\n        println(\"x is less than y\")\n    elseif x > y\n        println(\"x is greater than y\")\n    else\n        println(\"x is equal to y\")\n    end\n    return\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"If the expression x < y is true, the functions prints \"x is less than y\", otherwise, the expression x > y is evaluated, and if it is true, the functions prints \"x is greater than y\". If neither expression is true, the function prints \"x is equal to y\".","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> compare(1, 2.3)\nx is less than y\n\njulia> compare(4.7, 2.3)\nx is greater than y\n\njulia> compare(2.3, 2.3)\nx is equal to y","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"<div class = \"info-body\">\n<header class = \"info-header\">Function declaration:</header><p>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"So far, we did not mention how to define functions. However, the above example should suffice to show the basic syntax for defining functions. Note that the return keyword is used to specify the output of the function. In this case, the function returns nothing since we only want to compare numbers. If we want to define a function that returns one or more variables, then the following syntax is used","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"return x, y, z","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"where x, y, and z are some variables. See the third lecture for more information about functions.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"</p></div>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"The elseif and else keywords are optional, and it is possible to use as many elseif blocks as wanted","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> x, y = 2, 1;\n\njulia> if x < y\n           println(\"x is less than y\")\n       elseif x > y\n           println(\"x is greater than y\")\n       end\nx is greater than y\n\njulia> if x < y\n           println(\"x is less than y\")\n       end","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"The condition expressions in the if-elseif-else construct are evaluated until the first one evaluates to true, after which the associated block is evaluated, and no further condition expressions or blocks are evaluated.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In contrast to languages like Python or Matlab, the logical expression in the if-elseif-else statement must always return a boolean value, otherwise, an error will occur","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> if 1\n           println(\"Hello\")\n       end\nERROR: TypeError: non-boolean (Int64) used in boolean context","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"The if blocks do not introduce a local scope, i.e., it is possible to introduce a new variable inside the if block and used this variable outside the block","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> x, y = 2, 1;\n\njulia> if x < y\n           z = y\n       else\n           z = x\n       end\n2\n\njulia> z\n2","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"However, it is necessary to ensure that the variable will always be declared in all cases in such cases.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function compare(x, y)\n    if x < y\n        z = y\n    elseif x > y\n        z = x\n    end\n    return z\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"For example, the function defined above will work only for numbers, that are not equal","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> compare(1, 2.3)\n2.3\n\njulia> compare(4.7, 2.3)\n4.7\n\njulia> compare(2.3, 2.3)\nERROR: UndefVarError: z not defined","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Another a little bit unintuitive thing is that if blocks return values. This value is given by the last expression evaluated in the if block. It is possible to assign this value to a variable as follows","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function compare(x, y)\n    z = if x < y\n        y\n    else\n        x\n    end\n    return z\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In this case, the z variable is equal to y if x < y is true and to x otherwise","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> compare(1, 2.3)\n2.3\n\njulia> compare(4.7, 2.3)\n4.7\n\njulia> compare(2.3, 2.3)\n2.3","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Write a simple fact function that computes the factorial of the given number. Use the following function declaration","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function fact(n)\n    # some code\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Make sure that the input argument is a non-negative integer. For negative input arguments or arguments that can not be represented as an integer, the function should throw an error.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Hint: use recursion, the isinteger function and the error function.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"We will split the solution into three cases:","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"the given number n is smaller than zero or is not an integer.\nthe given integer n is equal to zero, then the function returns 1.\nthe given integer n is larger than zero, then we use recursion.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function fact(n)\n    if n < 0 | !isinteger(n)\n        error(\"argument must be non-negative integer\")\n    elseif n == 0\n        1\n    else\n        n * fact(n - 1)\n    end\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Since the if block returns a value from the latest evaluated expression, it is possible to use it after the return keyword to define a function's output.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> fact(4)\n24\n\njulia> fact(0)\n1\n\njulia> fact(-5)\nERROR: argument must be non-negative integer\n\njulia> fact(1.4)\nERROR: argument must be non-negative integer","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"</p></details>","category":"page"},{"location":"lecture_02/conditions/#Ternary-operator","page":"Conditional Evaluation","title":"Ternary operator","text":"","category":"section"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"The ternary operator ? is closely related to the if-else statement and can instead be used to decide between two options based on a single condition. The syntax is following","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"a ? b : c","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"This expression can be read as follows: if a is true, evaluate b otherwise evaluate c. Note that white spaces around ? and : are mandatory.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> x, y = 2, 1;\n\njulia> println(x < y ? \"x is less than y\" : \"x is greater than or equal to y\")\nx is greater than or equal to y","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In this case, there are two possibilities:","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"if x < y is true, then the string \"x is less than y\" is returned,\nif x < y is false, then the string \"x is greater than or equal to y\" is returned.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Since we wrapped the whole expression into the println function, the ternary operator's output is printed in the REPL.","category":"page"},{"location":"lecture_02/conditions/#Short-circuit-evaluation","page":"Conditional Evaluation","title":"Short-circuit evaluation","text":"","category":"section"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Julia provides a so-called Short-circuit evaluation that is similar to the conditional evaluation. The behavior is found in most imperative programming languages having the && and || boolean operators. In a series of boolean expressions connected by these operators, only the minimum number of expressions are evaluated as are necessary to determine the final boolean value of the entire chain:","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In the expression a && b, the subexpression b is only evaluated if a evaluates to true.\nIn the expression a || b, the subexpression b is only evaluated if a evaluates to false.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Both && and || associate to the right, but && has higher precedence than || does.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"To investigate this behavior, let's define the following two functions","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"t(x) = (println(x); true)\nf(x) = (println(x); false)","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"The t function prints x and returns true. Similarly, the f function prints x and returns false. Using these two functions, we can easily find out which expressions are evaluated when using short-circuit evaluation.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> t(1) && println(2) # both expressions are evaluated\n1\n2\n\njulia> f(1) && println(2) # only the first expression is evaluated\n1\nfalse\n\njulia> t(1) || println(2) # only the first expression is evaluated\n1\ntrue\n\njulia> f(1) || println(2) # both expressions are evaluated\n1\n2","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"In the same way, we can examine the behavior of various combinations of && and || operators","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> t(1) && t(2) || println(3) # the first two expressions are evaluated\n1\n2\ntrue\n\njulia> f(1) && t(2) || println(3) # the first and the last expressions are evaluated\n1\n3\n\njulia> f(1) && f(2) || println(3) # the first and the last expressions are evaluated\n1\n3\n\njulia> t(1) && f(2) || println(3) # all expressions are evaluated\n1\n2\n3\n\njulia> t(1) || t(2) && println(3) # the first expression is evaluated\n1\ntrue\n\njulia> f(1) || t(2) && println(3) # all expressions are evaluated\n1\n2\n3\n\njulia> f(1) || f(2) && println(3) # the first two expressions are evaluated\n1\n2\nfalse\n\njulia> t(1) || f(2) && println(3) # the first expression is evaluated\n1\ntrue","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Rewrite the factorial function from the exercises in the first section. Use short-circuit evaluation to check if the given number is a non-negative integer and ternary operator for recursion.","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Since we want to check if the input number is a non-negative integer, we need to check two conditions. It can be done separately using short-circuit evaluation","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function fact(n)\n    isinteger(n) || error(\"argument must be non-negative integer\")\n    n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"However, it can be even simplified, if we combine && and || operators as follows","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"function fact(n)\n    isinteger(n) && n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"Since && has higher precedence than ||, the first expression that is evaluated is isinteger(n) && n >= 0. The error is thrown only if this condition does not hold. We can easily check that this function works the same as the fact function from the first section","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"julia> fact(4)\n24\n\njulia> fact(0)\n1\n\njulia> fact(-5)\nERROR: argument must be non-negative integer\n\njulia> fact(1.4)\nERROR: argument must be non-negative integer","category":"page"},{"location":"lecture_02/conditions/","page":"Conditional Evaluation","title":"Conditional Evaluation","text":"</p></details>","category":"page"},{"location":"lecture_03/scope/#Scope-of-Variables","page":"Scope of Variables","title":"Scope of Variables","text":"","category":"section"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"The scope of a variable is the region of a code where a variable is visible. In Julia, there are two main types of scopes: global and local. A global scope can contain multiple local scope blocks, and moreover, local scope blocks can be nested. There is also a distinction in Julia between constructs which introduce a hard scope and those which only introduce a soft scope, which affects whether shadowing a global variable by the same name is allowed or not.","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"The following table shows constructs that introduce scope blocks","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Construct Scope type Allowed within local\nmodule, baremodule global ✗\nstruct local (soft) ✗\nmacro local (hard) ✗\nfor, while, try local (soft) ✔\nlet, functions, comprehensions, generators local (hard) ✔","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"In the table above, there are several constructs that we have not introduced yet. Some of these constructions will be discussed later in the course (modules and structures). The rest is described in the official documentation.","category":"page"},{"location":"lecture_03/scope/#Local-scope","page":"Scope of Variables","title":"Local scope","text":"","category":"section"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"A function declaration introduces a new (hard) local scope. It means that all variables defined inside a function body can be accessed and modified inside the function body. However, it is not possible to access these variables outside the function, i.e., all these variables are local","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> function f()\n           z = 42\n           return\n       end\nf (generic function with 1 method)\n\njulia> f()\n\njulia> z\nERROR: UndefVarError: z not defined","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Thanks to this property, we can use the names most suitable for our variables (x, y, z, etc.) without the risk of clashing with the declaration of other functions. It is possible to specify a global variable inside a function using the global keyword","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> function f()\n           global z = 42\n           return\n       end\nf (generic function with 1 method)\n\njulia> f()\n\njulia> z\n42","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"However, this is not recommended.  If we need a variable defined inside a function, we should probably return that variable as an output of the function","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> function f()\n           z = 42\n           return z\n       end\nf (generic function with 1 method)\n\njulia> z = f()\n42\n\njulia> z\n42","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"In the example above, the z variable in the function is local, and the z variable outside of the function is global. These two variables are not the same.","category":"page"},{"location":"lecture_03/scope/#Global-scope","page":"Scope of Variables","title":"Global scope","text":"","category":"section"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Each module introduces a new global scope, separate from the global scope of all other modules. Note that the interactive prompt (aka REPL) is in the global scope of the module Main","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> module A\n           a = 1 # a global in A's scope\n           b = 2 # b global in A's scope\n       end\nA\n\njulia> a # errors as Main's global scope is separate from A's\nERROR: UndefVarError: a not defined","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Modules can introduce variables of other modules into their scope through the using (or import)  keyword  statements or qualified access using the dot-notation","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> using .A: b # make variable b from module A available\n\njulia> A.a\n1\n\njulia> b\n2","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Note that while variable bindings can be read externally, they can only be changed within the module to which they belong","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> b = 4\nERROR: cannot assign a value to variable A.b from module Main","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"Note that global scope variables can be accessed anywhere inside the global scope, even in the local scopes defined in that global scope. In the following example, we define a variable c in the Main's global scope, and then we define a function foo (that introduces a new local scope inside the Main's global scope), and inside this function, we use the variable c","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"julia> c = 10\n10\n\njulia> foo(x) = x + c\nfoo (generic function with 1 method)\n\njulia> foo(1)\n11","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"However, it is not recommended to use global variables in this way. The reason is that global variables can change their type and value at any time, and therefore they cannot be properly optimized by the compiler. We can see the performance drop in a simple test","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"x = rand(10);\ny = rand(10);\nf_global() = x .+ y\nf_local(x, y) = x .+ y\n\nhcat(f_global(), f_local(x, y))","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"In the example above, we defined two functions that do the same thing. The first function has no arguments and returns a sum of two global variables, x and y. The second function also returns a sum of variables x and y. However, in this case, these variables are local since they are introduced as the inputs to the function. If we use the @time macro, we can measure the time needed to call these two functions","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"@time f_global();\n@time f_local(x, y);","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"We can see that the second function is faster and also needs fewer allocations. The reason is that when we call the f_local function for the first time, the function is optimized for the given arguments. Each time a function is called for the first time with new types of arguments, it is compiled. This can be seen in the following example, where the first call is slower due to the compilation","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"a, b = 1:10, 11:20;\n\n@time f_local(a, b);\n@time f_local(a, b);","category":"page"},{"location":"lecture_03/scope/","page":"Scope of Variables","title":"Scope of Variables","text":"On the other hand, the f_global function cannot be optimized because it contains two global variables, and these two variables can change at any time.","category":"page"},{"location":"lecture_02/loops/#for-and-while-loop","page":"Loops and Iterators","title":"for and while loop","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"As in other languages, Julia supports two basic constructs for repeated evaluation: the while andfor loops. Loops are useful when we want to repeat some computation multiple times with different values. A typical example is performing operations on array elements.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"The while loop evaluates the condition expression, and as long it remains true, keeps also evaluating the body of the while loop. If the condition expression is false when the while loop is first reached, the body is never evaluated","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> i = 1\n1\n\njulia> while i <= 5\n           @show i\n           i += 1\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"The @show macro used in the example above takes an expression and prints the expression and its result. It can also be used to print multiple variables at once","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> a, b, c = 1, \"hello\", :world;\n\njulia> @show (a, b, c);\n(a, b, c) = (1, \"hello\", :world)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"The for loops can be created similarly as in Matlab. In the following example, we iterate over the range of integers from 1 to 10, and in each iteration, we use the @show macro to print the current value of the variable i","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:5\n           @show i\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"info-body\">\n<header class = \"info-header\">An alternative notation for <code>for</code> loops</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"There are two alternative notations for the for loop. It is possible to use  the = or ∈ symbol instead of the in keyword","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i = 1:5\n           @show i\n       end\ni = 1\ni = 2\ni = 3\ni = 4\ni = 5","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"However, it is better to use the in keyword to improve the code's readability or be consistent and use the same keyword in all for loops.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"In Julia (similarly to Python), it is possible to loop not only over ranges but over any iterable object. For example, it is possible to loop over arrays or tuples. This possibility is advantageous because it allows us to get elements of iterable objects directly without having to use indexes","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> persons = [\"Alice\", \"Bob\", \"Carla\", \"Daniel\"];\n\njulia> for name in persons\n           println(\"Hi, my name is $name.\")\n       end\nHi, my name is Alice.\nHi, my name is Bob.\nHi, my name is Carla.\nHi, my name is Daniel.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"It is also possible to iterate over other data structures. For example, we can iterate over dictionaries. In such a case, in each iteration, we get a tuple of the key and corresponding value","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> persons = Dict(\"Alice\" => 10, \"Bob\" => 23, \"Carla\" => 14, \"Daniel\" => 34);\n\njulia> for (name, age) in persons\n           println(\"Hi, my name is $name and I am $age old.\")\n       end\nHi, my name is Carla and I am 14 old.\nHi, my name is Alice and I am 10 old.\nHi, my name is Daniel and I am 34 old.\nHi, my name is Bob and I am 23 old.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Use for or while loop to print integers from 1 to 100.  Use conditions to print only the integers divisible by 3 and 7 simultaneously.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Hint: use the mod function.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"The first thing that we have to do is to check if the given integer is divisible by 3 and 7 simultaneously. It can be done using the mod function in combination with the if-else statement as follows","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> i = 21\n21\n\njulia> if mod(i, 3) == 0 && mod(i, 7) == 0\n           println(\"$(i) is divisible by 3 and 7\")\n       end\n21 is divisible by 3 and 7","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"or using the short-circuit evaluation","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> i = 21\n21\n\njulia> mod(i, 3) == mod(i, 7) == 0 && println(\"$(i) is divisible by 3 and 7\")\n21 is divisible by 3 and 7","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"When we know how to check the given conditions, it is easy to write a for loop to iterate over integers from 1 to 100 as follows","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:100\n           mod(i, 3) == mod(i, 7) == 0 && @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A while loop can be created in a similar way","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> i = 0;\n\njulia> while i < 100\n           i += 1\n           mod(i, 3) == mod(i, 7) == 0 && @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"lecture_02/loops/#break-and-continue","page":"Loops and Iterators","title":"break and continue","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"It is sometimes useful to stop the for loop based on some condition. It can be done using the break keyword. In the following example, the loop iterates over the range from 1 to 10 and breaks when i == 4, i.e., only the first four numbers are printed","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:10\n           i == 4 && break\n           @show i\n       end\ni = 1\ni = 2\ni = 3","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Another useful feature is to skip some elements. It can be done using the continue keyword. For example, the following code prints all even numbers from 1 to 10","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:10\n           mod(i, 2) == 0 || continue\n           @show i\n       end\ni = 2\ni = 4\ni = 6\ni = 8\ni = 10","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that the code after the continue keyword expression is not evaluated.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Rewrite the code from the exercise in the section above. Use the combination of the while loop and keywords continue to print integers from 1 to 100 divisible by by 3 and 7 simultaneously. In the declaration of the while loop use the true value instead of a condition. Use the break keyword and proper condition to terminate the loop.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"If we use the true value in the declaration of thewhile loop, we will create an infinite loop, and it is necessary to end it in the loop with the break keyword. Because the variable i represents an integer and we want to iterate over integers from 1 to 100, the correct termination condition isi> 100","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> i = 0;\n\njulia> while true\n           i += 1\n           i > 100 && break\n           mod(i, 3) == mod(i, 7) == 0 || continue\n           @show i\n       end\ni = 21\ni = 42\ni = 63\ni = 84","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that we use short-circuit evaluation to break the loop. To check the given integer's divisibility, we use the same condition as in the exercise above. However, we use || instead of && because we want to use the continue keyword.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"lecture_02/loops/#Nested-loops","page":"Loops and Iterators","title":"Nested loops","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"In Julia, Nested loops can be created in a standard way as in other languages","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:3\n           for j in i:3\n               @show (i, j)\n           end\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that the inner loop range depends on the variable i from the outer loop. This style of writing nested loops is typical in other languages and is very useful. However, in Julia, it is possible to use an even shorter syntax","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:3, j in i:3\n           @show (i, j)\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"In this case, the output is the same as in the previous example, but this syntax is not equivalent to the previous one. The main difference is when using the break keyword. If we use the first syntax, the break keyword inside an inner loop exits only the inner loop.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:3\n           for j in i:10\n               j > 3 && break\n               @show (i, j)\n           end\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)\n(i, j) = (2, 2)\n(i, j) = (2, 3)\n(i, j) = (3, 3)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"However, if we use the shorter syntax, the break keyword inside an inner loop exits the entire nested loops","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:3, j in i:10\n           j > 3 && break\n           @show (i, j)\n       end\n(i, j) = (1, 1)\n(i, j) = (1, 2)\n(i, j) = (1, 3)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"There are other limitations of the shorter syntax. For example, it is not possible to perform any operation outside the inner loop. Nevertheless, it is still a very useful syntax in many cases.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Use nested loops to create a matrix with elements given by the following formula","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A_i j = frac12expleftfrac12 (x_i^2 - y_j^2) right quad i in 1 2 3  j in  1 2 3 4","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"where x in 04 23 46, y in 14 -31 24 52.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Bonus: try to create the same matrix in a more effective way.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Firstly, we have to define vectors x and y","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"x = [0.4, 2.3, 4.6]\ny = [1.4, -3.1, 2.4, 5.2]","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"If we want to use nested loops, we have to create an empty array of the proper size and element type","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A = zeros(Float64, length(x), length(y))","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"In this case, the element type specification can be omitted since the elements will be of type Float64, which is a default type for the zeros function. Now we have to use proper indexes since we want to fill the A array. In this case, we get the indexes 1:3 for the vector x and 1:4 for the vector y. Altogether, we get the following nested for loops","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:length(x), j in 1:length(y)\n           A[i, j] = exp((x[i]^2 - y[j]^2)/2)/2\n       end\n\njulia> A\n3×4 Array{Float64,2}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"However, there are more efficient ways how to create this array in Julia. The one way is to use broadcasting. It can be done as follows","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> y_row = y'\n1×4 LinearAlgebra.Adjoint{Float64,Array{Float64,1}}:\n 1.4  -3.1  2.4  5.2\n\njulia> A = @. exp((x^2 - y_row^2)/2)/2\n3×4 Array{Float64,2}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that we use y', which indicates the transposition of the vector y, i.e.,  the resulting array represents a row vector. Also, note that we use the @ . macro to perform all operations elementwise.  The third way to create the same matrix is to use a list comprehension, and we will discuss it in the next section.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"lecture_02/loops/#List-comprehension","page":"Loops and Iterators","title":"List comprehension","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"As we mentioned in the exercise's solution above, one way to create an array with prescribed elements is to use list comprehension. Comprehensions provide a general and powerful way to construct arrays, and the syntax is similar to set construction notation in mathematics","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A = [f(x, y, ...) for x in X, y in Y, ...]","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"The previous example reads: the function f will be evaluated for each combination of elements of iterable objects  X, Y, etc. The result will be an n-dimensional array of size (length(X), length(Y), ...). Returning to the previous exercise, we can create the required array as follows","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> X = [0.4, 2.3, 4.6];\n\njulia> Y = [1.4, -3.1, 2.4, 5.2];\n\njulia> A = [exp((x^2 - y^2)/2)/2 for x in X, y in Y]\n3×4 Array{Float64,2}:\n    0.203285    0.00443536     0.030405  7.27867e-7\n    2.64284     0.0576626      0.395285  9.46275e-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that the resulting array type depends on the types of the computed elements. In order to control the type explicitly, a type can be prepended to the comprehension","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> A = Float32[exp((x^2 - y^2)/2)/2 for x in X, y in Y]\n3×4 Array{Float32,2}:\n    0.203285    0.00443536     0.030405  7.27867f-7\n    2.64284     0.0576626      0.395285  9.46275f-6\n 7382.39      161.072       1104.17      0.0264329","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A handy feature is that it is possible to filter values when creating list comprehensions using the if keyword. However, in such a case, the result will always be a vector. In the example below, we create a vector of tuples (x, y, x + y), where x + y < 5","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> [(x, y, x + y)  for x in 1:10, y in 1:10 if x + y < 5]\n6-element Array{Tuple{Int64,Int64,Int64},1}:\n (1, 1, 2)\n (2, 1, 3)\n (3, 1, 4)\n (1, 2, 3)\n (2, 2, 4)\n (1, 3, 4)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Use the list comprehension to create a vector of all integers from 1 to 100 divisible by 3 and 7 simultaneously. What is the sum of all these integers?","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"We can use list comprehension with the same condition that we used in the exercise in the first section","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> v = [i for i in 1:100 if mod(i, 3) == mod(i, 7) == 0]\n4-element Array{Int64,1}:\n 21\n 42\n 63\n 84","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Then we can use the sum function to get their sum","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> sum(v)\n210","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"lecture_02/loops/#Generator-expressions","page":"Loops and Iterators","title":"Generator expressions","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"List comprehensions can also be written without enclosing square brackets, producing an object known as a generator. This object can be iterated to produce values on demand instead of allocating an array and storing them in advance. For example, the following expression sums a series without allocating memory.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> sum(1/n^2 for n in 1:1000)\n1.6439345666815615","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"It is possible to write nested list comprehensions and generators. The syntax is similar to writing nested loops","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> [(i,j) for i in 1:3 for j in 1:2]\n6-element Array{Tuple{Int64,Int64},1}:\n (1, 1)\n (1, 2)\n (2, 1)\n (2, 2)\n (3, 1)\n (3, 2)\n\njulia> gen = ((i,j) for i in 1:3 for j in 1:2);\n\njulia> collect(gen)\n6-element Array{Tuple{Int64,Int64},1}:\n (1, 1)\n (1, 2)\n (2, 1)\n (2, 2)\n (3, 1)\n (3, 2)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Iterables may still refer to outer loop variables. However, in such a case, it is necessary to use the for keyword before each iterable statement, and the result will be a vector","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> gen = ((i,j) for i in 1:3 for j in 1:i);\n\njulia> collect(gen)\n6-element Array{Tuple{Int64,Int64},1}:\n (1, 1)\n (2, 1)\n (2, 2)\n (3, 1)\n (3, 2)\n (3, 3)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Generated values can also be filtered using the if keyword.  Similarly to list comprehensions, the result in such a case will be a vector","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> gen = ((i,j) for i in 1:3 for j in 1:i if i+j == 4);\n\njulia> collect(gen)\n2-element Array{Tuple{Int64,Int64},1}:\n (2, 2)\n (3, 1)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Use a generator to sum the square of all integers from 1 to 100, which are divisible by 3 and 7 simultaneously.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"There are two ways how to solve the exercise. We can create a generator first and then use the sum function to get the result","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> gen = (i^2 for i in 1:100 if mod(i, 3) == mod(i, 7) == 0);\n\njulia> sum(gen)\n13230","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"or we can use the shorter syntax that allows us to write a generator inside the sum function","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> sum(i^2 for i in 1:100 if mod(i, 3) == mod(i, 7) == 0)\n13230","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"lecture_02/loops/#Iterators","page":"Loops and Iterators","title":"Iterators","text":"","category":"section"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Many structures are iterable in Julia. However, in many cases, it is not sufficient to iterate only over elements of a structure. Imagine the situation that we have the following array and we want to iterate over all its elements","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> A = [2.3 4.5; 6.7 7.1]\n2×2 Array{Float64,2}:\n 2.3  4.5\n 6.7  7.1","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Additionally, in each iteration, we want to print the index and the corresponding value. It can be done in the following way","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for i in 1:length(A)\n           println(\"i = $(i) and A[i] = $(A[i])\")\n       end\ni = 1 and A[i] = 2.3\ni = 2 and A[i] = 6.7\ni = 3 and A[i] = 4.5\ni = 4 and A[i] = 7.1","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"However, there is an even simpler way. We can do the same using the enumerate function that returns an iterator (an iterable object that can be iterated in for loops). It will produce couples of the form (i, x[i])","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for (i, val) in enumerate(A)\n           println(\"i = $(i) and A[i] = $(val)\")\n       end\ni = 1 and A[i] = 2.3\ni = 2 and A[i] = 6.7\ni = 3 and A[i] = 4.5\ni = 4 and A[i] = 7.1","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Other very useful functions return iterators. For example, the eachcol function returns an iterator that will iterate over columns of the given matrix","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for col in eachcol(A)\n           println(\"col = $(col)\")\n       end\ncol = [2.3, 6.7]\ncol = [4.5, 7.1]","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Similarly, the eachrow function returns an iterator that will iterate over the given matrix's rows. A convenient function is the zip function, which can zip together multiple iterable objects and iterate over them simultaneously","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for (i, j, k) in zip([1, 4, 2, 5], 2:12, (:a, :b, :c))\n           @show (i, j, k)\n       end\n(i, j, k) = (1, 2, :a)\n(i, j, k) = (4, 3, :b)\n(i, j, k) = (2, 4, :c)","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Note that in this case, the iterable objects can be of different lengths. However, the iterator returned by the zip function will have the same length as the shortest of the input iterable objects","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"It is also possible to combine these handy functions to get an even more useful iterator.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for (i, vals) in enumerate(zip([1, 4, 2, 5], 2:12, (:a, :b, :c)))\n           @show (i, vals)\n       end\n(i, vals) = (1, (1, 2, :a))\n(i, vals) = (2, (4, 3, :b))\n(i, vals) = (3, (2, 4, :c))","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Create a matrix with elements given by the following formula","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"A_i j = frac12expleftfrac12 (x_i^2 - y_j^2) right quad i in 1 2 3  j in  1 2 3 4","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"where x in 04 23 46, y in 14 -31 24 52. Compute the sum of all elements in each row and print the following message:","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Sum of all elements in a row i is i_sum,","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"where i represents row's number and i_sum the sum of all elements in this row. Do the same for each column and print the following message:","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Sum of all elements in a column i is i_sum,","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Hint: use iterators eachcol and eachrow.","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Firstly we have to generate the matrix A. It can be done using list comprehension as follows","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"X = [0.4, 2.3, 4.6]\nY = [1.4, -3.1, 2.4, 5.2]\nA = [exp((x^2 - y^2)/2)/2 for x in X, y in Y]","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"To compute the sum of each row and print the appropriate message, we can use a combination of the enumerate and eachrow functions","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for (i, row) in enumerate(eachrow(A))\n           println(\"Sum of all elements in a row $(i) is $(sum(row))\")\n       end\nSum of all elements in a row 1 is 0.2381259460051036\nSum of all elements in a row 2 is 3.0957940729669864\nSum of all elements in a row 3 is 8647.66342895583","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"Similarly, to compute the sum of each column and print the appropriate message, we can use a combination of the enumerate and eachcol functions","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"julia> for (i, row) in enumerate(eachcol(A))\n           println(\"Sum of all elements in a column $(i) is $(sum(row))\")\n       end\nSum of all elements in a column 1 is 7385.236904243371\nSum of all elements in a column 2 is 161.13431527671185\nSum of all elements in a column 3 is 1104.5996863997295\nSum of all elements in a column 4 is 0.026443054989612996","category":"page"},{"location":"lecture_02/loops/","page":"Loops and Iterators","title":"Loops and Iterators","text":"</p></details>","category":"page"},{"location":"final_project/homeworks/#homeworks","page":"Homeworks","title":"Homeworks","text":"","category":"section"},{"location":"lecture_04/standardlibrary/#Statistics","page":"Standard Library","title":"Statistics","text":"","category":"section"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"Multiple standard packages are shipped together with Julia's release. Those packages are not loaded by default in the new Julia session and need to be load manually.","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"The first package we mention is the Statistics package, which provides fundamental statistic related functions such as functions for computing mean, variance, or standard deviation","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"using Statistics\nx = rand(10);\nmean(x)\nvar(x)\nstd(x)","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"See official documentation for more information. More statistics-related functions can be found in StatsBase package. This package provides functions for computing scalar statistics, high-order moment computation, counting, ranking, covariances, sampling, and empirical density estimation.","category":"page"},{"location":"lecture_04/standardlibrary/#LinearAlgebra","page":"Standard Library","title":"LinearAlgebra","text":"","category":"section"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"Another package that should be mentioned is the LinearAlgebra package, which provides a native implementation of many common and useful linear algebra operations. The package provides functions for computing matrix determinant, inversion, norm or eigenvalues, and eigenvectors","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"using LinearAlgebra\nA = [-4.0 -17.0; 2.0 2.0]\n\ndet(A)\ninv(A)\nnorm(A)\neigvals(A)\neigvecs(A)","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"The package also provides an implementation of multiple matrix types that represent matrices with special symmetries and structures. As an example, we can mention Symmetric, Hermitian or Diagonal matrices. These special matrix types allow for fast computation using specialized algorithms developed for particular matrix types. Matrices of these types can be constructed via their constructors. For example, a diagonal matrix can be created as follows","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"D = Diagonal([1,2,3])","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"Another handy function provided by the package is the identity operator I representing the identity matrix. The identity operator I is defined as a constant and is an instance of UniformScaling. The size of this operator is generic and match the other matrix in the binary operations +, -, * and \\","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"D + I\nD - I","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"Note that for D+I and D-I, the matrix D must be square.","category":"page"},{"location":"lecture_04/standardlibrary/#Random","page":"Standard Library","title":"Random","text":"","category":"section"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"The last package that we will describe in more detail is the Random package. This package provides more functionality for generating random numbers in Julia. The package allows setting the seed for the random generator using the seed! function. The seed! function can be used to create a reproducible code  that contains randomly generated values","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"using Random\nusing Random: seed!\n\nseed!(1234);\nrand(2)\nseed!(1234);\nrand(2)","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"The package also other handy functions. For example, the randperm function constructs a random permutation of the given length","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"randperm(4)","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"or the shuffle function that returns a randomly permuted copy of the given array","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"v = [1,2,3,4]\nshuffle(v)","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"<div class = \"info-body\">\n<header class = \"info-header\">Other useful standard packages</header><p>","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"There are other useful standard packages in Julia, but there is not enough space to present them all. So we provide at least a list of the most important","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"Test: provides simple unit testing functionality. Unit testing is a way to see if your code is correct by checking that the results are what you expect. It can help to ensure your code still works after you make changes. Unit tests can also be used when developing as a way of specifying the behaviors your code should have when complete\nSparseArrays: provides special types to store and work with sparse arrays.\nDistributed: provides support for distributed computing.","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"See section Standard Library in the official documentation for more information.","category":"page"},{"location":"lecture_04/standardlibrary/","page":"Standard Library","title":"Standard Library","text":"</p></div>","category":"page"},{"location":"lecture_03/methods/#Methods","page":"Methods","title":"Methods","text":"","category":"section"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"So far, we have defined all functions (with some exceptions) without annotating the types of input arguments. When the type annotation is omitted, the default behavior in Julia is to allow values to be of any type. Thus, one can write many useful Julia functions without ever explicitly using types. However, when additional expressiveness is needed, it is easy to gradually introduce explicit type annotations into previously untyped code.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"In Julia, functions consist of multiple methods. The choice of which method to execute when a function is applied is called dispatch. Julia allows the dispatch process to choose which of a function's methods to call based on","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"the number of arguments given\ntypes of all of the function's arguments.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Using all of a function's arguments to choose which method should be invoked is known as multiple dispatch.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"As an example of usage of multiple-dispatch, we will define a product function that will compute the product of the given numbers","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(x, y) = x * y\nproduct (generic function with 1 method)","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"In the REPL, we can see the message that tells us that the product function has only one method. In this case,  we defined only the method for two input arguments without type specification","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product(2.4, 3.1)\n7.4399999999999995","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"A list of all methods for a given function can be obtained using the methods function","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> methods(product)\n# 1 method for generic function \"product\":\n[1] product(x, y) in Main at none:1","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Because we did not specify types of input arguments, the product function accepts arguments of all types. However, the * operator will not work, for example, for symbols","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(:a, :b)\nERROR: MethodError: no method matching *(::Symbol, ::Symbol)\n[...]","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"We can avoid such errors by specifying types of input arguments. Since we want to create a function that computes the product of two numbers, it makes sense to allow input arguments to be only numbers.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"product(x::Number, y::Number) = x * y\nproduct(x, y) = throw(ArgumentError(\"product is defined for numbers only.\"))","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Note that we also redefined the original definition of the product function to throw an error if we call the function with non-numeric input arguments.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> methods(product)\n# 2 methods for generic function \"product\":\n[1] product(x::Number, y::Number) in Main at none:1\n[2] product(x, y) in Main at none:1","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Now, we have a function with two methods, that returns a product if the input arguments are numbers and throw an error otherwise.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product(:a, :b)\nERROR: ArgumentError: product is defined for numbers only.\n\njulia> product(\"a\", \"b\")\nERROR: ArgumentError: product is defined for numbers only.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"As in the previous example, it is always better to use abstract types like Number or Real instead of concrete types like Float64, Float32, or Int64. The reason is that if we use an abstract type, the function will work for all its subtypes. To find a supertype for a specific type, we can use the supertype function from InteractiveUtils package","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> using InteractiveUtils: supertype\n\njulia> supertype(Float64)\nAbstractFloat","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The problem with the supertype function is that it will not return the whole supertype hierarchy, but only the closest larger supertype for the given type. For Float64 the closest large supertype is AbstractFloat. However, as in the example before, we do not want to use this supertype, since then the function will only work for floating-point numbers. Solve the following exercise to get the tool, which allows you to print the whole supertypes hierarchy.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Create a function supertypes_tree that prints the whole tree of all supertypes for the given type. If the given type T satisfies the following condition T === Any, then the function should do nothing. Use the following function declaration","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"function supertypes_tree(T::Type, level::Int = 0)\n    # code\nend","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The optional argument level sets the level of indentation for printing","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Hints:","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Use the supertype function in combination with recursion.\nUse the repeat function and string with white space \"    \" to create a proper indentation.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The supertypes_tree function can be defined as follows","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"function supertypes_tree(T::Type, level::Int = 0)\n    T === Any && return\n    println(repeat(\"   \", level), T)\n    supertypes_tree(supertype(T), level + 1)\n    return\nend","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"On the first line, we check if the given input type is Any, and if yes, then the function returns nothing. Otherwise, the function prints the type with a proper indentation given by repeat(\"   \", level), i.e., four white-spaces are repeated level-times. On the third-line, we call the supertypes_tree function recursively for the supertype of the type T and level of indentation level + 1.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"</p></details>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Now we can use the supertypes_tree function to get the whole supertypes hierarchy for Float64.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> supertypes_tree(Float64)\nFloat64\n   AbstractFloat\n      Real\n         Number","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"We can check the type hierarchy using <: operator for comparing type, i.e., if T1 <: T2 is true, then T1 is a subtype (or the same type) of T2","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> Float64 <: AbstractFloat <: Real <: Number\ntrue","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Similarly to the supertype function, there is the subtypes function that returns all subtypes for the given type","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> using InteractiveUtils: subtypes\n\njulia> subtypes(Number)\n2-element Array{Any,1}:\n Complex\n Real","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"But there is the same problem as for the supertype function: It is impossible to get the whole hierarchy of all subtypes using only this function. Solve the following exercise to get the tool, which allows you to print the whole subtypes hierarchy.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Create a function subtypes_tree that prints the whole tree of all subtypes for the given type. Use the following function declaration","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"DocTestSetup = quote\n   using InteractiveUtils: subtypes\nend","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"function subtypes_tree(T::Type, level::Int = 0)\n    # code\nend","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The optional argument level sets the level of indentation for printing","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Hints:","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Use the subtypes function in combination with recursion.\nUse the repeat function and string with white space \"    \" to create a proper indentation.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The subtypes_tree function can be defined as follows","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"function subtypes_tree(T::Type, level::Int = 0)\n    println(repeat(\"   \", level), T)\n    subtypes_tree.(subtypes(T), level + 1)\n    return\nend","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The function prints the type with a proper indentation given by repeat(\"   \", level), i.e., four white-spaces are repeated level-times. On the second-line, we call the subtypes_tree function recursively for all subtypes of the type T and level of indentation level + 1.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"</p></details>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Now we can use the subtypes_tree function to get the whole subtypes hierarchy for the Number type","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> subtypes_tree(Number)\nNumber\n   Complex\n   Real\n      AbstractFloat\n         BigFloat\n         Float16\n         Float32\n         Float64\n      AbstractIrrational\n         Irrational\n      Integer\n         Bool\n         Signed\n            BigInt\n            Int128\n            Int16\n            Int32\n            Int64\n            Int8\n         Unsigned\n            UInt128\n            UInt16\n            UInt32\n            UInt64\n            UInt8\n      Rational","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"From the tree of all subtypes of the abstract type Number, we see the whole structure of Julia's numerical types. So if we want to define a function that accepts all numeric types, we should use inputs of type Number. However, many operations are restricted to only real numbers. In such a case, we want to use the Real type instead of Number.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Now we can go back to our example with the product function. The problem with this function is that it is too restrictive since the product of two strings is a legitimate operation that should return their concatenation. So we should define a method for strings. To use the proper type, we can use the supertypes_tree function for the String type","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> supertypes_tree(String)\nString\n   AbstractString","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"We see that the largest supertype for String is the AbstractString, and that is the type we should use","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"product(x::AbstractString, y::AbstractString) = x * y\nproduct(x, y) = throw(ArgumentError(\"product is defined for numbers and strings only.\"))","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"We also redefined the original definition of the product function to throw an appropriate error.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product(\"a\", \"b\")\n\"ab\"\n\njulia> product(:a, :b)\nERROR: ArgumentError: product is defined for numbers and strings only.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Sometimes, it can be very complicated to guess which method will be used for concrete inputs. In such a case, there is a useful macro @which that returns the method that would be called for given arguments","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> using InteractiveUtils: @which\n\njulia> @which product(1, 4.5)\nproduct(x::Number, y::Number) in Main at none:1\n\njulia> @which product(\"a\", :a)\nproduct(x, y) in Main at none:1\n\njulia> @which product(\"a\", \"b\")\nproduct(x::AbstractString, y::AbstractString) in Main at none:1","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The previous example with the product function shows how methods in Julia works. However, it is a good practice to use type annotation only if we want to have a specialized function or if we want to define a function, which does different things for different types of input arguments.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"g(x::Real) = x + 1\ng(x::String) = repeat(x, 4)","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"For example, the g function returns x + 1 if the input x is a real number or repeats four times the input argument if it is a string. Otherwise, it will throw a method error since we define only these two specific methods.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> g(1.2)\n2.2\n\njulia> g(\"a\")\n\"aaaa\"\n\njulia> g(:a)\nERROR: MethodError: no method matching g(::Symbol)\nClosest candidates are:\n  g(!Matched::String) at none:1\n  g(!Matched::Real) at none:1","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"<div class = \"info-body\">\n<header class = \"info-header\">Do not overuse type annotation!!!</header><p>","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The product function should be defined without the type annotation. It is a good practice not to restrict input argument types if it is not necessary. The reason is that, in this case, there is no benefit of using the type annotation. If we define a function product_new in the following way","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"product_new(x, y) = x * y","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Then we can apply this function to the same inputs as the original product function, and we will get the same results","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(1, 4.5)\n4.5\n\njulia> product_new(1, 4.5)\n4.5\n\njulia> product(\"a\", \"b\")\n\"ab\"\n\njulia> product_new(\"a\", \"b\")\n\"ab\"","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"with only one exception","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> product(\"a\", :a)\nERROR: ArgumentError: product is defined for numbers and strings only.\n\njulia> product_new(\"a\", :a)\nERROR: MethodError: no method matching *(::String, ::Symbol)\n[...]","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Here we get a different error, but the error given by the product_new function is more useful since it tells us what the real problem is. We can see that it is not possible to use the * operator to multiply String and Symbol. Now we can decide if it is the desired behavior, and if not, we can define a method for the * operator that will fix it.","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"</p></div>","category":"page"},{"location":"lecture_03/methods/#Method-Ambiguities","page":"Methods","title":"Method Ambiguities","text":"","category":"section"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"It is possible to define a set of function methods such that there is no unique most specific method applicable to some combinations of arguments","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"f(x::Float64, y) = x * y\nf(x, y::Float64) = x + y","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Here, the f function has two methods. The first method applies if the first argument is of type Float64, and the second method applies if the second argument is of type Float64","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> f(2.0, 3)\n6.0\n\njulia> f(2, 3.0)\n5.0","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"The case where both arguments are of type Float64 can be handled by both methods. The problem is that neither method is more specific than the other. In such cases, Julia raises a MethodError rather than arbitrarily picking a method","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> f(2.0, 3.0)\nERROR: MethodError: f(::Float64, ::Float64) is ambiguous. Candidates:\n  f(x::Float64, y) in Main at none:1\n  f(x, y::Float64) in Main at none:1\nPossible fix, define\n  f(::Float64, ::Float64)","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"We can avoid method ambiguities by specifying an appropriate method for the intersection case","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> f(x::Float64, y::Float64) = x - y\nf (generic function with 3 methods)","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"Now we can see that the f function has three methods","category":"page"},{"location":"lecture_03/methods/","page":"Methods","title":"Methods","text":"julia> f(2.0, 3.0)\n-1.0","category":"page"},{"location":"lecture_02/scope/#Soft-Local-Scope","page":"Soft Local Scope","title":"Soft Local Scope","text":"","category":"section"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"The scope of a variable is the region of a code where a variable is visible. There are two main types of scopes in Julia: global and local, and we will discuss it later. In this section, we will only focus on loops.","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"Every variable created inside a loop is local, i.e., it is possible to use it only inside the loop","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"julia> for i in 1:2\n           t = 1 + i\n           @show t\n       end\nt = 2\nt = 3\n\njulia> t\nERROR: UndefVarError: t not defined","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"Note that the variable i in the example above is also local. It is possible to create nested local scopes, for example, nested loops. In such a case, the behavior is as follows","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"julia> for j in 1:5\n           for i in 1:2\n               @show i + j\n           end\n           i\n       end\ni + j = 2\ni + j = 3\nERROR: UndefVarError: i not defined","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"The variable j is a local variable defined in the outer loop.  It means that j can be accessed in any local scope defined inside the outer loop, i.e., we can use it inside the inner loop.  On the other hand, the variable i is a local variable from the inner loop and, therefore, cannot be accessed in the outer loop.","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"What happens if we want to use variables from the global scope inside loops? In this case, it depends whether the loop is created in interactive context (REPL, Jupyter notebook) or non-interactive (file, eval). In the interactive case (in the REPL in our case), global variables can be accessed and modified in local scopes without any restrictions","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"julia> s = 0\n0\n\njulia> for i = 1:10\n           t = 1 + i # new local variable t\n           s = t # assigning a new value to the global variable\n       end\n\njulia> s\n11","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"In this case, if we want to assign a value to a variable, there are two possibilities:","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"The case of variable t: there is no global variable with the same name, then a new local variable is created.\nThe case of variable s: there is a global variable with the same name, then a new value is assigned to the global variable.","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"However, in the non-interactive case, the variables behave differently. In the following example, we create a Julia code as a string and then evaluate it using the include_string function.","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"julia> code = \"\"\"\n       s = 0\n       for i = 1:10\n           t = 1 + i # new local variable t\n           s = t #  new local variable s + warning\n       end\n       s\n       \"\"\";\n\njulia> include_string(Main, code)\n┌ Warning: Assignment to `s` in soft scope is ambiguous because a global variable by the same name exists: `s` will be treated as a new local. Disambiguate by using `local s` to suppress this warning or `global s` to assign to the existing global variable.\n└ @ string:4\n0","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"In this case, if we want to assign a value to a variable inside a loop, there are two possibilities:","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"The case of variable t: there is no global variable with the same name, then a new local variable is created.\nThe case of variable s: there is a global variable with the same name, then assignment in soft scope is ambiguous, and a new local variable is created as in the first case.","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"In our example, the variable s is defined before the loop as global. In the loop, we get a warning that the assignment to s in soft scope is ambiguous, and a new local variable s is created instead. The behavior described above can be changed by using the local","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"code_local = \"\"\"\ns = 0\nfor i = 1:10\n    t = 1 + i # new local variable t\n    local s = t # assigning a new value to the global variable\nend\ns\n\"\"\"","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"or the global keyword","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"code_global = \"\"\"\ns = 0\nfor i = 1:10\n    t = 1 + i # new local variable t\n    global s = t # assigning a new value to the global variable\nend\ns\n\"\"\"","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"to specify whether the variable should be defined as local or global","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"julia> include_string(Main, code_global)\n11\n\njulia> include_string(Main, code_local)\n0","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"There are two obvious questions one could ask:","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"Why doesn't it just work like the REPL everywhere?\nWhy doesn't it just work like in files everywhere? And maybe skip the warning?","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"The behavior from REPL has the advantage of being intuitive and convenient since it approximates the behavior inside of a function body. In particular, it makes it easy to move code back and forth between a function body and the REPL when trying to debug the behavior of a function. However, it may easily lead to confusion and errors, especially if the code is long and/or split into multiple files. The intent of the following code is obvious: we want to modify the existing global variable s inside the loop","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"s = 0\nfor i = 1:10\n    s += i\nend","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"However, the actual code is usually more complicated. Consider the following example","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"x = 200\n\n# much later\n# maybe in a different file\n\nfor i = 1:10\n    x = 1000\n    println(x)\nend\n\n# much later\n# maybe in yet another file\n# or maybe back in the first one where `x = 200`\n\ny = x + 234","category":"page"},{"location":"lecture_02/scope/","page":"Soft Local Scope","title":"Soft Local Scope","text":"It is not clear what should happen here. Should be the variable x inside the loop considered local or global? If we consider the variable x inside the loop as local, then the variable y will be 434. On the other hand, if we consider the variable x inside the loop as global, then we assign a new value to it, and the variable y will be 1234. We can accidentally change the value of a variable and get incorrect results because we use the same variable name multiple times in different scopes.  In this case, it is complicated to find why the results are wrong since there is no error in the code. To help users, Julia prints the warning about the ambiguity in such cases. For more information see official documentation.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"using Plots","category":"page"},{"location":"lecture_12/theory/#Differential-equations","page":"Differential equations","title":"Differential equations","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Differential equations describe many natural phenomena. The Newton's law of motion","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"F = fracpartialpartial tmv","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"is a simple but extremely important example of an ordinary differential equation. Besides applications in physics and engineering, differential equations appear in almost any (smoothly) evolving system. Examples include economics (Black-Scholes formula) or biology (population growth). There are whole fields dedicated to solving a single equation such as the wave or heat equations. The basic distinction is:","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Ordinary differential equations (ODEs) depend only on time.\nPartial differential equations (PDEs) depend both on time and space. The spacial variable is usually 1D, 2D or 3D.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"There are many extensions; let us name systems of differential equations, stochastic differential equations, differential algebraic equations (system of differential and non-differential equations) and others.","category":"page"},{"location":"lecture_12/theory/#Ordinary-differential-equations","page":"Differential equations","title":"Ordinary differential equations","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Oridnary differential equations take form","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = f(t y(t))","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"on some interval tin 0T. To obtain a correct definition, the initial value y(0)=y_0 needs to be provided. A solution is a (sufficiently smooth) function y(t) such that the above formula is satisfied (almost) everywhere on 0T. The existence and uniqueness is ensured by mild conditions.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">Picard–Lindelöf theorem</header><p>","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Suppose f is uniformly Lipschitz continuous in y (the Lipschitz constant is independent of t) and continuous in t. Then for some value varepsilon  0, there exists a unique solution y(t) to the initial value problem on the interval t_0-varepsilon t_0+varepsilon.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"</p></div>","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"However, it may happen than even simple equations do not have a unique solution.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"<div class = \"info-body\">\n<header class = \"info-header\">Uniqueness</header><p>","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"The uniqueness of solution is not guaranteed even for simple equations. Equation","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"beginaligned\ndot y(t) = y^frac 23(t) \ny(0) = 0\nendaligned","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"has at least two solution: y_1(t)=0 and y_2(t)=(frac t3)^3. This is possible because the right-hand side of the ODE has an infinite derivative at zero and the Lipschitz continuity assumption of the Picard–Lindelöf theorem is not satisfied.","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"</p></div>","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"The theory of partial differential equations is complicated because they employ a special definition of derivative (weak derivative) and the solution is defined on special spaces (Sobolev spaces). It may happen that a function has (weak) derivative but it is not continuous.","category":"page"},{"location":"lecture_12/theory/#Linear-ODE","page":"Differential equations","title":"Linear ODE","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Linear ordinary equations","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = Ay(t) + b(t)","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"form an important subclass of differential equations. They admit a \"closed-form\" solution. This closed form employs the matrix exponential defined by","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"e^A = sum_k=0^infty fracA^kk","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"where A^k is the standard multiplication of matrices. This is a generalization from scalars to matrices and has similar properties. For example, the derivative of the matrix exponential is the same object due to","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"fracpartialpartial Ae^A = sum_k=0^infty AfracA^k-1k = sum_k=0^infty fracA^kk = e^A","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Then the solution of the linear equation above equals to","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"y(t) = e^Atleft(y_0 + int_0^t e^-Asb(s)dsright)","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"Indeed, the derivative of the previous term equals to","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"dot y(t) = Ae^Atleft(y_0 + int_0^t e^-Asb(s)dsright) + e^Ate^-Atb(t) = Ay(t) + b(t)","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"because e^Ate^-At is the identity matrix (similarly to e^xe^-x=1). The matrix exponential can be computed using matrix decompositions.","category":"page"},{"location":"lecture_12/theory/#Matrix-decompositions","page":"Differential equations","title":"Matrix decompositions","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"There are many matrix decompositions. They are closely related to finding eigenvalues and eigenvectors. We mention only two basic decompositions.","category":"page"},{"location":"lecture_12/theory/#Cholesky-decomposition","page":"Differential equations","title":"Cholesky decomposition","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"For a real positive semidefinite matrix A, its Cholesky decomposition always exists and reads","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"A = LL^top","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"where L is a real lower triangular matrix (zeros above the diagonal). This matrix is easily invertible and the decomposition is used in iterative algorithms where the matrix inversion needs to be computed many times.","category":"page"},{"location":"lecture_12/theory/#Eigenvalue-decomposition","page":"Differential equations","title":"Eigenvalue decomposition","text":"","category":"section"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"For a square matrix A of size ntimes n, we assume that there are n linearly independent eigenvectors (matrices which do not satisfy this are called defective). Then the eigendecomposition equals to","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"A = QLambda Q^-1","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"where Lambda is a diagonal matrix with eigenvalues on the diagonal and the columns of Q are orthonormal eigenvectors. This allows us to compute the matrix exponential","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"e^A = e^QLambda Q^-1 = Qe^Lambda Q^-1","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"as e^Lambda is a diagonal matrix with entries","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"(e^Lambda)_ij = begincases e^Lambda_iitextif i=j  0textotherwiseendcases","category":"page"},{"location":"lecture_12/theory/","page":"Differential equations","title":"Differential equations","text":"This allows to compute the closed-form solution of the linear ODEs.","category":"page"},{"location":"lecture_01/data_structures/#Tuples","page":"Data Structures","title":"Tuples","text":"","category":"section"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"A tuple is an immutable, ordered, fixed-sized group of elements, i.e., it is not possible to add new elements or change the value of any element in a tuple. Tuples are created using the following syntax","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t = (1, 2.0, \"3\")\n(1, 2.0, \"3\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"It is even possible to omit the brackets","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t = 1, 2.0, \"3\"\n(1, 2.0, \"3\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"The same syntax is used in a function definition to return multiple values at once. The types of all its elements give the type of a tuple","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> typeof(t)\nTuple{Int64,Float64,String}","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"In this case,  we have a tuple that contains three elements, where the first one is of type Int64, the second one of type Float64, and the last one of type String.","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"To access elements of a tuple, we can use the same syntax as for arrays","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t[1] # the first element\n1\n\njulia> t[end] # the last element\n\"3\"\n\njulia> t[1:2] # the first two elements\n(1, 2.0)","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"A handy feature is that it is possible to unpack a tuple over many values","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> a, b, c = t\n(1, 2.0, \"3\")\n\njulia> println(\"The values stored in the tuple are: $a, $b and $c\")\nThe values stored in the tuple are: 1, 2.0 and 3","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Note that arrays can be unpacked similarly. Tuples are usually used for storing a small number of values, and then this feature may be useful. On the other hand, arrays are usually large, so such a feature is not useful for arrays most of the time.","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Create a tuple that contains the first four letters of the alphabet (these letters should be of type String). Then unpack this tuple into four variables a, b, c and d.","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Such a tuple can be created easily using the standard syntax","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t = (\"a\", \"b\", \"c\", \"d\")\n(\"a\", \"b\", \"c\", \"d\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"To unpack the tuple, we can use the four variables and the = sign","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> a, b, c, d = t\n(\"a\", \"b\", \"c\", \"d\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"</p></details>","category":"page"},{"location":"lecture_01/data_structures/#Named-Tuples","page":"Data Structures","title":"Named Tuples","text":"","category":"section"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Named tuples are similar to tuples, i.e., a named tuple is immutable, ordered, fixed-sized group of elements. The only difference is that each element consists of a name (identifier) and value. Named tuples are created using the following syntax","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t = (a = 1, b = 2.0, c = \"3\")\n(a = 1, b = 2.0, c = \"3\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"or it is possible to create a named tuple directly from variables","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> a = 1;\n\njulia> b = 2.0;\n\njulia> c = \"3\";\n\njulia> t = (; a, b, c)\n(a = 1, b = 2.0, c = \"3\")","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Here the semicolon is mandatory because, without the semicolon, the result will be a tuple instead of a named tuple. Similarly to tuples, the elements of a named tuple can be accessed via square brackets. However, in opposed to tuples, it is not possible to access multiple elements at once","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t[1] # the first element\n1\n\njulia> t[end] # the last element\n\"3\"\n\njulia> t[1:2] # error\nERROR: MethodError: no method matching getindex(::NamedTuple{(:a, :b, :c),Tuple{Int64,Float64,String}}, ::UnitRange{Int64})\n[...]","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Moreover, it is possible to get elements of a named tuple via their names or unpack elements directly to variables","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> t.a\n1\n\njulia> t.c\n\"3\"\n\njulia> a, b, c = t\n(a = 1, b = 2.0, c = \"3\")\n\njulia> println(\"The values stored in the tuple are: a = $a, b = $b\")\nThe values stored in the tuple are: a = 1, b = 2.0","category":"page"},{"location":"lecture_01/data_structures/#Dictionaries","page":"Data Structures","title":"Dictionaries","text":"","category":"section"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Dictionaries are mutable, unordered (random order) collections of pairs of keys and values. The syntax for creating a dictionary is as follows","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> d = Dict(\"a\" => [1, 2, 3], \"b\" => 1)\nDict{String,Any} with 2 entries:\n  \"b\" => 1\n  \"a\" => [1, 2, 3]","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"or using symbols instead of strings as keys","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> d = Dict(:a => [1, 2, 3], :b => 1)\nDict{Symbol,Any} with 2 entries:\n  :a => [1, 2, 3]\n  :b => 1","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"In fact, it is possible to use almost any type as a key in a dictionary. The elements of a dictionary can be accessed via square brackets and a key","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> d[:a]\n3-element Array{Int64,1}:\n 1\n 2\n 3","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"If the key does not exist in the dictionary and we try to get it using the square brackets syntax, an error will occur","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> d[:c]\nERROR: KeyError: key :c not found\n\njulia> haskey(d, :c)\nfalse","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Note that we use the haskey function to check if the given dictionary has the :c key. To avoid such errors, we can use the get function that accepts three arguments: a dictionary, key, and a default value for this key, which is returned if the key does not exist in the given dictionary","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> get(d, :c, 42)\n42","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"There is also an in-place version of the get function. The get! function add the default value to the dictionary if the key does not exist","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> get!(d, :c, 42)\n42\n\njulia> get!(d, :d, [\"hello\", \"world\"])\n2-element Array{String,1}:\n \"hello\"\n \"world\"\n\njulia> d\nDict{Symbol,Any} with 4 entries:\n  :a => [1, 2, 3]\n  :b => 1\n  :d => [\"hello\", \"world\"]\n  :c => 42","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Unwanted keys from the dictionary can be removed using the delete! function","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> delete!(d, :d)\nDict{Symbol,Any} with 3 entries:\n  :a => [1, 2, 3]\n  :b => 1\n  :c => 42\n\njulia> haskey(d, :d)\nfalse","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"An alternative is the pop! function, which removes the key from the dictionary and returns the value corresponding to this key","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> pop!(d, :c)\n42\n\njulia> haskey(d, :c)\nfalse","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"Optionally it is possible to add a default value for a given key to the pop! function, which is returned if the key does not exist in the given dictionary","category":"page"},{"location":"lecture_01/data_structures/","page":"Data Structures","title":"Data Structures","text":"julia> haskey(d, :c)\nfalse\n\njulia> pop!(d, :c, 444)\n444","category":"page"},{"location":"lecture_04/DataFrames/#DataFrames.jl","page":"DataFrames.jl","title":"DataFrames.jl","text":"","category":"section"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"DataFrames is a package that provides a set of tools for working with tabular data in Julia. Its design and functionality are similar to those of pandas (in Python) and data.frame, data.table and dplyr (in R), making it a great general-purpose data science tool, especially for those coming to Julia from R or Python.","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using CSV\nusing DataFrames","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The core of the package is the DataFrame structure that represents a data table. The simplest way of constructing a DataFrame is to pass column vectors using keyword arguments or pairs","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\ndf = DataFrame(A = 1:4, B = [\"M\", \"F\", \"F\", \"M\"], C = rand(4))","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Since each column is stored in a DataFrame as a separate vector, it is possible to combine columns of different element types. Columns can be accessed directly without copying as follows","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.A","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"or using indexing syntax, which is similar to indexing syntax for arrays","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df[!, :A]","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Note that we use ! to select all rows. If we use :,  then we get a copy of a column. Since vectors are mutable structures and accessing a column of DataFrame via syntax above does not make a copy, it is possible to change elements of the DataFrame as follows","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.A[1] = 5\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"However, sometimes it is useful to get a copy of a column instead. To do that, we can use the following syntax","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"col = df[:, :A]\ncol[1] = 4\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"<div class = \"info-body\">\n<header class = \"info-header\">Column names</header><p>","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"DataFrames allow using symbols (like :A) and strings (like \"A\") for all column indexing operations for convenience. However, using symbols is slightly faster and should be preferred. One exception is when the column names are generated using string manipulation.","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"</p></div>","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The standard format for storing table data is the csv file format. The CSV package provides an interface for saving and loading csv files.","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using CSV\nCSV.write(\"dataframe.csv\", df)\ntable = CSV.read(\"dataframe.csv\", DataFrame; header = true)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"See the package documentation for more information.","category":"page"},{"location":"lecture_04/DataFrames/#Adding-columns-and-rows","page":"DataFrames.jl","title":"Adding columns and rows","text":"","category":"section"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is common for tables to be created column by column or row by row. DataFrames provides an easy way to extend existing tables. To add a new column to a DataFrame, we can use a direct way as follows","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df.D = [:a, :b, :c, :d]\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Alternatively, we can use the insertcols! function. This function allows you to insert multiple columns at once and also provides advanced options for column manipulation. For example, you can specify the column index into which the columns are to be inserted. For more information, see the insertcols! help","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"insertcols!(df, 3, :B => rand(4), :B => 11:14; makeunique = true)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"New rows can be added to the existing DataFrame using the push! function. It is possible to append a new row in the form of a vector or tuple of the correct length or in the form of a dictionary with keys the same as the column names of the target table","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"push!(df, [10, \"F\", 0.1, 15, 0.235, :f])\npush!(df, (10, \"F\", 0.1, 15, 0.235, :f))\npush!(df, Dict(:B_1 => 0.1, :B_2 => 15, :A => 10, :D => :f, :B => \"F\", :C => 0.235))\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is possible to start with an empty DataFrame and build the table incrementally.  There is no problem when the DataFrame is constructed in a column by column manner","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\ndf_empty = DataFrame()\ndf_empty.A = 1:3\ndf_empty.B = [:a, :b, :c]\ndf_empty","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"However, this approach will not work if the DataFrame is created row by row. In this case, the empty DataFrame must be initialized with empty columns of appropriate element types","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"df_empty = DataFrame(A = Int[], B = Symbol[])\npush!(df_empty, [1, :a])\npush!(df_empty, (2, :b))\npush!(df_empty, Dict(:A => 3, :B => :c))\ndf_empty","category":"page"},{"location":"lecture_04/DataFrames/#Renaming","page":"DataFrames.jl","title":"Renaming","text":"","category":"section"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Sometimes it is useful to get the names of all the columns. In such a case, two functions can be used. The first is the names function, which returns column names as a vector of strings. The propertynames function does the same thing but returns a vector of symbols","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"names(df)\npropertynames(df)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"If we are not satisfied with the column names, we can change them using the rename! function. This function can be used to rename all columns at once","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"rename!(df, [:a, :b, :c, :d, :e, :f])\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"or to change the names of specific columns","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"rename!(df, :a => :A, :f => :F)\ndf","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Moreover, it is possible to use a function to generate column names","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"myname(x) = string(\"column_\", uppercase(x))\nrename!(myname, df)\ndf","category":"page"},{"location":"lecture_04/DataFrames/#Working-with-DataFrames","page":"DataFrames.jl","title":"Working with DataFrames","text":"","category":"section"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\nusing RDatasets","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"In the next part of the lecture, we will use the RDatasets package. The package provides an easy way for Julia users to use many standard data sets available in the core of the R programming language. For further examples, we will use Iris dataset","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using RDatasets, DataFrames\niris = dataset(\"datasets\", \"iris\")\nfirst(iris, 6)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Note that we use the first function to print only the first n = 6 rows of the given table. Similarly, the last function can be used to show the last n rows of the given table.","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"When we start to work with a new data table that we are not familiar with, it is helpful to get some basic description of the dataset. DataFrames provides the describe function that returns descriptive statistics for each column of the given DataFrame","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"describe(iris)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"It is also possible to get a specific subset of a DataFrame. To do that, we can use indexing syntax, which is similar to indexing syntax for matrices","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"iris[2:4, [:SepalLength, :Species]]","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Additionally, DataFrames provides Not, Between, Cols and All selectors that can be used in more complex column selection scenarios","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"iris[2:4, Not([:SepalLength, :Species])]","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The last thing that we will present in this section is the Query package, which allows advanced manipulation with DataFrame. For example, in the code below, we select only rows where SepalLength >= 6 and at the same time SepalWidth >= 3.4. Then we create a new DataFrame, where for each of the selected rows, we add corresponding Species, the sum of sepal length and width, and the sum of petal length and width","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using Query\n\ntable = @from row in iris begin\n    @where row.SepalLength >= 6 && row.SepalWidth >= 3.4\n    @select {\n        row.Species,\n        SepalSum = row.SepalLength + row.SepalWidth,\n        PetalSum = row.PetalLength + row.PetalWidth,\n    }\n    @collect DataFrame\nend","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"There are tons of other topics related to DataFrames. However, there is no time to cover them all. Also, there is no reason to do that, since DataFrames provides excellent documentation with a lot of examples.","category":"page"},{"location":"lecture_04/DataFrames/#Visualizing-using-StatsPlots","page":"DataFrames.jl","title":"Visualizing using StatsPlots","text":"","category":"section"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using DataFrames\nusing RDatasets\nusing StatsPlots\nusing Query\n\niris = dataset(\"datasets\", \"iris\")\nCore.eval(Main, :(using StatsPlots))","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"The StatsPlots package provides recipes for plotting histograms, boxplots, and many other statistic related plots. This package also provides @df macro, which allows simple plotting of tabular data. As a simple example, we can create a scatter plot of SepalLength and SepalWidth grouped based on the Species","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using StatsPlots\n@df iris scatter(\n    :SepalLength,\n    :SepalWidth;\n    xlabel = \"SepalLength\",\n    ylabel = \"SepalWidth\",\n    group = :Species,\n    marker = ([:d :h :star7], 8),\n)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Note that keyword arguments can be used in the same way as usual.","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"StatsPlots provides a large amount of statistic related plots. As one example, we can mention marginalkde function for plotting marginal kernel density estimations. In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. The marginalkde function can be used together with @df macro as follows","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"using StatsPlots: marginalkde # hide\n@df iris marginalkde(\n    :SepalLength,\n    :SepalWidth;\n    xlabel = \"SepalLength\",\n    ylabel = \"SepalWidth\",\n)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Another example of a useful statistics related  graph is the corrplot function, which shows the correlation between input variables","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"@df iris corrplot(\n    cols(1:4);\n    grid = false,\n    nbins = 15,\n    fillcolor = :viridis,\n    markercolor = :viridis,\n)","category":"page"},{"location":"lecture_04/DataFrames/","page":"DataFrames.jl","title":"DataFrames.jl","text":"Note, that in this case, we use cols(1:4) instead of the names of columns. The reason for that is simple: it is shorter. Anyway, it is possible to use a vector of column names too.","category":"page"},{"location":"lecture_01/strings/#Strings","page":"Strings","title":"Strings","text":"","category":"section"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In Julia, as in other programming languages, a string is a sequence of one or more characters and can be created using quotes","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"Hello, world.\"\n\"Hello, world.\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The strings are immutable and, therefore, cannot be changed after creation. However, it is very easy to create a new string from parts of existing strings. Individual characters of a string can be accessed via square brackets and indices (the same syntax as for arrays)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1] # returns the first character\n'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The return type, in this case, is a Char","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> typeof(str[1])\nChar","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"A Char value represents a single character. It is just a 32-bit primitive type with a special literal representation and appropriate arithmetic behaviors. Chars can be created using an apostrophe","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> 'x'\n'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"It is also possible to convert characters to a numeric value representing a Unicode and vice versa","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> Int('x')\n120\n\njulia> Char(120)\n'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Substrings from the existing string can be extracted via square brackets and indexing syntax which is similar to the one for arrays","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1:5] # returns the first five characters\n\"Hello\"\n\njulia> str[[1,2,5,6]]\n\"Heo,\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that we use a range 1:5 to access the first five elements of the string (further details on ranges are given in the section on arrays). Be aware that the expressions str[k] and str[k:k] do not give the same result","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str[1] # returns the first character as Char\n'H': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)\n\njulia> str[1:1] # returns the first character as String\n\"H\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"When using strings, we have to pay attention to some special characters, specifically to the following three characters: \\, \" and $. If we want to use any of these three characters, we have to use a backslash before them. The reason is that these characters have a special meaning. For example, if we use a quote inside a string, then the rest of the string will be interpreted as a Julia code and not a string.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str1 = \"This is how a string is created: \\\"string\\\".\"\n\"This is how a string is created: \\\"string\\\".\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Similarly, the dollar sign is reserved for string interpolation, and if we want to use it as a character, we have to use a backslash too","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str2 = \"\\$\\$\\$ dollars everywhere \\$\\$\\$\"\n\"\\$\\$\\$ dollars everywhere \\$\\$\\$\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The print of the strings can be done using the print function or the println function that also add a new line at the end fo the string","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> println(str1)\nThis is how a string is created: \"string\".\n\njulia> println(str2)\n$$$ dollars everywhere $$$","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"There is one exception to using quotes inside a string: quotes without backslashes can be used in multiline strings. Multiline strings can be created using triple quotes syntax as follows","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> mstr = \"\"\"\n       This is how a string is created: \"string\".\n       \"\"\"\n\"This is how a string is created: \\\"string\\\".\\n\"\n\njulia> print(mstr)\nThis is how a string is created: \"string\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"This syntax is usually used for docstring for functions. It is possible to write a string in the same way as it will appear after printing in REPL","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"\"\"\n             Hello,\n             world.\n           \"\"\"\n\"  Hello,\\n  world.\\n\"\n\njulia> print(str)\n  Hello,\n  world.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Create a string with the following text","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Quotation is the repetition or copy of someone else's statement or thoughts. \nQuotation marks are punctuation marks used in text to indicate a quotation. \nBoth of these words are sometimes abbreviated as \"quote(s)\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"and print the string into the REPL. The printed string should look the same as the text above, i.e., each sentence should be on a separate line. Also, use an indent of length 4 for each sentence.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"There are two basic ways to get the right result. The first is to use a multiline string and write the message in the correct form","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"\"\"\n           Quotation is the repetition or copy of someone else's statement or thoughts.\n           Quotation marks are punctuation marks used in text to indicate a quotation.\n           Both of these words are sometimes abbreviated as \"quote(s)\".\n       \"\"\";\n\njulia> println(str)\n    Quotation is the repetition or copy of someone else's statement or thoughts.\n    Quotation marks are punctuation marks used in text to indicate a quotation.\n    Both of these words are sometimes abbreviated as \"quote(s)\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that we do not have to use backslashes to escape quotation marks in the text in this case. The second way is to use a regular string and new line symbol \\n. In this case, it is necessary to use backslashes to escape quotation marks. Also, we have to add four spaces before each sentence to get a proper indentation","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"    Quotation is the repetition or copy of someone else's statement or thoughts.\\n    Quotation marks are punctuation marks used in text to indicate a quotation.\\n    Both of these words are sometimes abbreviated as \\\"quote(s)\\\".\";\n\njulia> println(str)\n    Quotation is the repetition or copy of someone else's statement or thoughts.\n    Quotation marks are punctuation marks used in text to indicate a quotation.\n    Both of these words are sometimes abbreviated as \"quote(s)\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></details>","category":"page"},{"location":"lecture_01/strings/#String-concatenation-and-interpolation","page":"Strings","title":"String concatenation and interpolation","text":"","category":"section"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"One of the most common operations on strings is their concatenation. It can be done using the string function that accepts any number of input arguments and converts them to a single string.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> string(\"Hello,\", \" world\")\n\"Hello, world\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that it is possible to concatenate strings with numbers and other types that can be converted to a string","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> a = 1.123\n1.123\n\njulia> string(\"The variable a is of type \", typeof(a), \" and its value is \", a)\n\"The variable a is of type Float64 and its value is 1.123\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In general, it is not possible to perform mathematical operations on strings, even if the strings look like numbers. However, there are two exceptions. The * operator performs string concatenation","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"Hello,\" * \" world\"\n\"Hello, world\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"This approach can only be applied to Strings, unlike the string function, which also works for other types. The second exception is the ^ operator, which performs repetition","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"Hello\"^3\n\"HelloHelloHello\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The example above is equivalent to calling the repeat function","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> repeat(\"Hello\", 3)\n\"HelloHelloHello\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Using the string function to concatenate strings can lead to too long expressions and be cumbersome. To simplify the construction of strings, Julia allows interpolation into string literals using the $ symbol","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> a = 1.123\n1.123\n\njulia> string(\"The variable a is of type \", typeof(a), \" and its value is \", a)\n\"The variable a is of type Float64 and its value is 1.123\"\n\njulia> \"The variable a is of type $(typeof(a)), and its value is $(a)\"\n\"The variable a is of type Float64, and its value is 1.123\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that we use parentheses to separate expressions that should be interpolated into a string. It is not mandatory, but it can prevent mistakes. In the example below, we can see different results with and without parentheses","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> \"$typeof(a)\"\n       \"$(typeof(a))\"\nERROR: cannot document the following expression:\n\n\"$(typeof(a))\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In the case without parentheses, only the function name is interpolated into the string. In the second case, the result of the expression typeof(a) is interpolated into the string literal. It is more apparent when we declare a variable myfunc that refers to typeof function","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> myfunc = typeof\ntypeof (built-in function)\n\njulia> \"$myfunc(a)\"\n       \"$(myfunc(a))\"\nERROR: cannot document the following expression:\n\n\"$(myfunc(a))\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Both concatenation and string interpolation call string to convert objects into string form. Most non-AbstractString objects are converted to strings closely corresponding to how they are entered as literal expressions","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> v = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> \"vector: $v\"\n\"vector: [1, 2, 3]\"\n\njulia> t = (1,2,3)\n(1, 2, 3)\n\njulia> \"tuple: $(t)\"\n\"tuple: (1, 2, 3)\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Print the following message for a given vector","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\"<vec> is a vector of length <len> with elements of type <type>\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"where <vec> is the string representation of the given vector, <len> is the actual length of the given vector, and <type> is the type of its elements. Use the following two vectors","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"a = [1,2,3]\nb = [:a, :b, :c, :d]","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"We will show two ways how to solve this exercise. The first way is to use the string function in combination with the length function to get the length of the vector and the eltype function to get the type of its elements","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> a = [1,2,3];\n\njulia> str = string(a, \" is a vector of length \",  length(a), \" with elements of type \", eltype(a));\n\njulia> println(str)\n[1, 2, 3] is a vector of length 3 with elements of type Int64","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"The second way is to use string interpolation","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> b = [:a, :b, :c, :d];\n\njulia> str = \"$(b) is a vector of length $(length(b)) with elements of type $(eltype(b))\";\n\njulia> println(str)\n[:a, :b, :c, :d] is a vector of length 4 with elements of type Symbol","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></details>","category":"page"},{"location":"lecture_01/strings/#Useful-functions","page":"Strings","title":"Useful functions","text":"","category":"section"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"A handy function is the join function that performs string concatenation. Additionally, it supports defining a custom separator and a different separator for the last element","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\n\"apples, bananas and pineapples\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"In many cases, it is necessary to split the given string according to some conditions. In such cases, the split function can be used","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"JuliaLang is a pretty cool language!\"\n\"JuliaLang is a pretty cool language!\"\n\njulia> split(str)\n6-element Array{SubString{String},1}:\n \"JuliaLang\"\n \"is\"\n \"a\"\n \"pretty\"\n \"cool\"\n \"language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"By default, the function splits the given string based on spaces. But it can be changed by defining a custom delimiter","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> split(str, \" a \")\n2-element Array{SubString{String},1}:\n \"JuliaLang is\"\n \"pretty cool language!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Julia also provides multiple functions that can be used to find specific characters or substring in the given string. The contains function checks if the string contains a specific substring or character. Similarly, the occursin function determines if the specified string or character occurs in the given string. These two functions differ only in the order of arguments.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> contains(\"JuliaLang is pretty cool!\", \"Julia\")\ntrue\n\njulia> occursin(\"Julia\", \"JuliaLang is pretty cool!\")\ntrue","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"A very useful function is the endswith function, which checks if the given string ends with the given substring or character. It can be used, for example, to check that the file has a proper suffix","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> endswith(\"figure.png\", \"png\")\ntrue","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Sometimes, it is necessary to find indexes of characters in the string based on some conditions. For such cases, Julia provides several find functions","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> str = \"JuliaLang is a pretty cool language!\"\n\"JuliaLang is a pretty cool language!\"\n\njulia> findall(isequal('a'), str)\n5-element Array{Int64,1}:\n  5\n  7\n 14\n 29\n 33\n\njulia> findfirst(isequal('a'), str)\n5\n\njulia> findlast(isequal('a'), str)\n33","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Note that isequal('a') creates a function that checks if its argument is equal to the character a.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"As we said before, strings are immutable and cannot be changed. However, we can easily create new strings. The replace function returns a new string with a substring of characters replaced with something else","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> replace(\"Sherlock Holmes\", \"e\" => \"ee\")\n\"Sheerlock Holmees\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"It is also possible to apply a function to a specific substring using the replace function. The following example shows how to change all e letters in the given string to uppercase","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> replace(\"Sherlock Holmes\", \"e\" => uppercase)\n\"ShErlock HolmEs\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Use the split function to split the following string","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"\"Julia!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"into a vector of single-character strings and convert all these strings to uppercase.","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"Hint: we can say that an empty string separates the characters in the string \"\".","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"To separate a string into separate single-character strings, we can use the split function and an empty string (\"\") as a delimiter. Then, we can use the uppercase function to convert strings to uppercase","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"julia> uppercase.(split(\"Julia!\", \"\"))\n6-element Array{String,1}:\n \"J\"\n \"U\"\n \"L\"\n \"I\"\n \"A\"\n \"!\"","category":"page"},{"location":"lecture_01/strings/","page":"Strings","title":"Strings","text":"</p></details>","category":"page"},{"location":"lecture_03/exceptions/#Exception-Handling","page":"Exception Handling","title":"Exception Handling","text":"","category":"section"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"In many cases, unexpected behavior may occur during running code, which may lead to the situation that some function is unable to return a reasonable value to its caller. In such cases, it may be best for the exceptional condition to either terminate the program while printing a diagnostic error message or, if the programmer has provided code to handle such exceptional circumstances, then allow that code to take the appropriate action.","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"In the following example, we define a factorial function in the same way as we did in the  Short-circuit evaluation section","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"function fact(n)\n    isinteger(n) && n >= 0 || error(\"argument must be non-negative integer\")\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"Note that we use the error function, which will throw the ErrorException if the input argument does not meet the given conditions. This function works quite well and returns a reasonable error message for incorrect input arguments","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"julia> fact(1.4)\nERROR: argument must be non-negative integer\n\njulia> fact(-5)\nERROR: argument must be non-negative integer","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"However, it is better to use error messages that are as descriptive as possible. In this case, the error message only tells us what conditions the argument should meet, but not the value of the argument. Fortunately, Julia provides several predefined types of exceptions that can be used to create more descriptive error messages. In our example, we want to check whether the argument is a non-negative integer. For such a case, we can use more specific DomainError as follows","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"function fact(n)\n    isinteger(n) && n >= 0 || throw(DomainError(n, \"argument must be non-negative integer\"))\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"Note that we must use the throw function because the DomainError(x, msg) function will only create an instance of type DomainError, but will not raise an error.","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"julia> fact(1.4)\nERROR: DomainError with 1.4:\nargument must be non-negative integer\n\njulia> fact(-5)\nERROR: DomainError with -5:\nargument must be non-negative integer","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"The error message now contains a short description, the input argument's value, and the type of expectation. Now imagine that due to an error, the fact function is used to calculate the factorial from a string (or any other non-numeric value)","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"julia> fact(\"a\")\nERROR: MethodError: no method matching isinteger(::String)\nClosest candidates are:\n  isinteger(::BigFloat) at mpfr.jl:859\n  isinteger(::Missing) at missing.jl:100\n  isinteger(::Integer) at number.jl:20\n  ...\nStacktrace:\n [1] fact(::String) at ./REPL[1]:2\n [2] top-level scope at REPL[2]:1","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"In this case, the MethodError is raised for the isinteger function, and the error says nothing about the fact function. We can track that the error occurs when calling the fact function using the Stacktrace section located under the error message. The Stacktrace provides us an ordered list of function calls (from the last one) that preceded the error. In this case, we see that the last function call before the error is fact(:: String). It tells us that the error occurs in the function fact with a string as the input argument. In this particular case, it makes sense to define factorial function only for real numbers. This can be done simply by entering the type of the input argument in the function declaration as follows","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"function fact_new(n::Real)\n    isinteger(n) && n >= 0 || throw(DomainError(n, \"argument must be non-negative integer\"))\n    return n == 0 ? 1 : n * fact(n - 1)\nend","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"This function declaration will only work for arguments of a type that is a subtype of Real. Otherwise, the MethodError will occur","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"julia> fact_new(\"aaa\")\nERROR: MethodError: no method matching fact_new(::String)\n[...]","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"Note that MethodError provides two important pieces of information. The first is that the fact_new function is not defined for arguments of type String. The second one is the list of methods closest to the one we tried to call. In this case, the fact_new function has only one method, which works for any subtype of Real, as can be checked using the methods function","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"julia> methods(fact_new)\n# 1 method for generic function \"fact_new\":\n[1] fact_new(n::Real) in Main at none:1","category":"page"},{"location":"lecture_03/exceptions/","page":"Exception Handling","title":"Exception Handling","text":"A more precise description and a list of all predefined exception types can be found in the official documentation.","category":"page"},{"location":"lecture_04/Plots/#Plots.jl","page":"Plots.jl","title":"Plots.jl","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The Plots package is not a standard plotting package known from other languages. The Plots package provides a unified interface and toolset for creating plots, and the plots themselves are drawed by different backends, like GR, PyPlot, PGFPlotsX, or Plotly. If one backend does not support desired features, it is possible to switch to another backend with one command. No need to change the code. No need to learn a new syntax.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"warning: Time to the first plot\nCompared to Python or Matlab, it takes a lot of time to create the first plot in a new Julia session. In Julia, all functions are compiled at their first run, and the result is that the first run of a function is slow.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The Plots package's core is the plot function that provides an interface for creating all types of plots. The most basic plot style provided by the plot function is line style. The line plot can be created by calling the plot function on two vectors of numbers","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots\nx = range(0, 2π; length = 100)\ny = sin.(x)\nplot(x, y)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The plot is displayed in a plot pane, a stand-alone window, or the browser, depending on the environment and backend, see official documentation for more details. Each column in the given input arguments to the plot function is treated as a separate plot series, i.e., a set of related points that form one line, surfaces, or any other plot type. Thus it is possible to create multiple curves at once","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"y = hcat(sin.(x), cos.(x))\nplot(x, y)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"However, sometimes it is more convenient to add new curves to the existing plot incrementally in many cases. It can be done using the plot! function, which modifies the current plot","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot!(x, sin.(x .+ π/4))","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"By default, the Plots package determines the current plot using the global variable Plots.CURRENT_PLOT. However, it is possible to pass figure that should be modified as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plt = plot(x, hcat(sin.(x), cos.(x)))\nplot!(plt, x, sin.(x .+ π/4))","category":"page"},{"location":"lecture_04/Plots/#Plot-attributes","page":"Plots.jl","title":"Plot attributes","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"So far, we have created several simple plots without any change of style. In reality, we typically want to change the plot appearance based on our preferences. The Plots package provides a large number of plot attributes to change the plot appearance. The package follows a simple rule with data vs. attributes: positional arguments are input data, and keyword arguments are attributes.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"As an example, we can modify the plot of trigonometric functions from the previous section. We will use the following attributes:","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"label: the label for a series, which appears in a legend.\nxguide, yguide: axis guide (label).\nlegend: legend position.\ntitle: plot title.\nxticks: position and labels for ticks.\ncolor: series color.\nlinestyle: style of the line.\nlinewidth: width of the line.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The names of the attributes are in almost all cases intuitive and sufficiently descriptive.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\ny = hcat(sin.(x), cos.(x))\nplot(x, y;\n    label = [\"sine\" \"cosine\"],\n    xguide = \"x\",\n    yguide = \"y\",\n    legend = :bottomleft,\n    title = \"Trigonometric functions\",\n    xticks = (0:0.5π:2π, [\"0\", \"0.5π\", \"π\", \"1.5π\", \"2π\"]),\n    color = [:red :blue],\n    linestyle = [:dash :dot],\n    linewidth = [2 4],\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that we use multiple values for some attributes since we want to use a different setting for different curves. The logic is the same as for input data, i.e., each column corresponds to one series, so we have to use row vectors. However, it is also possible to use column vectors as attributes. In such a case, the different values of the attributes will be applied to data points. For example, in the following example, we create a sine function plot from 1000 data points. As a linewidth attribute, we use a range from 1 to 50 of length 1000, i.e., each point of the resulting curve will be of different width. The same applies to the color attribute. We use the palette function to generate 1000 colors from the viridis color scheme. Then each color is applied to one point of the resulting curve","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"n = 200\nx = range(0, 2π; length = n)\nlinewidth = range(1, 50; length = n)\ncolor = palette(:viridis, n)\nxlims = (0, 7)\nylims = (-1.2, 1.2)\nlabel = \"\"\n\nplot(x, sin.(x); linewidth, color, label, xlims, ylims)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that it is possible to use column vectors and row vectors as attributes at the same time. In the following example, we add a cosine function into the previous plot and set its color to red","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(x, [sin.(x) cos.(x)]; linewidth, color = [color :red], label, xlims, ylims)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"There is a large number of attributes. The Plots package provides the plotattr to print a list of all attributes for either series, plots, subplots, or axes","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(:Series)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The plotattr function accepts any of the following arguments: :Plots, :Series, :Subplot, and :Axis. It is also possible to use the plotattr function to print a concrete attribute description","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"title\")","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that in this case, we use a String instead of Symbol. Be aware that not all attributes are supported. For example, attributes that can be specified for different axes, such as xguide and yguide, are not usually supported","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"xguide\")","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"However, descriptions for these attributes can be found using the attribute name without the axis specification, i.e., for example, guide instead of xguide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plotattr(\"guide\")","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Consider the following set of equations","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"beginaligned\nx(t)  = cos(3t) \ny(t)  = sin(2t)\nendaligned","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"where t in 0 2pi. Create a plot of the curve described by the equations above. Use plot attributes to set the following properties","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The line width of the resulting curve should start at 1 and increase to 50 and then decrease back to 1.\nThe line color of the resulting curve should change with the changing line width.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Use :viridis color scheme or any other color scheme supported by the Plots package. Use additional plot attributes to get a nice looking graph.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Hint: use the pallete function combined with the collect function to generate a vector of colors from the :viridis color scheme.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Firstly, we define the vector t  using the range function with a predefined length","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"n = 1000\nt = range(0, 2π; length = n)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Then we define functions described by the set of equations in the exercise description","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"fx(t) = cos(3t)\nfy(t) = sin(2t)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"We want to use different plot attributes to each point of the resulting curve. Since we know that the resulting curve will be of length 1000, the attributes must be vectors of length 1000. The increase and decrease of the line width can be done using the linewidth argument with values given by the range function as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"linewidth = vcat(\n    range(1, 50; length = n ÷ 2),\n    range(50, 1; length = n - n ÷ 2)\n)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that we use integer division to set the length in the range function. In the same way, we can create a vector of colors. The Plots package provides the palate function that allows generating equidistantly spaced colors from a given color scheme","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"c = palette(:viridis, 2);\ntypeof(c)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"However, as shown in the example above, the palette function returns the ColorPalette type. It is perfectly fine in most cases. However, in our case, we want to concatenate two vectors of colors together. So we have to use the collect function to extract the vector of colors from the ColorPalette type","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"c = collect(palette(:viridis, 2))","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Now we can use a similar code as before in combination with the rev keyword to change the order of colors","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"color = vcat(\n    collect(palette(:viridis, n ÷ 2)),\n    collect(palette(:viridis, n - n ÷ 2; rev = true))\n)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Finally, we can call the plot function with input arguments and attributes defined above. Note that we use axis = nothing and border = :none to remove all decorators such as ticks or axis frame","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(fx.(t), fy.(t);\n    linewidth,\n    color,\n    lims = (-1.2, 1.2),\n    legend = false,\n    axis = nothing,\n    border = :none,\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></details>","category":"page"},{"location":"lecture_04/Plots/#Function-plotting","page":"Plots.jl","title":"Function plotting","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"In the previous section, we used the sine and cosine functions to show the plot function basic functionality. In all previous examples, we first calculated the values of the functions and then created the graphs. However, it is possible to pass functions directly to the plot function","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"t = range(0, 2π; length = 100)\nplot(t, [sin, cos]; label = [\"sine\" \"cosine\"])","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"It is even possible to pass two functions first and then the vector of values in which these function will be evaluated","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(sin, x -> sin(2x), t; linewidth = 2, label = \"\")","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Instead of the vector of values, it is also possible to use the similar syntax as for ranges and to pass the starting, stopping point, and length (the length is optional)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(sin, x -> sin(2x), 0, 2π, 100; linewidth = 2, label = \"\")","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Create a plot given by the following set of equations","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"beginaligned\nx(t)  = (a + b)cos(t) - b cdot cos left( left(fracab + 1 right)t right) \ny(t)  = (a + b)sin(t) - b cdot sin left( left(fracab + 1 right)t right) \nendaligned","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"where a = 423, b = 235 and t in -15 20. Use additional plot attributes to get a nice looking graph.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"This exercise is straightforward. The first thing that we have to do is to define functions described by the set of equations in the exercise description","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"fx(t; a = 4.23, b = 2.35) = (a + b)*cos(t) - b*cos((a/b + 1)*t)\nfy(t; a = 4.23, b = 2.35) = (a + b)*sin(t) - b*sin((a/b + 1)*t)\n\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"We now use the ability of the Plots package to plot functions directly","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(fx, fy, -15, 20, 500;\n    linewidth = 2,\n    legend = false,\n    axis = nothing,\n    border = :none,\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></details>","category":"page"},{"location":"lecture_04/Plots/#Changing-the-Plotting-Series","page":"Plots.jl","title":"Changing the Plotting Series","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"In the previous sections, we used only line plots. However, there are many other series types, such as scatter plots, heatmaps, or contours. One way how to change the plot series is to use the seriestype attribute. In the following example, we create a sine function plot using the scatter series type.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\ny = sin.(x)\nplot(x, y; seriestype = :scatter)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The second way is to use the specialized function. The Plots package provides a specialized function for each series type. These functions have the same name as the corresponding series type. For example, the scatter function can be used instead of the seriestype = :scatter attribute","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"scatter(x, y)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Consider the following function","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"f(x y) = fracx^2 cdot y^2x^4 + y^4","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Draw this function for x y in -5 5. Use the following three plot series contourf, heatmap, and surface with the following settings:","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":":viridis color scheme,\ncamera angle (25, 65),\nno legend, color bar, or decorators (axis, frame and ticks).","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Hint: Removing all decorators is a bit tricky. It can be done using the following attributes: axis = nothing,border = :none.","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"As usual, we first define the function and the values in which the function is to be evaluated","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(-5, 5; length = 200)\nfz(x, y) = x^2*y^2/(x^4 + y^4)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Now, since we want to create three different plots with the same attributes, we can create a named tuple to store the attribute values. It will allow us to reuse the attributes in a simple way","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"kwargs = (\n    color = :viridis,\n    legend = false,\n    cbar = false,\n    axis = nothing,\n    border = :none,\n)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"With defined input arguments and attributes, we can use the plot function with the seriestype = :contourf keyword to draw a filled contour plot or the contourf function","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"contourf(x, x, fz; kwargs...) # or plot(x, x, fz; seriestype = :contourf, kwargs...)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that we use triple-dot syntax to unpack keyword arguments. Recall that in this case, the semi-colon is mandatory. Similarly, we can draw the heatmap plot","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"heatmap(x, x, fz; kwargs...)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"and the 3D surface plot. For the surface plot, we also change the camera angle","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"surface(x, x, fz; camera = (25, 65), kwargs...)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"</p></details>","category":"page"},{"location":"lecture_04/Plots/#Subplots","page":"Plots.jl","title":"Subplots","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Sometimes it is useful to create a plot with a specific layout that contains multiple subplots. The Plots package provides the layout keyword to do it. The primary usage is as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(0, 2π; length = 100)\nplot(x, [sin, cos, tan, sinc];\n    layout = 4,\n    linewidth = 2,\n    legend = false,\n    title = [\"1\" \"2\" \"3\" \"4\"]\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"In the example above, we create four curves at once, and by the layout keyword, we tell to Plots package to draw each curve in a separate subplot. Note that in this case, if we use attributes with multiple values (row vectors), then each value is applied to one subplot. The Plots package also provides the grid function used to create a subplot grid manually with additional properties. For example, we can easily change the grid to 4x1 and set the height of each subplot as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"plot(x, [sin, cos, tan, sinc];\n    layout = grid(4, 1; heights = [0.1 ,0.4, 0.4, 0.1]),\n    linewidth = 2,\n    legend = false\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"It is possible to create even more advanced layouts using the @layout macro. This macro allows creating nonsymmetric grids. In the example below, we create a layout with one subplot on the first row and two subplots on the second row. Moreover, we set the width of the first subplot on the second row to be 0.3 the whole plot width","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"l = @layout [a ; b{0.3w} c]\nplot(x, [sin, cos, tan]; layout = l, linewidth = 2, legend = false)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"All examples above can also be created incrementally. For example, we can reproduce the last example as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"linewidth = range(1, 20; length = 100)\np1 = plot(x, sin; legend = false, line_z = 1:100, color = :viridis, linewidth)\np2 = plot(x, cos; legend = false, line_z = 1:100, color = :Blues_9, linewidth)\np3 = plot(x, tan; legend = false, line_z = 1:100, color = :hsv, linewidth)\nnothing # hide","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Note that we use the line_z keyword that allows applying different colors to the curve's different points in an easy way. When we are happy with the appearance of each plot, we can use the plot function and the layout keyword to create a final plot","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"l = @layout [a ; b{0.3w} c]\nplot(p1, p2, p3; layout = l)","category":"page"},{"location":"lecture_04/Plots/#Animations","page":"Plots.jl","title":"Animations","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"using Plots","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The last thing we will discuss in this lecture is creating animations. In the following example, we will show how to update the existing curve. The first thing we have to do is to create an empty plot a set all attributes we want","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"n = 300\nplt = plot(Float64[], [sin, cos];\n    legend = false,\n    xlims = (0, 6π),\n    ylims = (-1.1, 1.1),\n    linewidth = range(1, 20; length = n),\n    color = palette(:viridis, n),\n    axis = nothing,\n    border = :none\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"The next step is to create an empty animation using the Animation function","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"anim = Animation()","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Finally, we can use a simple for loop and the frame function to create an animation. On the second line, we use the push! function to append new points to the plt plot we defined before. The frame function captures the current state of the plt plot and creates a new frame for the animation","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"for x in range(0, 6π; length = n)\n    push!(plt, x, [sin(x), cos(x)])\n    frame(anim)\nend","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"When the animation is created, we can save it as a gif using the gif function","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"gif(anim, \"animsincos.gif\", fps = 15)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Another way how to create an animation is using the @animate macro. Consider the following 3D surface plot","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"x = range(-5, 5; length = 400)\nfz(x, y) = x^2*y^2/(x^4 + y^4)\nplt = surface(x, x, fz;\n    camera = (30, 65),\n    color = :viridis,\n    legend = false,\n    axis = nothing,\n    border = :none,\n    cbar = false,\n)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"In the following example, we create an animation of the surface defined above, where we change the camera's position in each frame. To change the camera position, we can use the plot! function and the camera keyword arguments as follows","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"anim = @animate for i in vcat(30:60, 60:-1:30)\n    plot!(plt, camera = (i, 65))\nend","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Finally, we can save the animation using the gif  function as in the previous example","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"gif(anim, \"animsurf.gif\", fps = 15)","category":"page"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"(Image: )","category":"page"},{"location":"lecture_04/Plots/#Integration-with-other-packages","page":"Plots.jl","title":"Integration with other packages","text":"","category":"section"},{"location":"lecture_04/Plots/","page":"Plots.jl","title":"Plots.jl","text":"Plots package provides a simple way of defining special plots for custom data types using so-called recipes (in fact, recipes are defined in a stand-alone package RecipeBase). By defining custom recipes, it is possible to change the data preprocessing before they are plotted. Many packages provide specialized plot recipes. For example, StatsPlots provides recipes for plotting histograms and boxplots or violin plots. This package also offers recipes to treat DataFrames and Distributions, allowing simple plotting of tabular data and distributions.","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"using Plots","category":"page"},{"location":"lecture_08/theory/#Theory-of-regression-and-classification","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Regression and classification are a part of machine learning which try to predict certain variables based on labelled data.","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Regression predicts a continuous variable (such as height based on weight).\nClassification predict a variable with a finite number of states (such as cat/dog/none from images).","category":"page"},{"location":"lecture_08/theory/#Linear-regression","page":"Theory of regression and classification","title":"Linear regression","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Linear regression requires a dataset with data points (samples) x_i and labels y_i. It uses a linear classifier to minimize the error between the prediction w^top x_i and the label y_i, that is","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"(w^top x_i - y_i)^2","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Since we are interested in average performance, we sum this (mean square) error over all samples","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"operatornameminimizeqquad sum_i=1^n (w^top x_i - y_i)^2","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Many algorithms use average (mean) instead of sum. However, both these formulations are equivalent.","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"In this case, it is simpler to work in the matrix notation, where we form a matrix X whose rows are the samples x_i. It is not difficult to show that the previous problem is equivalent to","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"operatornameminimizeqquad Xw - y^2","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"where the norm is the l_2 norm. Since this is a convex quadratic problem, it is equivalent to its optimality conditions. Setting the derivative to zero yields","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"2X^top (Xw-y) = 0","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"From here, we obtain the closed-form solution to the linear regression","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"w = (X^top X)^-1X^top y","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"<div class = \"info-body\">\n<header class = \"info-header\">Closed-form solution</header><p>","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Linear regression is probably the only machine learning model with a closed-form solution. All other models must be solved by iterative algorithms such as gradient descent. In some cases, it may be advantageous to use iterative algorithms even for linear regression. This includes, for example, the case of a large number of features m because then X^top X is an mtimes m matrix which may be difficult to invert.","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"</p></div>","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"<div class = \"info-body\">\n<header class = \"info-header\">Linear classifiers</header><p>","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"We realize that","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"w^top x + b = (w b)^top beginpmatrixx  1endpmatrix","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"That means that if we add 1 to each sample x_i, it is sufficient to consider the classifier in the form w^top x without the bias (shift, intercept) b. This allows for simpler implementation.","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"</p></div>","category":"page"},{"location":"lecture_08/theory/#Logistic-regression","page":"Theory of regression and classification","title":"Logistic regression","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"The name logistic regression is misleading because it is actually a classification problem. In its simplest form, it assumes binary labels yin01. It considers the linear classifier f(x)=w^top x and predicts the positive class with probability","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"mathbbP(y=1mid x) = sigma(f(w)) = frac11+e^-w^top x","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"where","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"sigma(z) = frac11+e^-z = frace^z1+e^z","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"is the sigmoid function. The probability of the negative class is then","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"mathbbP(y=0mid x) = 1 - sigma(f(w)) = frace^-w^top x1+e^-w^top x","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Denoting hat y the probabily of predicting 1, the loss function is the cross-entropy loss","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"operatornameloss(yhat y) = - ylog hat y - (1-y)log(1-hat y)","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"It is not difficult to show that then the logistic regression problems reads","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"operatornameminimizeqquad frac1nsum_i=1^nleft(log(1+e^-w^top x_i) + (1-y_i)w^top x_i right)","category":"page"},{"location":"lecture_08/theory/#Numerical-method","page":"Theory of regression and classification","title":"Numerical method","text":"","category":"section"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"The logistic regression can be optimized by Newton's method. Denoting the loss function L(w), its partial derivative with respect to one component equals to","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"beginaligned\nfracpartial Lpartial w_j(w) = frac1nsum_i=1^nleft(-frac11+e^-w^top x_ie^-w^top x_ix_ij + (1-y_i)x_ij right) \n= frac1nsum_i=1^nleft(-frac11+e^w^top x_ix_ij + (1-y_i)x_ij right)\nendaligned","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"where x_ij is the j-th component of x_i (it is also the (ij) entry of matrix X). The second partial derivative amounts to","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"fracpartial^2 Lpartial w_j partial w_k(w) = frac1nsum_i=1^n frac1(1+e^w^top x_i)^2e^w^top x_ix_ijx_ik = frac1nsum_i=1^n hat y_i(1-hat y_i)x_ijx_ik","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"Now we will write it in a more compact notation (recall that x_i is a column vector). We have","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"beginaligned\nnabla L(w) = frac1n sum_i=1^n left((hat y_i-1)x_i + (1-y_i)x_i right) = frac1n sum_i=1^n (hat y_i-y_i)x_i  \nnabla^2 L(w) = frac 1n sum_i=1^nhat y_i(1-hat y_i)x_i x_i^top\nendaligned","category":"page"},{"location":"lecture_08/theory/","page":"Theory of regression and classification","title":"Theory of regression and classification","text":"If the fit is perfect, y_i=hat y_i, then the Jacobian nabla L(w) is zero. Then the optimizer minimized the objective and satisfied the optimality condition.","category":"page"},{"location":"howto/#How-to-use-special-html-elements","page":"How to use special html elements","title":"How to use special html elements","text":"","category":"section"},{"location":"howto/#Exercise","page":"How to use special html elements","title":"Exercise","text":"","category":"section"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"Some text that describes the exercise","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"Solution","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"</p></details>","category":"page"},{"location":"howto/#Info","page":"How to use special html elements","title":"Info","text":"","category":"section"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"<div class = \"info-body\">\n<header class = \"info-header\">???</header><p>","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"Some info","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"</p></div>","category":"page"},{"location":"howto/#Homework","page":"How to use special html elements","title":"Homework","text":"","category":"section"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"<div class = \"homework-body\">\n<header class = \"homework-header\">Homework</header><p>","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"Homework text","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"</p></div>","category":"page"},{"location":"howto/#Theorem","page":"How to use special html elements","title":"Theorem","text":"","category":"section"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">???</header><p>","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"Some info","category":"page"},{"location":"howto/","page":"How to use special html elements","title":"How to use special html elements","text":"</p></div>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"using Plots\n\nf(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nxs = range(-3, 1, length = 40)\nys = range(-2, 1, length = 40)\nf_mod = (x, y) -> f([x; y])","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"f(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]","category":"page"},{"location":"lecture_07/numerical_methods/#Numerical-methods","page":"Numerical methods","title":"Numerical methods","text":"","category":"section"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"This part introduces the most basic optimization algorithm called gradient (or steepest) descent.","category":"page"},{"location":"lecture_07/numerical_methods/#Gradient-descent","page":"Numerical methods","title":"Gradient descent","text":"","category":"section"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"We learnt that the gradient is the direction of steepest descent. The straightforward idea is to move in the opposite direction. This gives rise to the gradient descent algorithm","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"x^k+1 = x^k - alpha^knabla f(x^k)","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The stepsize alpha^k0 can be tuned as a hyperparameter.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"<div class = \"info-body\">\n<header class = \"info-header\">Terminology</header><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"In classical optimization, the usual terminology is:","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Variable is to be optimized.\nParameter is external (fixed) such as material parameters.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"In machine learning, the usual terminology is:","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Parameter is to be optimized.\nHyperparameter is an external model parameter which is not optimized and needs to be tuned. The example is the steplength because the gradient descent finds a different solution for different steplength but it is not changed during the optimization.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The different terminology (and the fact that there are adaptive schemes to select the steplenght which should make it a parameter instead of a hyperparameter) makes the notation confusing.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></div>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Gradient descent</header><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Implement function optim which takes as inputs function f, its gradient, starting point x^0 and fixed stepsize alpha and runs the gradient descent. Its output should be the first 100 iterations.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"This example is rather artificial because usually only the last iteration is returned and some stopping criterion is employed instead of the fixed number of iterations. We want to get all iterations to make visualizations.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"First we need to create an empty array into which we store the iterates. Then at every iteration we compute the gradient g(x), perform the update and save the new value of x. ","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"function optim(f, g, x, α; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    xs[:,1] = x\n    for i in 1:max_iter\n        x -= α*g(x)\n        xs[:,i+1] = x\n    end\n    return xs\nend\nnothing # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p>\n</details>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The implementation does not use the values of f but only its gradient nabla f. Moreover, if the algorithm converges x^k to bar x, then passing to the limit in the gradient update results in nabla f(bar x)=0. Therefore, as most optimization methods, gradient descent looks for stationary points.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Gradient descent</header><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Use the implementation of the gradient descent to minimize the function","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"f(x) = sin(x_1 + x_2) + cos(x_1)^2","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"from the starting point x^0=(0-1) and constant stepsize alpha=01. Store all iterations into matrix xs.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Plot again the contours of f and all iterations xs.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Use one line of code to evaluate the function values for all iterations xs (hint: you need to iterate via eachcol(xs) or eachrow(xs) depending on how you represent xs). Plot these values. ","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"We call optim written in the previous exercise. Then we plot the contours as before. Since x_gd[1,:] stores the x coordinate of all iterations and similarly x_gd[2,:], we plot them. We need to use plot! instead of plot to add the line to the contour plot.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"x_gd = optim([], g, [0; -1], 0.1)\n\ncontourf(xs, ys, f_mod, color = :jet)\n\nplot!(x_gd[1,:], x_gd[2,:], line=(4,:black), label = \"\")\n\nsavefig(\"numer1.svg\") # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"This example is similar to [? for h in hs] encountered earlier. To iterate over all columns, we use [? for x in eachcol(x_gd)] and apply f(x) instead of ?. Another (more complicated) way is to iterate over indices instead of vectors and write [f(x_gs[:,i]) for i in 1:size(x_gd,2)].","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"f_gd = [f(x) for x in eachcol(x_gd)]\n\nplot(f_gd, label=\"\", xlabel=\"Iteration\", ylabel=\"Function value\")\n\nsavefig(\"numer2.svg\") # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></details>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"(Image: )","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"(Image: )","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The convergence looks very nice, and the function value decreases. First, the decrease is faster, but when the iterations get closer to the minimum, it slows down.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"What happens if we choose a different stepsize though? Let us try with two different values. First let us try alpha=001.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"x_gd = optim([], g, [0; -1], 0.01)\n\ncontourf(xs, ys, f_mod, color = :jet)\n\nplot!(x_gd[1,:], x_gd[2,:], line=(4,:black), label = \"\")\n\nsavefig(\"numer3.svg\") # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"(Image: )","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"We see that when the stepsize is reduced, the steps are shorter and we would need to increase the number of iterations (and thus time) to converge. When the stepsize is larger, say alpha=1, the situation is different. ","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"x_gd = optim([], g, [0; -1], 1)\n\ncontourf(xs, ys, f_mod, color = :jet)\n\nplot!(x_gd[1,:], x_gd[2,:], line=(4,:black), label = \"\")\n\nsavefig(\"numer4.svg\") # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"(Image: )","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"For a large stepsize, the algorithm gets close to the solution and then starts jumping around. If we further increase the stepsize, it will even diverge to infinite. Try it.","category":"page"},{"location":"lecture_07/numerical_methods/#Adaptive-stepsize","page":"Numerical methods","title":"Adaptive stepsize","text":"","category":"section"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"To handle this numerical instability, safeguards are introduced. One of the possibilities is the Armijo condition which automatically selects the stepsize. It looks for alpha^k which satisfies","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"f(x^k - alpha^knabla f(x^k)) le f(x^k) - c alpha^k nabla f(x^k)^2","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Here  cin(01) is a small constant, usually c=10^-4. Since the left-hand side is the function value at the new iterate x^k+1, the Armijo condition ensures that the sequence of function values is strictly decreasing. This prevents oscillations.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The implementation of optim(f, g, x, α; max_iter=100) from the exercise above is rather stupid because it does not allow to modify the selection of the step. The simplest fix would be to include if conditions inside the function. However, this would result in a long function, which may be difficult to debug and modify. A more elegant solution is to create an abstract class","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"abstract type Step end","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"and for each possible step selection method implement a optim_step method, which selects the step. First, we create the gradient descent class GD as a subclass of Step by","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"struct GD <: Step\n    α::Real\nend","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"It is a structure with parameter α. Then we create the optim_step function by","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"optim_step(s::GD, f, g, x) = -s.α*g(x)\nnothing # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Due to the first input argument, it will be called only for the  GD stepsize. To access the parameter α, we need to retrieve it from the structure by s.α. Now we can modify the optim function by","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"function optim(f, g, x, s::Step; max_iter=100)\n    for i in 1:max_iter\n        x += optim_step(s, f, g, x)\n    end\n    return x\nend\nnothing # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The specification of the input s::Step allows for any subclass of the abstract class Step. Using this implentation results in","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"gd = GD(0.1)\nx_opt = optim(f, g, [-1;0], gd)\nprintln(x_opt) # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"We obtained the same results as in the previous case. This is not surprising as the code does exactly the same things; it is only written differently. The next exercise shows the power of defining the Step class.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Armijo condition</header><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Implement the Armijo subclass of the Step class. It should have two parameters c from the definition and α_max which will be the initial value of alpha. The value alpha should be divided by two until the Armijo condition is satisfied.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Then run the optimization with the Armijo selection of the stepsize.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"We define the class in the same way as for GD:","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"struct Armijo <: Step\n    c::Real\n    α_max::Real\nend","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"For the search for the stepsize, we first save the values for the function value f(x) and the gradient nabla f(x). If we do not do this, it will be recomputed at every step. Then we initialize the value of alpha and run the while loop until the Armijo condition is satisfied. We added a termination condition (also a safe check) α <= 1e-6 to prevent the loop for continuing indefinitely.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"function optim_step(s::Armijo, f, g, x)\n    fun = f(x)\n    grad = g(x)\n    α = s.α_max\n    while f(x .- α*grad) > fun - s.c*α*(grad'*grad)\n        α /= 2\n        if α <= 1e-6\n            warning(\"Armijo line search failed.\")\n            break\n        end\n    end\n    return -α*grad\nend\nnothing # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"Then we create the Armijo object and run the optimization again.","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"gd = Armijo(1e-4, 1)\nx_opt = optim(f, g, [-1;0], gd)\nnothing # hide","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"</p></details>","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"The correct solution is","category":"page"},{"location":"lecture_07/numerical_methods/","page":"Numerical methods","title":"Numerical methods","text":"println(round.(x_opt, digits=4)) # hide","category":"page"},{"location":"final_project/project/#project","page":"Final project","title":"Final project","text":"","category":"section"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"n_digits = 4\nround_a(x::Number) = round(x, digits=n_digits)\nround_a(x) = round_a.(x)\n\nusing BSON: @load\n\nfile_name = joinpath(\"data\", \"iris.bson\")\n@load file_name X y y_name\n\nusing Random\n\nRandom.seed!(666)\n\nfunction split(X::AbstractMatrix, y::AbstractVector; ratio_train=0.8)\n    @assert size(X,1) == size(y,1)\n    \n    n = size(X,1)\n    n_train = Int.(round(ratio_train*n))\n    i_rand = randperm(n)\n    i_train = i_rand[1:n_train]\n    i_test = i_rand[n_train+1:end]\n\n    return X[i_train,:], y[i_train], X[i_test,:], y[i_test]\nend\n\nusing Statistics\n\nfunction normalize(X_train, X_test)\n    col_means = [mean(X_col) for X_col in eachcol(X_train)]'\n    col_std = [std(X_col) for X_col in eachcol(X_train)]'\n\n    return (X_train .- col_means) ./ col_std, (X_test .- col_means) ./ col_std\nend\n\nfunction onehot(y, classes)\n    y_onehot = zeros(length(classes), length(y))\n    for i in 1:length(classes)\n        y_onehot[i,y.==classes[i]] .= 1\n    end\n    return y_onehot\nend\n\nonecold(y, classes) = [classes[findmax(y_part)[2]] for y_part in eachcol(y)]\n\nfunction m(x, W1, b1, W2, b2)\n    z1 = W1*x .+ b1\n    a1 = max.(z1, 0)\n    z2 = W2*a1 .+ b2\n    a2 = exp.(z2) ./ sum(exp.(z2), dims=1)\nend\n\nloss(y_hat, y; ϵ=1e-10) = -sum(y .* log.(y_hat .+ ϵ), dims=1)\n\nfunction initialize(n1, n2, n3)\n    W1 = randn(n2,n1)\n    b1 = randn(n2)\n    W2 = randn(n3,n2)\n    b2 = randn(n3)\n    return W1, b1, W2, b2\nend\n\nfunction grad(x::AbstractVector, y, W1, b1, W2, b2; ϵ=1e-10)\n    z1 = W1*x .+ b1\n    a1 = max.(z1, 0)\n    z2 = W2*a1 .+ b2\n    a2 = exp.(z2) ./ sum(exp.(z2))\n    l = loss(a2, y; ϵ=ϵ)\n\n    e_z2 = exp.(z2)\n    l_part = (- e_z2 * e_z2' + Diagonal(e_z2 .* sum(e_z2))) / sum(e_z2)^2\n\n    l_a2 = - y ./ (a2 .+ ϵ)\n    l_z2 = l_part * l_a2 \n    l_a1 = W2' * l_z2\n    l_z1 = l_a1 .* (a1 .> 0)\n    l_x = W1' * l_z1\n\n    l_W2 = l_z2 * a1'\n    l_b2 = l_z2\n    l_W1 = l_z1 * x'\n    l_b1 = l_z1\n\n    return l, l_W1, l_b1, l_W2, l_b2\nend\n\nusing LinearAlgebra\nusing Statistics\n\nmean_tuple(d::AbstractArray{<:Tuple}) = [mean([d[k][i] for k in 1:length(d)]) for i in 1:length(d[1])]\n\npredict(X) = m(X, W1, b1, W2, b2)\naccuracy(X, y) = mean(onecold(predict(X), classes) .== onecold(y, classes))","category":"page"},{"location":"lecture_09/exercises/#Exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"homework-body\">\n<header class = \"homework-header\">Homework: Optimal setting</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Perform an analysis of hyperparameters of the neural network from this lecture. Examples may include network architecture, learning rate (stepsize), activation functions or normalization.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Write a short summary (in LaTeX) of your suggestions.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 1: Universal approximation of neural networks</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Proof the theorem about universal approximation of neural networks.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Since piecewise linear functions are dense in the set of continuous functions, there is a piecewise linear function h such that h-g_inftyle varepsilon. Assume that h has kinks at x_1dotsx_n with function values h(x_i)=y_i for i=1dotsn. Defining","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"d_i = fracy_i+1-y_ix_i+1-x_i","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"then h has the form","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"h(x) = y_i + d_i(x-x_i) qquadtext for xin x_ix_i+1","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"It is not difficult to show that","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"h(x) = y_1 + sum_i=1^n(d_i-d_i-1)operatornamemaxx-x_i0","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"where we defined d_0=0.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Then h can be represented as the following network with two layers:","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Dense layer with n hidden neurons and ReLU activation function. Neuron i has weight 1 and bias -x_i.\nDense layer with 1 ouput neurons and identity activation function. Connection i has weight d_i-d_i-1 and the joint bias is y_1.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"This finishes the proof.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 2: Keyword arguments</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Keyword arguments (often denoted as kwargs... but any name may be used) specify additional arguments which do not need to be used when the function is called. We recall the prepare_data function written earlier.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"function prepare_data(X, y; do_normal=true, kwargs...)\n    X_train, y_train, X_test, y_test = split(X, y; kwargs...)\n\n    if do_normal\n        X_train, X_test = normalize(X_train, X_test)\n    end\n\n    X_train = Matrix(X_train')\n    X_test = Matrix(X_test')\n\n    classes = unique(y)\n\n    y_train = onehot(y_train, classes)\n    y_test = onehot(y_test, classes)\n\n    return X_train, y_train, X_test, y_test, classes\nend\nnothing # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"All keyword arguments kwargs will be passed to the split function. They could also be passed to normalize or any other function. The benefit is that we do not need to specify the keyword arguments for split in prepare_data.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Recall that split takes ratio_split as an optional argument. Write an one-line function ratio_train which gets the training and testing sets and computes the ratio of samples in the training set. Then call the prepare_data with:","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"no normalization and default split ratio;\nnormalization and split ratio of 50/50;\nno normalization and split ratio of 50/50.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"The ratio_train function reads","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"ratio_train(X_train, X_test) = size(X_train, 2) / (size(X_train,2) + size(X_test,2))\nnothing # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"For the first call, we want to use the default ratio, hence we do not pass ratio_split. Since we do not want to use normalization, we need to pass do_normal=false.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"X_train, y_train, X_test, y_test, classes = prepare_data(X, y; do_normal=false)\nprintln(\"Ratio train/test = \" * string(ratio_train(X_train, X_test)))","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"For the second call, it is the other way round. We use the default normalization, thus we do not need to specify do_normal=true (even though it may be a good idea to do so). We need to pass ratio_train=0.5.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"X_train, y_train, X_test, y_test, classes = prepare_data(X, y; ratio_train=0.5)\nprintln(\"Ratio train/test = \" * string(ratio_train(X_train, X_test)))","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"For the final call, we need to use both arguments. Note that  do_normal is passed as an optional argument and therefore, its default value will be overwritten while ratio_train is passed in kwargs and goes into the split function.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"X_train, y_train, X_test, y_test, classes = prepare_data(X, y; do_normal=false, ratio_train=0.5)\nprintln(\"Ratio train/test = \" * string(ratio_train(X_train, X_test)))","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 3: Showing the contours</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"The goal of this exercise will be to show the separation graphically. For this reason, we need to consider only two features. The description may be a bit unclear. If you are uncertain, check the correct answer and try to reproduce the graph.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"First, use the same data and the same training procedure as during lecture with the exception that we will consider only the last two features of X. Train the network with five hidden neurons.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Second, write a function rectangles(x, y, r) where x and y are vectors of the same size and r is a positive number. It should return two outputs of size (5,n) where n is length of x and y. Column i of the outputs forms the edges of the rectangle with center (x[i],y[i]) and length 2r. The first and second outputs correspond to x and y coordinates, respectively. For plotting, the outputs need to have five edges (instead of four), where the first and the last one are the same.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Thirs, create a uniform discretization of -22times -22 with grid 01 and convert it into rectangles using the rectangle function. Assign one of three colours (blue, red, green) to each rectangle based on the prediction of its center. Plot all rectangle using the corresponding colour. Use fill=(0,0.2,???), where ??? is the colour. Finally, using the scatter plot, show the testing data in the same colours.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"The procedure for training the network is the same as during the lecture","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"X_train, y_train, X_test, y_test, classes = prepare_data(X[:,3:4], y)\n\nW1, b1, W2, b2 = initialize(size(X_train,1), 5, size(y_train,1))\n\nα = 1e-1\nmax_iter = 1000\nfor iter in 1:max_iter\n    grad_all = [grad(X_train[:,k], y_train[:,k], W1, b1, W2, b2) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n\n    W1 .-= α*grad_mean[2]\n    b1 .-= α*grad_mean[3]\n    W2 .-= α*grad_mean[4]\n    b2 .-= α*grad_mean[5] \nend\n\nnothing # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"For the rectangles function, we first create realize that if a rectangle is centered at zero, its x and y coordinates are [-r; r; r; -r; -r] and [-r; -r; r; r; -r], respectively. Then we reshape the input x vector into a row vector and move the rectangle derived above into the proper center. Note that the implementation adds a column vector reshape(x, 1, :) and a row vector [-r; r; r; -r; -r]. The result is a matrix with an appropriate dimension.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"function rectangles(x::AbstractVector, y::AbstractVector, r::Number)\n    xs = reshape(x, 1, :) .+ [-r; r; r; -r; -r]\n    ys = reshape(y, 1, :) .+ [-r; -r; r; r; -r]\n    return xs, ys\nend\n\nnothing # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"To create the discretization, we first discretize the x axis via x = collect(-2:x_diff:2). To get the grid, we then create all combinations of x with x. To have a proper dimension for the neural network, it should be dimension (1,n^2). Finally, we evaluate all these points via the model m and convert the one-hot into the one-cold representation.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"x_diff = 0.1\nx = collect(-2:x_diff:2)\nn = length(x)\nxy = hcat(repeat(x, n, 1), repeat(x', n, 1)[:])'\nz = m(xy, W1, b1, W2, b2)\nz = onecold(z, classes)\n\nnothing # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Finally, for plotting, we first define the three colours as three symbols. Then we create a loop over all three classes. In the first plot, we need to call plot while in the remaining ones, we call plot!. For each predicted class, we find the indices with the predicted class z.==classes[i] and plot the corresponding rectangles. Besides the fill parameter, we specify the line as well via line. For the prediction on the testing set, we repeat the same procedure. This time the indices are found by onecold(y_test, classes) .== classes[i] and we use the scatter plot. We specify the marker for a better visualization.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\n\ncolours = (:blue, :red, :green)\n\nfor i in 1:length(classes)\n    i == 1 ? p = plot : p = plot!\n    ii1 = z .== classes[i]\n    ii2 = onecold(y_test, classes) .== classes[i]\n    p(rectangles(xy[1,ii1], xy[2,ii1], x_diff/2)..., line=(0, 0.2, colours[i]), fill=(0, 0.2, colours[i]), label=\"\")\n    scatter!(X_test[1,ii2][:], X_test[2,ii2][:], marker=(8, 0.8, colours[i]), label=y_name[classes[i]], legend=:topleft)\nend\n\nsavefig(\"Separation.svg\") # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 4: Overfitting</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"This exercise will show the well-known effect of overfitting. Since the model sees only the testing set, it may happen that it fits it too perfectly (overfits it) and generalizes poorly to unseen examples (testing set).","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"As in the previous exercise, consider only the last two features and train the network with 50 hidden neurons for 5000 iterations. Plot the evolution of the objective (loss) function on the training and testing sets.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Make two countour plots as in the previous exercise. The first one depicts the scatter plot for the testing set while the second one depicts it for the training set. Describe what went wrong.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"The first part of the exercise is the same as before. The only change is that we need to save the training and testing objective. Note that the training loss could be extracted from grad_all. ","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"X_train, y_train, X_test, y_test, classes = prepare_data(X[:,3:4], y)\n\nW1, b1, W2, b2 = initialize(size(X_train,1), 50, size(y_train,1))\n\nα = 1e-1\nmax_iter = 5000\nL_train = zeros(max_iter)\nL_test = zeros(max_iter)\nfor iter in 1:max_iter\n    grad_all = [grad(X_train[:,k], y_train[:,k], W1, b1, W2, b2) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n    \n    W1 .-= α*grad_mean[2]\n    b1 .-= α*grad_mean[3]\n    W2 .-= α*grad_mean[4]\n    b2 .-= α*grad_mean[5] \n\n    L_train[iter] = mean(loss(m(X_train, W1, b1, W2, b2), y_train)[:])\n    L_test[iter] = mean(loss(m(X_test,  W1, b1, W2, b2), y_test)[:])\nend","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Then we plot it. We ignore the first nine iterations. ","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"plot(L_train[10:end], xlabel=\"Iteration\", label=\"Training loss\", legend=:topleft)\nplot!(L_test[10:end], label=\"Testing loss\")\n\nsavefig(\"Train_test.svg\") # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"We see the classical procedure of overfitting. While the loss function on the training set decreases steadily, on the testing set, it decreases first and after approximately 100 iterations, it starts increasing. This behaviour may be prevented by several techniques which we discuss in the next lecture. ","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"We create the contour plot in the same way as in the previous exercise.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"z = m(xy, W1, b1, W2, b2)\nz = onecold(z, classes)\n\nfor i in 1:length(classes)\n    i == 1 ? p = plot : p = plot!\n    ii1 = z .== classes[i]\n    ii2 = onecold(y_test, classes) .== classes[i]\n    p(rectangles(xy[1,ii1], xy[2,ii1], x_diff/2)..., line=(0, 0.2, colours[i]), fill=(0, 0.2, colours[i]), label=\"\", title=\"Testing set\")\n    scatter!(X_test[1,ii2][:], X_test[2,ii2][:], marker=(8, 0.8, colours[i]), label=y_name[classes[i]], legend=:topleft)\nend\nsavefig(\"Over1.svg\") # hide\n\nfor i in 1:length(classes)\n    i == 1 ? p = plot : p = plot!\n    ii1 = z .== classes[i]\n    ii2 = onecold(y_train, classes) .== classes[i]\n    p(rectangles(xy[1,ii1], xy[2,ii1], x_diff/2)..., line=(0, 0.2, colours[i]), fill=(0, 0.2, colours[i]), label=\"\", title=\"Training set\")\n    scatter!(X_train[1,ii2][:], X_train[2,ii2][:], marker=(8, 0.8, colours[i]), label=y_name[classes[i]], legend=:topleft)\nend\n\nsavefig(\"Over2.svg\") # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"We see that the separation on the testing set is very good but it could be better for the two bottommost green circles (iris virginica). The model predicted (in background) the red color (iris versicolor) there. This is wrong. The reason is clear from the picture depicting the training set. The classifier tried to fit perfectly the boundary between the green and red points, making a outward-pointing tip there from otherwise a rather flat boundary. This is precisely overfitting and the reason of the misclassification on the testing set.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"plot(L_train, xlabel=\"Iteration\", label=\"Training loss\", legend=:topleft) # hide\nplot!(L_test, label=\"Testing loss\") # hide\n\nsavefig(\"Train_test0.svg\") # hide","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 5: Generalization</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Compare the contour plots from Exercises 2 and 3. They are strikingly different, especially in the top-left and bottom-right corners. Why is that?","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"Since the dataset does not contain any data in the top-left or bottom-right corners, it does not know what to put there. From its perspective, both separations are very good. This raises an important take-away message.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"info-body\">\n<header class = \"info-header\">Generalization</header><p>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"If a classifier does not have any data in some region, it may predict anything there. Including predictions with no sense.","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_09/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_12/ode/#Wave-equation","page":"Wave equation","title":"Wave equation","text":"","category":"section"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Wave equation is one of the most important differential equation. It models propagation of waves and has numerous applications in acoustics, electromagnetics or fluid dynamics.","category":"page"},{"location":"lecture_12/ode/#Statement","page":"Wave equation","title":"Statement","text":"","category":"section"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"We consider the simplest case of one-dimensional wave equation such as a string. The wave equation on tin0T has the form","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"fracpartial^2 y(tx)partial t^2 = c^2 fracpartial^2 y(tx)partial x^2","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The function y0Ttimes 0Ltomathbb R describes the displacement of the string. To obtain a complete formulation, we need to add boundary (in space) and initial (in time) conditions. Assuming that the string is fixed on its edges, the boundary conditions","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"y(cdot0) = y_0 quad y(cdotL) = y_L","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"are time-independent. The initial conditions are prescribed by functions","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"beginaligned\ny(0cdot) = f(cdot) \nfracpartial y(0cdot)partial t = g(cdot)\nendaligned","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"which vary in space. For consistency, we need f(0)=y_0 and f(L)=y_L.","category":"page"},{"location":"lecture_12/ode/#Solving-the-wave-equation","page":"Wave equation","title":"Solving the wave equation","text":"","category":"section"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The following few exercises show how to solve the wave equation via the finite differences technique.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Design a numerical method to solve the one-dimensional wave equation on 0Ttimes 0L by applying finite differences in time and space. Derive the formulas.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"To discretize, we need to choose stepsizes Delta t and Delta x. For simplicity, we assume that the discretization is uniform (the length of the interval T can be divided by the time step Delta t and similarly for L and Delta x). ","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The initial conditions prescribe the value","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"y(0x) = f(x)","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"for all xin0Delta x2Delta xdotsL. For the values at Delta t, we approximate the initial condition for the derivative by the finite difference and get ","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"y(Delta t x) = y(0 x) + Delta t g(x)","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Since the finite difference approximation of the first derivative is","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"fracpartial y(tx)partial t approx fracy(t + Delta tx) - y(tx)Delta t","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"the finite difference approximation of the second derivative can be obtained in the same way by","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"beginaligned\nfracpartial^2 y(tx)partial t^2 = frac1Delta tleft(fracy(t + Delta tx) - y(tx)Delta t - fracy(tx) - y(t-Delta tx)Delta tright) \n= fracy(t+Delta tx) - 2y(tx) + y(t-Delta tx)Delta t^2\nendaligned","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Doing the same discretization for x and plugging the result into the wave equation yields","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"fracy(t+Delta tx) - 2y(tx) + y(t-Delta tx)Delta t^2 = c^2 fracy(tx+Delta x) - 2y(tx) + y(tx-Delta x)Delta x^2","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The computation now is the same as for a normal ODE. We know the initial state y(cdot0), then we compute y(cdotDelta t), then y(cdot 2Delta t) and so on. These states can be computed by rearranging the previous formula to","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"y(t + Delta tx) = fracc^2Delta t^2Delta x^2  Big(y(tx + Delta x) - 2y(tx) + y(tx - Delta x)Big) + 2y(tx) - y(t - Delta tx)","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"This formula can be applied for t=2Delta t 3Delta t dotsT.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></details>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Before writing any code, it may be a good idea to decide on its structure. The following exercise aims to do so.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Write function declaration (function name, inputs and outputs) which will be needed to solve the wave equation and to plot the solution. Do not write any code.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Before we can solve the wave equation, we need to perform discretization of time and space. We write the discretize function, whose inputs are the limits xlims. We use optional keyword arguments, which may specify the stepsize or the number of discretized points. The output will be the discretization xs. Even though we denote all inputs and outputs with x, this function will be used for time as well.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function discretize(xlims; kwargs...)\n    ...\n    return xs\nend","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The simplest way to work with objects with lots of parameters, is to create a structure to save these parameters. We therefore create struct Wave with fields f, g and c. We do not use the boundary values y_0 and y_L as they can be computed from f.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"struct Wave\n    f\n    g\n    c\nend","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The wave equation is solved in solve_wave(ts, xs, wave::Wave). Its inputs are the time discretization ts, the space discretization xs and the wave parameters stored in wave. It returns a matrix y with dimensions equals the number of time and space points.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function solve_wave(ts, xs, wave::Wave)\n    ...\n    return y\nend","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Finally, to plot, we define plot_wave function, where the inputs are the computed wave equation y and a name file name file_name to save the animation to. The optional arguments can be the number of frames per second fps and any additional arguments used for plotting.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function plot_wave(y, file_name; fps=60, kwargs...)\n    ...\n    return nothing\nend","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></details>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The most difficult part is done. We have done the thinking and finished the code structure. Now we just need to do manual labour and fill the empty functions with code.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"struct Wave\n    f\n    g\n    c\nend","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Write the functions from the previous exercise. Do not forget to include any pacakges needed.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The discretization will use the range function. We pass to it the keyword arguments, which will usually be either the length of the sequence length or the discretization step step. To obtain an array, we use the collect function. If the step is specified, the last point of xs may be different from xlims[2]. In such a case, we add it and throw a warning.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"using Plots\nusing LinearAlgebra\n\nfunction discretize(xlims; kwargs...)\n    xs = range(xlims[1], xlims[2]; kwargs...) |> collect\n    if xs[end] != xlims[2]\n        @warn \"Discretization not equidistant.\"\n        push!(xs, xlims[2])\n    end\n    return xs\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"To solve the wave equation, we first perform a check that both discretizations are uniform. The better way would be to write a function which admits a non-equidistant discretization but we did not derive the formulas for it. If ts is equidistant, then diff(ts) should be a vector of constants and therefore diff(diff(ts)) should be a vector of zeros. ","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Then we initialize y with zeros and set the initial condition y[1,:] via wave.f and the boundary conditions y[:,1] and y[:,end] which are fixed and, therefore, the same as y[1,1] and y[1,end], respectively. We recall that the formulas for computing the solution are","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"beginaligned\ny(Delta t x) = y(0 x) + Delta t g(x) \ny(t + Delta tx) = fracc^2Delta t^2Delta x^2  Big(y(tx + Delta x) - 2y(tx) + y(tx - Delta x)Big) + 2y(tx) - y(t - Delta tx)\nendaligned","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Since the boundary conditions are prescribed, we set the first condition to y[2,2:end-1] and the other to y[i+1,2:end-1].","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function solve_wave(ts, xs, wave::Wave)\n    norm(diff(diff(ts))) <= 1e-10 || error(\"Time discretization must be equidistant.\")\n    norm(diff(diff(xs))) <= 1e-10 || error(\"Space discretization must be equidistant.\")\n\n    n_t = length(ts)\n    n_x = length(xs)\n    \n    y = zeros(n_t, n_x)    \n    y[1,:] = wave.f.(xs)\n    y[:,1] .= y[1,1]\n    y[:,end] .= y[1,end]\n    y[2,2:end-1] = y[1,2:end-1] + (ts[2]-ts[1])*wave.g.(xs[2:end-1])\n\n    s = wave.c^2 * (ts[2]-ts[1])^2 / (xs[2]-xs[1])^2\n    for i in 2:n_t-1\n        y[i+1,2:end-1] .= s*(y[i,3:end]+y[i,1:end-2]) + 2*(1-s)*y[i,2:end-1] - y[i-1,2:end-1]\n    end\n    return y\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"The best visualization of the wave equation is via an animation. Each frame will be a plot of a row of y. We use the keyword arguments kwargs. We run the for loop over all rows, create the animation via the @animate macro and save it into anim. To save the animation to the hard drive, we use the gif function, for which we specify fps.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function plot_wave(y, file_name; fps=60, kwargs...)\n    anim = @animate for y_row in eachrow(y)\n        plot(y_row; kwargs...)\n    end\n    gif(anim, file_name, fps=fps)\n    return nothing\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></details>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Now we can finally plot the solution.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Solve the wave equation for L=frac32pi, T=240, c=002 and the initial conditions","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"beginaligned\nf(x) = 2e^-(x-frac L2)^2 + fracy_LLx \ng(x) = 0\nendaligned","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Do the time discretization with stepsize Delta t=1 and the space discretization with N_x=101 and N_x=7 steps (plot two graphs, each for one N_x).","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"First, we assign the parameters","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"f(x,L,y_L) = 2*exp(-(x-L/2)^2) + y_L*x/L\ng(x) = 0\n\nL = 1.5*pi\nT = 240\nc = 0.02\ny_L = 1\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Since we want to do the same task for two different N_x, we write a function run_wave, which performs the discretizations, creates the Wave structure, solves the wave equation and finally plots the wave. We use different keywords for the discretize function as we have stepsize for the temporal discretization and number of steps for the spatial discretization.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"function run_wave(L, T, Δ_t::Float64, N_x::Int64, file_name; kwargs...)\n    ts = discretize((0,T); step=Δ_t)\n    xs = discretize((0,L); length=N_x)\n    wave = Wave(x -> f(x,L,y_L), g, c)\n\n    y = solve_wave(ts, xs, wave)\n    plot_wave(y, file_name; kwargs...)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"Now we call this function with different values of N_x. All keyword arguments are passed to the plot function inside plot_wave.","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"run_wave(L, T, 1., 101, \"wave1.gif\"; ylims=(-2,3), label=\"\")\nrun_wave(L, T, 1., 7, \"wave2.gif\"; ylims=(-2,3), label=\"\")\n\nnothing # hide","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"</p></details>","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"(Image: )","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"(Image: )","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"If you see these two waves in different phases (positions), please refresh the page (the animations have already run for some time and the error accumulated).","category":"page"},{"location":"lecture_12/ode/","page":"Wave equation","title":"Wave equation","text":"After the potential reload, the waves should start from the same location and move at the same speed. This is an important property of any physical system: it is consistent. If we use a different discretization, their behaviour should be roughly similar. Of course, the finer spatial discretization results in smoother lines but both waves have similar shapes and move at similar speeds. If we see that one moves two times faster, there is a mistake in the code.","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"using Plots\n\nfunction create_anim(f, path, xlims, ylims; file_name = \"\", fps=15)\n    xs = range(xlims...; length = 100)\n    ys = range(ylims...; length = 100)\n    plt = contourf(xs, ys, f, color = :jet, axis = false, ticks = false, cbar = false)\n\n    # adds an empty plot to plt\n    plot!(Float64[], Float64[]; line = (4, :black), label = \"\")\n    \n    # extracts last plot series\n    plt_path = plt.series_list[end]\n    \n    # creates the  animation\n    anim = Animation()\n    for x in eachcol(path)\n        push!(plt_path, x[1], x[2]) # add new point to plt_grad\n        frame(anim)\n    end\n    gif(anim, file_name, fps = fps)\n    return nothing\nend\n\nf(x) = sin(x[1] + x[2]) + cos(x[1])^2\ng(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]\n\nf(x1,x2) = f([x1;x2])","category":"page"},{"location":"lecture_07/constrained/#lagrangian","page":"Constrained optimization","title":"Constrained optimization","text":"","category":"section"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The usual formulation of constrained optimization is","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"tagP\nbeginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad g_i(x) le 0 i=1dotsI \nh_j(x) = 0 j=1dotsJ\nendaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"This optimization problem is also called the primal formulation. It is closely connected with the Lagrangian","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"L(xlambdamu) = f(x)  + sum_i=1^I lambda_i g_i(x) + sum_j=1^J mu_j h_j(x)","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Namely, it is simple to show that the primal formulation (P) is equivalent to","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"operatorname*minimize_xquad operatorname*maximize_lambdage 0muquad L(xlambdamu)","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The dual problem then switches the minimization and maximization to arrive at","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"tagD operatorname*maximize_lambdage 0mu quadoperatorname*minimize_xquad L(xlambdamu)","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"<div class = \"info-body\">\n<header class = \"info-header\">Linear programming</header><p>","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The linear program","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ntextminimizeqquad c^top x \ntextsubject toqquad Ax=b \nxge 0\nendaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"is equivalent to","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ntextmaximizeqquad b^top mu \ntextsubject toqquad A^top mule c\nendaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We can observe several things:","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Primal and dual problems switch minimization and maximization.\nPrimal and dual problems switch variables and constraints.","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The optimality conditions for constrained optimization take a more complex form.","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">Theorem: Karush-Kuhn-Tucker conditions</header><p>","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Let f, g_i and h_j be differentiable function and let a constraint qualification hold. If x is a local minimum of the primal problem (P), then there are lambdage 0 and mu such that","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"    beginaligned\n    textOptimality  nabla_x L(xlambdamu) = 0 \n    textFeasibility  nabla_lambda L(xlambdamu)le 0 nabla_mu L(xlambdamu) = 0 \n    textComplementarity  lambda^top g(x) = 0\n    endaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"If f and g are convex and h is linear, then every stationary point is a global minimum of (P).","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"</p></div>","category":"page"},{"location":"lecture_07/constrained/#Numerical-method","page":"Constrained optimization","title":"Numerical method","text":"","category":"section"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We present only the simplest method for constraint optimization. Projected gradients ","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ny^k+1 = x^k - alpha^knabla f(x^k) \nx^k+1 = P_X(y^k+1)\nendaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"compute the gradient as for standard gradient descent, and then project the point onto the feasible set. Since the projection needs to be simple to compute, projected gradients are used for simple sets X such as boxes or balls. ","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"We will use projected gradients to solve","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"beginaligned\ntextminimizeqquad sin(x_1 + x_2) + cos(x_1)^2 \ntextsubject toqquad x_1 x_2in -11\nendaligned","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The implementation of projected gradients is the same as gradient descent but it needs projection function P as input. For reasons of plotting, it returns both x and y.","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"function optim(f, g, P, x, α; max_iter=100)\n    xs = zeros(length(x), max_iter+1)\n    ys = zeros(length(x), max_iter)\n    xs[:,1] = x\n    for i in 1:max_iter\n        ys[:,i] = xs[:,i] - α*g(xs[:,i])\n        xs[:,i+1] = P(ys[:,i])\n    end\n    return xs, ys\nend\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The projection function P computes the projection on [x_min, x_max]. Since it is a box, the projection is computed componentwise:","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"P(x, x_min, x_max) = min.(max.(x, x_min), x_max)\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"Now we can call projected gradients from the same starting point as before","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"x_min = [-1; -1]\nx_max = [0; 0]\n\nxs, ys = optim(f, g, x -> P(x,x_min,x_max), [0;-1], 0.1)\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"To plot the path, we need to merge them together when one point from xs is followed by a point from ys and so on. Since xs and ys have different number of entries, we can do it via","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"xys = hcat(reshape([xs[:,1:end-1]; ys][:], 2, :), xs[:,end])\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"It is probably not the nicest thing to do, but it is Saturday evening, I am tired and it works. Sorry :) The animation can be created in the same way aa before. ","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"xlims = (-3, 1)\nylims = (-2, 1)\n\ncreate_anim(f, xys, xlims, ylims; file_name = \"anim6.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"There is one significant drawback to this animation: One cannot see the boundary. One possibility would be to reduce the plotting ranges xlims and ylims. However, then one would not see the iterations outside of the box. Another possibility is to modify f into f_mod which has the same values inside the box and is constant outside of it. Because f is bounded below by -1, we define f_mod by -2 outside of the box. ","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"f_mod(x) = all(x .>= x_min) && all(x .<= x_max) ? f(x) : -2\nf_mod(x1,x2) = f_mod([x1; x2])\n\ncreate_anim(f_mod, xys, xlims, ylims; file_name = \"anim7.gif\")\n\nnothing # hide","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"(Image: )","category":"page"},{"location":"lecture_07/constrained/","page":"Constrained optimization","title":"Constrained optimization","text":"The animation shows that projected gradients converge to the global minimum. Most of the iterations are outside of the feasible region but they are projected back to boundary. ","category":"page"},{"location":"lecture_04/basics/#Package-management","page":"Package Management","title":"Package management","text":"","category":"section"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Julia provides a simple and intuitive built-in package manager Pkg.jl, that handles operations such as installing, updating, and removing packages. The package manager provides an interactive Pkg REPL, which simplifies the package management process. The Pkg REPL can be entered from the Julia REPL simply by pressing ]. To get back to the Julia REPL, press backspace or ^C. After entering the Pkg REPL, the screen similar to the following one should appear","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg>","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Registered packages can be installed using the add keyword in the following way","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg> add JSON BSON","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Note that it is possible to install multiple packages at once simply by entering their names separated by a space. It is also possible to install the unregistered package using the add keyword. However, in this case, we have to specify the package URL","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg> add https://github.com/JuliaLang/Example.jl","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"To list all installed packages, we can use the status keyword or its shorthand st","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg> st\nStatus `~/.julia/environments/v1.5/Project.toml`\n  [fbb218c0] BSON v0.2.6\n  [7876af07] Example v0.5.4 `https://github.com/JuliaLang/Example.jl#master`\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"If we want to update some package (for example, because the new version was released), we can do it using the update keyword followed by the package name","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg> update Example","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"If the package name is not provided, all installed packages will be updated. Note that, in this case, even the unregistered packages are update based on their name. The difference between managing the registered and the unregistered package is only during installation.","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Any installed package can be removed using the rm keyword similarly as the installation works","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(@v1.5) pkg> rm Example","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"<div class = \"info-body\">\n<header class = \"info-header\">Non-interactive package manager</header><p>","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"The package manager can also be used in a non-interactive way. For example, packages can be installed in the following way","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"using Pkg\nPkg.add([\"JSON\", \"BSON\"])\nPkg.add(url = \"https://github.com/JuliaLang/Example.jl\")","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Updating and removing a package can be done in a similar way.","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"</p></div>","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"<div class = \"info-body\">\n<header class = \"info-header\">JuliaHub</header><p>","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"JuliaHub is a web service provided by Julia Computing that allows you to explore the ecosystem, build packages, and run code in the cloud on large machines and clusters on demand. The most important feature for beginners is the possibility to explore packages, documentation, repositories, or codes in a simple unified way.","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"</p></div>","category":"page"},{"location":"lecture_04/basics/#Enviroments","page":"Package Management","title":"Enviroments","text":"","category":"section"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"So far, we have dealt with the basic management of packages: adding, updating, or removing packages. However, Julia's package manager offers significant advantages over traditional package managers by organizing dependencies into environments. Environments should be familiar to people who use Python. The difference between Python and Julia is that it is effortless to create and manage environments in Julia. Of course, some utilities simplify the work with environments in Python, such as the Conda package manager. However, in Julia, it is still more convenient, and the whole process of creating and managing environments can be done within Julia itself.","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"You may have noticed the (v1.5) in the REPL prompt. It indicates that the active environment is v1.5.  The active environment is the environment that will be modified by Pkg commands such as add, rm or update. A new environment can be set up using the activate keyword followed by the absolute or relative path","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"julia> mkdir(\"./tutorial\") # create an empty folder tutorial\n\"./tutorial\"\n\n(@v1.5) pkg> activate ./tutorial/\n Activating new environment at `/tutorial/Project.toml`\n\n(tutorial) pkg>","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"In the example above, we create an empty directory tutorial and activate a new environment inside this directory. Note that the prompt in the package REPL changed from @v1.5 to tutorial. It indicates that tutorial is the active environment, i.e., this environment will be modified by Pkg commands. Now we can check the status of the environment using the status keyword","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(tutorial) pkg> status\nStatus `/tutorial/Project.toml` (empty project)","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"Note that the path printed by the status command (/tutorial/Project.toml) is the location of the Project.toml corresponding to the active environment. A Project.toml is a file where the package manager stores metadata for the environment. Because we have not yet added any packages to the environment, the Project.toml is not created yet","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"julia> readdir(\"./tutorial\") # returns and empty array since tutorial is an empty folder\nString[]","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"We can install packages to the tutorial environment in the same way as we did it in the section above","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"(tutorial) pkg> add JSON BSON\n\n(tutorial) pkg> st\nStatus `/tutorial/Project.toml`\n  [fbb218c0] BSON v0.2.6\n  [682c06a0] JSON v0.21.1","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"We can see that two packages were installed in the environment, and we can also check that the project file was created.","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"julia> readdir(\"./tutorial\")\n2-element Array{String,1}:\n \"Manifest.toml\"\n \"Project.toml\"","category":"page"},{"location":"lecture_04/basics/","page":"Package Management","title":"Package Management","text":"The Project.toml describes the project on a high level. For example, the package/project dependencies and compatibility constraints are listed in the Project.toml file. The Manifest.toml file is an absolute record of the state of the packages used in the environment. It includes exact information about (direct and indirect) dependencies of the project. Given a Project.toml + Manifest.toml pair, it is possible to instantiate the exact same package environment, which is very useful for reproducibility.","category":"page"},{"location":"why/#Why-julia?","page":"Why Julia?","title":"Why julia?","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"There are a lot of established programming languages like Python, Matlab, R, or C. So when a new language is introduced, it is natural to ask, why should I learn this new language? What are the advantages and disadvantages of this language? In this section, we will try to introduce the major advantages and disadvantages of Julia and compare Julia to Python, Matlab, R, or C.","category":"page"},{"location":"why/#Intuitive-and-flexible-syntax","page":"Why Julia?","title":"Intuitive and flexible syntax","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Julia provides very intuitive and yet flexible syntax, that allows users to write relatively complicated functions in a simple and readable way. As an example, we can compare the definition of the function that computes the Fibonacci number in different languages. In Matlab, the naive implementation of such function is as follows","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function f = fib(n)\n    if n < 2\n        f = n;\n    else\n        f = fib(n-1) + fib(n-2);\n    end\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Note that we do not check if the input argument is a non-negative integer. Using the Python, we get the following implementation","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"def fib(n):\n    if n<2:\n        return n\n    return fib(n-1) + fib(n-2)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"and if we use the C language the function definition is following","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"int fib(int n) {\n    return n < 2 ? n : fib(n-1) + fib(n-2);\n}","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We see that all three implementations are very different. Surprisingly, the implementation in C is the shortest one. The reason is, that in C it is possible to use the ternary operator. In Matlab, it is possible to write the if-else statement on one line, however, it will decrease the code readability. Implementation of the Fibonacci function in Julia is the following","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"fib(n::Int) = n < 2 ? n : fib(n-1) + fib(n-2)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"But it is also possible to use traditional multiline function declaration syntax","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function fib(n::Int)\n    if n < 2\n        return n\n    else\n        return fib(n-1) + fib(n-2)\n    end\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Note that annotation of the input argument type and use of the return keyword is optional and can be omitted. What we can see it, that Julia supports different syntax for defining functions. It is very useful because it is possible to write simple functions on one line and use a multiline syntax for more complicated functions. Additionally, the authors of Julia took inspiration from other languages and the result is, that Julia provides many handy features known from other languages. For example:","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The syntax of matrix operations are inspired by the one in Matlab.\nStatistical packages use similar syntax to the packages in R.\nIt is possible to use list comprehensions and generators like in Python.","category":"page"},{"location":"why/#Type-system-and-Multiple-Dispatch","page":"Why Julia?","title":"Type system and Multiple-Dispatch","text":"","category":"section"},{"location":"why/#Performance","page":"Why Julia?","title":"Performance","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"One of the most obvious advantages of Julia is its speed. Since Julia uses just-in-time compilation it is possible to achieve the performance of C without using any special tricks or packages. It can be seen in the following figure which shows speed comparison of various languages in multiple micro-benchmarks. The full description of these micro-benchmarks can be found on the official Julia Micro-Benchmarks webpage.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"These micro-benchmarks test performance on a range of common code patterns, such as function calls, string parsing, sorting, numerical loops, random number generation, recursion, and array operations. It is important to say that the used benchmark codes are not optimized for maximal performance. Instead, the benchmarks are written to test the performance of identical algorithms and code patterns implemented in each language. In the following figure, we can see the computational time increase against the C language for several benchmark functions.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"(Image: )","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"It is fair to say, that in many cases it is possible to improve the performance of other languages using simple tricks. For example, the performance of Python can be improved using Numba, an open-source JIT compiler that translates a subset of Python and NumPy into fast machine code using LLVM compiler. Since both Numba and Julia use the same compiler, it is interesting to compare the performance of Julia and Python+Numba.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"For the comparison consider the following example of estimating pi using Monte Carlo sampling originally posted here. A naive implementation of such estimation in pure Python 3.8.5 (using NumPy for the random number generator) is as follows","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"import numpy as np\n\ndef estimate_pi(n):\n    n_circle = 0\n    for i in range(n):\n        x = 2*np.random.random() - 1\n        y = 2*np.random.random() - 1\n        if np.sqrt(x**2 + y**2) <= 1:\n           n_circle += 1\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In order to track the computational time, we use the IPython 7.13.0 command shell in combination with the timeit package as follows","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [2]: import timeit\n   ...: n = 10000000\n\nIn [3]: %timeit estimate_pi(n)\n18.3 s ± 990 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We see that the average computation time is 19.3 seconds, which is a lot. The reason is, that for loops in Python are slow. One way how to improve the performance is to use NumPy vectorized operations (it is a similar approach used often in Matlab to improve performance). The vectorized version of the function above can be written as follows","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"def estimate_pi_vec(n):\n    xy = 2*np.random.random((n, 2)) - 1\n    n_circle = (np.sqrt((xy**2).sum(axis = 1)) <= 1).sum()\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"Using the same function to track the computational time, we get 354 milliseconds as can be seen below","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [5]: %timeit estimate_pi_vec(n)\n354 ms ± 21.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The vectorized version is 50 times faster than the pure Python implementation using the for loop. However, it requires rewriting the code and in many cases, it can be very difficult or even impossible to vectorize the code. Another approach is to use the Numba package mentioned above. The Numba package is very easy to use. In our case, we only need to add one line of code before the function definition","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"import numba\n\n@numba.jit()\ndef estimate_pi_numba(n):\n    n_circle = 0\n    for i in range(n):\n        x = 2*np.random.random() - 1\n        y = 2*np.random.random() - 1\n        if np.sqrt(x**2 + y**2) <= 1:\n           n_circle += 1\n    return 4*n_circle/n","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The result, in this case, is quite impressive and the average computational time is only 109 milliseconds as can be seen below","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In [7]: %timeit estimate_pi_numba(n)\n109 ms ± 2.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"The resulting code is more than 150 times faster than the pure Python implementation. The question is, how fast is Julia? To answer this question, we use the exact same function definition as in the case of the pure Python implementation.","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"function estimate_pi(n)\n    n_circle = 0\n    for i in 1:n\n        x = 2*rand() - 1\n        y = 2*rand() - 1\n        if sqrt(x^2 + y^2) <= 1\n           n_circle += 1\n        end\n    end\n    return 4*n_circle/n\nend","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"In Julia, we can use the BenchmarkTools package that allows simple benchmarking of the code. To track the computational time we use @benchmark macro as follows","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"julia> using BenchmarkTools\n\njulia> n = 10000000\n10000000\n\njulia> @benchmark estimate_pi(n)\nBenchmarkTools.Trial:\n  memory estimate:  16 bytes\n  allocs estimate:  1\n  --------------\n  minimum time:     86.532 ms (0.00% GC)\n  median time:      93.298 ms (0.00% GC)\n  mean time:        95.266 ms (0.00% GC)\n  maximum time:     112.988 ms (0.00% GC)\n  --------------\n  samples:          53\n  evals/sample:     1","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"We see that the average computation time is 95.266 seconds. Without any modifications, Julia's code is faster than the Python implementation that uses Numba. The performance gap is not large. However, the Numba package will work only on a small subset of Python and NumPy functionalities. Of course, there are other packages that can be used to increase performance such as Cython. But all these packages have the same problem as Numba and will not support all Python functionalities. The reason is, that Python was not designed to be compiled and thus there are many limitations that can not be solved. On the other hand, Julia was designed to be fast and provides high-performance out of the box without the necessity to do any additional steps. Moreover, the performance in Julia is not restricted only to the subset of the Language as in the case of Numba and other similar packages.","category":"page"},{"location":"why/#Disadvantages","page":"Why Julia?","title":"Disadvantages","text":"","category":"section"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"There is no language that is perfect for all tasks. In most cases, the choice of the language is a matter of subjective preferences. To be as objective as possible we provide a list of disadvantages of Julia","category":"page"},{"location":"why/","page":"Why Julia?","title":"Why Julia?","text":"A limited number of packages: Even though Julia grows rapidly and there are a large number of packages, it can not be compared to the number of available packages in Python or R. However, Julia provides a simple way how to interact with other languages. So if there is no adequate package in Julia, it is possible to use packages from other languages.\nSlow first run: Since Julia uses just-in-time compilation, the first call of every function is slower due to compilation. This slowdown can be significant if multiple functions are called for the first time at once. Such a case is creating a plot in a fresh Julia session because packages for plotting are large and use a lot of functions.  It results in a long time to the first plot (~20 s with Plots.jl).\nLimited number of job opportunities: Because Julia is a relatively new language, there is a limited number of job opportunities, especially compared to Python. On the other hand, there is a list of Julia users and Julia Computing customers on the official webpage of Julia Computing containing for example Amazon, Google, IBM, Intel and many others.","category":"page"},{"location":"lecture_07/exercises/#l7-exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"homework-body\">\n<header class = \"homework-header\">Homework: Newton's method</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Newton's method for solving equation g(x)=0 is an iterative procedure which at every iteration x^k approximates the function g(x) by its first-order (linear) expansion g(x) approx g(x^k) + nabla g(x^k)(x-x^k) and finds the zero point of this approximation.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Newton's method for unconstrained optimization replaces the optimization problem by its optimality condition and solves the resulting equation.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Implement Newton's method to minimize","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"f(x) = sin(x_1 + x_2) + cos(x_1)^2","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"with the starting point x^0=(0-1).","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 1: Bisection method</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Similarly to Newton's method, the bisection method is primarily designed to solve equations by finding their zero points. It is only able to solve equations f(x)=0 where fmathbbRtomathbbR. It starts with an interval ab where f has opposite values f(a)f(b)0. Then it selects the middle point on ab and halves the interval so that the new interval again satisfies the constraint on opposite signs f(a)f(b)0. This is repeated until the function value is small or until the interval has a small length.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Implement the bisection method and use it to minimize f(x) = x^2 - x on -11. During the implementation, do not evaluate f unless necessary.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"First, we write the bisection method. We initialize it with arguments f and the initial interval ab. We also specify the optional tolerance. First, we save the function value fa = f(a) to not need to recompute it every time. The syntax fa == 0 && return a is a bit complex. Since && is the \"and\" operator, this first checks whether fa == 0 is satisfied and if so, it evaluates the second part. However, the second part exits the function and returns a. Since we need to have f(a)f(b)0, we check this condition, and if it is not satisfied, we return an error message. Finally, we run the while loop, where every iteration halves the interval. The condition on opposite signs is enforced in the if condition inside the loop.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"function bisection(f, a, b; tol=1e-6)\n    fa = f(a)\n    fb = f(b)\n    fa == 0 && return a\n    fb == 0 && return b\n    fa*fb > 0 && error(\"Wrong initial values for bisection\")\n    while b-a > tol\n        c = (a+b)/2\n        fc = f(c)\n        fc == 0 && return c\n        if fa*fc > 0\n            a = c\n            fa = fc\n        else\n            b = c\n            fb = fc\n        end\n    end\n    return (a+b)/2\nend\nnothing # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"This implementation is efficient in the way that only one function evaluation is neededper iteration. The price to pay are additional variables fa, fb and fc.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"To use the bisection method to minimize a function f(x), we use it find the solution of the optimality condition f(x)=0.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"f(x) = x^2 - x\ng(x) = 2*x - 1\nx_opt = bisection(g, -1, 1)\nnothing # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"println(round(x_opt, digits=4)) # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 2: JuMP</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The library to perform optimization is called JuMP. Install it, go briefly through its documentation, and use it to solve the linear optimization problem","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextminimizeqquad x_1 + x_2 + x_5 \ntextsubject toqquad x_1+2x_2+3x_3+4x_4+5x_5 = 8 \nx_3+x_4+x_5 = 2 \nx_1+x_2 = 2\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The best start is the official documentation of the JuMP package. Since JuMP is only an interface for solvers, we need to include an actual solver as well. For linear programs, we can use using GLPK, for non-linear ones, we would need to use using Ipopt. We specify the constraints in a matrix form. It is possible to write them directly via @constraint(model, x[1] + x[2] == 2). This second way is more pleasant for complex constraints. Since x is a vector, we need to use value.(x) instead of the wrong value(x).","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"using JuMP\nusing GLPK\n\nA = [1 2 3 4 5; 0 0 1 1 1; 1 1 0 0 0]\nb = [8; 2; 2]\nc = [1; 1; 0; 0; 1]\nn = size(A, 2)\n\nmodel = Model(GLPK.Optimizer)\n\n@variable(model, x[1:n] >= 0)\n\n@objective(model, Min, c'*x)\n@constraint(model, A*x .== b)\noptimize!(model)\n\nx_val = value.(x)\nnothing # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"println(round.(x_val, digits=4)) # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 3: SQP method</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Derive the SQP method for optimization problem with only equality constraints","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad h_j(x) = 0 j=1dotsJ\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"SQP writes the optimality (KKT) conditions and then applies Newton's method to solve the resulting system of equations. ","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Apply the obtained algorithm to","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextminimizeqquad sum_i=1^10 ix_i^4 \ntextsubject toqquad sum_i=1^10 x_i = 1\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Verify that the numerically obtained solution is correct.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The Lagrangian reads","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"L(xmu) = f(x) + sum_j=1^Jmu_j h_j(x)","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Since there are no inequality constraints, the optimality conditions contain no complementarity and read","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\nnabla f(x) + sum_j=1^Jmu_j nabla h_j(x) = 0\nh_j(x) = 0\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The Newton method's at iteration k has some pair (x^kmu^k) and performs the update","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginpmatrix x^k+1  mu^k+1 endpmatrix = beginpmatrix x^k  mu^k endpmatrix - beginpmatrix nabla^2 f(x^k) + sum_j=1^J mu_j^k nabla^2 h_j(x^k)  nabla h(x^k)  nabla h(x^k)^top  0 endpmatrix^-1 beginpmatrix nabla f(x^k) + sum_j=1^Jmu_j^k nabla h_j(x^k)  h(x^k) endpmatrix ","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"We define functions f and h and their derivates and Hessians for the numerical implementation. The simplest way to create a diagonal matrix is Diagonal from the LinearAlgebra package. It can be, of course, done manually as well. ","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"using LinearAlgebra\n\nn = 10\nf(x) = sum((1:n) .* x.^4)\nf_grad(x) = 4*(1:n)[:].*x.^3\nf_hess(x) = 12*Diagonal((1:n)[:].*x.^2)\nh(x) = sum(x) - 1\nh_grad(x) = ones(n)\nh_hess(x) = zeros(n,n)\nnothing # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"To implement SQP, we first randomly generate initial x and mu and then write the procedure derived above. Since we update x in a for loop, we need to define it as a global variables; otherwise, it will be a local variable, and the global (outside of the loop) will not update. We can write inv(A)*b or the more efficient A\\b. To subtract from x, we use the shortened notation x -= ?, which is the same as x = x - ?.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"x = randn(n)\nμ = randn()\nfor i in 1:100\n    global x, μ\n    A = [f_hess(x) + μ*h_hess(x) h_grad(x); h_grad(x)' 0]\n    b = [f_grad(x) + μ*h_grad(x); h(x)]\n    step = A \\ b\n    x -= step[1:n]\n    μ -= step[n+1] \nend","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The need to differentiate global and local variables in scripts are one of the reasons why functions should be used as much as possible.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"To validate, we need to verify the optimality and the feasibility; both need to equal to zero. These are the same as the b variable. However, we cannot call b directly, as it is inside the for loop and therefore local only.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"f_grad(x) + μ*h_grad(x)\nh(x)","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The correct solution is","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"println(round.(x, digits=4)) # hide","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 4 (theory)</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Show that the primal formulation for a problem with no inequalities is equivalent to the min-max formulation.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The primal problem with no inequalities reads","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextminimizeqquad f(x) \ntextsubject toqquad h_j(x) = 0 j=1dotsJ\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The Lagrangian has form","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"L(xlambdamu) = f(x) + sum_j=1^J mu_j h_j(x)","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Now consider the min-max formulation","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"operatorname*minimize_xquad operatorname*maximize_muquad f(x) + sum_j=1^J mu_j h_j(x)","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"If h_j(x)neq 0, then it is simple to choose mu_jso that the inner maximization problem has the optimal value +infty. However, since the outer problem minimizes the objective, the value of +infty is irrelevant. Therefore, we can ignore all points with h_j(x)neq 0 and prescribe h_j(x)=0 as a hard constraint. That is precisely the primal formulation.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 5 (theory)</header><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Derive the dual formulation for the linear programming.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"The linear program","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextminimizeqquad c^top x \ntextsubject toqquad Ax=b \nxge 0\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"has the Lagrangian","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"L(xlambdamu) = c^top x - lambda^top x + mu^top (b-Ax) = (c - lambda - A^topmu)^top x + b^top mu","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"We need to have - lambda^top x because we require constraints g(x)le 0 or in other words -xle 0. The dual problem from its definition reads","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"operatorname*maximize_lambdage0 mu quad operatorname*minimize_x quad (c - lambda - A^topmu)^top x + b^top mu","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"Since the minimization with respect to x is unconstrained, the same arguments as the previous exercise imply the hard constraint c - lambda - A^topmu=0. Then we may simplify the dual problem into","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"beginaligned\ntextmaximizeqquad b^top mu \ntextsubject toqquad c - lambda - A^topmu = 0 \nlambdage 0\nendaligned","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"From this formulation, we may remove lambda and obtain A^top mule c. This is the desired dual formulation.","category":"page"},{"location":"lecture_07/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_02/exercises/#Julia-set","page":"Exercises","title":"Julia set","text":"","category":"section"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"So far, we use only the standard library that is shipped with Julia. However, the standard library provides only basic functionality. If we want to get additional functions, we have to use extra packages. For example, there is a Plots.jl package that allows us to create plots. Packages can be installed via Pkg REPL. To enter the Pkg REPL from the Julia REPL, we have to press the ] symbol. Then the  Plots package can be installed as follows","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(@v1.5) pkg> add Plots","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"If we install an additional package, we have to use the using keyword to load the package, and then we can start using it. For example, we can use the Plots package to visualize the sin and cos functions as follows","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nx = 0:0.01π:2π\n\nplot(x, sin.(x); label = \"sinus\", linewidth = 2)\nplot!(x, cos.(x); label = \"cosinus\", linewidth = 2)\n\nsavefig(\"sin.svg\") # hide","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"There will be a whole section about the Plots package later in the course.  However, we need some basic functionality to visualize the outputs of the following exercises.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 1: </header><p>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Every programmer should be able to rewrite pseudocode to actual code. The goal of this exercise is to rewrite the following pseudocode","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"The given pseudocode describes how to compute the Julia set for the following function","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"f_c(z) = z^2 + c","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"where c in mathbbC is a complex parameter. To test the resulting code, try the following settings of input parameters","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"x is a vector of 1500 evenly spaced numbers from -1.5 to 1.5.\ny is a vector of 1000 evenly spaced numbers from -1 to 1.\nc = - 04 + 061 cdot i\nR = 2\nN = 1000","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Use the code given below to plot the resulting matrix A","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nheatmap(A;\n    c = :viridis,\n    clims = (0, 0.15),\n    cbar = :none,\n    axis = :none,\n    ticks = :none\n)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Firstly, we have to define all input parameters","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = - 0.4 + 0.61im\nR = 2\nN = 1000\nL = 1500\nK = 1000","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"The second step is to define vectors x and y. Since we know that these vectors contain evenly spaced numbers, and we also know the starting point, the stopping point, and the length of the vectors, we can use the range function to generate them","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"x = range(-1.5, 1.5; length = L)\ny = range(-1.0, 1.0; length = K)\nnothing # hide","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"The next step is to define the A matrix full of zeros. This step can be done simply by using the zeros function","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"A = zeros(K, L)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Now, we can rewrite the for loops from the given pseudocode. It is possible to rewrite the pseudocode in an almost identical way. However, in many cases, the code can be simplified. For example, we can use the shorter syntax for writing nested for loops as follows","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"for k in 1:K, l in 1:L\n    z = x[l] + y[k]*im\n    for n in 1:N\n        z = z^2 + c\n        if abs(z) > R^2 - R\n            A[k, l] = n/N\n            break\n        end\n    end\nend","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Finally, we can use the code provided in the description of the exercise to visualize the matrix A","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nheatmap(A;\n    c = :viridis,\n    clims = (0, 0.15),\n    cbar = :none,\n    axis = :none,\n    ticks = :none,\n    size = (800, 600),\n)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 2:</header><p>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"In the above exercise, we rewrote the pseudocode to the actual Julia code. However, the resulting code is not written in the best possible way. In this exercise, we will try to improve the central part of the code, i.e., the inner loop. Try to write a function that replaces the inner loop in the code from the exercise above. Use the following function definition","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"function juliaset(z, c, R, N)\n    ???\n    return ???\nend","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"where z c in mathbbC, R in mathbbR and N in mathbbN. Try to use the while loop to replace the for loop in the original pseudocode. Visualize the resulting matrix using the same code as in the previous exercise.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Hint: do not forget, that the function should return 0 if n == N and n/N otherwise.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"As suggested in the exercise description, we will use the while loop because it is more suitable in this case. When using the while loop, we have to define the stopping condition. In this case, we have two conditions:","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"maximal number of iterations is N,\nthe absolute value of variable z has to be smaller or equal to R^2 - R.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"These two conditions can be merged together as follows n <= N && abs(z) <= R^2 - R. Inside the while loop, we onlye have to update variables n and z. Altogether the function can be defined in the following way","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"function juliaset(z, c, R, N)\n    n = 0\n    while n <= N && abs(z) <= R^2 - R\n        n += 1\n        z = z^2 + c\n    end\n    return n == N ? 0 : n/N\nend","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Note that we use the ternary operator to decide which value is returned. With a defined function, we have to define all input parameters as in the previous exercise","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = - 0.4 + 0.61im\nR = 2\nN = 1000\nx = range(-1.5, 1.5; length = 1500)\ny = range(-1.0, 1.0; length = 1000)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Now we can use nested for loops to create the A matrix. However, it is not the easiest way. It is simpler to use the list comprehension or broadcasting to vectorize the juliaset function","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"A1 = [juliaset(xl + yk*im, c, R, N) for yk in y, xl in x]\nA2 = juliaset.(x' .+ y .* im, c, R, N)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"In the second case, we have to pay attention to use the correct form of the input. Note that we use transposition of the vector x. Finally, we can call the same code as before to create the same plot","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\nheatmap(A1;\n    c = :viridis,\n    clims = (0, 0.15),\n    cbar = :none,\n    axis = :none,\n    ticks = :none,\n    size = (800, 600),\n)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 3: </header><p>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Try different values of variable c to create different plots. For inspiration, check the Wikipedia page about Julia set.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = 0285 + 001 cdot i","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = - 0835 - 02321 cdot i","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = -08 + 0156 cdot i","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c = -070176 + 03842 cdot i","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_02/exercises/#Animation","page":"Exercises","title":"Animation","text":"","category":"section"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"warning: Warning\nIt takes a lot of time to create the animation described below, especially when using the default GR backend for the Plots package. The plotting time can be reduced by using a different backend. For example, the PyPlot backend can be used as followsusing Plots, PyPlot\npyplot()Note that the PyPlot package must be installed first. An alternative way is to use the Makie package instead of the Plots package.","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"It is also possible to create animations using the Plots package. Just for illustration, we will create an animation of Julia sets for c values defined as follows","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"c_k = 07885 exp  k cdot i  qquad k in left fracpi2 frac3pi2 right ","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"The vector of all values c can be created using the combination of the range function and broadcasting in the following way","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"cs = 0.7885 .* exp.(range(π/2, 3π/2; length = 500) .* im)","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"We use the length keyword to specify the length of the resulting vector. The only thing that we have to do to create an animation is to use the for loop in combination with the @animate macro as follows","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"anim = @animate for c in cs\n    A = juliaset.(x' .+ y .* im, c, R, N)\n    heatmap(A;\n        c = :viridis,\n        clims = (0, 0.15),\n        cbar = :none,\n        axis = :none,\n        ticks = :none,\n        size = (800, 600),\n    )\nend\ngif(anim, \"juliaset.gif\", fps = 20) # save animation as a gif","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"Note that the code inside the loop is the same as we used in the previous exercises. The result is the following animation","category":"page"},{"location":"lecture_02/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In Julia, a function is an object that maps a tuple of argument values to a return value. There are multiple ways to create a function, and each of them is useful in different situations. The first way is to use function ... end syntax","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function plus(x,y)\n    x + y\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In the previous example, we created a plus function that accepts two arguments, x, y, and returns their sum.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus(2, 3)\n5\n\njulia> plus(2, -3)\n-1","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"By default, functions in Julia returns the last evaluated expression, which in our example is x + y. However, in many situations, it is useful to return something other than the last expression. For such a case, there is the return keyword. The previous example can be equivalently rewritten as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function plus(x,y)\n    return x + y\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Even though both function definitions do exactly the same, it is always good to use the return keyword. Using the return keyword usually improves the readability of the code and can prevent potential confusion.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function plus(x, y)\n    return x + y\n    println(\"I am a useless line of code!!\")\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In the example above, there is the println function on the last line. However, if the function is called, nothing is printed into the REPL. The reason is that the expressions after the return keyword are never evaluated","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus(4, 5)\n9\n\njulia> plus(3, -5)\n-2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"It is also possible to return multiple values at once. It can be done by writing multiple comma-separated values after the return keyword (or on the last line when return is omitted)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function powers(x)\n    return x, x^2, x^3, x^4\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"This syntax creates a tuple of values, and then this tuple is returned as a function output. It can be seen, if we call the powers function that returns the first four powers of the given variable x","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> ps = powers(2)\n(2, 4, 8, 16)\n\njulia> typeof(ps)\nNTuple{4,Int64}","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Since the function returns a tuple, returned values can be directly unpacked into multiple variables. It can be done in the same way as unpacking tuples","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> x1, x2, x3, x4 = powers(2)\n(2, 4, 8, 16)\n\njulia> x3\n8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Write a function that for a given real number x and integer p computes x^p without using the ^ operator. Use only basic arithmetic operators +, -, *, / and if condition.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Hint: use recursion.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"To use recursion, we have to split the computation into three parts:","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"p = 0: the function should return 1.\np > 0: the function should be called recursively with arguments x, p - 1 and the result should be multiplied by x.\np < 0: then it is equivalent to call the power function with arguments 1/x, - p.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"These three cases can be defined simply one if condition as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function power(x::Real, p::Integer)\n    if p == 0\n        return 1\n    elseif p > 0\n        return x * power(x, p - 1)\n    else\n        return power(1/x, - p)\n    end\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that we use type annotation for function arguments. Using type annotation, we can assure that the input arguments are always of the proper type. In the example above, the first argument must be a real number, and the second argument must be an integer","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> power(2, 5)\n32\n\njulia> power(2, -2)\n0.25\n\njulia> power(2, 5) == 2^5\ntrue\n\njulia> power(5, -3) == 5^(-3)\ntrue","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"If we call the function with arguments of inappropriate types, an error will occur","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> power(2, 2.5)\nERROR: MethodError: no method matching power(::Int64, ::Float64)\n[...]","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"We will discuss the type annotation later in the section about methods.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></details>","category":"page"},{"location":"lecture_03/functions/#One-line-functions","page":"Functions","title":"One-line functions","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Besides the traditional function declaration syntax above, it is possible to define a function in a compact one-line form","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"plus(x, y) = x + y","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"that is equivalent to the previous definition of the plus function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus(4, 5)\n9\n\njulia> plus(3, -5)\n-2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"This syntax is very similar to the mathematical notation, especially in combination with the Greek alphabet. For example, the following function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"f(varphi) = - 4 cdot sinleft(varphi - fracpi12right)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"can be in Julia defined in almost identical form","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"f(φ) = -4sin(φ - π/12)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Even with one-line syntax, it is possible to create more complex functions with some intermediate calculations. It can be done, using brackets and semicolons to separate expressions. The last expression in brackets is then returned  as a function output","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"g(x) = (x -= 1; x *= 2; x)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In this example, the g function subtracts 1 from the given x and then multiply it by 2 and returns the result","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> g(3)\n4","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, for better code readability, the traditional multiline syntax should be used for more complex functions.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Write a one-line function that returns true if the input argument is an even number and false otherwise.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Hint: use modulo function and ternary operator ?.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"From the section about the ternary operator, we know the syntax","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"a ? b : c","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"This expression can be read as follows: if a is true, evaluate b otherwise evaluate c. We also know that even numbers are divisible by 2, and we can check it using the modulo, i.e., the given integer x is even if mod(x, 2) == 0.  Altogether, we get the following function definition","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"even(x::Integer) = mod(x, 2) == 0 ? true : false","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that we use type annotation to assure that the argument is always an integer.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> even(11)\nfalse\n\njulia> even(14)\ntrue","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></details>","category":"page"},{"location":"lecture_03/functions/#Optional-arguments","page":"Functions","title":"Optional arguments","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In many cases, it is advantageous to set predefined values to some function arguments. Arguments with a default value are typically called optional arguments. Like in Python, optional arguments can be created by assigning a default value to the normal argument. The following function has only one argument, which is optional with a default value world","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"hello(x = \"world\") = println(\"Hello $(x).\")","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Since the only argument is optional, we can call the function without any argument. In such a case, the function prints \"Hello $(x).\", where the default value replaces x. Or we can call the function with one argument and change the printed sentence","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> hello()\nHello world.\n\njulia> hello(\"people\")\nHello people.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In the same way, it is possible to define multiple optional arguments. It is even possible to define optional arguments that depend on other arguments. However, there are some rules. Arguments must be sorted as follows: firstly, we have to define all mandatory arguments, and then we can define optional arguments","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"powers(x, y = x*x, z = y*x, v = z*x) = x, y, z, v","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"This function has one mandatory argument and three optional ones. If only the first argument s is provided, then the function returns the first four powers of the given x","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> powers(2)\n(2, 4, 8, 16)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Otherwise, the function output depends on the given input arguments. For example, if two arguments x and y are provided, the function returns these two arguments unchanged, their product x*y and also x^2*y","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> powers(2, 3)\n(2, 3, 6, 12)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that optional arguments can depend only on the arguments defined before; otherwise, an error will occur.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"f(x = 1, y = x) = (x, y)\ng(x = y, y = 1) = (x, y)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The definition of the f function is correct and the definition of the g function is incorrect, since the variable y is not defined when we define x","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> f()\n(1, 1)\n\njulia> g()\nERROR: UndefVarError: y not defined\n[...]","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Write a function, that computes the value of the following quadratic form","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"q_abc(x) = ax^2 + bxy + cy^2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"where a b c x in mathbbR. Use optional arguments to set default values for parameters","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"a = 1 quad b = 2a quad c = 3(a + b)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"What is the function value at point (4 2) for default parameters? What is the function value at the same point if we use c = 3?","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The quadratic form can be implemented as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"q(x, y, a = 1, b = 2*a, c = 3*(a + b)) = a*x^2 + b*x*y + c*y^2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Since we want to evaluate the function q at point (4, 2) with default parameters, we can simply use only the first two arguments","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> q(4, 2)\n68","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In the second case, we want to evaluate the function at the same point with c = 3. However, it is not possible to set only the last optional argument. We have to set all previous optional arguments too. For the first two optional arguments, we use the default values, i.e., a = 1 and b = 2*a = 2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> q(4, 2, 1, 2, 3)\n44","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></details>","category":"page"},{"location":"lecture_03/functions/#Keyword-arguments","page":"Functions","title":"Keyword arguments","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The previous exercise shows the most significant disadvantage of using optional arguments, i.e., it is not possible to change only one optional argument unless it is the first one. Luckily there are also keyword arguments that can be used instead of optional arguments. The syntax is the same as for optional arguments, with one exception: we have to use a semicolon before the first keyword argument.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"linear(x; a = 1, b = 0) = a*x + b","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"This function is a simple linear function, where a represents slope, and b represents intercept. As with functions with optional arguments, we can call the function with the mandatory arguments only","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> linear(2)\n2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"or we can change the value of any keyword argument by assigning a new value to its name","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> linear(2; a = 2)\n4\n\njulia> linear(2; b = 4)\n6\n\njulia> linear(2; a = 2, b = 4)\n8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that the semicolon, in this case, is not mandatory and can be omitted. Also, the order of keyword arguments can be arbitrary. It is even possible to mix keyword arguments with positional arguments as can be seen in the following example","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> linear(b = 4, 2, a = 2)\n8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, it's a good practice to always separate keyword arguments from optional arguments with a semicolon.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Julia also provides one very nice feature that can be used to pass keyword arguments. Imagine that we have two variables, a and b, and we want to pass them as keyword arguments to the linear function defined above. The standard way is as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> a, b = 2, 4\n(2, 4)\n\njulia> linear(2; a = a, b = b)\n8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, in Julia, we can use the shorter version, that can be used if the variable name is the same as the name of the keyword argument we want to set. In such a case, the following is equivalent to the previous example","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> linear(2; a, b)\n8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Write a probability density function for the Gaussian distribution, that is given by the following formula","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"f_mu sigma(x) = frac1sigma sqrt 2pi  expleft -frac12 left( fracx - musigma right) ^2 right","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"where mu in mathbbR and sigma^2  0. Use keyword arguments  to set the following default values mu = 0 and sigma = 1.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Bonus: check that this function is a probability density function, i.e., that the sum over all possible values is equal to 1.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Hint: use the error function to check if the variance is positive.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The probability density function for the Gaussian distribution can be simply written as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function gauss(x::Real; μ::Real = 0, σ::Real = 1)\n    σ^2 > 0 || error(\"the variance `σ^2` must be positive\")\n    return exp(-1/2 * ((x - μ)/σ)^2)/(σ * sqrt(2*π))\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that we use type annotation to assure that all input arguments are real numbers. We also check whether the given standard deviation sigma does not lead to a zero variance (the first line in the function body)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> gauss(0)\n0.3989422804014327\n\njulia> gauss(0.1; μ = 1, σ = 1)\n0.2660852498987548","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The integral of the probability density function over all real numbers should be equal to one. We can check it numerically as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> step = 0.01\n0.01\n\njulia> x = -100:step:100;\n\njulia> sum(gauss, x) * step\n1.0000000000000002\n\njulia> g(x) = gauss(x; μ = -1, σ = 1.4)\ng (generic function with 1 method)\n\njulia> sum(g, x) * step\n1.0000000000000007","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"We use the sum function, which can accept a function as the first argument and apply it to each value before summation. The result is always multiplied by 0.01. It is because we use a range with stepsize 0.01  to approximate continuous interval [-100, 100].","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"We can also visualize the probability density functions using Plots.jl package","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"using Plots\nfunction gauss(x::Real; μ::Real = 0, σ::Real = 1)\n    σ^2 > 0 || error(\"the variance `σ^2` must be positive\")\n    return exp(-1/2 * ((x - μ)/σ)^2)/(σ * sqrt(2*π))\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"using Plots\nx = -15:0.1:15\n\nplot(x, gauss.(x); label = \"μ = 0, σ = 1\", linewidth = 2, xlabel = \"x\", ylabel = \"f(x)\");\nplot!(x, gauss.(x; μ = 4, σ = 2); label = \"μ = 4, σ = 2\", linewidth = 2);\nplot!(x, gauss.(x; μ = -3, σ = 2); label = \"μ = -3, σ = 2\", linewidth = 2);\nsavefig(\"gauss.svg\") # hide","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"(Image: )","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></details>","category":"page"},{"location":"lecture_03/functions/#Variable-number-of-arguments","page":"Functions","title":"Variable number of arguments","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Sometimes, it is very convenient to define a function that can accept any number of arguments. Such functions are traditionally known as varargs functions (short for variable number of arguments). In Julia, varargs functions can be defined using triple-dot syntax after the last positional argument as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"nargs(x...) = println(\"Number of arguments: \", length(x))","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that the triple-dot ... is also known as the splat operator. The nargs function defined above prints the number of given input arguments","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> nargs()\nNumber of arguments: 0\n\njulia> nargs(1, 2, \"a\", :b, [1,2,3])\nNumber of arguments: 5","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that we use input arguments of different types.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The splat operator can also be used to pass multiple arguments to the function at once. Imagine the situation, that we have a tuple of values and we want to use these values as arguments to some function. We can do it manually as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> args = (1, 2, 3)\n(1, 2, 3)\n\njulia> nargs(args[1], args[2], args[3])\nNumber of arguments: 3","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, in Julia, it is possible to use the splat operator to unpack the tuple of arguments directly to the function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> nargs(args...)\nNumber of arguments: 3","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note the difference if we omit the splat operator","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> nargs(args)\nNumber of arguments: 1","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In such a case, the function receives only one argument instead of three arguments. The same syntax can be used for any iterable object, such as ranges or arrays","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> nargs(1:100)\nNumber of arguments: 1\n\njulia> nargs(1:100...)\nNumber of arguments: 100\n\njulia> nargs([1,2,3,4,5])\nNumber of arguments: 1\n\njulia> nargs([1,2,3,4,5]...)\nNumber of arguments: 5","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"It is also possible to use the same syntax to define a function with an arbitrary number of keyword arguments. Functions that accept any number of keyword arguments can be beneficial. Consider the following situation: we want to define a function that computes the modulo of the given numbers and then rounds the result. To define such a function, we can use the combination of the mod and round functions. However, the round function has many keyword arguments, and we want to have an option to use them all. In such a case, we can use the following syntax to define the roundmod function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"roundmod(x, y; kwargs...) = round(mod(x, y); kwargs...)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"With this simple syntax, we are able to pass all keyword arguments to the round function without the necessity to define them all in the roundmod function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> roundmod(12.529, 5)\n3.0\n\njulia> roundmod(12.529, 5; digits = 2)\n2.53\n\njulia> roundmod(12.529, 5; sigdigits = 2)\n2.5","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Write a function wrapper, that accepts a number and applies the round, ceil or floor function based on the keyword argument type. Make sure that all optional and keyword arguments can be passed to these three functions.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Use the function to solve the following tasks","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Round 1252.1518 to the nearest larger integer and convert the resulting value to Int64.\nRound 1252.1518 to the nearest smaller integer and convert the resulting value to Int16.\nRound 1252.1518 to 2 digits after the decimal point.\nRound 1252.1518 to 3 significant digits.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The one way how to define such a function is to use if-elseif-else statement as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function wrapper(x...; type = :round, kwargs...)\n    if type == :ceil\n        return ceil(x...; kwargs...)\n    elseif type == :floor\n        return floor(x...; kwargs...)\n    else\n        return round(x...; kwargs...)\n    end\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In this case, the type keyword argument is used to determine which function should be used. Note that we use an optional number of arguments as well as an optional number of keyword arguments","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> x = 1252.1518\n1252.1518\n\njulia> wrapper(Int64, x; type = :ceil)\n1253\n\njulia> wrapper(Int16, x; type = :floor)\n1252\n\njulia> wrapper(x; digits = 2)\n1252.15\n\njulia> wrapper(x; sigdigits = 3)\n1250.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The second way to solve this exercise is to use the fact that it is possible to pass functions as arguments. Using this fact, we can omit the if conditions, and we can pass the appropriate function directly","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"wrapper_new(x...; type = round, kwargs...) = type(x...; kwargs...)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that in the function definition, we use the type keyword argument as a function. It can be done since we assume that a function is assigned to the type keyword argument","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> wrapper_new(1.123; type = ceil)\n2.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"If we use, for example, Symbol instead of a function, the error will occur","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> wrapper_new(1.123; type = :ceil)\nERROR: MethodError: objects of type Symbol are not callable\n[...]","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Finally, we can test the wrapper_new function on the same arguments as we tried the wrapper function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> x = 1252.1518\n1252.1518\n\njulia> wrapper_new(Int64, x; type = ceil)\n1253\n\njulia> wrapper_new(Int16, x; type = floor)\n1252\n\njulia> wrapper_new(x; digits = 2)\n1252.15\n\njulia> wrapper_new(x; sigdigits = 3)\n1250.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"</p></details>","category":"page"},{"location":"lecture_03/functions/#Anonymous-functions","page":"Functions","title":"Anonymous functions","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"It is also common to use anonymous functions, i.e., functions without a specified name. Anonymous functions can be defined in almost the same way as a normal function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"h1 = function (x)\n    x^2 + 2x - 1\nend\nh2 = x ->  x^2 + 2x - 1\nnothing # hide","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Those two function declarations create functions with automatically generated names. Then variables h1 and h2 only refer to these functions. The primary use for anonymous functions is passing them to functions that take other functions as arguments. A classic example is the map function, which applies a function to each value of the given iterable object and returns a new array containing the resulting values","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> map(x -> x^2 + 2x - 1, [1,3,-1])\n3-element Array{Int64,1}:\n  2\n 14\n -2","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Julia also provides a reserved word do, that also allows creating anonymous functions. In the following example, we apply the map function to two arrays.  Using do block, we create an anonymous function that prints the given values a return their sum","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> map([1,3,-1], [2,4,-2]) do x, y\n           println(\"x = $(x), y = $(y)\")\n           return x + y\n       end\nx = 1, y = 2\nx = 3, y = 4\nx = -1, y = -2\n3-element Array{Int64,1}:\n  3\n  7\n -3","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Note that the body of such a function is written in the same way as a normal function. The arguments are defined after the do keyword. However, it is usually better to create an actual function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"function f(x, y)\n    println(\"x = $(x), y = $(y)\")\n    return x + y\nend","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"and then use it in the map function","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> map(f, [1,3,-1], [2,4,-2])\nx = 1, y = 2\nx = 3, y = 4\nx = -1, y = -2\n3-element Array{Int64,1}:\n  3\n  7\n -3","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"There are many possible uses quite different from the map function, such as managing system state. For example, there is a version of the open function that runs code ensuring that the opened file is eventually closed","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"open(\"outfile\", \"w\") do io\n    write(io, data)\nend","category":"page"},{"location":"lecture_03/functions/#Dot-Syntax-for-Vectorizing-Functions","page":"Functions","title":"Dot Syntax for Vectorizing Functions","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In technical-computing languages, it is common to have vectorized versions of functions. Consider that we have a function f(x). Its vectorized version is a function that applies function f to each element of an array A and returns a new array f(A). Such functions are beneficial in languages, where loops are slow and vectorized versions of functions are written in a low-level language (C, Fortran,...) and are much faster. As an example, we can mention Matlab.","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In Julia, vectorized functions are not required for performance, and indeed it is often beneficial to write loops, but they can still be convenient. As an example, consider the sine function and imagine that we want to compute its value for all following values [0, π/2, 3π/4]. Using the loops, we can do it as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> x = [0, π/2, 3π/4];\n\njulia> A = zeros(length(x));\n\njulia> for (i, xi) in enumerate(x)\n           A[i] = sin(xi)\n       end\n\njulia> A\n3-element Array{Float64,1}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"or using list compherension","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> A = [sin(xi) for xi in x]\n3-element Array{Float64,1}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, in this case, the most convenient way is to use dot syntax for vectorizing functions as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> A = sin.(x)\n3-element Array{Float64,1}:\n 0.0\n 1.0\n 0.7071067811865476","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In Julia, it is possible to use this syntax for any function to apply it to each element of the given array (or any other iterable object). It is handy since it allows us to write simple functions that accept, for example, only numbers as arguments, and then we can easily apply them to whole arrays","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"plus(x::Real, y::Real) = x + y","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Here, we define a function that accepts two real numbers and returns their sum. This function will work for two numbers","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus(1,3)\n4\n\njulia> plus(1.4,2.7)\n4.1","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"But, if we try to apply this function to arrays, an error will occur","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> x = [1,2,3,4]; # column vector\n\njulia> plus(x, x)\nERROR: MethodError: no method matching plus(::Array{Int64,1}, ::Array{Int64,1})\n[...]","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"However, we can use the dot syntax for vectorizing functions. Then the plus function will be applied to arrays x and y element-wise","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus.(x, x)\n4-element Array{Int64,1}:\n 2\n 4\n 6\n 8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"More generally, if we have a function f and we use dot syntax f.(args...), then it is equivalent to calling the broadcast function  in the following way broadcast(f, args...)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> broadcast(plus, x, x)\n4-element Array{Int64,1}:\n 2\n 4\n 6\n 8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The dot syntax allows us to operate on multiple arrays (even of different shapes)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> y = [1 2 3 4]; # row vector\n\njulia> plus.(x, y)\n4×4 Array{Int64,2}:\n 2  3  4  5\n 3  4  5  6\n 4  5  6  7\n 5  6  7  8","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"or a mix of arrays and scalars","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> plus.(x, 1)\n4-element Array{Int64,1}:\n 2\n 3\n 4\n 5","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"For more information, see the section about broadcasting in the official documentation.","category":"page"},{"location":"lecture_03/functions/#Function-composition-and-piping","page":"Functions","title":"Function composition and piping","text":"","category":"section"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"As in mathematics, functions in Julia can be composed. If we have two functions f mathcalX  rightarrow mathcalY and g mathcalY  rightarrow mathcalZ, then their composition can be mathematically written as","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"(g circ f)(x) = g(f(x)) quad forall x in mathcalX","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"In Julia, we can similarly compose functions using the function composition operator ∘ (can be typed as \\circ<tab>)","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> (sqrt ∘ +)(3, 6) # equivalent to sqrt(3 + 6)\n3.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"It is even possible to compose multiple functions at once","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> (sqrt ∘ abs ∘ sum)([-3, -6, -7])  # equivalent to sqrt(abs(sum([-3, -6, -7])))\n4.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"There is also another concept that allows the chaining of functions.  That concept is sometimes called piping or using a pipe to send data to a subsequent function. The piping can be used to pass the output of one function as an input to another one. In Julia, it can be done by the pipe operator |>","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> [-3, -6, -7] |> sum |> abs |> sqrt\n4.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"The pipe operator can be combined with broadcasting as follows","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> [-4, 9, -16] .|> abs .|> sqrt\n3-element Array{Float64,1}:\n 2.0\n 3.0\n 4.0","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"Or as in the next example, we can use broadcasting in combination with the pipe operator to apply a different function to each element of the given vector","category":"page"},{"location":"lecture_03/functions/","page":"Functions","title":"Functions","text":"julia> [\"a\", \"list\", \"of\", \"strings\"] .|> [uppercase, reverse, titlecase, length]\n4-element Array{Any,1}:\n  \"A\"\n  \"tsil\"\n  \"Of\"\n 7","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Plots\nENV[\"GKSwstype\"] = \"100\"\ngr()","category":"page"},{"location":"#Julia-for-Machine-Learning","page":"Home","title":"Julia for Machine Learning","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to our course Julia for Machine Learning. This course consists of two parts:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Basics of Julia: Julia is a fast programming language for scientific computing. Designed and developed at MIT, it quickly keeps gaining popularity and scored rank 25 among programming languages in the PYPL rating (as of February 2021).\nApplications: The second part of the course will be dedicated to applications. The main emphasis will given to machine learning, but we will also go through statistics and differential equations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Since there are no course requirements, all students who want to learn to program efficiently or machine learning techniques are welcome to join.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The course's main requirement is to finish a small project of your choice. This project can be connected to your bachelor or master thesis, and we hope that our course will help you prepare a better thesis.","category":"page"},{"location":"#Information-about-the-course","page":"Home","title":"Information about the course","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Teachers: Lukáš Adam, Václav Mácha\nCredits: 3\nFJFI code: 01SUJ\nRequirements for the course:\nFinish three homeworks. Each homework is a short task.\nFinish one final project. Project is a more complex task, where you can choose the topic.\nGrading: The attendance and homeworks are compulsory to pass the course. The final grade will be based solely on the project.\nTeaching way: online via MS Teams. CTU students will be added automatically to a team after registering for the course in KOS. Students from other universities should write us an email.","category":"page"},{"location":"#What-will-we-emphasize?","page":"Home","title":"What will we emphasize?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main goals of the course are the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"You will learn the connections between theory and coding. There are many lectures which teach either only theory or only coding. We will show you both.\nYou will learn how to code efficiently. We will teach you to split the code into small parts which are simpler to debug or optimize. We will often show you several writing possibilities and comment on the differences.\nYou will learn about machine learning and neural networks. You will understand neural networks by writing a simple one from scratch. Then you will learn how to use packages to write simple code for complicated networks.\nYou will learn independence. The problem formulation of many exercises is very general, which simulates when no step-by-step procedure is provided.","category":"page"},{"location":"#What-will-you-learn?","page":"Home","title":"What will you learn?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Selected examples of what you will be able to write at the end of the course include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Efficient coding: The following plot can be created in twenty lines of code (Image: )\nNumerical techniques: You will learn many techniques to minimize functions (Image: )\nNeural networks: And apply techniques to train neural networks (Image: )\nFigure 1 contains digit 5 with probability 0.999683.\nFigure 2 contains digit 0 with probability 1.000000.\nFigure 3 contains digit 4 with probability 0.974734.\nConnection to Matlab, R or Python: Do you have a Matlab code which you need to run from Julia? No problem, write five lines of code to get (Image: )","category":"page"},{"location":"#Recommended-courses","page":"Home","title":"Recommended courses","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We recommend the following courses at FJFI:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Matematické problémy nematematiků invites people from companies to talk about how scientific methods are used in real applications.","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Official documentation\nThink Julia: How to Think Like a Computer Scientist\nFrom Zero to Julia!\nWikiBooks","category":"page"},{"location":"installation/julia/#Julia","page":"Julia","title":"Julia","text":"","category":"section"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"In this section, we provide instructions on how to install all the software needed for this course. However, we only provide installation instructions for Windows 10 operating system.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"Surprisingly the first thing we have to install is the Julia programming language. The first step is to download the proper installation file from the official download page. In most cases, the appropriate version is the 64-bits version for the Windows operating system.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"If you're using an operating system other than Windows 10, follow the platform-specific instructions. Otherwise, you can follow the instructions below. Run the downloaded Julia installer and follow the given instruction.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"There is no need to change the default settings. However, in the installer's last window, make sure that the Open Julia directory option is selected.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"After finishing the installation, the Julia terminal and the Julia directory in the file explorer should open. Do not close the Julia directory, since we will need it later!!!","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/#Adding-Julia-to-PATH","page":"Julia","title":"Adding Julia to PATH","text":"","category":"section"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"To allow Julia to run by simply typing julia into the command line, we need to add the Juliabin directory toPATH. Open the Run app using the shortcut Windows key + R or by typing Run in the search bar.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"Then type rundll32 sysdm.cpl,EditEnvironmentVariables into the Run app and press OK","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"After the previous step, the Environment Variables window should appear. Under the User Variables section, select the row with the variable Path and click the Edit button.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"The Edit environment variable window will appear. Now we need to get the path to Julia bin folder. It can be done easily from the Julia directory opened by the Julia installer. In Julia directory, navigate to the bin folder. (Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"In the Julia bin folder, select and copy the path from the system file explorer's path bar.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"Navigate back to the Edit environment variable window, select the first empty row, press the Edit button, and paste the path to the Julia bin folder. Then press the OK button to leave the window and again to leave the Environment Variables window too.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"Finally, we can check that we added the path correctly. Type cmd into the search bar and open the Command Prompt.","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"In the Command Prompt type julia and press Enter. If everything is set correctly,  it will start a new Julia session (REPL).","category":"page"},{"location":"installation/julia/","page":"Julia","title":"Julia","text":"(Image: )","category":"page"},{"location":"lecture_08/logistic/#Logistic-regression","page":"Logistic regression","title":"Logistic regression","text":"","category":"section"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The last part predicted a continuous variable. This part will be closer to the iris dataset's spirit: It will predict one of two classes.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Load the data as before","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using StatsPlots\nusing RDatasets\n\niris = dataset(\"datasets\", \"iris\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The data contain three classes. However, we considered only binary problems with two classes. We therefore cheat.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Modify data in the following way:","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Label \"setosa\" will be deleted.\nLabel \"versicolor\" will be the negative class.\nLabel \"virginica\" will be the positive class.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"For the features, consider only petal length and petal width.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"For reason which will be clear later, we will first create the reduced dataset by removing the \"setosa' label","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"iris_reduced = iris[iris.Species .!= \"setosa\", :]\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Now we can create data X and labels y. Since iris_reduced is a DataFrame, we need to convert it first into a Matrix before calling hcat. Note that we use iris_reduced.Species instead of the equivalent iris_reduced[:,Species] ","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"X = hcat(Matrix(iris_reduced[:, 3:4]), ones(size(iris_reduced,1)))\ny = iris_reduced.Species .== \"virginica\"\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></details>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We again plot the data. Since we are interested in a different prediction than last time, we will plot them differently.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Since X has two features (columns), it is simple to visualize. Use scatter plot to show the data. Use different colours for different classes. Try to produce a nice graph by including names of classes and axis labels (petal length and petal width).","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We make use of the iris_reduced variable. To plot the points in different colours, we use the keyword group = :Species.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using Plots\n\n@df iris_reduced scatter(\n    :PetalLength,\n    :PetalWidth;\n    group = :Species,\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    legend = :topleft,\n)\n\nsavefig(\"iris1.svg\") # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></details>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"(Image: )","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We see that the classes are almost perfectly separable. It would not be difficult to estimate the separating hyperplane by hand. However, we will do it automatically.","category":"page"},{"location":"lecture_08/logistic/#Training-the-classifier","page":"Logistic regression","title":"Training the classifier","text":"","category":"section"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Write a function log_reg which takes as an input the dataset, the labels and the initial point. It should use Newton's method to find the optimal weights w. Print the results when started from zero.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"It would be possible to use the code optim(f, g, x, s::Step) from the previous lecture and define only the step function s for the Newton's method. However, sometimes it may be better to write simple functions separately instead of using more complex machinery.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"To write the desired function, we need to implement the gradient and Hessian from derived in the theoretical lecture. First, we need to create hat y. We may use for loop notation [1/(1+exp(-w'*x)) for x in eachrow(X)]. However, in this case, it is simpler to use matrix operations 1 ./(1 .+exp.(-X*w)) to get the same result. The gradient can be written in the same way. Again, we use matrix notation. For the Hessian, we first create X_mult = [row*row' for row in eachrow(X)] which computes all products x_ix_i^top. This creates an array of length 100, each element of this array is a 2times 2 matrix. Since it is an array, we may multiply it by y_hat.*(1 .-y_hat). As mean from the Statistics package operates on any array, we can call it (or similarly sum). We may use mean(???) but we find the alternative  ??? |> mean more readable in this case. We use hess \\ grad, as explained in the previous lecture for Newton's method, to update the weights.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using Statistics\n\nfunction log_reg(X, y, w; max_iter=100, tol=1e-6)\n    X_mult = [row*row' for row in eachrow(X)]\n    for i in 1:max_iter\n        y_hat = 1 ./(1 .+exp.(-X*w))\n        grad = X'*(y_hat.-y) / size(X,1)\n        hess = y_hat.*(1 .-y_hat).*X_mult |> mean\n        w -= hess \\ grad\n    end\n    return w\nend\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The definition of X_mult should be outside the for loop, as it needs to be computed only once. ","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"After the tough work, it remains to call it.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"w = log_reg(X, y, zeros(size(X,2)))\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></details>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The correct solution is","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"println(round.(w, digits=4)) # hide","category":"page"},{"location":"lecture_08/logistic/#Analyzing-the-solution","page":"Logistic regression","title":"Analyzing the solution","text":"","category":"section"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"We can now show the solution. Since the intercept is the third component (where x_3=1), the separating hyperplane takes form","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"w_1x_1 + x_2x_2 + w_3 = 0","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"To express it as a function, we obtain","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"operatornamesep(x_1) = x_2 = frac-w_1x_1 - w_3w_2","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Now we plot it.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"f_hyper(x, w) = (-w[3]-w[1]*x)/w[2]\n\nxlims = extrema(iris_reduced.PetalLength) .+ [-0.1, 0.1]\nylims = extrema(iris_reduced.PetalWidth) .+ [-0.1, 0.1]\n\n@df iris_reduced scatter(\n    :PetalLength,\n    :PetalWidth;\n    group = :Species,\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    legend = :topleft,\n    xlims,\n    ylims,\n)\n\nplot!(xlims, x -> f_hyper(x,w); label = \"Prediction\", line = (:black,3))\n\nsavefig(\"iris2.svg\") # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"(Image: )","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"This is the optimal solution obtained by the logistic regression. Since the norm of the gradient","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"using LinearAlgebra\n\ny_hat = 1 ./(1 .+exp.(-X*w))\ngrad = X'*(y_hat.-y) / size(X,1)\nnorm(grad)","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"equals to zero, we found a stationary point. It can be shown that logistic regression is a convex problem, and, therefore, we found a global solution.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The picture shows that there are misclassified samples. The next exercise analyses them.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Compute how many samples were correctly and incorrectly classified.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"Since hat y_i is the probability that a sample is of the positive class, we will predict that it is positive if this probability is greater than frac 12. Then it suffices to compare the predictions pred with the correct labels y.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"pred = y_hat .>= 0.5\n\"Correct number of predictions: \" * string(sum(pred .== y))\n\"Wrong   number of predictions: \" * string(sum(pred .!= y))\n\nnothing # hide","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"There is an alternative (but equivalent way). Since the separating hyperplane has form w^top x, we predict that a sample is positive whenever w^top xge 0. Write arguments on why these two approaches are equivalent.","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"</p></details>","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"The correct answer is","category":"page"},{"location":"lecture_08/logistic/","page":"Logistic regression","title":"Logistic regression","text":"println(\"Correct number of predictions: \" * string(sum(pred .== y))) # hide\nprintln(\"Wrong   number of predictions: \" * string(sum(pred .!= y))) # hide","category":"page"},{"location":"lecture_10/theory/#Theory-of-neural-networks","page":"Theory of neural networks","title":"Theory of neural networks","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"In the previous lecture, we presented an introduction to neural networks. We also showed how to train neural networks using gradient descent. This lecture is going to show more layers and a more sophisticated way of training.","category":"page"},{"location":"lecture_10/theory/#Layers","page":"Theory of neural networks","title":"Layers","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The last lecture concentrated on the dense layer. Even though it is widely used due to its simplicity, it suffers from several disadvantages, especially in visual recognition. These disadvantages include:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Large number of parameters. For an image with 500times 500times 3 pixels and the output layer of only 1000 neurons, the dense layer would contain 750 million parameters. This is too much to optimize.\nNo structural information. Dense layers assign a weight to every pixel and then add the weighted values. This means that information from the top-leftmost and bottom-rightmost pixels of the image will be combined. Since a combination of these two pixels should carry no meaningful information, redundant computation is performed.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Convolutional layers were designed to alleviate these issues.","category":"page"},{"location":"lecture_10/theory/#Convolutional-layer:-Motivation","page":"Theory of neural networks","title":"Convolutional layer: Motivation","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"To understand the convolutional layers, we need to go back to the definition of convolution. Having a function f and  a kernel g, their convolution is defined by","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(x) = int_-infty^infty f(x - t)g(t) dt","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Let us consider the simplest case when","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"g(t) = begincases frac12varepsilon textif tin-varepsilonvarepsilon  0 textotherwise endcases","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Then ","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(x) = int_-infty^infty f(x - t)g(t) dt = frac12varepsilonint_-varepsilon^varepsilonf(x - t)dt","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Then (fast g)(x) does not take the value of f at x but it integrates f over a small neighbourhood of x. Applying this kernel results in a smoothening of f.  ","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"In image processing, the image f is not represented by a function but by a collection of pixels. The kernel g is represented by a small matrix. For the commonly used 3times 3 kernel matrix, the convolution has the form","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(fast g)(xy) = sum_i=-1^1sum_j=1^1 f(x+iy+j)g(ij)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The following kernels","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"K_1 = beginpmatrix 0  0  0  0  1  0  0  0  0 endpmatrix qquad\nK_2 = frac 19beginpmatrix 1  1  1  1  1  1  1  1  1 endpmatrix qquad\nK_3 = beginpmatrix -1  -1  -1  -1  8  -1  -1  -1  -1 endpmatrix","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"perform identity, image smoothening and edge detection, respectively.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/theory/#Convolutional-layer:-Formulas","page":"Theory of neural networks","title":"Convolutional layer: Formulas","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Traditional techniques for image processing use multiple fixed kernels and combine their results. The idea of convolutional layers is to remove all human-made assumptions about which kernels to choose and learn the kernels' parameters based purely on data. Even though it gives superb results, it also removes any insight or interpretation humans may make. ","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The input of a convolutional layer has dimension I_1times J_1times C_1, where I_1times J_1 is the size of the image and C_1 is the number of channels (1 for grayscale, 3 for coloured, anything for hidden layers). Its input is also the kernel K. The output of the convolutional layer has dimension I_2times J_2times C_2 and its value at some (i_0j_0c_0) equals to","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"textoutput(i_0j_0c_0) = lleft(sum_c=1^Csum_i=-a^asum_j=-b^b Big( K_c_0(ijc) textinput(i_0+ij_0+jc) + b(c)Big)right)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"After the linear operation inside, an activation function l is applied. Without it, the whole network would a product of linear function and therefore linear function (written in a very complicated form).","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The natural question is the interpretation of the linear operator and the number of parameters:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The kernel matrix K contains (2a+1)(2b+1)C_1C_2 parameters. What does it mean? First, there is a separate kernel for each output channels. Second, the kernel also averages (more precisely, computes a linear combination) over all input channels. However, the coefficients of this linear combination do not depend on the position (i_0j_0). \nThe bias b has dimension C_2. Again, it does not depend on the position (i_0j_0).","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The important thing to realize is that the number of parameters does not depend on the size of the image or the hidden layers. For example, even for an input image 500times 500times 3, the convolutional layer contains only 448 parameters for 3times 3 kernel and 16 output channels (do the computations).","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This results in fixing the two issues mentioned above.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The number of parameters of convolutional layers stays relatively small.\nUsing kernels means that only local information from neighbouring pixels is propagated to subsequent layers.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Practical convolutional layers involve additional complexities such as layers with even size (we showed only even sizes), padding (should zeros be added or should the output image be smaller) or stride (should there be any distance between convolutions). This goes, however, beyond the lecture.","category":"page"},{"location":"lecture_10/theory/#Recurrent-layer","page":"Theory of neural networks","title":"Recurrent layer","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Recurrent layers are designed to handle one-dimensional data. They are similar to convolutional layers with J_1=J_2=C_1=C_2=1. Unlike convolutional layers, they store additional hidden variables. The most-known representative is the long short-term memory (LSTM) cell.","category":"page"},{"location":"lecture_10/theory/#Pooling-layer","page":"Theory of neural networks","title":"Pooling layer","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The goal of pooling layers is to reduce the size of the network. They take a small (such as 2times 2) window and perform a simple operation on this window (such as maximum or mean). Since the pooled windows do not overlap, this reduces the size of each dimension in half. Pooling layers do not have any trainable parameters. ","category":"page"},{"location":"lecture_10/theory/#Skip-connections","page":"Theory of neural networks","title":"Skip connections","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"From the previous lecture, we know that the gradient is computed via the chain rule","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"nabla f = nabla f_Mnabla f_M-1dotsnabla f_1","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Since the formula contains multiplication, it means that if any of the gradients is too small, then the whole gradient will be too small. Specifically, the deeper the network, the higher the chance that the initial point will be in a point with a small gradient and the training will progress slowly. This phenomenon is called vanishing gradients.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"To solve the issue with vanishing gradients, skip connections are sometimes added. Even though it is not a layer, we include it here. They do precisely what their name suggest: They skip one or more layers. This makes the network more flexible: Due to its deep structure, it can approximate complicated functions, and due to its shallow structure (because of skip connections), the initial training can be fast.","category":"page"},{"location":"lecture_10/theory/#Network-structure","page":"Theory of neural networks","title":"Network structure","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"When an input is an image, the usual structure of the neural network is the following:","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Convolutional layer followed by a pooling layer.\nThis is repeated many times.\nFlatten layer (it reshapes the three-dimensional tensor into a vector).\nDense (fully connected) layer.\nSoftmax layer.\nCross-entropy loss function.","category":"page"},{"location":"lecture_10/theory/#Stochastic-gradient-descent","page":"Theory of neural networks","title":"Stochastic gradient descent","text":"","category":"section"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"We recall that machine learning problems minimize the loss function","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"L(w) = frac1nsum_i=1^n operatornameloss(y_i f(w x_i))","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Its gradient equals to","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"nabla L(w) = frac1nsum_i=1^n operatornameloss(y_i f(w x_i))nabla_w f(w x_i)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"If the dataset contains many samples (n is large), then it takes long time to compute the gradient. Therefore, the full gradient is replaced by its stochastic (random) approximation","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"frac1Isum_iin I operatornameloss(y_i f(w x_i))nabla_w f(w x_i)","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Here, the minibatchI is a small (32 64 dots) subset of all samples 1dotsn. Sometimes the gradient descent is replaced by other options such as ADAM or RMSprop, which in some way consider the history of gradients.","category":"page"},{"location":"lecture_10/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This technique is called stochastic gradient descent. During one epoch (the time during which the optimizer evaluates each sample once), it performs many gradient updates (unlike the standard gradient descent which performs only one update). Even though these updates are imprecise, numerical experiments show that stochastic gradient descent is much faster than standard gradient descent. The probable reason is that the full dataset contains lots of duplicate information, and the full gradient performs unnecessary computation, which slows it down.  ","category":"page"},{"location":"lecture_04/otherpackages/#Distributions.jl","page":"Other Useful Packages","title":"Distributions.jl","text":"","category":"section"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using Distributions\nusing StatsPlots","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The Distributions package provides a large collection of probabilistic distributions and related functions. Each distribution is defined as a custom type, which allows creating distribution instances in a simple way as follows","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using Distributions\nD = Normal(2, 0.5)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"In the example above, we created Normal distribution with mean μ = 2 and standard deviation σ = 0.5. Distributions package provides many useful functions to compute mean, variance, or quantiles of the given distribution","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"mean(D)\nvar(D)\nquantile(D, 0.9)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The package also provides functions to evaluate probability density function or cumulative probability at a given point","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"pdf(D, 2)\ncdf(D, 2)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"In combination with the StatsPlots package, it is possible to plot probability density functions as follows","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using StatsPlots\nplot(D; linewidth = 2, xlabel = \"x\", ylabel = \"pdf(x)\", legend = false)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The Distributions package also provides methods to fit a distribution to a given set of samples","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"x = rand(Normal(2, 0.5), 10000); # generate 10000 random numbers from Normal(2, 0.5)\nD = fit(Normal, x)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The fit function will choose a reasonable way to fit the distribution, which, in most cases, is maximum likelihood estimation. Note that this is not supported for all distributions. We can easily check that the distribution fit the given data nicely using a histogram","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"histogram(x; normalize = :pdf, legend = false, opacity = 0.5)\nplot!(D; linewidth = 2, xlabel = \"x\", ylabel = \"pdf(x)\")","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Create a figure that will show Gamma distributions with the following parameters: (2, 2), (9, 0.5), (7.5, 1) and (0.5, 1).","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Hint: to plot cumulative probability functions, use the Plots ability to plot a function on a given interval.","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The easiest way to create distributions with given parameters is to use Julia's broadcast system as follows","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Ds = Gamma.([2, 9, 7.5, 0.5], [2, 0.5, 1, 1])\nnothing #hide","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Similarly, we can use broadcasting to create a vector of labels for given distributions","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"labels = reshape(string.(\"Gamma\", params.(Ds)), 1, :)\nnothing #hide","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Note that we reshape labels to be a row vector. The reason is that we want to plot multiple distributions at once, and in such a case Plot package expects that labels will be a row vector, where each column represents a label for one curve. Now, we can call the plot function to plot all distributions at once","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"plot(Ds;\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"pdf(x)\", (0, 0.5)),\n    labels = labels,\n    linewidth = 2,\n    legend = :topright,\n)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"A plot of cumulative probability functions cannot be done in the same way. However, StatsPlots provides the func keyword argument  that allows specifying which function should be plotted for a given distribution","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"plot(Ds;\n    func = cdf,\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"cdf(x)\", (0, 1.05)),\n    labels = labels,\n    linewidth = 2,\n    legend = :bottomright,\n)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Another way to plot cumulative probability functions is to use the Plots package capability to plot functions directly. To do this, we need to define a function with one argument, which at a given point returns the value of the cumulative probability function. Such functions for all our distributions can be easily defined as anonymous functions","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"cdfs = [x -> cdf(D, x) for D in Ds]\nnothing # hide","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Note that the previous expression returns a vector of functions. Now we can use the plot function that creates a curve for each element of the vector of cumulative probability functions. In the example below, we create these curves for x from0 to 20","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"plot(cdfs, 0, 20;\n    func = cdf,\n    xaxis = (\"x\", (0, 20)),\n    yaxis = (\"cdf(x)\", (0, 1.05)),\n    labels = labels,\n    linewidth = 2,\n    legend = :bottomright,\n)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"</p></details>","category":"page"},{"location":"lecture_04/otherpackages/#BSON.jl","page":"Other Useful Packages","title":"BSON.jl","text":"","category":"section"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"BSON is a package for working with the Binary JSON serialization format. It can be used as a general store for Julia's data structures. To save the data, BSON provides the bson function.  The data can be passed to the function directly via keyword arguments","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using BSON\nBSON.bson(\"test2.bson\", a = [1+2im, 3+4im], b = \"Hello, World!\")","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"or as a dictionary","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"data = Dict(:a => [1+2im, 3+4im], :b => \"Hello, World!\")\nBSON.bson(\"test1.bson\", data)","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"To load the data, BSON provides the load function that accepts the path to the data","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"BSON.load(\"test1.bson\")\nBSON.load(\"test2.bson\")","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The package also provides an alternative way to saving and loading data using the @save and @load macro","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using BSON: @save, @load\n\na = [1+2im, 3+4im];\nb = \"Hello, World!\";\n\n@save \"test.bson\" a b # Same as above\n@load \"test.bson\" a b # Loads `a` and `b` back into the workspace","category":"page"},{"location":"lecture_04/otherpackages/#ProgressMeter.jl","page":"Other Useful Packages","title":"ProgressMeter.jl","text":"","category":"section"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The ProgressMeter package provides excellent utilities for printing progress bars for long-running computation. The package provides the @showprogress macro that can be used for printing the progress bar for for loops in the following way","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"julia> using ProgressMeter\n\njulia> @showprogress 1 \"Computing...\" for i in 1:50\n           sleep(0.1)\n       end\nComputing... 20%|███████▊                               |  ETA: 0:00:04","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The same syntax can also be used with the map/pmap/reduce function. Progress bars can also be created manually, which allows additional formatting of the output. For example, it is possible to print and update information related to the computation by using the showvalues keyword as follows","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"julia> x, n = 1 , 10;\n\njulia> p = Progress(n);\n\njulia> for iter in 1:10\n           x *= 2\n           sleep(0.5)\n           ProgressMeter.next!(p; showvalues = [(:iter, iter), (:x, x)])\n       end\nProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\n  iter:  10\n  x:     1024","category":"page"},{"location":"lecture_04/otherpackages/#BenchmarkTools.jl","page":"Other Useful Packages","title":"BenchmarkTools.jl","text":"","category":"section"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The BenchmarkTools package provides a framework for writing and running groups of benchmarks as well as comparing benchmark results. The primary macro provided by BenchmarkTools is the @benchmark macro","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"using BenchmarkTools\n@benchmark sin(x) setup=(x=rand())","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"The setup expression is run once per sample and is not included in the timing results. Another handy macro provided by the package is the @btime macro. The output of this macro is similar to the built-in @time macro","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"A = rand(3,3);\n@btime inv($A);","category":"page"},{"location":"lecture_04/otherpackages/","page":"Other Useful Packages","title":"Other Useful Packages","text":"Note that we use $ to interpolate variable A into the benchmark expression. Any expression that is interpolated in such a way is \"pre-computed\" before benchmarking begins.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function bisection(f, a, b; tol=1e-6)\n    fa = f(a)\n    fb = f(b)\n    fa == 0 && return a\n    fb == 0 && return b\n    fa*fb > 0 && error(\"Wrong initial values for bisection\")\n    while b-a > tol\n        c = (a+b)/2\n        fc = f(c)\n        fc == 0 && return c\n        if fa*fc > 0\n            a = c\n            fa = fc\n        else\n            b = c\n            fb = fc\n        end\n    end\n    return (a+b)/2\nend","category":"page"},{"location":"lecture_12/optimal_control/#Optimal-control","page":"Optimal control","title":"Optimal control","text":"","category":"section"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"This section considers the optimal control, which combines ordinary differential equations with optimization. It was extensively studied many decades ago, when it was used to steer rockets in space.","category":"page"},{"location":"lecture_12/optimal_control/#Permanent-magnet-synchronous-motors","page":"Optimal control","title":"Permanent magnet synchronous motors","text":"","category":"section"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We will consider the problem of optimal steering of a PMSM (permanent magnet synchronous motor), which appear in electrical drives. The motor can be described via a linear equation","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"dot x(t) = Ax(t) + q(t) + Bu(t)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"where x(t) is the state, q(t) is the bias and u(t) is the control term. More specifically, we have","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"A = -beginpmatrix fracR_1L_1  0  0  fracR_2L_2 endpmatrix - omega beginpmatrix 0  -1  1  0 endpmatrix qquad B = beginpmatrix 1  0  0  1endpmatrix qquad q(t) = beginpmatrix fracR_1L_1psi_rm pm  0 endpmatrix","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"where R is the resistance, L the inductance, psi the flux and omega the rotor speed. The state x(t) are the currents in the dq reference frame and the control u(t) is the provided voltage. For simplicity we assume that the ratio of resistances and inductances is the same and that the bias is constant:","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"rho = fracR_1L_1 = fracR_2L_2qquad q=q(t)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The goal is to apply such voltage so that the system reaches the desired position x_rm tar from an initial position x_0 in minimal possible time. With maximal possible allowed voltage U_rm max this amounts to solving","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ntextminimizeqquad tau \ntextsubject toqquad dot x(t) = Ax(t) + q + u(t) qquad tin0tau \nu(t)le U_rm maxqquad tin0tau \nx(0) = x_0 x(tau)=x_rm tar\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Discretizing the problem and solving it by means of non-linear programming would result in a large number of variables (their number would also be unknown due to the minimal time tau) and is not feasible. Instead, we analyze the problem and try to simplify it.","category":"page"},{"location":"lecture_12/optimal_control/#Computing-trajectories","page":"Optimal control","title":"Computing trajectories","text":"","category":"section"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"From the theoretical part, we know that the optimal solution of the ODE equals to","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\nx(t) = e^Atleft(x_0 + int_0^t e^-As(q+u(s))dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t e^-Asu(s)dsright)\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"This term contains the matrix exponential e^At. To compute it, we may run exp(A). It is important to realize that matrix exponential is different from elementwise exponential exp.(A) (try it). We set up the parameters","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"ω = 2\nρ = 0.01\n\nA = -ρ*[1 0; 0 1] -ω*[0 -1; 1 0]\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"By computing the eigenvalues and eigenvectors","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"using LinearAlgebra\n\nλ, V = eigen(A)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"we can deduce that eigendecomposition","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"A = frac 12beginpmatrix i  -i  1  1 endpmatrix beginpmatrix -rho - iomega  0 0  -rho+iomega endpmatrix beginpmatrix i  1  -i  1 endpmatrix","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We have divided the expression by 2 because all eigenvectors should have unit norm. Then the matrix exponential is","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ne^At = frac 12beginpmatrix i  -i  1  1 endpmatrix beginpmatrix e^-rho t - iomega t  0 0  e^-rho t+iomega t endpmatrix beginpmatrix i  1  -i  1 endpmatrix \n= dots = e^-rho tbeginpmatrix cosomega t  sinomega t  -sinomega t  cosomega tendpmatrix\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Verify that the matrix exponential is computed correctly and that the it is different from elementwise exponential.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"A simple way to verify is to fix some t and evaluate all the expressions derived above","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"t = 5\nexp0 = exp.(t*A)\nexp1 = exp(t*A)\nexp2 = V*diagm(exp.(λ*t))*V'\nexp3 = exp(-ρ*t)*[cos(ω*t) sin(ω*t); -sin(ω*t) cos(ω*t)]\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Now, exp1, exp2 and exp3 must be identical and differ from exp0. Since there are rounding errors for different methods, the matrices will not be exactly identical and we need to check whether they norm is almost zero.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"norm(exp1 - exp0) >= 1e-10 || error(\"Matrices are wrong\")\nnorm(exp1 - exp2) <= 1e-10 || error(\"Matrices are wrong\")\nnorm(exp1 - exp3) <= 1e-10 || error(\"Matrices are wrong\")\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Since the computation resulted in no error (note the opposite sign for exp0), our computation seems to be correct.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></details>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Similarly to the wave equation, this system has many parameters. To keep track of them, and to prevent accidently changing them in a script, we should save them in a structure. We will create this structure so that it can also compute the matrix exponential and other useful functions.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We define the structure","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"struct Params\n    ρ\n    ω\n    A\n    invA\n    expA\n    expAT\n    n\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"which besides rho, omega and A also stores the inverse matrix A^-1, the matrix exponential functions tmapsto e^At, tmapsto e^A^top t and the size of A.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Write a constructor (function) Params(ρ, ω), which creates this object.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The inverse matrix can be obtained by inv(A). The rest is obtained as the formulas above. for the transposition of the exponential, we need to convert it back to Matrix, otherwise we could have problems later.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function Params(ρ, ω)\n    A = -ρ*[1 0; 0 1] -ω*[0 -1; 1 0]\n    invA = inv(A)\n    expA(t) = exp(-ρ*t)*[cos(ω*t) sin(ω*t); -sin(ω*t) cos(ω*t)]\n    expAT(t) = Matrix(expA(t)')\n    n = size(A,1)\n    return Params(ρ, ω, A, invA, expA, expAT, n)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></details>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"For the rest of this section, we will work with the following parameter setting","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"ρ = 0.1\nω = 2\nx0 = [0;-0.5]\nq = [1;0]\n\nps = Params(ρ, ω)\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Now we can finally plot the trajectories of the electric motor.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Consider the case of time interval 010. The other parameters are specified directly above this exercise.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Compute the trajectory x(t) for no control (u(t)=0) using finite differences with Delta t=001. Then compute the exact solution using the formulas derived above. Plot the trajectories as a plot (no animations).","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We store the solution obtained by finite differences in xs1 and the true solution in xs2. We initialize both arrays and add x0 at the first time instant. Then we use the discretization formula. All the parameters connected with A are retrieved from the ps structure.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"using Plots\n\nΔt = 0.01\nts = 0:Δt:10\n\nxs1 = zeros(2, length(ts))\nxs1[:,1] = x0\nxs2 = zeros(2, length(ts))\nxs2[:,1] = x0\n\neye(n) = Diagonal(ones(n))\n\nfor i in 1:length(ts)-1\n    xs1[:,i+1] = xs1[:,i] + Δt*(ps.A*xs1[:,i] + q)\n    xs2[:,i+1] = ps.expA(ts[i])*(x0 + ps.invA*(eye(ps.n)-ps.expA(-ts[i]))*q)\nend\n\nplot(xs1[1,:], xs1[2,:], label=\"Finite differences\")\nplot!(xs2[1,:], xs2[2,:], label=\"True value\")\n\nsavefig(\"Comparison1.svg\") # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></details>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The trajectories are different. Something is wrong. However, when we use the time discretization Delta t=00001, the solutions are suddenly equal.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Δt_aux = Δt\nts_aux = ts\n\nΔt = 0.0001\nts = 0:Δt:10\n\nxs1 = zeros(2, length(ts))\nxs1[:,1] = x0\nxs2 = zeros(2, length(ts))\nxs2[:,1] = x0\n\nfor i in 1:length(ts)-1\n    xs1[:,i+1] = xs1[:,i] + Δt*(ps.A*xs1[:,i] + q)\n    xs2[:,i+1] = ps.expA(ts[i])*(x0 + ps.invA*(eye(ps.n)-ps.expA(-ts[i]))*q)\nend\n\nplot(xs1[1,:], xs1[2,:], label=\"Finite differences\")\nplot!(xs2[1,:], xs2[2,:], label=\"True value\")\n\nsavefig(\"Comparison2.svg\") # hide\n\nΔt = Δt_aux\nts = ts_aux","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Can you guess why this happened? The problem is that the finite difference method performs a first order approximation of the non-linear function x(t). But since the trajectory always \"bends leftwards\", the finite differences follow this bending with a delay. The error accummulates over time and is quite large at the end.","category":"page"},{"location":"lecture_12/optimal_control/#Solving-the-optimal-control-problem","page":"Optimal control","title":"Solving the optimal control problem","text":"","category":"section"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"So far, we did not consider any control. This part shows how the optimal control can be computed. Using a rather complicated theory, it can be shown that for any terminal state x_rm tar, there is some p_0 such that the optimal control has form","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\np(t) = e^-A^top tp_0 \nu(t) = U_rm maxfracp(t)p(t)\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The next remark hints at the derivation of these formulas. It can be safely skipped.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"info-body\">\n<header class = \"info-header\">Connection with optimization</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Optimal control forms the Hamiltonian (similar to the Langrangian)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"H = tau + p(t)^top (Ax(t) + q + u(t))","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Since the constraint is time-dependent, the adjoint variable (multiplier) p(t) must also depend on time. Differentiating the Hamiltonian with respect to the x(t) and setting the derivative to -dot p(t) (instead of zero as in nonlinear optimization) results in","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"-dot p(t) = A^top p(t)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"which has the solution","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"p(t) = e^-A^top tp_0","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"This is the first condition written above. The second condition can be obtained by maximizing the Hamiltonian with respect to u and arguing that the constraint u(t)=U_rm max will always be satisfied (this goes beyond the content of this lecture).","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"It is not difficult to show that","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"e^-Ata^-A^top t = e^2rho tI","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We intend to compute the trajectory. The most difficult part is the integral from  e^-Asu(s). Since","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\ne^-Asu(s) = U_rm maxfrace^-Ase^-A^top sp_0e^-A^top sp_0 = U_rm maxfrace^-Ase^-A^top sp_0sqrtp_0^top e^-Ase^-A^top sp_0 =  U_rm maxfrace^2rho sp_0sqrtp_0^top e^2rho sI p_0 = U_rm maxe^rho sfracp_0p_0\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"the trajectory equals to ","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"beginaligned\nx(t) = e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t e^-Asu(s)dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + int_0^t U_rm maxe^rho sfracp_0p_0 dsright) \n= e^Atleft(x_0 + A^-1(I-e^-At)q + fracU_rm maxrho(e^rho t-1)fracp_0p_0 right)\nendaligned","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"This allows us to plot the optimal trajectories.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Write functions x(t, ???) and trajectory(ts, ???) which compute the optimal solution x(t) and the trajectory x(t)_tin rm ts (saved into a matrix).","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The optimal trajectory depends on the normed vector p_0. All such vectors form a unit circle in mathbb R^2. Therefore, they can be parameterized by an angle alphain02pi. Fix U_rm max=01 and time interval 010 with time step Delta t=001. Then plot eight possible optimal trajectories (each would correspond to a different target x_rm tar) with uniformly distributed alpha.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"For functions x, we need to rewrite the previous formula into code. For trajectory, we call x for t in ts. Since x returns a two-dimensional vector, we need to cat the results to a matrix.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"function x(t, ps, x0, U_max, p0, q)\n    return ps.expA(t)*(x0 + ps.invA*(eye(ps.n)-ps.expA(-t))*q + U_max/ρ*(exp(ρ*t)-1)*p0)\nend\n\ntrajectory(ts, ps, x0, U_max, p0, q) = hcat([x(t, ps, x0, U_max, p0, q) for t in ts]...)\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"For plotting, we initialize the variables","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"U_max = 0.1\n\nΔt = 0.01\nts = 0:Δt:10\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"then create an empty plot. We make a uniform discretization of 02pi and for each alpha from this interval, we compute p_0, the trajectory and finally plot the result. Since we plot in a loop, we need to display the plot.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"pa = plot()\nfor α = 0:π/4:2*π\n    p0 = [sin(α); cos(α)]\n    traj =  trajectory(ts, ps, x0, U_max, p0, q)\n    plot!(traj[1,:], traj[2,:], label=\"\")\nend\ndisplay(pa)\n\nsavefig(\"Trajectories.svg\") # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></details>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Rearranging the previous equation results in","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho t-1) fracp_0p_0 = e^-tAx(t) - x_0 - A^-1(I-e^-At)q","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"We take the norm of both sides to arrive at","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho t-1) = e^-tAx(t) - x_0 - A^-1(I-e^-At)q","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Since this realization needs to hold true for all tin0tau, we set t=tau and use the target relation x(tau)=x_rm tar","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"fracU_rm maxrho(e^rho tau-1) = e^-tau Ax_rm tar - x_0 - A^-1(I-e^-Atau)q","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"All data besides tau are known. Therefore, if we solve it, we obtain the optimal time tau. This is done in the next exercise.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Solve the optimal control problem for x_rm tar= (025 -05). Plot the optimal trajectory to this point.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"To solve the equation above, we need to find a zero point of ","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"f(t) = e^-Atx_rm tar - x0 - A^-1(I-e^-At)q - fracU_rm maxrho(e^rho t-1)","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"The graph of the function (plot it) shows that it has a single zero point (for this parameter setting). It can be found by evaluating it at many points at selecting the point with the value closest to zero. A more formal approach is to use the bisection method written earlier.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"x_tar = [0.25;-0.5]\n\nf(t) = norm(ps.expA(-t)*x_tar - x0 - ps.invA*(eye(ps.n)-ps.expA(-t))*q) - U_max/ps.ρ*(exp(ps.ρ*t)-1)\n\nτ = bisection(f, minimum(ts), maximum(ts))\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"To compute the optimal control and optimal trajectory, we first need to compute p_0 and then use the trajectory function. We restrict the interval ts to 0tau.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"p0 = ps.ρ/(U_max*(exp(ps.ρ*τ)-1))*(ps.expA(-τ)*x_tar - x0 - ps.invA*(eye(ps.n)-ps.expA(-τ))*q)\np0 /= norm(p0)\n\nts_opt = ts[ts .<= τ + Δt]\n\ntraj = trajectory(ts_opt, ps, x0, U_max, p0, q)\n\nnothing # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"Then we plot the trajectory and the target point.","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"plot(traj[1,:], traj[2,:], label=\"Optimal trajectory\")\nscatter!([x_tar[1]], [x_tar[2]], label=\"Target point\")\n\nsavefig(\"Optimal.svg\") # hide","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"</p></details>","category":"page"},{"location":"lecture_12/optimal_control/","page":"Optimal control","title":"Optimal control","text":"(Image: )","category":"page"},{"location":"installation/tutorial/#Creating-new-project","page":"Quick Start Guide","title":"Creating new project","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"This section provides a step-by-step tutorial in which we show how to create a new project, add a new file, initialize a git repository, and publish the repository on Github.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"The first thing we have to do when creating a new project is to select a folder where we want to store the project. Open the file Explorer in the VS Code by pressing its icon in the activity bar and then press the Open Folder button. Alternatively, use the keyboard shortcut Ctrl + K Ctrl + O.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"A system file explorer should open, so find and select the folder you want to use as a project folder. In our case, it is a Tutorial folder in Documents.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Now go to the project manager by pressing the appropriate button in the activity bar. Since we are creating the first project, the project manager tab should be empty. Press the Project Manager: Save Project button, type a project name in the popup bar, and then press Enter.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"It will add a new project to the project manager. In our case, it is a project called Tutorial.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Now go back to the file explorer. In the sidebar, under the project name, there should be an empty space. Press the New File button next to the project name and write a new file name with the .jl extension. Alternatively, use the keyboard shortcut Ctr + N to create a new file and then Ctrl + S to save the file.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"The new file will open in the editor to the right of the File Explorer sidebar. Type println(\"Hello, world.\") in the new file and press Ctrl + S to save the change. Now select the code and press Ctrl + Enter to execute the code. This shortcut runs the new Julia session and sends the code to the session. Congratulations, you create and run a Hello, world program in Julia.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/#Initialize-Git-Repository","page":"Quick Start Guide","title":"Initialize Git Repository","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Now that we have created a new project, it is time to initialize the git repository to track the project's changes. Go to the Source Control bar by pressing the appropriate button in the activity bar. Then press the Initialize Repository button, and it will create a new Git repository in the project folder.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"We can check if the Git repository is initialized in the system file explorer. Go to the project folder, and in the file explorer, in the top bar under the View tab, select the Hidden items option. Now you should see the .git folder in the project directory.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"With the initialized Git repository, we can start tracking changes in our work. Note the number 1 in the control source icon. It indicates that there is one change against the last version of the project.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Git provides the commit command to capture changes in the project. To create a new git commit, we must first select what changes we want to capture. In our case, it is trivial since there is only one change. In the source control under the Changes section, you should see the test.jl file. Press the Stage Changes button located on the file name's right (+ icon).","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"It will move the file under the Staged Changes section. The git commit will capture all files in this section. The next step is to add a message to the git commit. Type any message that describes changes made in the project. It is good to use short but descriptive messages since it will help later to navigate the project history. We use the Initial commit message. To finish the git commit, press the Commit button above the message bar or use the keyboard shortcut Ctrl + Enter in the message bar. Congratulations, you just created your first git commit.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Now return to the file explorer bar and open the Timeline drop-down menu at the bottom. In the Timeline bar, you can see the history of the currently open file. In our case, we can see the history of the test.jl file: one git commit created by user  User Name and described by the Initial commit message. If you click on that git commit, it will open an editor with changes that were made to the current file. On the left-hand side, we can see the file's state before the git commit and on the right-hand side after the git commit. It allows us to see all the changes made in the file easily. In our case, we can see that we added one line of code.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/#Publish-on-GitHub","page":"Quick Start Guide","title":"Publish on GitHub","text":"","category":"section"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"Now it's time to publish our work on GitHub. With GitHub, it's easy to share and collaborate on a project with multiple people. If you did not create a GitHub account in the previous section about Git installation, please do it now.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"To publish a local git project on GitHub, press the Publish Changes button on the bottom status bar. Then VS Code extension GitHub asks to sign in using a GitHub account. Press the Allow button and follow the given instructions.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"After logging into GitHub, a pop-up window will appear. Enter the desired repository name and select whether the repository should be private or public, and press Enter. In our case, we use the Tutorial.jl name for the repository since it is an easy way to show that the project is written in Julia. You may also need to add permissions to Git Credential Manager to access your GitHub account.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"If everything went well, a pop-up window would inform you that the project was successfully published to Github. Press the Open in GitHub button to open the repository in your browser.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"And that's all. Now that you've published your first repository on GitHub, you can easily share your project with others.","category":"page"},{"location":"installation/tutorial/","page":"Quick Start Guide","title":"Quick Start Guide","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using BSON\nusing Flux\nusing MLDatasets\nusing DataFrames\n\nusing Flux: onehotbatch, onecold, flatten\n\nCore.eval(Main, :(using Flux)) # hide\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nMNIST.traindata()\n\nfunction reshape_data(X::AbstractArray{T, 3}, y::AbstractVector) where T\n    s = size(X)\n    return reshape(X, s[1], s[2], 1, s[3]), reshape(y, 1, :)\nend\n\nfunction train_or_load!(file_name, m, X, y; force=false, kwargs...)\n\n    !isdir(dirname(file_name)) && mkpath(dirname(file_name))\n\n    if force || !isfile(file_name)\n        train_model!(m, X, y; file_name=file_name, kwargs...)\n    else\n        m_loaded = BSON.load(file_name)[:m]\n        Flux.loadparams!(m, params(m_loaded))\n    end\nend\n\nfunction load_data(dataset; T=Float32, onehot=false, classes=0:9)\n    X_train, y_train = reshape_data(dataset.traindata(T)...)\n    X_test, y_test = reshape_data(dataset.testdata(T)...)\n    y_train = T.(y_train)\n    y_test = T.(y_test)\n\n    if onehot\n        y_train = onehotbatch(y_train[:], classes)\n        y_test = onehotbatch(y_test[:], classes)\n    end\n\n    return X_train, y_train, X_test, y_test\nend\n\nusing Plots\n\nplot_image(x::AbstractArray{T, 2}) where T = plot(Gray.(1 .-x'), axis=false, ticks=false)\n\nfunction plot_image(x::AbstractArray{T, 3}) where T\n    size(x,3) == 1 || error(\"Image is not grayscale.\")\n    plot_image(x[:,:,1])\nend\n\n\nT = Float32\ndataset = MLDatasets.MNIST\n\nX_train, y_train, X_test, y_test = load_data(dataset; T=T, onehot=true)","category":"page"},{"location":"lecture_10/exercises/#Exercises","page":"Exercises","title":"Exercises","text":"","category":"section"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The first two exercises handle training neural networks on GPUs instead of CPUs. Even though this is extremely important for reducing the training time, we postponed it to the exercises because some course participants may not have a compatible GPU for training. If you are not able to do these two exercises for this reason, we apologize.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 1: Operations on GPUs</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"While most computer operations are performed on CPUs (central processing unit), neural networks are trained on other hardware such as GPUs (graphics processing unit) or specialized hardware such as TPUs.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To use GPUs, include packages Flux and CUDA. Then generate a random matrix Ain mathbbR^100times 100 and a random vector bin mathbbR^100. They will be stored in the memory (RAM) and the computation will be performed on CPU. To move them to the GPU memory and allow computations on GPU, use gpu(A) or the more commonly used A |> gpu.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Investigate how long it takes to perform multiplication Ab if both objects are on CPU, GPU or if they are saved differently. Check that both multiplications resulted in the same vector.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The beginning is simple","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using Flux\nusing CUDA\n\nA = randn(100,100)\nb = randn(100)\nA_g = A |> gpu\nb_g = b |> gpu","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To test the time, we measure the time for multiplication","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"@time A*b;\n@time A_g*b_g;\n@time A_g*b;","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"0.069785 seconds (294.76 k allocations: 15.585 MiB, 14.75% gc time)\n0.806913 seconds (419.70 k allocations: 22.046 MiB)\n0.709140 seconds (720.01 k allocations: 34.860 MiB, 1.53% gc time)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We see that all three times are different. Can we infer anything from it? No! The problem is that during a first call to a function, some compilation usually takes place. We should always compare only the second time.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"@time A*b;\n@time A_g*b_g;\n@time A_g*b;","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"0.000083 seconds (1 allocation: 896 bytes)\n0.000154 seconds (11 allocations: 272 bytes)\n0.475280 seconds (10.20 k allocations: 957.125 KiB)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We conclude that while the computation on CPU and GPU takes approximately the same time, when using the mixed types, it takes much longer.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To compare the results, the first idea would be to run","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"norm(A*b - A_g*b_g)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"which would result in an error. We cannot use any operations on arrays stored both on CPU and GPU. The correct way is to move the GPU array to CPU and only then to compute the norm","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using LinearAlgebra\n\nnorm(A*b - cpu(A_g*b_g))","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"1.2004562847861718e-5","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The norm is surprisingly large. Checking the types","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(typeof(A), typeof(A_g))","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Array{Float64,2}, CUDA.CuArray{Float32,2})","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"we realize that one of the arrays is stored in Float64 while the second one in Float32. Due to the different number of saved digits, the multiplication results in this error.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The previous exercise did not show any differences when performing a matrix-vector multiplication. The probable reason was that the running times were too short. The next exercise shows the time difference when applied to a larger problem.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Load the MNIST dataset and the model saved in data/mnist.bson. Compare the evaluation of all samples from the testing set when done on CPU and GPU. For the latter, you need to convert the model to GPU.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We load the data, model and convert everything to GPU","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using CUDA\n\nm = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m, X_train, y_train)\n\nm_g = m |> gpu\nX_test_g = X_test |> gpu","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Now we can measure the evaluation time. Remember that before doing so, we need to compile all the functions by evaluating at least one sample.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"m(X_test[:,:,:,1:1])\nm_g(X_test_g[:,:,:,1:1])\n\n@time m(X_test);\n@time m_g(X_test_g);","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"1.190033 seconds (40.24 k allocations: 1.069 GiB, 21.73% gc time)\n0.071805 seconds (789 allocations: 27.641 KiB)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Using GPU speeded the computation by more than ten times.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"info-body\">\n<header class = \"info-header\">Computation on GPU</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Using GPUs speeds up the training of neural networks in orders of magnitude. However, one needs to be aware of some pitfalls.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Make sure that all computation is performed either on CPU or GPU. Do not mix them. When computing on GPU, make sure that all computations are fast. One important example is","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"accuracy(x, y) = mean(onecold(cpu(m(x))) .== onecold(cpu(y)))","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Because onecold accesses individual elements of an array, it is extremely slow on GPU. For this reason, we need to move the arrays on CPU first.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Another thing to remember is to always convert all objects to CPU before saving them.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Exercises which do not require GPUs start here.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 3:</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Load the network from data/mnist.bson. Then create a 10times 10 table, where the (i+1j+1) entry is the number of samples, where digit i was misclassified as digit j.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Convert the table into a dataframe and add labels.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"First, we load the data as many times before","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"m = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m, X_train, y_train)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"When creating a table, we specify that its entries are Int. We save the predictions y_hat and labels y. Since we do not use the second argument to onecold, the entries of y_hat and y are between 1 and 10. Then we run a for loop over all misclassified samples and add to the error counts.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"y_hat = onecold(m(X_test))\ny = onecold(y_test)\n\nerrors = zeros(Int, 10, 10)\nfor i in findall(y_hat .!= y)\n    errors[y[i], y_hat[i]] += 1\nend","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To create the dataframe, we use df = DataFrame(errors). It prints correctly integers and not strings. We change labels x1 to miss0, ... Similarly, we add the labels as the first column.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"using DataFrames\n\ndf = DataFrame(errors)\n\nrename!(df, [Symbol(\"miss$(i)\") for i in 0:9])\ninsertcols!(df, 1, :label => string.(0:9))\n\nnothing # hide","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"df # hide","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Surprisingly, the largest number of misclassifications is 9 into 7. One would expect 8 to 0, 5 to 6 or 8 to 9. We investigate this in the next exercise.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 4:</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Plot all images which are 9 but were classified as 7.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To plot all these misclassified images, we find their indices and use the function plot_image. Since y are stored in the 1:10 format, we need to shift the indices by one. Since there are 11 of these images, and since 11 is a prime number, we cannot plot it in a layout. We use a hack and add an empty plot p_empty. When plotting, we specify layout and to minimize the empty space between images also size.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"i1 = 9\ni2 = 7\n\np = [plot_image(X_test[:,:,:,i]) for i in findall((y.==i1+1) .& (y_hat.==i2+1))]\np_empty = plot(legend=false,grid=false,foreground_color_subplot=:white)\n\nplot(p..., p_empty; layout=(3,4), size=(800,600))\n\nsavefig(\"miss.svg\") # hide","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We see that some of the nines could be recognized as a seven even by humans.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The following exercise depicts how images propagate through the network.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise 5: Visualization of neural networks 1</header><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We know that the output of the convolutional layers has the same number of dimensions as the inputs. If the activation function is the sigmoid, the output values stay within 01 and can also be interpreted as images. Use the same network as before but replace ReLU by sigmoid activation functions. Load the model from data/mnist_sigmoid.bson (you can check that the model accuracy is 0.9831).","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"For all digits, select the first five samples from the training set of this digit. Then create 5times 5 graph (there will be 10 of them for each digit), where each column corresponds to one sample. The rows should be:","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The original image.\nThe first channel of the layer after the first pooling layer.\nThe last channel of the layer after the first pooling layer.\nThe first channel of the layer after the second pooling layer.\nThe last channel of the layer after the second pooling layer.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Discuss the images.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"To create the network and to load the data, we use","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"m = Chain(\n    Conv((2,2), 1=>16, sigmoid),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, sigmoid),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nfile_name = joinpath(\"data\", \"mnist_sigmoid.bson\")\ntrain_or_load!(file_name, m, X_train, y_train)","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Before plotting, we perform a for loop over the digits. Then onecold(y_train, classes) .== i creates a BitArray with ones if the condition is satisfied, and zeros if the condition is not satisfied. Then findall(???) selects all ones, and ???[1:5] finds the first five indices. Since we need to plot the original image, and the images after the second and fourth layer (there is always a convolutional layer before the pooling layer), we save these values into z1, z2 and z3. Since plot_image(z1[:,:,1,i]) plots the first channel of the i^rm th samples from z1, we create an array of plots by p1 = [plot_image(z1[:,:,1,i]) for i in 1:size(z1,4)]. As the length of z1 is five, the length of p1 is also five. This is the first row of the final plot. We create the other rows in the same way. To plot the final plot, we do plot(p1..., p2a..., p2b..., p3a..., p3b...), which unpacks the 5 arrays into 25 inputs to the plot function.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"classes = 0:9\nfor i in classes\n    ii = findall(onecold(y_train, classes) .== i)[1:5]\n\n    z1 = X_train[:,:,:,ii]\n    z2 = m[1:2](X_train[:,:,:,ii])\n    z3 = m[1:4](X_train[:,:,:,ii])\n\n    p1 = [plot_image(z1[:,:,1,i]) for i in 1:size(z1,4)]\n    p2a = [plot_image(z2[:,:,1,i]) for i in 1:size(z2,4)]\n    p3a = [plot_image(z3[:,:,1,i]) for i in 1:size(z3,4)]\n    p2b = [plot_image(z2[:,:,end,i]) for i in 1:size(z2,4)]\n    p3b = [plot_image(z3[:,:,end,i]) for i in 1:size(z3,4)]\n\n    plot(p1..., p2a..., p2b..., p3a..., p3b...; layout=(5,5), size=(600,600))\n    savefig(\"Layers_$(i).svg\")\nend","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We plot and comment on three selected digits below.","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Digit 0","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Digit 1","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"Digit 9","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"We may observe several things:","category":"page"},{"location":"lecture_10/exercises/","page":"Exercises","title":"Exercises","text":"The functions inside the neural network do the same operations on all samples. The second row is always a black digit on a grey background.\nThe size of the image decreases when propagated deeper into the network. The second and third rows (after the second layer) contain more pixels than the fourth and fifth rows (after the fourth layer).\nThe channels of the same layer produce different outputs. While the second row (first channel after the second layer) depicts black digits on a grey background, the third row (last channel after the second layer) depicts white digits on black background.\nEach digit produce different images. This is important for separation and correct predictions.","category":"page"},{"location":"installation/git/#Git","page":"Git","title":"Git","text":"","category":"section"},{"location":"installation/git/","page":"Git","title":"Git","text":"Git is a distributed version control system for tracking changes in any set of files, designed for coordinating work among programmers cooperating on source code during software development. The whole Julia package system is based on Git, and the whole Julia project is hosted on GitHub. GitHub is a service that provides internet hosting for software development and version control using Git. This section offers a basic tutorial on how to install and set Git on Windows 10.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"Git installer can be download from the official download page.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"Download the proper installer, run it and follow the given instructions.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"There is no need to change the default settings. However, we recommend changing the default editor used by Git to Visual Studio Code.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"After setting the editor used by Git, finish the installation with default settings.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"<div class = \"info-body\">\n<header class = \"info-header\">GitHub Account</header><p>","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"Create a GitHub account on the official GitHub page. Do not forget to verify your email address.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"</p></div>","category":"page"},{"location":"installation/git/#User-settings","page":"Git","title":"User settings","text":"","category":"section"},{"location":"installation/git/","page":"Git","title":"Git","text":"Before using Git, we need to make the necessary settings. Type cmd into the search bar and open the Command Prompt.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"In the Command Prompt type the following two commands","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"git config --global user.name \"USERNAME\"git config --global user.email \"USEREMAIL\"","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"and press Enter. Do not forget to change USERNAME and USEREMAIL. Typically the username and email from GitHub are used.","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"(Image: )","category":"page"},{"location":"installation/git/","page":"Git","title":"Git","text":"The commands above set the user name and email for Git. Because Git is designed for collaboration between multiple people, this information is used to track who made what changes.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"n_digits = 4\nround_a(x::Number) = round(x, digits=n_digits)\nround_a(x) = round_a.(x)","category":"page"},{"location":"lecture_10/iris/#Introduction-to-Flux","page":"Introduction to Flux","title":"Introduction to Flux","text":"","category":"section"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Flux is a library for using neural networks. This part will present the basics of Flux on the Iris dataset from the previous lecture. We include the auxiliary functions from the previous lesson into the utilities.jl file, which we include by","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"include(\"utilities.jl\")\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We set the seed and load the data in the same way as during the last lecture.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Random\nusing BSON: @load\n\nRandom.seed!(666)\n\nfile_name = joinpath(\"data\", \"iris.bson\")\n@load file_name X y y_name\n\nX_train, y_train, X_test, y_test, classes = prepare_data(X, y)\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We start by creating the same network.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Find the documentation of Flux.jl online and create the same network as in the previous lecture.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To create the neural network, Flux uses Chain(???, ???, ...), where ??? are individual layers. Dense layers are created by Dense with the correct number of input and output neurons. We also need to specify the activation functions.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Flux\n\nn_hidden = 5\nm = Chain(\n    Dense(size(X_train,1), n_hidden, relu),\n    Dense(n_hidden, size(y_train,1), identity),\n    softmax,\n    )\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Since identity is the default argument, it is possible to remove it. However, we recommend to keep it for clarity.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"</p></details>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To evaluate the whole dataset, we call","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"m(X_train)","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Because there are 3 classes and 120 samples, it returns an array of size 3times 120. Note that the columns are probabilities.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We can access the neural network parameters by using params(m). At the same time, we can select the second layer of m by m[2]. This can be naturally combined, so that","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"params(m[2])","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"returns the parameters of the second layer. Since the second layer has 5 input and 3 output neurons, the matrix is of size 3times 5 and the bias is a vector of length 3. The parameters params(m[2]) are a tuple of the matrix and the vector. This also implies that the parameters are initialized randomly, and we do not need to take care of it. If for any reason, we need to use a special initialization, we can assign to parameters via","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"params(m[2])[2] .= [-1;0;1]\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Here, we assigned to the bias of the second layer.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To train the model, we first need to specify the loss function. Since it is the cross-entropy between the prediction and the label, it can be done via","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"import Flux: crossentropy\n\nloss(x,y) = crossentropy(m(x), y)\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"The loss function does not have m as input. Even though there could be an additional input parameter, it is customary to write it without it. To evaluate the loss function, we simply write","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"loss(X_train, y_train)","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"This computes the loss function on the whole training set. Since Flux is (unlike our implementation from the last lecture) smart, there is no need to take care of individual samples.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"<div class = \"info-body\">\n<header class = \"info-header\">Notation</header><p>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"While the standard definition of cross-entropy is operatornameloss(yhat y), Flux uses operatornameloss(hat yy).","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"</p></div>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Since we have the model and the loss function, the only remaining required thing for training is the gradient. This can be done in a simple way by","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"gs = gradient(() -> loss(X_train, y_train), params(m))\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"The function gradient takes two inputs. The first one is the function we want to differentiate, and the second one are the parameters. The loss function needs to be evaluated at the correct points X_train and y_train. In some applications (adversarial learning), we may need to differentiate with respect to other parameters such as X_train. This can be achieved by changing the second parameters of the gradient function","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"gs = gradient(() -> loss(X_train, y_train), params(X_train))\n\nsize(gs[X_train])","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Since X_train is of shape 4times 120, the gradient needs to have the same size.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Use the documentation of Flux.jl once again and train the neural network for 250 iterations with ADAM(0.01) optimizer and no minibatches. You may want to use the Flux update! function.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"Plot the accuracy on the testing set in every iteration.","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"We first create the accuracy function as before","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"accuracy(x, y) = mean(onecold(m(x), classes) .== onecold(y, classes))\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"To compute the gradient, we first save ps = params(m) so that we do not need to call params all the time. The gradient can be computed by gs = gradient(() -> loss(X_train, y_train), ps). Finally, the update takes the optimizer, the parameters and the gradient and performs the update. The whole code is","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"ps = params(m)\nopt = ADAM(0.01)\nmax_iter = 250\n\nacc_test = zeros(max_iter)\nfor i in 1:max_iter\n    gs = gradient(() -> loss(X_train, y_train), ps)\n    Flux.Optimise.update!(opt, ps, gs)\n    acc_test[i] = accuracy(X_test, y_test)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"</p></details>","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"using Plots # hide\n\nplot(acc_test, xlabel=\"Iteration\", ylabel=\"Test accuracy\", label=\"\", ylim=(-0.01,1.01)) # hide\n\nsavefig(\"Iris_acc.svg\") # hide","category":"page"},{"location":"lecture_10/iris/","page":"Introduction to Flux","title":"Introduction to Flux","text":"(Image: )","category":"page"},{"location":"installation/vscode/#Visual-Studio-Code","page":"Visual Studio Code","title":"Visual Studio Code","text":"","category":"section"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"In the previous section, we installed the Julia programming language. It is possible to write Julia codes in any text editor and run them directly from the terminal. However, it is usually better to use some IDE that provides additional features such as syntax highlight or code suggestions. Several text editors provide Julia support. However, we recommend using Visual Studio Code. Visual Studio Code is a free source-code editor made by Microsoft that supports many programming languages (Julia, Python, LaTex, ...) via extensions. The editor is available on the official download page.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"Download the proper installer, run it and follow the given instructions","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"There is no need to change the default settings. On the installer's last window, select the Launch Visual Studio Code option and press the Finish button.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"If the installation was successful, the VS Code should open in a new window.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/#Extensions","page":"Visual Studio Code","title":"Extensions","text":"","category":"section"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"If we want to use the VS Code as IDE for Julia, we have to install the Julia extension. It can be done directly from the VS Code. Open the Extension MarketPlace by pressing the button in the Activity bar (the left bar). Type julia in the search bar and select the Julia extension. Then press the Install button to install the extension.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"After the installation, press Ctrl + Shift + P to open the command palette. Type Julia: Start REPL into the command palette and press enter.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"The panel with the terminal and new Julia session should open.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"There are other useful extensions. We recommend installing the Project Manager extension that provides additional features to manage projects.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"We also recommend installing the Bracket Pair Colorizer 2 extension. This extension allows matching brackets to be identified with colors.","category":"page"},{"location":"installation/vscode/","page":"Visual Studio Code","title":"Visual Studio Code","text":"(Image: )","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"using Plots","category":"page"},{"location":"lecture_09/theory/#Theory-of-neural-networks","page":"Theory of neural networks","title":"Theory of neural networks","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Neural networks appeared for the first time decades ago but were almost forgotten after a few years. Their resurgence in the last one or two decades is mainly due to available computational power. Their impressive list of applications include:    ","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"One of the first applications was reading of postal codes to automatize sorting of letters. Since only ten black and white digits can appear at five predetermined locations, simple networks could be used.\nA similar type of neural (convolutional) networks is used in autonomous vehicles to provide information about cars, pedestrians or traffic signs. These networks may also use bounding boxes to specify the position of the desired object.\nWhile the previous techniques used 2D structure of the input (image), recurrent neural networks are used for series-type data (text, sound). The major application is automatic translators.\nAnother application includes generating new content. While there may exist useful applications such as artistic composition (music or writing scripts), these networks are often used to generate fake content (news, images).","category":"page"},{"location":"lecture_09/theory/#Neural-networks","page":"Theory of neural networks","title":"Neural networks","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The first three bullets from the previous paragraph are all used for classification. The idea is the same as for linear networks. For an input x with a label y, the classifier f minimizes the loss between the prediction f(wx) and the label y. We stress that f has two parameters: w is to be trained (weights) while x are inputs (data). Having n samples (data points), this results in","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornameminimizeqquad frac1nsum_i=1^n operatornameloss(y_i f(wx_i))","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The previous lecture used the linear classifier f(x)=w^top x and the cross-entropy loss for classification and the squared l_2 norm operatornameloss(y hat y) = (y - hat y)^2 for regression.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The main idea of neural networks is to use a more complex function f than linear with a certain structure such that:","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"It has good approximative quality.\nIt does not contain many parameters to learn (train).\nThe computation of derivatives (training) is simple.","category":"page"},{"location":"lecture_09/theory/#Layers","page":"Theory of neural networks","title":"Layers","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The previous bullets are achieved in an elegant way by representing the neural network via a layered structure. The input goes into the first layers, the output of the first layer goes into the second layer and so on. Mathematically speaking, a network f with M layers has the structure","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"f(x) = (f_M circ dots circ f_1)(x)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where f_1dotsf_M are individual layers. Since two layers that are not next to each other (such as the first and the third layer) are never directly connected (except skip connections), the function value can be propagated through the network simply. The same holds for the gradients, which can be easily computed via chain rules.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_09/theory/#Dense-layer","page":"Theory of neural networks","title":"Dense layer","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The dense layer is the simplest layer which has the form","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"f_m(a) = l_m(W_ma + b_m)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where W_m is a matrix of appropriate dimensions, b_m is the bias (shift) and l_m is an activation function. The weights of the neural network, which need to be trained, would be w=(W_mb_m)_m in this case.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The activation function is usually written as l_mmathbbRtomathbbR and its operation on the vector W_mz + b_m is understood componentwise. Examples of activation functions include:","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"beginaligned\ntextSigmoidl(z) = frac11+e^-z \ntextReLUl(z) = operatornamemax0z \ntextSoftplusl(z) = log(1+e^z) \ntextSwishl(z) = fracz1+e^-z \nendaligned","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"using Plots\n\nxs = -4:0.01:4\nylim = (-1,4)\n\np1 = plot(xs, 1 ./(1 .+exp.(-xs)), title=\"Sigmoid\", ylim=ylim, label=\"\")\np2 = plot(xs, max.(xs,0), title=\"ReLU\", ylim=ylim, label=\"\")\np3 = plot(xs, log.(1 .+exp.(xs)), title=\"Softplus\", ylim=ylim, label=\"\")\np4 = plot(xs, xs ./(1 .+exp.(-xs)), title=\"Swish\", ylim=ylim, label=\"\")\n\nplot(p1, p2, p3, p4; layout=(2,2))\n\nsavefig(\"Activation.svg\")","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_09/theory/#Softmax-layer","page":"Theory of neural networks","title":"Softmax layer","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The cross-entropy loss function (see below) requires that its input is a probability distribution. To achieve this, the softmax layer is applied directly before the loss function. Its formulation is","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornamesoftmax(a_1dotsa_K) = frac1sum_k=1^K e^a_k(e^a_1 dots e^a_K)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The exponential ensures that all outputs are positive. The normalization ensures that the sum of the outputs is one. Therefore, it is a probability distribution. When a dense layer precedes the softmax layer, it is used without any activation function (as, for example, ReLU would result in many probabilities being the same).","category":"page"},{"location":"lecture_09/theory/#One-hot-and-one-cold-representation","page":"Theory of neural networks","title":"One-hot and one-cold representation","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"One-hot and one-cold representations are directly connected with the softmax layer. The one-hot representation is \"the normal one\", while the one-cold representation is its probability distribution.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"For example, having 10 digits, label y=3 has one-cold representation 3 and one-hot representation (0001000000). Here, we count from 0 to 9.","category":"page"},{"location":"lecture_09/theory/#Other-layers","page":"Theory of neural networks","title":"Other layers","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"There are many other layers (convolutional, recurrent, pooling), which we will go through in the next lesson.","category":"page"},{"location":"lecture_09/theory/#Loss-functions","page":"Theory of neural networks","title":"Loss functions","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The most commonly used loss functions are:","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Mean) square error\noperatornameloss(yhat y) = (y-hat y)^2\nCross-entropy\noperatornameloss(yhat y) = sum_k=1^K y_klog hat y_k\nBinary cross-entropy\noperatornameloss(yhat y) = ylog hat y + (1-y)log(1- hat y)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Mean square error is used for regression problems while both cross-entropies for classification problem. The former for multi-class (K2) and the latter for binary (K=2) problems.","category":"page"},{"location":"lecture_09/theory/#Making-predictions","page":"Theory of neural networks","title":"Making predictions","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"For classification with K classes, the classifier f predict a probability distribution of K classes. The prediction is the label with the highest probability. Using the terminology from above, the classifier's output has the one-hot form, while the actual prediction has the one-cold form.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The most common metric for evaluating classifiers is the accuracy defined by","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"operatornameaccuracy = frac 1nsum_i=1^n I(y_i = hat y_i)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"where I is the characteristic (0/1) function which counts how often the argument is satisfied. With abuse of notation, we use both y_i and hat y_i as their one-cold representation. Therefore, accuracy measures the fraction of samples with correct predictions.","category":"page"},{"location":"lecture_09/theory/#Approximation-quality","page":"Theory of neural networks","title":"Approximation quality","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Even shallow neural networks (not many layers) can approximate any continuous function as the next theorem states.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"<div class = \"theorem-body\">\n<header class = \"theorem-header\">Theorem: Universal approximation of neural networks</header><p>","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Let gabto mathbbR be a continuous function defined on an interval. Then for every varepsilon0, there is a neural network f such that f-g_inftyle varepsilon.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Moreover, this network can be chosen as a chain of the following two layers:","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Dense layer with ReLU activation function.\nDense layer with identity activation function.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"</p></div>","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"As the proof suggests (Exercise 1), the price to pay is that the network needs to be extremely wide (lots of hidden neurons).","category":"page"},{"location":"lecture_09/theory/#Overfitting-and-regularization","page":"Theory of neural networks","title":"Overfitting and regularization","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The previous theorem says that any continuous classifier can be approximated to arbitrary precision by a sufficiently large network. Large networks contain a large number of parameters. If the amount of samples is the same, the network's complexity cannot be increased because there would be more parameters than samples. In such cases, the network may overfit the data.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"using Plots\nusing Random\n\nRandom.seed!(666)\n\nn = 10\nx = rand(n)\ny = x.^2 .+ 0.01*randn(n)\n\nscatter(x,y)\n\nX = zeros(n, n)\nfor i in 1:n\n    X[:,i] = x.^(i-1)\nend\n\nw = X \\ y\n\nf(x) = sum([w[i]*x^(i-1) for i in 1:n])\n\nx_plot = 0:0.001:1\n\nscatter(x, y, label=\"Data\", ylim=(-0.01,1.01), legend=:topleft)\nplot!(x_plot, f.(x_plot), label=\"Prediction\")\nplot!(x_plot, x_plot.^2, label=\"True dependence\")\n\nsavefig(\"Overfit.svg\")","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"(Image: )","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This figure shows data with quadratic dependence and a small added error. While the complex classifier (a polynomial of order 9) fits the data perfectly, the correct classifier (a polynomial of order 2) does not fit the data so well, but it is much better at predicting unseen samples. The more complicated classifier overfits the data. ","category":"page"},{"location":"lecture_09/theory/#Preventing-overfitting","page":"Theory of neural networks","title":"Preventing overfitting","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"To prevent overfitting, multiple techniques were developed:","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Early stopping stops the algorithm before it finds the optimum. This goes against the spirit of optimization as the loss function is actually not optimized.\nRegularization adds a term to the objective funtion, usually the squared l_2 norm of weights\noperatornameminimizeqquad frac1nsum_i=1^n operatornameloss(y_i f(wx_i)) + fraclambda2w^2\nThe more complicated classifier from the figure above contains (among others) the term 20222x^9. Since the coefficient is huge, its l_2 norm would be huge as well. Regularization prevents such classifiers. Another possibility is the (non-differentiable) l_1 norm, which induces sparsity (many weights should be zero).\nSimple networks cannot approximate overly complicated functions and they can also prevent overfitting.","category":"page"},{"location":"lecture_09/theory/#Train-test-split","page":"Theory of neural networks","title":"Train-test split","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"How should the classifier be evaluated? The figure above suggests that it is a bad idea to evaluate it on the same data on which they were trained. For this reason, the dataset is usually split into training and testing sets. The classifier is trained on the training and evaluated on the testing set. The classifier is not allowed to see the testing set during training. When the classifier contains a large number of hyperparameters, which need to be tuned, the dataset is split into training, validation and testing sets. Then models with multiple hyperparameters are trained on the training set, the best values of hyperparameters are selected on the validation set, and the classifier performance is evaluated on the testing set.","category":"page"},{"location":"lecture_09/theory/#Computation-of-gradients","page":"Theory of neural networks","title":"Computation of gradients","text":"","category":"section"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"We will derive the gradients for the most common case of the objective","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"L(w) = sum_i=1^n operatornameloss(y_i f(wx_i))","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"If the classifier has only a single output (as is the case for regression or binary classification), then the chain rule yields","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"nabla L(w) = sum_i=1^n operatornameloss(y_i f(wx_i))nabla_w f(wx_i)","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The most difficult term to compute is nabla_w f(wx_i). All neural networks presented in this course have a layered structure. For an input x, the evalutation of f(wx) is initialized by a_0=x and then the iterative update","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"beginaligned\nz_m = W_ma_m-1 + b_m \na_m = l_m(z_m)\nendaligned","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"for m=1dotsM is performed. The first equation z_m = W_ma_m-1 + b_m performs a linear mapping, while a_m = l_m(z_m) applies the activation function l_m to each component of z_m. The parameters of the network are (W_mb_m)_m. Since a_M=f(wx), the chain rule implies","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"beginaligned\nnabla_W_m f = nabla_W_ma_M = nabla_z_Ma_Mnabla_z_M-1a_Mnabla_a_M-1z_M-1dots nabla_z_ma_mnabla_W_mz_m \nnabla_b_m f = nabla_b_ma_M = nabla_z_Ma_Mnabla_z_M-1a_Mnabla_a_M-1z_M-1dots nabla_z_ma_mnabla_b_mz_m\nendaligned","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Care needs to be taken with this expression, for example nabla_W_mz_m differentiates a vector with respect to a matrix. The computation of nabla_W_m f and nabla_b_m f is almost the same and only the last term differs. This is the basics for an efficient computational procedure.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Now we need to compute the individual derivatives","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"beginaligned\nnabla_a_m-1 z_m = W_m \nnabla_z_m a_m = operatornameDiag(l_m(z_m))\nendaligned","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The derivative in l_m(z_m) is understood componentwise and operatornameDiag makes a diagonal matrix from the vector.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"Combining all these relations allow computing the derivative of the whole network.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"<div class = \"info-body\">\n<header class = \"info-header\">Computation of derivatives</header><p>","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This computation of derivatives looks complicated. However, it is just a complicated notation of a simple chain rule.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The forward pass starts with the input (which equals to a_0), computes the values (z_ma_m) in a forward way and finishes with evaluating the value of the classifier f.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"The backward pass starts with the classifier value (which equals to a_M), computes the partial derivatives in a backward way and chains them together to finish evaluating the derivative of the classifier nabla f.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"This computation is extremely efficient because the forward pass (computing function value) and the backward pass (computing derivatives) have the same complexity. Compare this with the finite difference method, where the computation of derivatives is much more expensive.","category":"page"},{"location":"lecture_09/theory/","page":"Theory of neural networks","title":"Theory of neural networks","text":"</p></div>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"abstract type Step end\n\nstruct GD <: Step\n    α::Real\nend\n\noptim_step(s::GD, f, g, x) = -s.α*g(x)\n\nfunction optim(f, g, x, s::Step; max_iter=100)\n    for i in 1:max_iter\n        x += optim_step(s, f, g, x)\n    end\n    return x\nend","category":"page"},{"location":"lecture_08/linear/#Linear-regression","page":"Linear regression","title":"Linear regression","text":"","category":"section"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Training a machine learning model requires data. Neural networks require lots of data. Since collecting data is difficult, there are many datasets at the UCI Machine Learning Repository. We will use the iris (kosatec in Czech) dataset which predicts one of the three types of iris based on sepal (kališní lístek in Czech) and petal (okvětní lístek in Czech) widths and lengths.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"If you do not see any differences between these three species, machine learning to the rescue!","category":"page"},{"location":"lecture_08/linear/#Loading-and-preparing-data","page":"Linear regression","title":"Loading and preparing data","text":"","category":"section"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"To experiment with machine learning models, we use the RDatasets package which stores many machine learning datasets, and load the data by","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"using StatsPlots\nusing RDatasets\n\niris = dataset(\"datasets\", \"iris\")\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"iris[1:5,:] # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Printing the first five entries of the data shows that the data are saved in DataFrame and the columns (features) are sepal length, sepal width, petal length and petal width.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"When designing a classification method, a good practice is to perform at least a basic analysis of the data. That may include checking for NaNs, infinite values, obvious errors, standard deviations of features or others. Here, we only plot the data. ","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"We will simplify the goal and estimate the dependence of petal width on petal length. Create the data X (do not forget to add the bias) and the labels y.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Make a graph of the dependence of petal width on petal length.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Since the petal length and width are the third and fourth columns, we assign them to X and y, respectively. We can use iris[:, 4] instead of y = iris[:, :PetalWidth] but the latter is more bulletproof. We need to concatenate X it with a vector of ones to add the bias.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"y = iris[:, :PetalWidth]\nX = hcat(iris[:, :PetalLength], ones(length(y)))\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The best plot, in this case, is the s   catter plot.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"using Plots\n\nscatter(X[:,1], y, label=\"\", xlabel=\"Petal length\", ylabel=\"Petal width\")\n\nsavefig(\"iris_lin1.svg\") # hide\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></details>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The figure shows a positive correlation between length and width. This is natural as bigger petals mean both longer and wider petals. We will quantify this dependence by the linear regression.","category":"page"},{"location":"lecture_08/linear/#Training-the-classifier","page":"Linear regression","title":"Training the classifier","text":"","category":"section"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Use the closed-form formula to get the coefficients w for the linear regression. Then use the optim method derived in the previous lecture to solve the optimization problem via gradient descent. The results should be identical.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The closed-form expression is (X^top X)^-1X^top y. This can be coded as (X'*X) \\ (X'*y).","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"w = (X'*X) \\ (X'*y)\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"For using the gradient descent, we first realize that the formula for the derivate is X^top (Xw-y). Defining the derivative function in g, we call the optim method in the same way as in the last lecture. Since we use the sum and not mean in the objective, we need to use much smaller stepsize this time.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"g(w) = X'*(X*w-y)\nw2 = optim([], g, zeros(size(X,2)), GD(1e-4); max_iter=10000)\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The difference between the solutions is","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"using LinearAlgebra\n\nnorm(w-w2)","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"which is acceptable.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></details>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The correct solution is","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"w # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"This gives a piece of advice on how to predict the petal width if only petal length is known.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Write the dependence on the petal width on the petal length. Plot it in the previous graph.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"The desired dependence is","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"textwidth approx -036 + 042*textlength","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Before plotting the prediction, we save it into f_pred","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"f_pred(x, w) = w[1]*x + w[2]\n\nnothing # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"Then we create the limits x_lim and finally plot a function which connects the two points. We show another possibility of plotting the graph instead of the scatter graph above. This possibility is better in the way that it based on the original iris variable and not the processed X. It can point to potential errors in processing X. We move the legend to the top-left corner.","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"x_lims = extrema(X[:,1]) .+ [-0.1, 0.1]\n\n@df iris scatter(\n    :PetalLength,\n    :PetalWidth;\n    xlabel = \"Petal length\",\n    ylabel = \"Petal width\",\n    label = \"\",\n    legend = :topleft,\n)\n\nplot!(x_lims, x -> f_pred(x,w); label = \"Prediction\", line = (:black,3))\n\nsavefig(\"iris_lin2.svg\") # hide","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"</p></details>","category":"page"},{"location":"lecture_08/linear/","page":"Linear regression","title":"Linear regression","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/#Conway's-Game-of-Life","page":"Exercises","title":"Conway's Game of Life","text":"","category":"section"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"The Game of Life (the following description is taken from Wikipedia), also known simply as Life, is a cellular automaton devised by the British mathematician John Horton Conway in 1970. It is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves. It is Turing complete and can simulate a universal constructor or any other Turing machine.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"The universe of the Game of Life is an infinite, two-dimensional orthogonal grid of square cells, each of which is in one of two possible states, live or dead, (or populated and unpopulated, respectively). Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each step in time, the following transitions occur:","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Any live cell with two or three live neighbours survives.\nAny dead cell with three live neighbours becomes a live cell.\nAll other live cells die in the next generation. Similarly, all other dead cells stay dead.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"The initial pattern constitutes the seed of the system. The first generation is created by applying the above rules simultaneously to every cell in the seed; births and deaths occur simultaneously, and the discrete moment at which this happens is sometimes called a tick. Each generation is a pure function of the preceding one. The rules continue to be applied repeatedly to create further generations.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Write a function neighbours that return the number of live neighbours of the given cell. The function should accept the world matrix of boolean values that represents state of all cells (true if cell is alive and false otherwise) and index of the row and column of the target cell.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Hint: use the following properties of the mod1 function to implement periodic boundaries","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"mod1(1, 4)\nmod1(4, 4)\nmod1(5, 4)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Bonus: define more general function that compute number of alive cells in a neighborhood of an arbitrary size.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"One way how to define the neighbours function is to manually write all neighbours indexes as follows","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"function neighbours(world, row, col)\n    n, m = size(world)\n\n    # this implements periodic boundaries\n    down  = mod1(row + 1, n)\n    up    = mod1(row - 1, n)\n    left  = mod1(col - 1, m)\n    right = mod1(col + 1, m)\n\n    return ( world[up,   left] + world[up,  col]  + world[up,   right]\n           + world[row,  left] +                  + world[row,  right]\n           + world[down, left] + world[down, col] + world[down, right])\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Note that it is possible to write an expression on multiple lines. However, the approach above can not be used to define a general version of the neighbours function. In this case, we can use nested loops. Firstly we compute proper row indexes using a linear range in combination with the mod1 function","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"rows = mod1.(row .+ (-r:r), size(world, 1))","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Column indexes can be computed similarly. Then we use nested loops to iterate through the rows and columns defined above. Do not forget to subtract the state of the middle cell.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"function neighbours(world, row, col; r = 1)\n    rows = mod1.(row .+ (-r:r), size(world, 1))\n    cols = mod1.(col .+ (-r:r), size(world, 2))\n\n    return sum(world[i, j] for i in rows, j in cols) - world[row, col]\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Add new method to the neighbours function that for the given world matrix returns matrix that contains numbers of living neighbours.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"We created a function that computes the number of living neighbours in the exercise above. One way how to create a matrix with numbers of living neighbours is as follows","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"function neighbours(world)\n    n, m = size(world, 1)\n    return [neighbours(world, row, col) for row in 1:n, col in 1:m]\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Write a function willsurvive that returns true if the cell will survive based on the conditions described in the beginning of the section, and false otherwise. This function should accept two arguments: state of the cell (true/false) and the number of living neighbours.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"This function can be written using the if-elseif-else statement as follows","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"function willsurvive(cell, k)\n    if k == 3\n        return true\n    elseif k == 2 && cell == 1\n        return true\n    else\n        return false\n    end\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"But we can also write the function in simpler form. The first thing that we have to realize the first two conditions can be merged together using short-circuit evaluation. Since the function returns  only true or false, we can write the function on one line as follows","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"willsurvive(cell, k) = k == 3 || k == 2 && cell == 1","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Use all functions defined above to write a function evolve! that evolve the given world matrix into a new generation.","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"The first thing we have to do is to compute the matrix  with numbers of living neighbours. Then we can iterate over all elements of the given world matrix and copute new state of the current element using the willsurvive function","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"function evolve!(world)\n    ks = neighbours(world)\n    for i in eachindex(world)\n        world[i] = willsurvive(world[i], ks[i])\n    end\n    return\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"</p></details>","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"In the four exercises above, we defined a function that are necessary to create an animation of Game of Life. Use the following code to get the initialization of the world","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"world = zeros(Bool, 30, 30)\nrow, col = 15, 15\n\nworld[row, col] = 1\nworld[row, col + 1] = 1\nworld[row - 1, col + 6] = 1\nworld[row + 1, col + 1] = 1\nworld[row + 1, col + 5] = 1\nworld[row + 1, col + 6] = 1\nworld[row + 1, col + 7] = 1","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"To create an animation, we will use the Plots package, that we introduced in the previous lecture","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"using Plots\n\nanim = @animate for i in 1:150\n    heatmap(world; axis = nothing, border = :none, cbar = false, ratio = :equal)\n    evolve!(world)\nend\ngif(anim, \"gameoflife.gif\"; fps = 10)","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"Many different types of patterns occur in the Game of Life. For example, the following initialization is called pulsar","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"world = zeros(Bool, 17, 17)\nline = zeros(17)\nline[5:7] .= 1\nline[11:13] .= 1\n\nfor ind in [3,8,10,15]\n    world[ind, :] .= line\n    world[:, ind] .= line\nend","category":"page"},{"location":"lecture_03/exercises/","page":"Exercises","title":"Exercises","text":"(Image: )","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using LinearAlgebra\n\nn_digits = 4\nround_a(x::Number) = round(x, digits=n_digits)\nround_a(x) = round_a.(x)","category":"page"},{"location":"lecture_09/nn/#Neural-networks","page":"Neural networks","title":"Neural networks","text":"","category":"section"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"During this lecture, we will train a better classifier for the iris dataset. From the previous lecture, it will differ in several points:","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"It will use a neural network instead of the linear classifier.\nIt will use all features and not only two.\nIt will use all classes and not only two.","category":"page"},{"location":"lecture_09/nn/#Prepare-data","page":"Neural networks","title":"Prepare data","text":"","category":"section"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We start with loading the iris dataset in the same way as in the last lecture.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using BSON: @load\n\nfile_name = joinpath(\"data\", \"iris.bson\")\n@load file_name X y y_name","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Since we will use random functions, it is a good idea to fix the seed. When the code is run multiple times, the results will always be the same. Since Julia uses one global seed (unlike Python, which uses different seeds in each package), we all should see the same results. However, if you obtain slightly different results, it may have happened due to a different Julia version or operating system.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using Random\n\nRandom.seed!(666)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The first exercise splits the dataset into the training and testing set.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write the split function, which splits the dataset and the labels into training and testing set. Its input should be the dataset X and the labels y. It should have four outputs. Include 80% of data in the training set and 20% of data in the testing set.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Since the input may have different forms, we assume that y is a vector and the samples of  X and y are across the first dimension. If this is not satisfied, the @assert statement returns an error. This is not necessary to include but it makes the code much more error-prone.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"To split the dataset, we first determine the number of samples n_train in the training set. We need to round it and convert it to integer. For the split, we create a random permumation of indices and then select the first n_train indices as the indices of the training set and the remaining as the indices of the testing set.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function split(X::AbstractMatrix, y::AbstractVector; ratio_train=0.8)\n    @assert size(X,1) == size(y,1)\n\n    n = size(X,1)\n    n_train = round(Int, ratio_train*n)\n    i_rand = randperm(n)\n    i_train = i_rand[1:n_train]\n    i_test = i_rand[n_train+1:end]\n\n    return X[i_train,:], y[i_train], X[i_test,:], y[i_test]\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Then we split the dataset by calling the split function","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"X_train, y_train, X_test, y_test = split(X, y)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The next exercises normalizes the data. In the previous lecture, we have already normalized the training set. We compute the normalizing constants (mean and standard deviation) for each feature and then apply them to the data. Since the normalization needs to be done before training, and since the testing set is not available during training, the normalizing constants can be computed only from the testing set. This also means that the features on the training set have zero mean and unit variance but features on the testing set may have different mean and variance.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write the normalize functions as described above. It should have two inputs and two outputs.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Normalize the data and print the first feature of the first sample in the testing set.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Since the features are in columns, we compute the mean and the standard deviation of each column. Since [??? for ??? in ???] creates a column vector, and since we want to apply this vector to all columns, we need to transpose it to a row vector. Otherwise it could not be broadcasted. Then we normalize the columns. Due to the reason mentioned above, we need to use the same normalizing constant for the training and testing sets.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using Statistics\n\nfunction normalize(X_train, X_test)\n    col_means = [mean(X_col) for X_col in eachcol(X_train)]'\n    col_std = [std(X_col) for X_col in eachcol(X_train)]'\n\n    return (X_train .- col_means) ./ col_std, (X_test .- col_means) ./ col_std\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Now we run the normalize function.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"X_train, X_test = normalize(X_train, X_test)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The correct answer is","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"println(round_a(X_test[1,1])) # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The standard representation of data in linear and logistic regression is that each row (first dimension) is one sample. However, neural networks work with more-dimensional data (each image is represented by three dimensions). The convention changed and the samples are represented in the last dimension.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The next exercise modifies the data into a standard form for machine learning.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Modify the data so that the first dimension of X are features and the second one the samples.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write onehot function which converts y into the one-hot representation. Write onecold function which converts the one-hot representation into the one-cold (original) representation. Both these functions need to have two arguments, the second one will be classes which will equal to unique(y).","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write a one-line check that both work correctly.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Finally, convert y into its one-hot representation.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We need to transpose X by X'. Since this creates an Adjoint type (check typeof(X')), we convert it to a standard matrix by calling Matrix(X').","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"X_train = Matrix(X_train')\nX_test = Matrix(X_test')\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The onehot function first creates an array y_onehot, where the first dimension is the number of classes. Since all but one entries of each column will be zeros, we initialize it by zeros. Then we run a for loop to fill one into each column. We perform the for loop over all classes but it is also possible to perform it over all columns.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function onehot(y, classes)\n    y_onehot = zeros(length(classes), length(y))\n    for i in 1:length(classes)\n        y_onehot[i,y.==classes[i]] .= 1\n    end\n    return y_onehot\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The onecold function finds the index of its maximum value via the findmax function. This is repeated for every column  y_col.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"onecold(y, classes) = [classes[findmax(y_col)[2]] for y_col in eachcol(y)]\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Functions onehot and onecold should be inverse to each other. That means that if we call them in succession, we obtain the original input. We could manually check","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"classes = unique(y)\n\nisequal(onecold(onehot(y, classes), classes), y)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"but it is better to perform this check automatically by including the error message","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"!isequal(onecold(onehot(y, classes), classes), y) && error(\"Function onehot or onecold is wrong.\")\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Now, the modification of  the labels is straigforward. As in the case of the matrix, we need to modify the split data.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"y_train = onehot(y_train, classes)\ny_test = onehot(y_test, classes)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Preparing the data is spread over many lines. It is better to combine them into one function","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function prepare_data(X, y; do_normal=true, kwargs...)\n    X_train, y_train, X_test, y_test = split(X, y; kwargs...)\n\n    if do_normal\n        X_train, X_test = normalize(X_train, X_test)\n    end\n\n    X_train = Matrix(X_train')\n    X_test = Matrix(X_test')\n\n    classes = unique(y)\n\n    y_train = onehot(y_train, classes)\n    y_test = onehot(y_test, classes)\n\n    return X_train, y_train, X_test, y_test, classes\nend\n\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Then the whole code to load and preprocess the data can be summarized in just three lines.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"file_name = joinpath(\"data\", \"iris.bson\")\n@load file_name X y y_name\n\nX_train, y_train, X_test, y_test, classes = prepare_data(X, y)\n\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Writing function prepare_data as above has other advantages, we will get back to them in the exercises.","category":"page"},{"location":"lecture_09/nn/#Create-the-network","page":"Neural networks","title":"Create the network","text":"","category":"section"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We will now construct a simple neural network.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Construct the following network:","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The first layer is a dense layer with the ReLU activation function.\nThe second layer is a dense layer with the identity activation function.\nThe third layer is the softmax.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write is as m(x, ???), where x is the input and ??? stands for all weights (parameters to optimize).","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The dense layer is a linear function z1 = W1*x .+ b1 followed by an activation function. If we assume that x is a vector, then + would work the same as .+ because both W1*x and b are of the same dimension. However, if we want x to be a matrix (each column corresponds to one sample), then we need to write .+ because W1*x is a matrix and the vector b needs to be broadcasted to be of the same size. The activation function is the ReLU function which needs to be applied componentwise. The second layer is the same but this time, we need to finish it with the softmax function. If x is a matrix, then z2 is a matrix, we  specify that we want to normalize along the first dimension because the first dimension are classes and the second samples. If we assume only vector inputs, then specifying the dimension is not necessary.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function m(x, W1, b1, W2, b2)\n    z1 = W1*x .+ b1\n    a1 = max.(z1, 0)\n    z2 = W2*a1 .+ b2\n    a2 = exp.(z2) ./ sum(exp.(z2), dims=1)\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Before we can use one of the numerical methods from the previous lectures to train the neural network, we need to initialize the weights.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Initialize all the weights randomly following the standard normal distribution. The first layer should have 5 hidden (output) neurons. You need to specify the number of neurons for the other layers correctly.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Evaluate the model m for the first datum from the training set.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We write a simple initialize function which takes the number of neurons in each layer as inputs, and randomly generates the matrices.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function initialize(n1, n2, n3)\n    W1 = randn(n2,n1)\n    b1 = randn(n2)\n    W2 = randn(n3,n2)\n    b2 = randn(n3)\n    return W1, b1, W2, b2\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"To initialize, we need to provide n1, n2 and n3. The first one is the number of features, the second one is specified to be 5 and the last one must equal to the number of classes (the length of the labels in the one-hot representation).","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"W1, b1, W2, b2 = initialize(size(X_train,1), 5, size(y_train,1))\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"To evaluate the model, we call the m function with the first sample in the training set","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"m(X_train[:,1], W1, b1, W2, b2)\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The correct answer is","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"println(round_a(m(X_train[:,1], W1, b1, W2, b2))) # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Due to the softmax layer, they sum to one and form a probability distribution describing the probability of each classes.","category":"page"},{"location":"lecture_09/nn/#Train-the-network","page":"Neural networks","title":"Train the network","text":"","category":"section"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"To train the network, we need to compute the gradients. It is rather complicated, it can be written as follows. When going through the code, it becomes clear that it is just a different form of the chain rule derived in the theoretical part.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"function grad(x::AbstractVector, y, W1, b1, W2, b2; ϵ=1e-10)\n    z1 = W1*x .+ b1\n    a1 = max.(z1, 0)\n    z2 = W2*a1 .+ b2\n    a2 = exp.(z2) ./ sum(exp.(z2))\n    l = -sum(y .* log.(a2 .+ ϵ))\n\n    e_z2 = exp.(z2)\n    l_part = (- e_z2 * e_z2' + Diagonal(e_z2 .* sum(e_z2))) / sum(e_z2)^2\n\n    l_a2 = - y ./ (a2 .+ ϵ)\n    l_z2 = l_part * l_a2\n    l_a1 = W2' * l_z2\n    l_z1 = l_a1 .* (a1 .> 0)\n    l_x = W1' * l_z1\n\n    l_W2 = l_z2 * a1'\n    l_b2 = l_z2\n    l_W1 = l_z1 * x'\n    l_b1 = l_z1\n\n    return l, l_W1, l_b1, l_W2, l_b2\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The function returns the function value l and derivatives with respect to all four variables.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"info-body\">\n<header class = \"info-header\">That's it? I thought neural networks are magic...</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Well, for a network with two layers and a loss, you can compute the function value and its derivative in only 16 lines of code. And it could be even shorter :)","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"info-body\">\n<header class = \"info-header\">Simple implementation</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The previous function grad can compute the gradient for only one sample. Since the objective in training neural network is a mean over all samples, this mean needs to be included externally. This is NOT the correct way of writing function. However, we decided to present it in the current way to keep the presentation (relatively) simple.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Any time when a simplication like this is included in the code, a check such as x::AbstractVector or an @assert statement should be included to prevent unexpected errors.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Having the gradient at hand, we can finally train the network.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Train the network with a gradient descent with stepsize alpha=01 for 1000 iterations. Save the objective value at each iteration and plot the results.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Due to the simplicity of the grad function, grad(X_train[:,k], y_train[:,k], W1, b1, W2, b2) returns a tuple of five objects. We can use the standard trick to create an array of such tuples by going through all columns [grad(X_train[:,k], y_train[:,k], W1, b1, W2, b2) for k in 1:size(X_train,2)]. To obtain a mean from this array, we write the mean_tuple function. To make sure that everything is correct, we specify the input type d::AbstractArray{<:Tuple}. If d is the input data, then d[k] is an element of the array (thefore a tuple) while d[i][k] is an element of the tuple. Since we want to compute the mean over the array, the inner loop needs to be with respect to k while the outer one with respect to i.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using LinearAlgebra\nusing Statistics\n\nmean_tuple(d::AbstractArray{<:Tuple}) = [mean([d[k][i] for k in 1:length(d)]) for i in 1:length(d[1])]\n\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Now the process is simple. We compute the gradient grad_all, then its mean grad_mean via the already written function mean_tuple. The first value of the tuple grad_mean is the objective, the remaining are the gradients. Thus, we save the first value to an array and use the remaining one to update the weights.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"α = 1e-1\nmax_iter = 1000\nL = zeros(max_iter)\nfor iter in 1:max_iter\n    grad_all = [grad(X_train[:,k], y_train[:,k], W1, b1, W2, b2) for k in 1:size(X_train,2)]\n    grad_mean = mean_tuple(grad_all)\n\n    L[iter] = grad_mean[1]\n\n    W1 .-= α*grad_mean[2]\n    b1 .-= α*grad_mean[3]\n    W2 .-= α*grad_mean[4]\n    b2 .-= α*grad_mean[5]\nend\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"using Plots # hide\nplot(L, xlabel=\"Iteration\", ylabel=\"Loss function\", label=\"\", title=\"Loss function on the training set\") # hide\nsavefig(\"loss.svg\") # hide\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"(Image: )","category":"page"},{"location":"lecture_09/nn/#Prediction","page":"Neural networks","title":"Prediction","text":"","category":"section"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We have trained our first network. We saw that the loss function keeps decreasing, which is a good sign of a good training procedure. Now we will evaluate the performance.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"Write a function which predict the labels for samples. Show the accuracy on both training and testing sets.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The predicted probabilities are obtained by using the model m. The prediction (highest predicted probability) is obtained by converting the one-hot into the one-cold representation. Finally, the accuracy computes in how many cases the prediction equals to the label.","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"predict(X) = m(X, W1, b1, W2, b2)\naccuracy(X, y) = mean(onecold(predict(X), classes) .== onecold(y, classes))\n\nprintln(\"Train accuracy = $(accuracy(X_train, y_train))\")\nprintln(\"Test accuracy = $(accuracy(X_test, y_test))\")\n\nnothing # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"</p></details>","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"The correct answer is","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"println(\"Train accuracy = $(round_a(accuracy(X_train, y_train)))\") # hide\nprintln(\"Test accuracy = $(round_a(accuracy(X_test, y_test)))\") # hide","category":"page"},{"location":"lecture_09/nn/","page":"Neural networks","title":"Neural networks","text":"We see that the testing accuracy is smaller than the training one. This is quite a common phenomenon which is named overfitting. The problem is that the algorithm sees only the data from the training set. If it fits this data \"too perfectly\", it is not able to generalize into unseen samples (the testing set).","category":"page"},{"location":"lecture_12/diff_eq/#Julia-package","page":"Julia package","title":"Julia package","text":"","category":"section"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"To solve differential equations, we will use package DifferentialEquations.","category":"page"},{"location":"lecture_12/diff_eq/#Introduction","page":"Julia package","title":"Introduction","text":"","category":"section"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"DifferentialEquations consider ODEs in the form","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"dot u(t) = f(t u(t) p(t))","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"with the initial condition u(t_0)= u_0. While u is the solution, p described external parameters.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"We will start with a simple problem","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"dot u(t) = 098u","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"with initial condition u(0) = 1. This has closed-form solution u(t) = e^098t. To solve this ODE by DifferentialEquations, we first need to create the problem prob by supplying function f, the initial point u_0 and the time interval t_0t_1 to the constructor ODEProblem","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"using DifferentialEquations\n\nf(u,p,t) = 0.98*u\n\nu0 = 1.0\ntspan = (0.0, 1.0)\n\nprob = ODEProblem(f, u0, tspan)\n\nnothing # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"We can solve the ODE by","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"sol = solve(prob)","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The first line specifies that the solution was successful. We can automatically check whether the solution was successful by sol.retcode == :Success. The second line specifies the interpolation method. Even though the solution was evaluated at only 5 points sol.t with values sol.u, the interpolation ","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"using Plots\n\nplot(sol)\n\nsavefig(\"intro.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The sol structure is heavily overloaded. It can be used to evaluate the solution u at any time","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"sol(0.8)","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The next exercise shows how to specify the interpolation technique and compares the resutlts.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"When calling the solve function, we can specify the interpolation way. Solve the ODE with linear interpolation (dense=false) and the Runge-Kutta method of fourth order (RK4()). Plot the results and compare them with the default and original solutions.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"To compues the additional solutions, we add the arguments as specified above","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"sol2 = solve(prob, dense=false)\nsol3 = solve(prob, RK4())\n\nnothing # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"For plotting, we create a discretization ts of the time interval and then plot the four functions","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"ts = collect(range(tspan[1], tspan[2], length=100))\n\nplot(ts, t->exp(0.98*t), label=\"True solution\", legend=:topleft)\nplot!(ts, t->sol(t), label=\"Default\")\nplot!(ts, t->sol2(t), label=\"Linear\")\nplot!(ts, t->sol3(t), label=\"Runge-Kutta\")\n\nsavefig(\"Comparison.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></details>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"We see that all solutions are the same with the exception of the linear approximation.","category":"page"},{"location":"lecture_12/diff_eq/#Lorenz-system","page":"Julia package","title":"Lorenz system","text":"","category":"section"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Lorenz system is a prime example of the butterfly effect in the chaos theory. There, a small changes in the initial conditions results in large changes after a long time. This effect was first described in 1961 during work on weather modelling.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The three-dimensional Lorenz system is described by the set of equations ","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"beginaligned\nfracpartial xpartial t = sigma (y - x) \nfracpartial ypartial t = x (rho - z) - y \nfracpartial zpartial t = x y - beta z\nendaligned","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"We define the right-hand side","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"function lorenz(u, p, t)\n    σ, ρ, β = p\n    x_t = σ*(u[2]-u[1])\n    y_t = u[1]*(ρ-u[3]) - u[2]\n    z_t = u[1]*u[2] - β*u[3]\n    return [x_t; y_t; z_t]\nend\n\nnothing # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The parameters are saved in a tuple or array p. Since the right-hand side of the Lorenz system is a vector, we need to return a vector as well. Now, we compute the solution in the same way as before.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"u0 = [1.0; 0.0; 0.0]\np = [10; 28; 8/3] \n\ntspan = (0.0, 100.0)\nprob = ODEProblem(lorenz, u0, tspan, p)\n\nsol = solve(prob)\n\nnothing # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Using the same function to plot","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"plot(sol)\n\nsavefig(\"lorenz0.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"results in two-dimensional graph of all coorinates. To plot 3D, we need to specify it","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"plt1 = plot(sol, vars=(1,2,3), label=\"\")\n\nsavefig(\"lorenz1.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"We see again the power of interpolation. If we used linear interpolation (connected the points)","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"plot(sol, vars=(1,2,3), denseplot=false; label=\"\")\n\nsavefig(\"lorenz2.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"we would obtain a much coarse graph. This shows the strength of the DifferentialEquations package. With a small computational effort, it is able to compute a good solution. Note that the last plotting call is equivalent to","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"traj = hcat(sol.u...)\nplot(traj[1,:], traj[2,:], traj[3,:]; label=\"\")","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"In the introduction to this part, we mentioned the chaos theory. We will elaborate on this in the next exercise.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Consider the same setting as above but perturb the first parameter of p by the smallest possible value (with respect to the machine precision). Then solve the Lorenz system again and compare results by plotting the two trajectories next to each other.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The machine precision can be obtained by eps(T), where T is the desired type. However, when we add this to p[1], we obtain the same number","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"p[1] + eps(eltype(p)) == p[1]","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The reason is that p[1] has value 10 and the sum exceeds the allowed number of valid digits and it is truncated back to 10. We therefore cheat a bit and manually modify the number","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"p0 = (10.000000000000001,28,8/3) \n\nnothing # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Then we plot the graphs as before","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"prob0 = ODEProblem(lorenz, u0, tspan, p0)\nsol0 = solve(prob0)\n\nplt0 = plot(sol0, vars=(1,2,3), label=\"\")\n\nplot(plt1, plt0; layout=(1,2))\n\nsavefig(\"lorenz4.svg\") # hide","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></details>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"(Image: )","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The solutions look obviously different. Comparing the terminal states of both solutions","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"hcat(sol(tspan[2]), sol0(tspan[2]))","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"shows that they are different by a large margin. This raises a natural question.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Can we trust the solutions? Why?","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Unfortunately, we cannot. Numerical methods always introduce some errors by","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"Rounding errors due to representing real numbers in machine precision.\nDiscretization errors for continuous systems when the derivative is approximated by some kind of finite difference.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"However, if the system itself is unstable in the way that an extremely small perturbation results in big differences in solutions, the numerical method even enhances these errors. The solution could be trusted on some small interval but not after it.","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"</p></details>","category":"page"},{"location":"lecture_12/diff_eq/","page":"Julia package","title":"Julia package","text":"The next section will show a situation where we try to mitigate this possible effect by using mathematical formulas to compute the exact solution as long as possible. This delays the necessary discretization and may bring a better stability.","category":"page"},{"location":"lecture_01/arrays/#Vectors","page":"Arrays","title":"Vectors","text":"","category":"section"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"A vector is a special case of an array with only one dimension and is represented as a list of ordered data that share a common type (Int64, Float64, Any,...). A vector in Julia can be constructed directly using square brackets and a comma (or semicolon) as value separators","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1, 2, 3, 4, 5, 6, 7, 8] # or equivalently v = [1; 2; 3; 4; ...]\n8-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Information about the number of dimension or type of elements of a given vector can be obtained from the output of the typeof function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(v)\nArray{Int64,1}","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The general description of an array in Julia is as follows: Array{T,N} denotes N-dimensional dense array with elements of type T. From this description, we can immediately see that vector v has one dimension and contains elements of type Int64. Another way how to get this information is to use the ndims and eltype function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> ndims(v)\n1\n\njulia> eltype(v)\nInt64","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"We can also check the size and the length of a vector using the size and length functions","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> size(v)\n(8,)\n\njulia> length(v)\n8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The size function returns a tuple containing the given array's sizes along each dimension. The length function returns a total number of elements in the given array.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Elements of a vector can be accessed via square brackets and the index of the element. Contrary to other programming languages like C or Python and similarly to Matlab, arrays are indexed from 1. For example, the third element of vector v can be accessed via the following syntax","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[3]\n3","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"There are also special keywords to access the first and last element of a given vector","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[begin] # the first element\n1\n\njulia> v[end] # the last element\n8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Multiple elements can be accessed at once using a similar syntax. The only difference is that instead of only one index, we use a vector of multiple indexes. For example, to access the second and third element of vector v, we can do","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[[2, 3]]\n2-element Array{Int64,1}:\n 2\n 3","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to select multiple indexes using the range function. The range function always accepts the starting point as a first argument, and then the keyword argument stop or length. The user can also set the step length using the keyword argument step. If the keywords length, stop, and step are all specified, they must agree. For example, to generate integers from 1 to 10 with step length 2, the following code can be used","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> range(1; stop = 10, step = 2)\n1:2:9","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Ranges can also be constructed using the shorter syntax start:step:stop, where the step can be omitted if equal to 1. Then the previous example can be equivalently rewritten as","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> 1:2:10\n1:2:9","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"This shorter syntax is handy for accessing array elements","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[1:3] # the first three elements\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> v[1:2:end] # select all elements with odd index\n4-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n\njulia> v[:] # all elements\n8-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"New elements can be appended to the vector using the append! function. Notice the ! symbol in the function name. This is Julia's convention for naming functions that modify their input arguments (usually the first one). In this case, the append! function appends one or more elements to the end of the given vector","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> append!(v, 4)\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> append!(v, [5,6])\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> append!(v, 7:8)\n8-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"As has already been said, the elements of a vector share the same type. In this case, we have a vector with elements of type Int64. If we try to append the value that is not representable as Int64 it will result in an errors","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> append!(v, 3.0)\n9-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 3\n\njulia> append!(v, 3.1415)\nERROR: InexactError: Int64(3.1415)","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"In the first case, it is possible to append a floating-point number since it can be represented as an integer. We can use the isinteger function to test whether the number is numerically equal to some integer","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> isinteger(3.0)\ntrue","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"In the second case, we cannot convert the given number to an Int64 without losing precision, thus the error. The vector v can store only values of type Int64 or values that can be safely converted to Int64 (such as Int32). To avoid these errors, we can initialize the type of elements when creating a vector. It can be done using a type name followed by a square bracket","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = Float64[1, 2, 3]\n3-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\n\njulia> append!(v, 3.1415)\n4-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\n 3.1415","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Since arrays in Julia are mutable objects, it is possible to change the values of their elements. It can be done simply by assigning a new value to some element","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1, 2, 3, 4]\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> v[2] = 4\n4\n\njulia> v\n4-element Array{Int64,1}:\n 1\n 4\n 3\n 4","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to assign one value to multiple elements of an array at once. However, in this case, we have to use dot syntax, which is in Julia used for element-wise operations","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[3:4] .= 11\n2-element view(::Array{Int64,1}, 3:4) with eltype Int64:\n 11\n 11\n\njulia> v\n4-element Array{Int64,1}:\n  1\n  4\n 11\n 11","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Create a vector of positive integers that contains all odd numbers smaller than 10. Then change the first element to 4 and the last two elements to 1.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Such a vector can be created in a manual way as follows","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [1,3,5,7,9]\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"or we can use the range function to create a range with given properties and then use the collect function to create a vector or use the Vector type to convert the range to a vector","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> collect(1:2:9)\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9\n\njulia> Vector(1:2:9)\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The values stored in the vector can be changed using the .= sign and proper indexes. Do not forget to add a dot before the = sign to perform operation element-wise.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v[1] = 4\n4\n\njulia> v[end-1:end] .= 1\n2-element view(::Array{Int64,1}, 4:5) with eltype Int64:\n 1\n 1\n\njulia> v\n5-element Array{Int64,1}:\n 4\n 3\n 5\n 1\n 1","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></details>","category":"page"},{"location":"lecture_01/arrays/#Matrices","page":"Arrays","title":"Matrices","text":"","category":"section"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"A matrix is a special case of an array with precisely two dimensions. In Julia, we can construct a matrix using square brackets similarly to vectors. Matrices are constructed row by row. Elements in rows are separated using spaces, and rows are separated using semicolons","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m = [1  2  3  4; 5  6  7  8]\n2×4 Array{Int64,2}:\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The basic information about matrices can be obtained using the same functions as for vectors","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(m)\nArray{Int64,2}\n\njulia> eltype(m)\nInt64\n\njulia> ndims(m)\n2\n\njulia> size(m)\n(2, 4)\n\njulia> length(m)\n8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Also, accessing matrix elements can be done in the same way as for vectors","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m[1] # the first element, equivalent to m[begin]\n1\n\njulia> m[2] # the second element\n5\n\njulia> m[end-1] # the last element\n4","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Note that the second element is 5. The reason is that Julia is column-oriented. Element at a specific position in a matrix can be accessed by the following syntax matrix[row_index, column_index]. The following code returns the second element in the first row","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m[1, 2]\n2","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It is also possible to access multiple elements at once","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m[1, [2, 3]] # the second and third element in the first row\n2-element Array{Int64,1}:\n 2\n 3\n\njulia> m[1:3] # the first three elements according to linear indexing\n3-element Array{Int64,1}:\n 1\n 5\n 2\n\njulia> m[:, 1:3] # the first three columns\n2×3 Array{Int64,2}:\n 1  2  3\n 5  6  7\n\njulia> m[1, :] # the first row\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> m[:] # all elements\n8-element Array{Int64,1}:\n 1\n 5\n 2\n 6\n 3\n 7\n 4\n 8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It is not possible to append new elements into arrays directly, except for vectors. However, arrays with matching sizes along some dimensions can be concatenated in this dimension. For example, we can horizontally concatenate the matrix m using the hcat function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> hcat(m, m)\n2×8 Array{Int64,2}:\n 1  2  3  4  1  2  3  4\n 5  6  7  8  5  6  7  8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"or vertically using hte vcat function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> vcat(m, m)\n4×4 Array{Int64,2}:\n 1  2  3  4\n 5  6  7  8\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"There is also a general function cat that concatenate given arrays along dimension specified by the dims keyword argument","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> cat(m, m; dims = 2) # equivalent to hcat(m, m)\n2×8 Array{Int64,2}:\n 1  2  3  4  1  2  3  4\n 5  6  7  8  5  6  7  8\n\njulia> cat(m, m; dims = 1) # equivalent to vcat(m, m)\n4×4 Array{Int64,2}:\n 1  2  3  4\n 5  6  7  8\n 1  2  3  4\n 5  6  7  8","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"If the sizes of arrays do not match, an error occurs","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v = [11, 12]\n2-element Array{Int64,1}:\n 11\n 12\n\njulia> vcat(m, v)\nERROR: ArgumentError: number of columns of each array must match (got (4, 1))\n[...]","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Create two vectors: vector of all odd positive integers smaller than 10 and vector of all even positive integers smaller than 10. Then concatenate these two vectors horizontally and fill the third row with 4.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"First, we have to create the two vectors. We can do it manually, or we can use ranges and the collect function as in the exercise in the previous section","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> v1 = collect(1:2:9)\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9\n\njulia> v2 = collect(2:2:10)\n5-element Array{Int64,1}:\n  2\n  4\n  6\n  8\n 10","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Then we can use the hcat function to concatenate these two vectors horizontally","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m = hcat(v1, v2)\n5×2 Array{Int64,2}:\n 1   2\n 3   4\n 5   6\n 7   8\n 9  10","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Finally, we select all elements in the third row and assign a new value to them","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> m[3,:] .= 4\n2-element view(::Array{Int64,2}, 3, :) with eltype Int64:\n 4\n 4\n\njulia> m\n5×2 Array{Int64,2}:\n 1   2\n 3   4\n 4   4\n 7   8\n 9  10","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></details>","category":"page"},{"location":"lecture_01/arrays/#N-dimensional-arrays","page":"Arrays","title":"N-dimensional arrays","text":"","category":"section"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"In many cases, it is useful to use arrays with more dimensions to store data. As an example, we can mention RGB images, which are typically stored in 3-dimensional arrays. In Julia, there is no straightforward way to create N-dimensional arrays. The typical way to create such an array is to create an empty array of appropriate size and then fill it manually or using a loop. In this lecture, we will focus only on the basics of creating arrays. The lecture focused on loops will be later in the course.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"There are several ways to initialize an array. The simplest and most common is using the zeros function. This function by default creates an array of given size filled with zeros of type Float64","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = zeros(3, 5, 2) # equivalent to A = zeros((3, 5, 2))\n3×5×2 Array{Float64,3}:\n[:, :, 1] =\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The type of elements can be changed by passing the type as a first argument","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> B = zeros(Int64, 3, 5, 2)  # equivalent to B = zeros(Int64, (3, 5, 2))\n3×5×2 Array{Int64,3}:\n[:, :, 1] =\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0\n\n[:, :, 2] =\n 0  0  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"As in the case of vectors and matrices, we can use the same functions to obtain basic information about the arrays","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(A)\nArray{Float64,3}\n\njulia> eltype(A)\nFloat64\n\njulia> ndims(A)\n3\n\njulia> size(A)\n(3, 5, 2)\n\njulia> length(A)\n30","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The process of assigning a new value to the element of an array is also the same","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> B[1] = 1 # assign 1 to the first element\n1\n\njulia> B[1, 2, 2] = 2 # assign 2 to the element at position (1,2,2)\n2\n\njulia> B[2,:,1] .= 4\n5-element view(::Array{Int64,3}, 2, :, 1) with eltype Int64:\n 4\n 4\n 4\n 4\n 4\n\njulia> B\n3×5×2 Array{Int64,3}:\n[:, :, 1] =\n 1  0  0  0  0\n 4  4  4  4  4\n 0  0  0  0  0\n\n[:, :, 2] =\n 0  2  0  0  0\n 0  0  0  0  0\n 0  0  0  0  0","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Other useful functions can be used to initialize an array. The ones function is similar to the zeros function, but instead of an array filled with zeros, it creates an array filled with ones","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> ones(Float32, 2, 3, 1)\n2×3×1 Array{Float32,3}:\n[:, :, 1] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Function fill creates an array of given size filled with the given value","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> fill(1.234, 2, 2)\n2×2 Array{Float64,2}:\n 1.234  1.234\n 1.234  1.234","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Create three matrices with the following properties:","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Matrix A is of size 2x3, and all its elements are equal to 0.\nMatrix B is of size 2x3x1, and all its elements are equal to 1.\nMatrix C is of size 2x3, and all its elements are equal to 2.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Concatenate these three matrices along with the third dimension.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Hint: use the cat function and the keyword dims.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Matrix A can be created using the zeros function, and similarly, matrix B using the ones function. To create a matrix C, we can use the fill function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = zeros(2,3)\n2×3 Array{Float64,2}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\njulia> B = ones(2,3, 1)\n2×3×1 Array{Float64,3}:\n[:, :, 1] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n\njulia> C = fill(2, 2, 3)\n2×3 Array{Int64,2}:\n 2  2  2\n 2  2  2","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Now we can use the cat function with dims = 3 to concatenate the matrices along with the third dimension","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> cat(A, B, C; dims = 3)\n2×3×3 Array{Float64,3}:\n[:, :, 1] =\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\n[:, :, 2] =\n 1.0  1.0  1.0\n 1.0  1.0  1.0\n\n[:, :, 3] =\n 2.0  2.0  2.0\n 2.0  2.0  2.0","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></details>","category":"page"},{"location":"lecture_01/arrays/#Broadcasting","page":"Arrays","title":"Broadcasting","text":"","category":"section"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"In Julia, with broadcasting, we indicate mapping a function or an operation (which are the same in Julia) over an array (or any other iterable object) element by element. There is no speed gain in doing so, as it will be exactly equivalent to writing a for loop, but its conciseness may be useful sometimes. So the core idea in Julia is to write functions that take single values and use broadcasting when needed unless the functions must explicitly work on arrays (for example, to compute the mean of a series of values, perform matrix operations, vector multiplications, etc.).","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The broadcasting notation for operators consists of adding a dot . before the operator (for example, .*, .+, ./)","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a = [1,2,3] # column vector\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> a .-= 4 # from each element of vector subtracts 4\n3-element Array{Int64,1}:\n -3\n -2\n -1","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Without the dot, we get an error since we cannot subtract a number from a vector","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a -= 1\nERROR: MethodError: no method matching -(::Array{Int64,1}, ::Int64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n[...]","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The same syntax can be applied to any function in Julia. It is extremely useful for basic operations. For example, we can compute the absolute value of all elements by the following code","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> abs.(a)\n3-element Array{Int64,1}:\n 3\n 2\n 1","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"With broadcasting, it is effortless to compute complex mathematical formulas. For example, if we want to evaluate the following formulas","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"sum_i = 1^3 fracexpsqrta_i - 12","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"we can simply us the following code","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> sum(exp.(sqrt.(abs.(a .- 1)))./2)\n8.577270075873834","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Broadcasting can also be used for matrix multiplication. Consider the following two vectors.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a = [1,2,3] # column vector\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> b = [4,5,6] # column vector\n3-element Array{Int64,1}:\n 4\n 5\n 6","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Since we have two column vectors, the matrix multiplication will not work","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a * b\nERROR: MethodError: no method matching *(::Array{Int64,1}, ::Array{Int64,1})\n[...]","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It makes perfect sense from a mathematical perspective, and the * operator behaves how we would mathematically expect. If we want to use matrix multiplication, we have to transpose one of the vectors","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a' * b\n32\n\njulia> a * b'\n3×3 Array{Int64,2}:\n  4   5   6\n  8  10  12\n 12  15  18","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Nonetheless, in programming, it is often useful to write operations that work in an element-wise manner. In such cases, broadcasting comes to our help","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> a .* b\n3-element Array{Int64,1}:\n  4\n 10\n 18","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Construct a matrix whose elements are given by the following formula","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"A_i j = frac12exp(x_i j + 1)^2 quad i in 1 2  j in  1 2 3","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"where the matrix B is defined as follows","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"B = [\n    -1  0  2;\n    2  -3  1;\n]","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Each element of the matrix A depends on only one element of the matrix B. In other words, matrix A can be created in an element-wise manner from matrix B, i.e. we can use broadcasting","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = exp.((B .+ 1) .^ 2) ./ 2\n2×3 Array{Float64,2}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Note that we use a dot before each operation since we want to perform all operations element-wise. In this case, we can use the @. macro.  The @. macro adds a dot before each operator and each function in an expression","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = @. exp((B + 1) ^ 2) / 2\n2×3 Array{Float64,2}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Just for the comparison, the same matrix can be created as follows using for loop","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = zeros(2, 3);\n\njulia> for i in 1:length(A)\n           A[i] = exp((B[i] + 1)^2)/2\n       end\n\njulia> A\n2×3 Array{Float64,2}:\n    0.5    1.35914  4051.54\n 4051.54  27.2991     27.2991","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"</p></details>","category":"page"},{"location":"lecture_01/arrays/#Views","page":"Arrays","title":"Views","text":"","category":"section"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"As in other programming languages, arrays are pointers to a location in memory. Thus we need to pay attention when we handle them. If we create an array A and we assign it to a variable B, the elements of the original array can be modified by accessing B","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> B = A\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> B[2] = 42\n42","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"We can check that both arrays are equal even though we modified only the array B","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A == B\ntrue","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The reason is that Julia, by default, will not create a copy of an array when assigning to a variable. This behavior is advantageous because it allows us to save memory. However, it also may have undesirable effects. If we want to make a copy of an array, we have to use the copy function","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> C = copy(A)\n2×3 Array{Int64,2}:\n  1  2  3\n 42  5  6\n\njulia> C[4] = 10\n10\n\njulia> A == C\nfalse","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"The different behavior occurs when accessing elements. Every time we access multiple elements of an array at once, a new array is created","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> D = A[1:2, 1:2]\n2×2 Array{Int64,2}:\n  1  2\n 42  5\n\njulia> D[1] = 15\n15","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"In this case, we modified only the array D, and array A remains unchanged","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> D == A[1:2, 1:2]\nfalse","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"However, even if we want to select some subarray, it may be useful to create only a link to the original array and not create a new array. In Julia, this can be achieved using the view function or alternatively, using the @view macro","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> E = view(A, 1:2, 1:2)\n2×2 view(::Array{Int64,2}, 1:2, 1:2) with eltype Int64:\n  1  2\n 42  5\n\njulia> E = @view A[1:2, 1:2]\n2×2 view(::Array{Int64,2}, 1:2, 1:2) with eltype Int64:\n  1  2\n 42  5\n\njulia> E[4] = 78\n78","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"We see that even if we change only the array in D, the change is propagated to A","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> E == A[1:2, 1:2]\ntrue","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Note that  function view creates a special type SubArray","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> typeof(E)\nSubArray{Int64,2,Array{Int64,2},Tuple{UnitRange{Int64},UnitRange{Int64}},false}","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Since SubArray is a subtype of AbstractArray, we can apply any function defined for Abstract Arrays to SubArray too. In other words, (almost) all functions that work for arrays will also work for subarray.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> A_view = @view A[:, :]\n2×3 view(::Array{Int64,2}, :, :) with eltype Int64:\n 1  2  3\n 4  5  6\n\njulia> sum(A)\n21\n\njulia> sum(A_view)\n21\n\njulia> minimum(A; dims = 1)\n1×3 Array{Int64,2}:\n 1  2  3\n\njulia> minimum(A_view; dims = 1)\n1×3 Array{Int64,2}:\n 1  2  3","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"It means that we can use arrays and subarray interchangeably without the necessity of changing existing code. Of course, there are some limitations, but we will talk about them later.","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"Note that the @view macro can only be applied directly to a reference expression. In many cases, we want to use views throughout the whole expression. In such a case, we can add the @view macro before each array-slicing operation","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> A = [1 2 3; 4 5 6];\n\njulia> sum(exp.(sqrt.(abs.(@view(A[1, :]) .- @view(A[2, :]))))./2)\n8.478350511051136","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"However, the resulting expression is long and difficult to read. To simplify this task, Julia provides the @views macro that converts every array-slicing operation in the given expression to return a view","category":"page"},{"location":"lecture_01/arrays/","page":"Arrays","title":"Arrays","text":"julia> @views sum(exp.(sqrt.(abs.(A[1, :] .- A[2, :])))./2)\n8.478350511051136","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using MLDatasets\n\nCore.eval(Main, :(using Flux)) # hide\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\nMNIST.traindata()","category":"page"},{"location":"lecture_10/nn/#More-complex-networks","page":"More complex networks","title":"More complex networks","text":"","category":"section"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"This section will show how to train more complex networks using stochastic gradient descent. We will also use the more complicated MNIST dataset which contains 60000 images of digits 0-9.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"As always, we start with the seed ","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using Random\n\nRandom.seed!(666)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/#Loading-data","page":"More complex networks","title":"Loading data","text":"","category":"section"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The convolutional layers in Flux require that the input has dimension n_xtimes n_ytimes n_ctimes n_s, where (n_xn_y) is the number of pixels in each dimension, n_c is the number of channels (1 for grayscale, and 3 for coloured images) and n_s is the number of samples. The simplest way to load the dataset is to use the MLDatasets package via MLDatasets.MNIST.traindata(T), where T is a given type (can be empty).","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Write function load_data which loads the data and transforms it into the correct size. Do not forgot to transform the labels into the one-hot representation, which can be done by using the onehotbatch function from Flux.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To load data, we define the desired type to be Float32, and select the dataset to be MNIST. Working with a general dataset has the advantage that it is simple to modify the code if we want to work with a different dataset such as FashionMNIST or CIFAR.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using MLDatasets\nusing Flux\nusing Flux: onehotbatch, onecold\n\nT = Float32\ndataset = MLDatasets.MNIST\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"As we have never worked with MLDatasets, we do not know in which format the loading function returns the data. For this reason, we check that","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"typeof(dataset.traindata(T))","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"is a tuple of the data and the labels. Performing one more check","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"size(dataset.traindata(T)[1])","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"shows that the channels are missing. For this reason, we need to add them by","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"function reshape_data(X::AbstractArray{T, 3}, y::AbstractVector) where T\n    s = size(X)\n    return reshape(X, s[1], s[2], 1, s[3]), reshape(y, 1, :)\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To prevent unexpected surprises, we specify that the data have only three dimensions via X::AbstractArray{T, 3}.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Now we can write the loading function. It is similar to the one we have already written. Pay attention to the line dataset.traindata(T).... It would be possible to use two arguments dataset.traindata(T)[1] and dataset.traindata(T)[2]. However, this would load the data two times. Line y_train = T.(y_train) should not be necessary as we specify T already in traindata(T). We include the optional parameter onehot.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"function load_data(dataset; T=Float32, onehot=false, classes=0:9)    \n    X_train, y_train = reshape_data(dataset.traindata(T)...)\n    X_test, y_test = reshape_data(dataset.testdata(T)...)\n    y_train = T.(y_train)\n    y_test = T.(y_test)\n\n    if onehot\n        y_train = onehotbatch(y_train[:], classes)\n        y_test = onehotbatch(y_test[:], classes)\n    end\n\n    return X_train, y_train, X_test, y_test\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Now we load the data by","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"X_train, y_train, X_test, y_test = load_data(dataset; T=T, onehot=true)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></details>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The previous example is rather general. Only small modifications are needed for other datasets.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Try to load the CIFAR10 dataset (dataset = MLDatasets.CIFAR10) and fix the error in one line of code.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"We try to load the data in the same way as before","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"load_data(MLDatasets.CIFAR10; T=T, onehot=true)","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"It results in an error","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"│  MethodError: no method matching reshape_data(::Array{Float32,4}, ::Array{Int64,1})\n│  Closest candidates are:\n│    reshape_data(::AbstractArray{T,3}, ::AbstractArray{T,1} where T) where T","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"We see that the problem is that we defined reshape_data only for input arrays of dimension 3 but since CIFAR contains coloured images, it has 4 dimensions. We, therefore, need to add more method for the function reshape_data","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"reshape_data(X::AbstractArray{T, 4}, y::AbstractVector) where T = (X, reshape(y, 1, :))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Now we can load the data","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"typeof(load_data(MLDatasets.CIFAR10; T=T, onehot=true))","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}},Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"We see that it correctly returned a tuple of four items.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></details>","category":"page"},{"location":"lecture_10/nn/#Visualization-of-images","page":"More complex networks","title":"Visualization of images","text":"","category":"section"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"When working with data, it is always good to have some understanding for them. Since MNIST is a dataset of images, the simplest way of understanding is plotting them.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Write a function plot_image which plots the input image. Since we work with grayscale images, the simplest way to plot is to use the plot function after converting all pixels to Gray type via a function of the same name, which is included in the Plots package.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Plot the third image from the training set and check that the label is correct. To do so, you will need our previously written onecold function or you can use the one from the Flux package.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To plot an image, we convert it into grayscale by Gray. We use the dot notation because the input is a matrix, and we need to apply the operator to all of its entries. Since we are not interested in the axis, we turn them off by axis=false and ticks=false. Note that we need to transpose the input; otherwise, the image would be rotated. We also use 1 .-x to invert the black and white colours.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using Plots\n\nplot_image(x::AbstractArray{T, 2}) where T = plot(Gray.(1 .-x'), axis=false, ticks=false)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To make sure that plot_image works even if we call it with an input with three  dimensions, we add one more function.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"function plot_image(x::AbstractArray{T, 3}) where T\n    size(x,3) == 1 || error(\"Image is not grayscale.\")\n    plot_image(x[:,:,1])\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Plotting the image is then simple. Note that this code calls the plot_image(x::AbstractArray{T, 3}) which performs the check whether the image is grayscale and then calls the plot_image(x::AbstractArray{T, 2}) function.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"i = 3\nplot_image(X_train[:,:,:,i])\n\nsavefig(\"MNIST.svg\") # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"For the correct label, we need to specify the classes 0:9. If we do not specify them, Flux will assign numbers 1 to 10 instead of correct 0 to 9, and the result will be shifted by one","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"onecold(y_train[:,i], 0:9)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></details>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The correct answer is","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"onecold(y_train[:,i], 0:9) # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"(Image: )","category":"page"},{"location":"lecture_10/nn/#Training-and-storing-the-network","page":"More complex networks","title":"Training and storing the network","text":"","category":"section"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To train the network, we will now write the function train_model!. Since it modifies the input model m, its name should contain the exclamation mark. Besides data X and labels y, it also contains as optional arguments optimizer the opt, the minibatch size batch_size, the number of epochs n_epochs, and the file name file_name to which the model should be saved.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using Base.Iterators: partition\nusing Flux: crossentropy\nusing BSON\n\nfunction train_model!(m, X, y;\n        opt=ADAM(0.001),\n        batch_size=128,\n        n_epochs=10,\n        file_name=\"\")\n\n    loss(x, y) = crossentropy(m(x), y)\n\n    batches_train = map(partition(randperm(size(y, 2)), batch_size)) do inds\n        return (X[:, :, :, inds], y[:, inds])\n    end\n\n    for _ in 1:n_epochs\n        Flux.train!(loss, params(m), batches_train, opt)\n    end\n\n    !isempty(file_name) && BSON.bson(file_name, m=m)\n\n    return\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"It starts with the crossentropy loss function, which needs to be loaded from the Flux package by using Flux: crossentropy.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"On the contrary to the models used before, it uses stochastic gradient descent instead of gradient descent. The reason is that the MNIST training set contains 50000 samples, and the computation of the full gradient would be too costly. To create minibatches, we create a random partion of all indices randperm(size(y, 2)), and use function partition to create an iterator, which creates the minibatches in the form of tuples (Xy).","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"batches_train = map(partition(randperm(size(y, 2)), batch_size)) do inds\n    return (X[:, :, :, inds], y[:, inds])\nend","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The equivalent formulation without the map function would be","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"batches_train = [(X[:, inds], y[:, inds]) for inds in partition(randperm(size(y, 2)), batch_size)]","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The type of batches_train is one-dimensional array (vector) of tuples","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Array{Tuple{Array{Int64,2},Array{Float64,2}},1}","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"This allows us to call the train! function, which computes the gradients on all minibatches and performs the same number of gradient updates as the number of minibatches. Since train! looked at every sample exactly once,","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Flux.train!(loss, params(m), batches_train, opt)","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"performs one training epoch. Computationally, this is roughly equivalent to one full gradient update, but this line of code performed as many gradient updates as there are minibatches. Therefore, we train for n_epoch epochs by","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"for _ in 1:n_epochs\n    Flux.train!(loss, params(m), batches_train, opt)\nend","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"As we do not need the index in the for loop, we use _. The last line saves the model whenever the file name is non-empty.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Train the model ","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"m = Chain(\n    Conv((2,2), 1=>16, relu),\n    MaxPool((2,2)),\n    Conv((2,2), 16=>8, relu),\n    MaxPool((2,2)),\n    flatten,\n    Dense(288, size(y_train,1)),\n    softmax,\n)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"for one epoch and save it into the file MNIST_simple.bson. Print the accuracy of the model on the testing set.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To train the model, it suffices to call the previously written function","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"file_name = \"mnist_simple.bson\"\ntrain_model!(m, X_train, y_train; n_epochs=1, file_name=file_name)\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The accuracy has been computed many times during the course","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"using Statistics\n\naccuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n\n\"Test accuracy = \" * string(accuracy(X_test, y_test))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"We defined accuracy in a different way than before. Can you spot the difference and explain why they are equivalent?","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></details>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"println(\"Test accuracy = \" * string(accuracy(X_test, y_test))) # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The accuracy is over 92%, which is not bad for training for one epoch only. Let us recall that training for one epoch means that the classifier evaluates each sample only once. To obtain better accuracy, we need to train the model for more epochs. Since that may take some time, it is not good to train the same model again and again. The next exercise determines automatically whether the trained model already exists. If not, it trains it.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"<div class = \"exercise-body\">\n<header class = \"exercise-header\">Exercise:</header><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Write a function train_or_load!(file_name, m, X, y; ???) which checks whether the file file_name exists.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"If it exists, it loads it and then copies its parameters into m using the function Flux.loadparams!\nIf it does not exist, it trains it using train_model!.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"In both cases, the model m should be modified inside the train_or_load! function. Pay special attention to the optional arguments ???. ","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"Load the model from data/mnist.bson and evaluate the performance at the testing set.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></div>\n<details class = \"solution-body\">\n<summary class = \"solution-header\">Solution:</summary><p>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The optional arguments should contain kwargs..., which will be passed to train_model!. Besides that, we include force which enforces that the model is trained even if it already exists (in which case, it will overwrite it). ","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"First, we should check whether the directory exists !isdir(dirname(file_name)) and if not, we create it mkpath(dirname(file_name)). Then we check whether the file exists (or whether we want to enforce the training). If yes, we train the model, which already modifies m. If not, we BSON.load the model and copy the loaded parameters into m by Flux.loadparams!(m, params(m_loaded)). We cannot load directly into m instead of m_loaded because that would create a local copy of m and the function would not modify the external m.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"function train_or_load!(file_name, m, X, y; force=false, kwargs...)\n    \n    !isdir(dirname(file_name)) && mkpath(dirname(file_name))\n\n    if force || !isfile(file_name)\n        train_model!(m, X, y; file_name=file_name, kwargs...)\n    else\n        m_loaded = BSON.load(file_name)[:m]\n        Flux.loadparams!(m, params(m_loaded))\n    end\nend\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"To load the model, we should use joinpath to be compatible with all operating systems. The accuracy is evaluated as before.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"file_name = joinpath(\"data\", \"mnist.bson\")\ntrain_or_load!(file_name, m, X_train, y_train)\n\n\"Test accuracy = \" * string(accuracy(X_test, y_test))\n\nnothing # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"</p></details>","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"println(\"Test accuracy = \" * string(accuracy(X_test, y_test))) # hide","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"The externally trained model has the accuracy of more than 98% (it has the same architecture as the one defined above, but it was trained for 50 epochs.). Even though there are perfect models (with accuracy 100%) on MNIST, we are happy with this result. We will perform further analysis of the network in the exercises.","category":"page"},{"location":"lecture_10/nn/","page":"More complex networks","title":"More complex networks","text":"ii = [1;2;54]\n\np1 = plot_image(X_train[:,:,:,ii[1]])\np2 = plot_image(X_train[:,:,:,ii[2]])\np3 = plot_image(X_train[:,:,:,ii[3]])\n\nplot(p1, p2, p3; layout=(1,3), size=(900,300))\n\nsavefig(\"nn_intro.svg\")\n\nm_val = m(X_train[:,:,:,ii])\np = maximum(m_val, dims=1)\ny_hat = onecold(m_val, 0:9)","category":"page"}]
}
