<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Unconstrained optimization · Julia for Optimization and Learning</title><meta name="title" content="Unconstrained optimization · Julia for Optimization and Learning"/><meta property="og:title" content="Unconstrained optimization · Julia for Optimization and Learning"/><meta property="twitter:title" content="Unconstrained optimization · Julia for Optimization and Learning"/><meta name="description" content="Documentation for Julia for Optimization and Learning."/><meta property="og:description" content="Documentation for Julia for Optimization and Learning."/><meta property="twitter:description" content="Documentation for Julia for Optimization and Learning."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Julia for Optimization and Learning logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Julia for Optimization and Learning logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Julia for Optimization and Learning</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why/">Why Julia?</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Installation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../installation/installation/">Installation</a></li><li><a class="tocitem" href="../../installation/tutorial/">Quickstart guide</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Basics I</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Elementary functions</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data structures</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: Basics II</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/functions/">Funcion basics</a></li><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional evaluations</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and iterators</a></li><li><a class="tocitem" href="../../lecture_02/scope/">Soft local scope</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/standardlibrary/">Standard library</a></li><li><a class="tocitem" href="../../lecture_03/pkg/">Package manager</a></li><li><a class="tocitem" href="../../lecture_03/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_03/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_03/otherpackages/">Other useful packages</a></li><li><a class="tocitem" href="../../lecture_03/interaction/">Interaction with other languages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_04/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_04/scope/">Scope of variables</a></li><li><a class="tocitem" href="../../lecture_04/exceptions/">Exception handling</a></li><li><a class="tocitem" href="../../lecture_04/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Type system and generic programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/compositetypes/">Abstract and composite types</a></li><li><a class="tocitem" href="../../lecture_05/currencies/">Generic programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Code organization I</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06_07/modules/">Files and modules</a></li><li><a class="tocitem" href="../../lecture_06_07/develop/">Package development</a></li></ul></li><li><span class="tocitem">7: Code organization II</span></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox" checked/><label class="tocitem" for="menuitem-11"><span class="docs-label">8: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../theory/">Introduction to continuous optimization</a></li><li><a class="tocitem" href="../gradients/">Gradients</a></li><li class="is-active"><a class="tocitem" href>Unconstrained optimization</a><ul class="internal"><li><a class="tocitem" href="#Gradient-descent"><span>Gradient descent</span></a></li><li><a class="tocitem" href="#Adaptive-stepsize"><span>Adaptive stepsize</span></a></li></ul></li><li><a class="tocitem" href="../constrained/">Constrained optimization</a></li><li><a class="tocitem" href="../exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">9: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/theory/">Introduction to regression and classification</a></li><li><a class="tocitem" href="../../lecture_09/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_09/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_09/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">10: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/nn/">Neural networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">11: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_11/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_11/iris/">Introduction to Flux</a></li><li><a class="tocitem" href="../../lecture_11/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_11/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">12: Statistics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_12/sparse/">Linear regression with sparse constraints</a></li><li><a class="tocitem" href="../../lecture_12/monte/">Monte Carlo sampling</a></li><li><a class="tocitem" href="../../lecture_12/glm/">Linear regression revisited</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">8: Optimization</a></li><li class="is-active"><a href>Unconstrained optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Unconstrained optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaTeachingCTU/Julia-for-Optimization-and-Learning" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaTeachingCTU/Julia-for-Optimization-and-Learning/blob/master/docs/src/lecture_08/unconstrained.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Unconstrained-optimization"><a class="docs-heading-anchor" href="#Unconstrained-optimization">Unconstrained optimization</a><a id="Unconstrained-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Unconstrained-optimization" title="Permalink"></a></h1><p>Unconstrained optimization means that we optimize a function on the whole space <span>$X=\mathbb{R}^n$</span>. Then the optimization problem reduces to</p><p class="math-container">\[    \text{minimize}\qquad f(x).\]</p><p>What do we look for when we minimize a function <span>$f$</span> over some <span>$X$</span>? The optimal point would be a global minimum, which is a point <span>$x\in X$</span> which satisfies</p><p class="math-container">\[f(x) \le f(y) \text{ for all }y\in X.\]</p><p>This point is often challenging to find. Sometimes we can find a local minimum, which is a global minimum on some small neighbourhood of <span>$x$</span>. However, as the following theorem suggests, we often need to lower our requirements even lower.</p><div class="admonition is-todo"><header class="admonition-header">Theorem: Connection between optimization problems and gradients</header><div class="admonition-body"><p>Consider a differentiable function <span>$f$</span> over <span>$X=\mathbb{R}^n$</span>. If <span>$x$</span> is its local minimum, then <span>$\nabla f(x)=0$</span>. Conversely, if <span>$f$</span> is convex, then every point <span>$x$</span> with <span>$\nabla f(x)=0$</span> is a global minimum of <span>$f$</span>.</p></div></div><p>Points with <span>$\nabla f(x)=0$</span> are known as stationary points. Optimization algorithms often try to find local minima or stationary points, hoping to minimize the function <span>$f$</span>. The reason is the following: To optimize <span>$f$</span>, we can evaluate it only at a limited number of points. Since evaluating <span>$f$</span> at a point conveys only information about the function value at this point or its small neighbourhood, we collect only local information about <span>$f$</span>. Therefore, unless <span>$f$</span> has a special structure, it is possible to obtain global results from only local evaluations. </p><p><img src="../minmax.svg" alt/></p><div class="admonition is-info"><header class="admonition-header">Take care:</header><div class="admonition-body"><p>This theorem does not hold if <span>$X$</span> is not the whole space. A simple counterexmple is minimization of <span>$f(x)=x$</span> on <span>$X=[0,1]$</span>.</p></div></div><p>Since the gradient is the direction of the steepest ascent, the straightforward idea is to move in the opposite direction. This gives rise to the gradient (or steepest) descent algorithm</p><p class="math-container">\[x^{k+1} = x^k - \alpha^k\nabla f(x^k),\]</p><p>where <span>$\alpha_k&gt;0$</span> is called stepsize. If this update converges, then <span>$x^{k+1}$</span> and <span>$x^k$</span> are close to each other, and therefore <span>$\nabla f(x^k)\to 0$</span>. This means that this method converges to a stationary point.</p><p>The stepsize <span>$\alpha^k&gt;0$</span> is usually fixed and determined before the optimization is started. However, some methods use an automatic selection of the stepsize. One of the possibilities is the <a href="https://en.wikipedia.org/wiki/Wolfe_conditions">Armijo condition</a> which looks for <span>$\alpha^k$</span> satisfying</p><p class="math-container">\[f(x^k - \alpha^k\nabla f(x^k)) \le f(x^k) - c \alpha^k \|\nabla f(x^k)\|^2.\]</p><p>Here  <span>$c\in(0,1)$</span> is a small constant, usually <span>$c=10^{-4}$</span>. Since the left-hand side is the function value at the new iterate <span>$x^{k+1}$</span>, the Armijo condition ensures that the sequence of function values is strictly decreasing. This prevents oscillations. Theoretical results ensure that there is some interval <span>$(0,\alpha_0)$</span> such that any <span>$\alpha$</span> from this interval satisfies the Armijo condition. Therefore, to find some <span>$\alpha$</span> satisfying the Armijo conditions, we start with some <span>$\alpha_{\rm max}$</span> and divide it by two until the condition is satisfied.</p><div class="admonition is-info"><header class="admonition-header">Terminology:</header><div class="admonition-body"><p>In classical optimization, the usual terminology is:</p><ul><li>Variable is to be optimized. The example would be <span>$x$</span>.</li><li>Parameter is an external (fixed) parameter such as a material parameter. The example would be <span>$\alpha$</span>.</li></ul><p>In machine learning, the usual terminology is:</p><ul><li>Parameter is to be optimized.</li><li>Hyperparameter is an external model parameter that is not optimized and needs to be tuned. The example is the steplength because the gradient descent finds a different solution for different steplength, but it is not changed during the optimization.</li></ul><p>The different terminology (and possibly the fact that there are adaptive schemes to select the steplength, which should make it a parameter instead of a hyperparameter) makes the notation confusing.</p></div></div><h2 id="Gradient-descent"><a class="docs-heading-anchor" href="#Gradient-descent">Gradient descent</a><a id="Gradient-descent-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-descent" title="Permalink"></a></h2><p>In this section, we will implement the gradient descent method.</p><div class="admonition is-warning"><header class="admonition-header">Exercise: Gradient descent:</header><div class="admonition-body"><p>Implement function <code>optim</code>, which takes as inputs function <span>$f$</span>, its gradient, starting point <span>$x^0$</span> and fixed stepsize <span>$\alpha$</span> and runs the gradient descent. Its output should be the first 100 iterations.</p><p>This example is rather artificial because usually only the last iteration is returned and some stopping criterion is employed instead of the fixed number of iterations. We want to get all iterations to make visualizations.</p></div></div><details class="admonition is-details"><summary class="admonition-header">Solution:</summary><div class="admonition-body"><p>First we need to create an empty array into which we store the data. Then at every iteration we compute the gradient <code>g(x)</code>, perform the update and save the new value of <span>$x$</span>.</p><pre><code class="language-julia hljs">function optim(f, g, x, α; max_iter=100)
    xs = zeros(length(x), max_iter+1)
    xs[:,1] = x
    for i in 1:max_iter
        x -= α*g(x)
        xs[:,i+1] = x
    end
    return xs
end</code></pre></div></details><p>The implementation does not use the values of <span>$f$</span> but only its gradient <span>$\nabla f$</span>. If the algorithm converges <span>$x^k \to \bar x$</span>, then passing to the limit in the gradient update results in <span>$\nabla f(\bar x)=0$</span>. Therefore, as with most optimization methods, gradient descent looks for stationary points.</p><p>Before plotting the path taken by gradient descent, we create the <code>create_anim</code> function, which creates animations of <code>path</code> over the contour plot of <code>f</code>. From <code>xlims</code> and <code>ylim</code>, it creates discretizations <code>xs</code> and <code>ys</code> and then plots the contour plot as background. Since <code>Animation</code> requires updating a graph, we start with an empty graph, and we push a new image to the animation in every iteration. The final command <code>gif</code> saves the animation into <code>file_name</code>.</p><pre><code class="language-julia hljs">using Random

function create_anim(
    f,
    path,
    xlims,
    ylims,
    file_name = joinpath(pwd(), randstring(12) * &quot;.gif&quot;);
    xbounds = xlims,
    ybounds = ylims,
    fps = 15,
)
    xs = range(xlims...; length = 100)
    ys = range(ylims...; length = 100)
    plt = contourf(xs, ys, f; color = :jet)

    # add constraints if provided
    if !(xbounds == xlims &amp;&amp; ybounds == ylims)
        x_rect = [xbounds[1]; xbounds[2]; xbounds[2]; xbounds[1]; xbounds[1]]
        y_rect = [ybounds[1]; ybounds[1]; ybounds[2]; ybounds[2]; ybounds[1]]

        plot!(x_rect, y_rect; line = (2, :dash, :red), label=&quot;&quot;)
    end

    # add an empty plot
    plot!(Float64[], Float64[]; line = (4, :arrow, :black), label = &quot;&quot;)

    # extract the last plot series
    plt_path = plt.series_list[end]

    # create the animation and save it
    anim = Animation()
    for x in eachcol(path)
        push!(plt_path, x[1], x[2]) # add a new point
        frame(anim)
    end
    gif(anim, file_name; fps = fps, show_msg = false)
    return nothing
end</code></pre><p>We now plot how gradient descent behaves.</p><div class="admonition is-warning"><header class="admonition-header">Exercise: Gradient descent</header><div class="admonition-body"><p>Use the implementation of the gradient descent to minimize the function</p><p class="math-container">\[f(x) = \sin(x_1 + x_2) + \cos(x_1)^2\]</p><p>from the starting point <span>$x^0=(0,-1)$</span>. Use the constant stepsize <span>$\alpha=0.1$</span>. Store all iterations into matrix <code>xs</code>.</p><p>Use the <code>create_anim</code> function to plot the iteration into a gif file.</p><p>Use one line of code to evaluate the function values for all iterations <code>xs</code> and plot these function values.</p><p><strong>Hint</strong>: to evaluate all <span>$xs$</span> in one line, use iterate either via <code>eachcol(xs)</code> or <code>eachrow(xs)</code>.</p></div></div><details class="admonition is-details"><summary class="admonition-header">Solution:</summary><div class="admonition-body"><p>We call <code>optim</code> from the previous exercise and then create the animation.</p><pre><code class="language-julia hljs">x_gd = optim([], g, [0; -1], 0.1)

xlims = (-3, 1)
ylims = (-2, 1)
create_anim(f, x_gd, xlims, ylims, &quot;anim1.gif&quot;)</code></pre><p>To plot the function values, we need to iterate over all columns. We use <code>[? for x in eachcol(x_gd)]</code> and apply <code>f(x)</code> instead of <code>?</code>. Another (more complicated) way is to iterate over indices instead of vectors and write <code>[f(x_gs[:,i]) for i in 1:size(x_gd,2)]</code>.</p><pre><code class="language-julia hljs">f_gd = [f(x) for x in eachcol(x_gd)]

plot(f_gd, label=&quot;&quot;, xlabel=&quot;Iteration&quot;, ylabel=&quot;Function value&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">&quot;/home/runner/work/Julia-for-Optimization-and-Learning/Julia-for-Optimization-and-Learning/docs/build/lecture_08/obj.svg&quot;</code></pre></div></details><p><img src="../anim1.gif" alt/> <img src="../obj.svg" alt/></p><p>The convergence looks very nice, and the function value decreases. Initially, the decrease is faster, but it slows down when the iterations get closer to the minimum.</p><p>What happens if we choose a different stepsize? Let us try with two different values. First let us try <span>$\alpha=0.01$</span>.</p><pre><code class="language-julia hljs">x_gd = optim([], g, [0; -1], 0.01)

create_anim(f, x_gd, xlims, ylims, &quot;anim2.gif&quot;)</code></pre><p><img src="../anim2.gif" alt/></p><p>When the stepsize is reduced, the steps are shorter, and we would need to increase the number of iterations (and thus the computational time) to converge. When the stepsize is larger, say <span>$\alpha=1$</span>, the situation is different.</p><pre><code class="language-julia hljs">x_gd = optim([], g, [0; -1], 1)

create_anim(f, x_gd, xlims, ylims, &quot;anim3.gif&quot;)</code></pre><p><img src="../anim3.gif" alt/></p><p>For a large stepsize, the algorithm gets close to the solution and then starts jumping around. If we further increase the stepsize, the algorithm will even diverge. Try it.</p><h2 id="Adaptive-stepsize"><a class="docs-heading-anchor" href="#Adaptive-stepsize">Adaptive stepsize</a><a id="Adaptive-stepsize-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptive-stepsize" title="Permalink"></a></h2><p>The implementation of <code>optim(f, g, x, α; max_iter=100)</code> does not allow modifying the step selection. The simplest fix would be to include <code>if</code> conditions inside the function. However, this would result in a long function, which may be difficult to debug and modify. A more elegant solution is to create an abstract type.</p><pre><code class="language-julia hljs">abstract type Step end</code></pre><p>For each possible step selection technique, we implement an <code>optim_step</code> method selecting the step. First, we create the gradient descent type <code>GD</code> as a subtype of <code>Step</code> by</p><pre><code class="language-julia hljs">struct GD &lt;: Step
    α::Float64
end</code></pre><p>It is a structure with parameter <code>α</code>. Then we create the <code>optim_step</code> function by</p><pre><code class="language-julia hljs">optim_step(s::GD, f, g, x) = -s.α*g(x)</code></pre><p>Due to the first input argument, it will be called only for the  <code>GD</code> stepsize. To access the parameter <code>α</code>, we need to retrieve it from the structure by <code>s.α</code>. Now we can modify the <code>optim</code> function by</p><pre><code class="language-julia hljs">function optim(f, g, x, s::Step; max_iter=100)
    xs = zeros(length(x), max_iter+1)
    xs[:,1] = x
    for i in 1:max_iter
        x += optim_step(s, f, g, x)
        xs[:,i+1] = x
    end
    return xs
end</code></pre><p>The specification of the input <code>s::Step</code> allows for any subtype of the abstract type <code>Step</code>. Using this implentation results in</p><pre><code class="language-julia hljs">gd = GD(0.1)
x_opt = optim(f, g, [0;-1], gd)

create_anim(f, x_opt, xlims, ylims, &quot;anim4.gif&quot;)</code></pre><p><img src="../anim4.gif" alt/></p><p>The result is the same as in the previous case. This is not surprising as the code does the same things; it is only written differently. The following exercise shows the power of defining the <code>Step</code> type.</p><div class="admonition is-warning"><header class="admonition-header">Exercise: Armijo condition</header><div class="admonition-body"><p>Implement the <code>Armijo</code> subtype of the <code>Step</code> type. It should have two parameters <code>c</code> from the definition and <code>α_max</code> which will be the initial value of <span>$\alpha$</span>. The value <span>$\alpha$</span> should be divided by two until the Armijo condition is satisfied.</p><p>Then run the optimization with the Armijo stepsize selection and plot the animation.</p></div></div><details class="admonition is-details"><summary class="admonition-header">Solution:</summary><div class="admonition-body"><p>We define the type in the same way as for <code>GD</code>:</p><pre><code class="language-julia hljs">struct Armijo &lt;: Step
    c::Float64
    α_max::Float64
end</code></pre><p>For the search for the stepsize, we first save the values for the function value <span>$f(x)$</span> and the gradient <span>$\nabla f(x)$</span>. If we do not do this, it will be recomputed at every step. Then we initialize the value of <span>$\alpha$</span> and run the while loop until the Armijo condition is satisfied. We add a termination condition <code>α &lt;= 1e-6</code> to prevent the loop from continuing indefinitely.</p><pre><code class="language-julia hljs">function optim_step(s::Armijo, f, g, x)
    fun = f(x)
    grad = g(x)
    α = s.α_max
    while f(x .- α*grad) &gt; fun - s.c*α*(grad&#39;*grad)
        α /= 2
        if α &lt;= 1e-6
            warning(&quot;Armijo line search failed.&quot;)
            break
        end
    end
    return -α*grad
end</code></pre><p>Then we create the <code>Armijo</code> struct and run the optimization.</p><pre><code class="language-julia hljs">gd = Armijo(1e-4, 1)
x_opt = optim(f, g, [0;-1], gd)

create_anim(f, x_opt, xlims, ylims, &quot;anim5.gif&quot;)</code></pre></div></details><p><img src="../anim5.gif" alt/></p><p>Since the Armijo condition determines the optimal stepsize automatically, the convergence is much faster than for gradient descent. Moreover, it is not necessary to specify the stepsize. The price to pay is that every iteration needs to perform several function evaluations, which is not the case for standard gradient descent.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gradients/">« Gradients</a><a class="docs-footer-nextpage" href="../constrained/">Constrained optimization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Thursday 26 September 2024 06:13">Thursday 26 September 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
