<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimal control · Julia for Optimization and Learning</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Julia for Optimization and Learning logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Julia for Optimization and Learning logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Julia for Optimization and Learning</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why/">Why Julia?</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Installation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../installation/julia/">Julia</a></li><li><a class="tocitem" href="../../installation/vscode/">Visual Studio Code</a></li><li><a class="tocitem" href="../../installation/git/">Git</a></li><li><a class="tocitem" href="../../installation/tutorial/">Quickstart guide</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Variables and basic operators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Elementary functions</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data structures</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: Control flow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional evaluations</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and iterators</a></li><li><a class="tocitem" href="../../lecture_02/scope/">Soft local scope</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_03/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_03/scope/">Scope of variables</a></li><li><a class="tocitem" href="../../lecture_03/exceptions/">Exception handling</a></li><li><a class="tocitem" href="../../lecture_03/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/standardlibrary/">Standard library</a></li><li><a class="tocitem" href="../../lecture_04/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_04/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_04/otherpackages/">Other useful packages</a></li><li><a class="tocitem" href="../../lecture_04/interaction/">Interaction with other languages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Type system and generic programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/compositetypes/">Abstract and composite types</a></li><li><a class="tocitem" href="../../lecture_05/currencies/">Generic programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Code organization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/modules/">Files and modules</a></li><li><a class="tocitem" href="../../lecture_06/pkg/">Package manager</a></li><li><a class="tocitem" href="../../lecture_06/develop/">Package development</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">Course requirements</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../final_project/homeworks/">Homework</a></li><li><a class="tocitem" href="../../final_project/project/">Final project</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">7: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/theory/">Introduction to continuous optimization</a></li><li><a class="tocitem" href="../../lecture_07/unconstrained/">Unconstrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/constrained/">Constrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">8: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/theory/">Introduction to regression and classification</a></li><li><a class="tocitem" href="../../lecture_08/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_08/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_08/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">9: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_09/nn/">Neural networks</a></li><li><a class="tocitem" href="../../lecture_09/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">10: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/iris/">Introduction to Flux</a></li><li><a class="tocitem" href="../../lecture_10/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">11: Statistics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_11/sparse/">Linear regression with sparse constraints</a></li><li><a class="tocitem" href="../../lecture_11/monte/">Monte Carlo sampling</a></li><li><a class="tocitem" href="../../lecture_11/glm/">Linear regression revisited</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-16" type="checkbox" checked/><label class="tocitem" for="menuitem-16"><span class="docs-label">12: Ordinary differential equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../theory/">Differential equations</a></li><li><a class="tocitem" href="../ode/">Wave equation</a></li><li><a class="tocitem" href="../diff_eq/">Julia package</a></li><li class="is-active"><a class="tocitem" href>Optimal control</a><ul class="internal"><li><a class="tocitem" href="#Permanent-magnet-synchronous-motors"><span>Permanent magnet synchronous motors</span></a></li><li><a class="tocitem" href="#Computing-trajectories-with-no-control"><span>Computing trajectories with no control</span></a></li><li><a class="tocitem" href="#Solving-the-optimal-control-problem"><span>Solving the optimal control problem</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">12: Ordinary differential equations</a></li><li class="is-active"><a href>Optimal control</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimal control</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaTeachingCTU/Julia-for-Optimization-and-Learning/blob/master/docs/src/lecture_12/optimal_control.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimal-control"><a class="docs-heading-anchor" href="#Optimal-control">Optimal control</a><a id="Optimal-control-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-control" title="Permalink"></a></h1><p>Optimal control combines ordinary differential equations with optimization. It was extensively studied many decades ago when it was used to steer rockets in space.</p><h2 id="Permanent-magnet-synchronous-motors"><a class="docs-heading-anchor" href="#Permanent-magnet-synchronous-motors">Permanent magnet synchronous motors</a><a id="Permanent-magnet-synchronous-motors-1"></a><a class="docs-heading-anchor-permalink" href="#Permanent-magnet-synchronous-motors" title="Permalink"></a></h2><p>We will consider optimal steering of a PMSM (permanent magnet synchronous motor), which appears in electrical drives. It can be described via the linear equation:</p><p class="math-container">\[\dot x(t) = Ax(t) + q(t) + Bu(t),\]</p><p>where <span>$x(t)$</span> is the state, <span>$q(t)$</span> is the bias and <span>$u(t)$</span> is the control term. In the simplest case, we have</p><p class="math-container">\[A = -\begin{pmatrix} \rho &amp; 0 \\ 0 &amp; \rho \end{pmatrix} - \omega \begin{pmatrix} 0 &amp; -1 \\ 1 &amp; 0 \end{pmatrix}, \qquad B = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1\end{pmatrix}, \qquad q(t) = \begin{pmatrix} \rho\psi_{\rm pm} \\ 0 \end{pmatrix},\]</p><p>where <span>$\rho=\frac RL$</span> is the ratio of resistance and inductance, <span>$\psi$</span> the flux and <span>$\omega$</span> the rotor speed. Vector <span>$q$</span> does not depend on time. The state <span>$x(t)$</span> are the currents in the <span>$dq$</span>-reference frame, and the control <span>$u(t)$</span> is the provided voltage.</p><p>From the theoretical part, we know that the trajectory of the ODE equals to</p><p class="math-container">\[\begin{aligned}
x(t) &amp;= e^{At}\left(x_0 + \int_0^t e^{-As}(q+u(s))ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t e^{-As}u(s)ds\right).
\end{aligned}\]</p><p>This term contains the matrix exponential <span>$e^{At}$</span>. It can be shown that the <a href="../../lecture_11/sparse/#matrix-eigen">eigendecomposition</a> of <span>$A=Q\Lambda Q^\top$</span> is</p><p class="math-container">\[A = \frac 12\begin{pmatrix} i &amp; -i \\ 1 &amp; 1 \end{pmatrix} \begin{pmatrix} -\rho - i\omega &amp; 0\\ 0 &amp; -\rho+i\omega \end{pmatrix} \begin{pmatrix} i &amp; 1 \\ -i &amp; 1 \end{pmatrix}.\]</p><p>We have divided the expression by <span>$2$</span> because the eigenvectors have a unit norm. Then it is simple to compute the matrix exponential.</p><p class="math-container">\[\begin{aligned}
e^{At} &amp;= \frac 12\begin{pmatrix} i &amp; -i \\ 1 &amp; 1 \end{pmatrix} \begin{pmatrix} e^{-\rho t - i\omega t} &amp; 0\\ 0 &amp; e^{-\rho t+i\omega t} \end{pmatrix} \begin{pmatrix} i &amp; 1 \\ -i &amp; 1 \end{pmatrix} \\
&amp;= \dots = e^{-\rho t}\begin{pmatrix} \cos\omega t &amp; \sin\omega t \\ -\sin\omega t &amp; \cos\omega t\end{pmatrix}.
\end{aligned}\]</p><h2 id="Computing-trajectories-with-no-control"><a class="docs-heading-anchor" href="#Computing-trajectories-with-no-control">Computing trajectories with no control</a><a id="Computing-trajectories-with-no-control-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-trajectories-with-no-control" title="Permalink"></a></h2><p>We start with no control term, therefore <span>$u(t)=0$</span>. Then the trajectory simplifies to:</p><p class="math-container">\[x(t) = e^{At}\left(x_0 + A^{-1}(I-e^{-At})q \right).\]</p><p>Similarly to the wave equation, this system has multiple parameters. To prevent accidentally changing them, we save them in a structure.</p><pre><code class="language-julia hljs">struct PMSM{T&lt;:Real}
    ρ::T
    ω::T
    A::Matrix{T}
    invA::Matrix{T}

    function PMSM(ρ, ω)
        A = -ρ*[1 0; 0 1] -ω*[0 -1; 1 0]
        return new{eltype(A)}(ρ, ω, A, inv(A))
    end
end</code></pre><p>Besides <span>$\rho$</span>, <span>$\omega$</span> and <span>$A$</span>, we also store the inverse matrix <span>$A^{-1}$</span> so that we do not have to recompute it. We now write the <code>expA</code> function, which computes the matrix exponential <span>$e^{At}$</span>.</p><pre><code class="language-julia hljs">function expA(p::PMSM, t)
    ρ, ω = p.ρ, p.ω
    return exp(-ρ*t)*[cos(ω*t) sin(ω*t); -sin(ω*t) cos(ω*t)]
end</code></pre><p>For the rest of this section, we will work with the following parameter setting.</p><pre><code class="language-julia hljs">ρ = 0.1
ω = 2
x0 = [0;-0.5]
q = [1;0]

ps = PMSM(ρ, ω)</code></pre><p>The first exercise checks that we computed the matrix exponential correctly.</p><div class="admonition is-category-exercise">
<header class="admonition-header">Exercise:</header>
<div class="admonition-body"><p>Verify that the matrix exponential is computed correctly and that it is different from the elementwise exponential.</p><p><strong>Hint</strong>: The matrix exponential can also be computed directly by the <code>exp</code> function from the <code>LinearAlgebra</code> package.</p></div></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>A simple way to verify is to fix some <span>$t$</span> and evaluate the expressions above.</p><pre><code class="language-julia hljs">using LinearAlgebra

t = 5
exp0 = exp.(t*ps.A)
exp1 = exp(t*ps.A)
exp2 = expA(ps, t)</code></pre><p>While <code>exp1</code> and <code>exp2</code> must be identical, they must differ from <code>exp0</code>. Since there are rounding errors for different methods, the matrices will not be identical, and we need to check whether their norm is almost zero.</p><pre><code class="language-julia hljs">norm(exp1 - exp0) &gt;= 1e-10 || error(&quot;Matrices are wrong&quot;)
norm(exp1 - exp2) &lt;= 1e-10 || error(&quot;Matrices are wrong&quot;)</code></pre><p>Since the computation resulted in no error (note the opposite sign for <code>exp0</code>), our computation seems to be correct.</p></p></details><p>Now we can finally plot the trajectories of the electric motor.</p><div class="admonition is-category-exercise">
<header class="admonition-header">Exercise:</header>
<div class="admonition-body"><p>Write two function <code>trajectory_fin_diff</code> and <code>trajectory_exact</code> which compute the trajectory. The first one should use the finite difference method to discretize the time, while the second one should use the closed-form formula.</p><p>Plot both trajectories on time interval <span>$[0,10]$</span> with time discretization step <span>$\Delta t=0.01$</span>. Since <span>$x(t)$</span> is a two-dimensional vector, plot each component on one axis.</p></div></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>Both functions create an empty structure for the solution and then iterate over time. Since finite differences compute the solution at the next time, the loop is one iteration shorter. We compute the iteration based on the formulas derived above. The exact method does not need values at the previous point, which implies that numerical errors do not accumulate due to discretization errors.</p><pre><code class="language-julia hljs">function trajectory_fin_diff(p::PMSM, x0, ts, q)
    xs = zeros(length(x0), length(ts))
    xs[:, 1] = x0

    for i in 1:length(ts)-1
        xs[:, i+1] = xs[:, i] + (ts[i+1]-ts[i])*(p.A * xs[:, i] + q)
    end
    return xs
end

function trajectory_exact(p::PMSM, x0, ts, q)
    xs = zeros(length(x0), length(ts))

    for (i, t) in enumerate(ts)
        xs[:, i] = expA(p, t)*(x0 + p.invA * (I - expA(p, -t))*q)
    end
    return xs
end</code></pre><p>For plotting, we create the time discretization, compute both trajectories and then plot them.</p><pre><code class="language-julia hljs">using Plots

ts = 0:0.01:10

xs1 = trajectory_fin_diff(ps, x0, ts, q)
xs2 = trajectory_exact(ps, x0, ts, q)

plot(xs1[1,:], xs1[2,:], label=&quot;Finite differences&quot;)
plot!(xs2[1,:], xs2[2,:], label=&quot;True value&quot;)</code></pre></p></details><p><img src="../Comparison1.svg" alt/></p><p>The trajectories are different. Something is wrong. However, when we use the time discretization <span>$\Delta t=0.0001$</span>, the solutions are suddenly equal.</p><pre><code class="language-julia hljs">ts = 0:0.0001:10

xs1 = trajectory_fin_diff(ps, x0, ts, q)
xs2 = trajectory_exact(ps, x0, ts, q)

plot(xs1[1,:], xs1[2,:], label=&quot;Finite differences&quot;)
plot!(xs2[1,:], xs2[2,:], label=&quot;True value&quot;)</code></pre><p><img src="../Comparison2.svg" alt/></p><p>Can you guess why this happened? The problem is that the finite difference method performs a first-order approximation of the non-linear function <span>$x(t)$</span>. Since the trajectory always &quot;bends leftwards&quot;, the finite differences follow this bending with a delay. The error accumulates over time and is quite large at the end.</p><h2 id="Solving-the-optimal-control-problem"><a class="docs-heading-anchor" href="#Solving-the-optimal-control-problem">Solving the optimal control problem</a><a id="Solving-the-optimal-control-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-the-optimal-control-problem" title="Permalink"></a></h2><p>The goal is to apply such voltage so that the system reaches the desired position <span>$x_{\rm tar}$</span> from an initial position <span>$x_0$</span> in minimal possible time. With maximal possible allowed voltage <span>$U_{\rm max}$</span> this amounts to solving</p><p class="math-container">\[\begin{aligned}
\text{minimize}\qquad &amp;\tau \\
\text{subject to}\qquad &amp;\dot x(t) = Ax(t) + q + u(t), \qquad t\in[0,\tau], \\
&amp;||u(t)||\le U_{\rm max},\qquad t\in[0,\tau], \\
&amp;x(0) = x_0,\ x(\tau)=x_{\rm tar}.
\end{aligned}\]</p><p>Discretizing the problem and solving it using non-linear programming would result in many variables (their number would also be unknown due to the minimal time <span>$\tau$</span>) and is not feasible. Instead, we analyze the problem and try to simplify it. It can be shown that for any terminal state <span>$x_{\rm tar}$</span>, there is some <span>$p_0$</span> such that the optimal control <span>$u(t)$</span> has form:</p><p class="math-container">\[\begin{aligned}
p(t) &amp;= e^{-A^\top t}p_0, \\
u(t) &amp;= U_{\rm max}\frac{p(t)}{||p(t)||}.
\end{aligned}\]</p><div class="admonition is-category-bonus"><header class="admonition-header">BONUS: Connection with optimization</header><div class="admonition-body"><p>This part hints at the derivation of the previous result and the connection to constrained optimization. Optimal control forms the Hamiltonian (similar to the <a href="../../lecture_07/constrained/#lagrangian">Langrangian</a>)</p><p class="math-container">\[H = \tau + p(t)^\top (Ax(t) + q + u(t))\]</p><p>Since the constraint is time-dependent, the adjoint variable (<a href="../../lecture_07/constrained/#lagrangian">multiplier</a>) <span>$p(t)$</span> must also depend on time. Differentiating the Hamiltonian with respect to the <span>$x(t)$</span> and setting the derivative to <span>$-\dot p(t)$</span> (instead of zero as in nonlinear optimization) results in</p><p class="math-container">\[-\dot p(t) = A^\top p(t),\]</p><p>which has the solution</p><p class="math-container">\[p(t) = e^{-A^\top t}p_0.\]</p><p>This is the first condition written above. The second condition can be obtained by maximizing the Hamiltonian with respect to <span>$u$</span> and arguing that the constraint <span>$||u(t)||=U_{\rm max}$</span> will always be satisfied (this goes beyond the content of this lecture).</p></div></div><p>It is not difficult to show</p><p class="math-container">\[e^{-At}a^{-A^\top t} = e^{2\rho t}I.\]</p><p>We intend to compute the trajectory. The most difficult part is the integral from  <span>$e^{-As}u(s)$</span>. Since</p><p class="math-container">\[\begin{aligned}
e^{-As}u(s) &amp;= U_{\rm max}\frac{e^{-As}e^{-A^\top s}p_0}{||e^{-A^\top s}p_0||} = U_{\rm max}\frac{e^{-As}e^{-A^\top s}p_0}{\sqrt{p_0^\top e^{-As}e^{-A^\top s}p_0}} =  U_{\rm max}\frac{e^{2\rho s}p_0}{\sqrt{p_0^\top e^{2\rho s}I p_0}} = U_{\rm max}e^{\rho s}\frac{p_0}{||p_0||},
\end{aligned}\]</p><p>the trajectory equals to </p><p class="math-container">\[\begin{aligned}
x(t) &amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t e^{-As}u(s)ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t U_{\rm max}e^{\rho s}\frac{p_0}{||p_0||} ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \frac{U_{\rm max}}{\rho}(e^{\rho t}-1)\frac{p_0}{||p_0||} \right).
\end{aligned}\]</p><p>When we know <span>$p_0$</span>, we can use this formula to compute the optimal trajectory with control. To compute <span>$p_0$</span>, we rearrange the previous equation to</p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho t}-1) \frac{p_0}{||p_0||} = e^{-At}x(t) - x_0 - A^{-1}(I-e^{-At})q.\]</p><p>We take the norm of both sides to arrive at</p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho t}-1) = ||e^{-tA}x(t) - x_0 - A^{-1}(I-e^{-At})q||.\]</p><p>Since this relation needs to hold for all <span>$t\in[0,\tau]$</span>, we set <span>$t=\tau$</span> and use the target relation <span>$x(\tau)=x_{\rm tar}$</span>:</p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho \tau}-1) = ||e^{-\tau A}x_{\rm tar} - x_0 - A^{-1}(I-e^{-A\tau})q||.\]</p><p>Since this is one equation for one variable, we can compute the optimal time <span>$\tau$</span> from it.</p><div class="admonition is-category-exercise">
<header class="admonition-header">Exercise:</header>
<div class="admonition-body"><p>Solve the optimal time for <span>$x_{\rm tar}= (0.25, -0.5)$</span> with the maximum voltage <span>$U_{\rm max} = 0.1$</span>.</p><p><strong>Hint</strong>: To solve the equation above for <span>$t$</span>, use the <a href="../../lecture_07/exercises/#l7-exercises">bisection method</a>.</p></div></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>To solve the equation above, we need to find a zero point of </p><p class="math-container">\[f(t) = ||e^{-At}x_{\rm tar} - x_0 - A^{-1}(I-e^{-At})q|| - \frac{U_{\rm max}}{\rho}(e^{\rho t}-1)\]</p><p>The graph of the function (plot it) shows a single zero point (for this parameter setting). It can be found by evaluating it at many points at selecting the point with the value closest to zero. A more formal approach is to use the bisection method.</p><pre><code class="language-julia hljs">U_max = 0.1
x_t = [0.25;-0.5]

f(t) = norm(expA(ps, -t)*x_t - x0 - ps.invA*(I-expA(ps, -t))*q) - U_max/ps.ρ*(exp(ps.ρ*t)-1)

τ = bisection(f, minimum(ts), maximum(ts))</code></pre></p></details><p>To compute the optimal control and optimal trajectory, we rewrite one of the formulas derived above.</p><pre><code class="language-julia hljs">function trajectory_control(p::PMSM, x0, ts, q, U_max, p0)
    xs = zeros(length(x0), length(ts))

    for (i, t) in enumerate(ts)
        eAt  = expA(p, t)
        emAt = expA(p, -t)
        xs[:, i] = eAt*(x0 + p.invA * (I - emAt)*q + U_max/ρ*(exp(ρ*t) - 1)*p0)
    end
    return xs
end</code></pre><p>To compute the optimal trajectory, we compute <span>$p_0$</span> by the formula derived above. Then we plot the trajectory and the target point.</p><pre><code class="language-julia hljs">p0 = ps.ρ/(U_max*(exp(ps.ρ*τ)-1))*(expA(ps, -τ)*x_t - x0 - ps.invA*(I-expA(ps, -τ))*q)
p0 /= norm(p0)

ts = range(0, τ; length=100)

traj = trajectory_control(ps, x0, ts, q, U_max, p0)

plot(traj[1,:], traj[2,:], label=&quot;Optimal trajectory&quot;)
scatter!([x0[1]], [x0[2]], label=&quot;Starting point&quot;)
scatter!([x_t[1]], [x_t[2]], label=&quot;Target point&quot;)</code></pre><p><img src="../Optimal.svg" alt/></p><p>We confirm that the optimal trajectory leads from the starting to the target point.</p><div class="admonition is-category-bonus">
<header class="admonition-header">BONUS: Plotting all optimal trajectories</header>
<div class="admonition-body"><p>The optimal trajectory depends on the normed vector <span>$p_0$</span>. All such vectors form a unit circle in <span>$\mathbb R^2$</span>. Therefore, they can be parameterized by an angle <span>$\alpha\in[0,2\pi]$</span>. We plot eight possible optimal trajectories, each corresponding to a different target <span>$x_{\rm tar}$</span>, with uniformly distributed <span>$\alpha$</span>. Since we plot in a loop, we need to initialize an empty plot and then <code>display</code> it.</p><pre><code class="language-julia hljs">ts = 0:0.01:10

plt = plot()
for α = 0:π/4:2*π
    trj = trajectory_control(ps, x0, ts, q, U_max, [sin(α); cos(α)])
    plot!(plt, trj[1,:], trj[2,:], label=&quot;&quot;)
end
display(plt)</code></pre><p><img src="../Trajectories.svg" alt/></p></p></details></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../diff_eq/">« Julia package</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.6 on <span class="colophon-date" title="Tuesday 21 September 2021 08:23">Tuesday 21 September 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
