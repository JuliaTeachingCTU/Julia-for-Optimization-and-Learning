<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Visualization of gradients · Numerical computing in Julia</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Numerical computing in Julia logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Numerical computing in Julia logo"/></a><div class="docs-package-name"><span class="docs-autofit">Numerical computing in Julia</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why_julia/">Why Julia?</a></li><li><a class="tocitem" href="../../howto/">How to...</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Variables and basic operators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Mathematical operations and Elementary functions</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data structures</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: Control flow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional evaluation</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and iterators</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_03/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_03/scope/">Scope of Variables</a></li><li><a class="tocitem" href="../../lecture_03/exceptions/">Exception Handling</a></li><li><a class="tocitem" href="../../lecture_03/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/basics/">Package management</a></li><li><a class="tocitem" href="../../lecture_04/standardlibrary/">Standard library</a></li><li><a class="tocitem" href="../../lecture_04/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_04/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_04/otherpackages/">Other useful packages</a></li><li><a class="tocitem" href="../../lecture_04/exercises/">Exercises</a></li></ul></li><li><span class="tocitem">5: Composite types and constructors</span></li><li><span class="tocitem">6: Modules and enviroments</span></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox" checked/><label class="tocitem" for="menuitem-10"><span class="docs-label">7: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../theory/">Theory of continuous optimization</a></li><li class="is-active"><a class="tocitem" href>Visualization of gradients</a><ul class="internal"><li><a class="tocitem" href="#Computation-of-gradients"><span>Computation of gradients</span></a></li></ul></li><li><a class="tocitem" href="../numerical_methods/">Numerical methods</a></li><li><a class="tocitem" href="../exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">8: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/theory/">Theory of regression and classification</a></li><li><a class="tocitem" href="../../lecture_08/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_08/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_08/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">9: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_09/nn/">Neural networks</a></li><li><a class="tocitem" href="../../lecture_09/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">10: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><span class="tocitem">11: Ordinary differential equations</span></li><li><span class="tocitem">12: Statistics I.</span></li><li><span class="tocitem">13: Statistics II.</span></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">7: Optimization</a></li><li class="is-active"><a href>Visualization of gradients</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Visualization of gradients</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/VaclavMacha/JuliaCourse/blob/master/docs/src/lecture_07/gradients.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Visualization-of-gradients"><a class="docs-heading-anchor" href="#Visualization-of-gradients">Visualization of gradients</a><a id="Visualization-of-gradients-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization-of-gradients" title="Permalink"></a></h1><p>For the numerical experiments, we will consider the following function</p><p class="math-container">\[f(x) = \sin(x_1 + x_2) + \cos(x_1)^2\]</p><p>on domain <span>$[-3,1]\times [-2,1]$</span>.</p><div class = "exercise-body">
<header class = "exercise-header">Contour plot</header><p><p>Write a function <code>g(x)</code> which computes the derivative of <span>$f$</span> at a point  <span>$x$</span>.</p><p>Plot the contours of <span>$f$</span> on the given domain. Use the optional argument <code>color = :jet</code> for better visualization.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>Function <code>f(x)</code> takes as an input a vector of two dimensions and returns a scalar. Therefore, the gradient is a two-dimensional vector, which we create by <code>[?; ?]</code>. Its components are computed from the chain rule.</p><pre><code class="language-julia">f(x) = sin(x[1] + x[2]) + cos(x[1])^2
g(x) = [cos(x[1] + x[2]) - 2*cos(x[1])*sin(x[1]); cos(x[1] + x[2])]</code></pre><p>We use the <code>Plots</code> package for plotting. We create the discretization <code>xs</code> and <code>ys</code> of both axis and then call the <code>contourf</code> function. Since the third argument of <code>contourf</code> requires a function of two variables, we need to modify <code>f</code> into <code>f_mod</code>.</p><pre><code class="language-julia">using Plots

xs = range(-3, 1, length = 40)
ys = range(-2, 1, length = 40)
f_mod = (x, y) -&gt; f([x; y])

contourf(xs, ys, f_mod, color = :jet)</code></pre></p></details><p><img src="../grad1.svg" alt/></p><h2 id="Computation-of-gradients"><a class="docs-heading-anchor" href="#Computation-of-gradients">Computation of gradients</a><a id="Computation-of-gradients-1"></a><a class="docs-heading-anchor-permalink" href="#Computation-of-gradients" title="Permalink"></a></h2><p>The simplest way to compute the gradients is to use a finite difference approximation. It replaces the limit in</p><p class="math-container">\[f&#39;(x) = \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\]</p><p>by fixing some <span>$h$</span> and approximates the gradient by</p><p class="math-container">\[f&#39;(x) \approx \frac{f(x+h)-f(x)}{h}.\]</p><div class = "exercise-body">
<header class = "exercise-header">Finite difference approximation</header><p><p>Write a function <code>finite_difference</code> which computes the approximation of <span>$f&#39;(x)$</span> by finite differences. The inputs are a function <span>$f:\mathbb R\to\mathbb R$</span> and a point <span>$x\in\mathbb{R}$</span>. It should have an optional input <span>$h\in\mathbb{R}$</span>, for which you need to choose a reasonable value. </p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>We just need to rewrite the formula above. Since the argument <code>h</code> is optional, it should be after <code>;</code>. Its good default value is anything between <span>$10^{-10}$</span> and <span>$10^{-5}$</span>. We specify <code>x::Real</code> as a sanity check for the case when a function of more variables is passed as input.</p><pre><code class="language-julia">finite_difference(f, x::Real; h=1e-8) = (f(x+h) - f(x)) / h</code></pre></p></details><p>This way of computing the gradient has two disadvantages:</p><ol><li>It is slow. For a function of <span>$n$</span> variables, we need to evaluate the function at least <span>$n+1$</span> times to get the whole gradient.</li><li>It is not precise. We will show this in the next example.</li></ol><div class = "exercise-body">
<header class = "exercise-header">Finite difference approximation</header><p><p>Fix a point <span>$x=(-2,-1)$</span>. For a proper discretization of <span>$h\in [10^{-15}, 10^{-1}]$</span> compute the finite difference approximation of the partial derivative of <span>$f$</span> with respect to the second variable.</p><p>Plot the dependence of this approximation on <span>$h$</span>. Add the true derivative computed from <code>g</code>.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>To compute the partial derivative with respect to the second argument, we need to fix the first argument and vary only the second one. The resulting function is <code>f_y</code>. We store all the values of <span>$h$</span> in <code>hs</code>. When the orders of magnitude are so different, logarithmic scale should be used. For this reason, we create a uniform discretization of the interval <span>$[-15,-1]$</span> and then use it as an exponent.</p><pre><code class="language-julia">x = [-2; -1]
f_y = y -&gt; f([x[1]; y])
hs = 10. .^(-15:0.01:-1)</code></pre><p>It is possible to use a <code>for</code> loop to compute all finite difference approximations, but there is a more efficient way. Then <code>[? for h in hs]</code> runs the function <code>?</code> for all <code>h in hs</code> and stores the results in an array with the same length as <code>hs</code>. Since we need to get finite differences, the function <code>?</code> will be replaced by <code>finite_difference(f_y, x[2]; h=h)</code>.</p><pre><code class="language-julia">fin_diff = [finite_difference(f_y, x[2]; h=h) for h in hs]</code></pre><p>The true gradient is computed by <code>g(x)</code>. It returns a vector of length two. Since we need only the partial derivative with respect to the second component, we select it by adding  <code>[2]</code>.</p><pre><code class="language-julia">true_grad = g(x)[2]</code></pre><p>It is possible to call <code>plot</code> twice (the second call would be <code>plot!</code>). However, we concatenate the true gradient <code>true_grad</code> and its finite difference approximation <code>fin_diff</code> by <code>hcat</code>. It is also possible to use <code>[? ?]</code> but not <code>[?, ?]</code> or <code>[?; ?]</code> (try it). To get the same shape of the arrays, we need to repeat <code>true_grad</code> from a scalar to a vector of the same length as <code>fin_diff</code>. Since <code>repeat</code> requires the input to be an array, we need to create it by <code>[true_grad]</code>.</p><pre><code class="language-julia">data = hcat(fin_diff, repeat([true_grad], length(fin_diff)))
plot(hs, data,
    xlabel = &quot;h&quot;,
    ylabel = &quot;Partial gradient wrt y&quot;,
    label = [&quot;Approximation&quot; &quot;True gradient&quot;],
    xscale = :log10,
)</code></pre></p></details><p><img src="../grad2.svg" alt/></p><p>We see that the approximation is good if the value <span>$h$</span> is not too small or too large. It cannot be too large because the definition of the gradient considers the limit to zero. It cannot be too small because then the numerical errors kick in. This is connected with machine precision, which is most vulnerable to subtraction of two numbers of almost the same value. A simple example shows</p><p class="math-container">\[(x + h)^2 - x^2 = 2xh + h^2\]</p><p>but the numerical implementation</p><pre><code class="language-julia-repl">julia&gt; x = 1;

julia&gt; h = 1e-13;

julia&gt; (x+h)^2 - x^2
1.9984014443252818e-13

julia&gt; 2*x*h + h^2
2.0000000000001e-13</code></pre><p>gives an error already on the third decimal point.</p><p>Finally, we show how the gradients look like.</p><div class = "exercise-body">
<header class = "exercise-header">Direction of gradients</header><p><p>Plot the contours of <span>$f$</span> and its gradient at <span>$(-2,-1)$</span>.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>We use the same functions as before. Since we want to add a line, we use <code>plot!</code> instead of <code>plot</code>. We specify its parameters in an optional argument <code>line = (:arrow, 4, :black)</code>. These parameters add the pointed arrow, the thickness and the colour of the line. Since we do not want any legend, we use <code>label = &quot;&quot;</code>.</p><pre><code class="language-julia">x = [-2; -1]
x_grad = g(x)

contourf(xs, ys, (x, y) -&gt; f([x; y]), color = :jet)

plot!([x[1]; x[1]+0.25*x_grad[1]], [x[2]; x[2]+0.25*x_grad[2]],
    line = (:arrow, 4, :black),
    label = &quot;&quot;,
)</code></pre></p></details><p><img src="../grad3.svg" alt/></p><p>The gradient is perpendicular to the contour lines. This makes perfect sense. Since the gradient is the direction of steepest ascent, and since the contours have constant values, it needs to be like this. Try this with different values of <span>$x$</span>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../theory/">« Theory of continuous optimization</a><a class="docs-footer-nextpage" href="../numerical_methods/">Numerical methods »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 7 January 2021 10:34">Thursday 7 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
