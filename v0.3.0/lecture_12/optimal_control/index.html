<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimal control Â· Julia for Machine Learning</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="Julia for Machine Learning logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="Julia for Machine Learning logo"/></a><div class="docs-package-name"><span class="docs-autofit">Julia for Machine Learning</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../why/">Why Julia?</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Installation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../installation/julia/">Julia</a></li><li><a class="tocitem" href="../../installation/vscode/">Visual Studio Code</a></li><li><a class="tocitem" href="../../installation/git/">Git</a></li><li><a class="tocitem" href="../../installation/tutorial/">Quickstart guide</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">1: Variables and basic operators</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_01/variables/">Variables</a></li><li><a class="tocitem" href="../../lecture_01/operators/">Elementary functions</a></li><li><a class="tocitem" href="../../lecture_01/strings/">Strings</a></li><li><a class="tocitem" href="../../lecture_01/arrays/">Arrays</a></li><li><a class="tocitem" href="../../lecture_01/data_structures/">Data structures</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">2: Control flow</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_02/conditions/">Conditional evaluations</a></li><li><a class="tocitem" href="../../lecture_02/loops/">Loops and iterators</a></li><li><a class="tocitem" href="../../lecture_02/scope/">Soft local scope</a></li><li><a class="tocitem" href="../../lecture_02/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">3: Functions and methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_03/functions/">Functions</a></li><li><a class="tocitem" href="../../lecture_03/methods/">Methods</a></li><li><a class="tocitem" href="../../lecture_03/scope/">Scope of variables</a></li><li><a class="tocitem" href="../../lecture_03/exceptions/">Exception handling</a></li><li><a class="tocitem" href="../../lecture_03/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">4: Packages</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_04/standardlibrary/">Standard library</a></li><li><a class="tocitem" href="../../lecture_04/Plots/">Plots.jl</a></li><li><a class="tocitem" href="../../lecture_04/DataFrames/">DataFrames.jl</a></li><li><a class="tocitem" href="../../lecture_04/otherpackages/">Other useful packages</a></li><li><a class="tocitem" href="../../lecture_04/interaction/">Interaction with other languages</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">5: Type system and generic programming</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_05/compositetypes/">Abstract and composite types</a></li><li><a class="tocitem" href="../../lecture_05/currencies/">Generic programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">6: Code organization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_06/modules/">Files and modules</a></li><li><a class="tocitem" href="../../lecture_06/pkg/">Package manager</a></li><li><a class="tocitem" href="../../lecture_06/develop/">Package development</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-10" type="checkbox"/><label class="tocitem" for="menuitem-10"><span class="docs-label">Course requirements</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../final_project/homeworks/">Homework</a></li><li><a class="tocitem" href="../../final_project/project/">Final project</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-11" type="checkbox"/><label class="tocitem" for="menuitem-11"><span class="docs-label">7: Optimization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_07/theory/">Introduction to continuous optimization</a></li><li><a class="tocitem" href="../../lecture_07/unconstrained/">Unconstrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/constrained/">Constrained optimization</a></li><li><a class="tocitem" href="../../lecture_07/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-12" type="checkbox"/><label class="tocitem" for="menuitem-12"><span class="docs-label">8: Regression and classification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_08/theory/">Theory of regression and classification</a></li><li><a class="tocitem" href="../../lecture_08/linear/">Linear regression</a></li><li><a class="tocitem" href="../../lecture_08/logistic/">Logistic regression</a></li><li><a class="tocitem" href="../../lecture_08/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">9: Neural networks I.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_09/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_09/nn/">Neural networks</a></li><li><a class="tocitem" href="../../lecture_09/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">10: Neural networks II.</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_10/theory/">Theory of neural networks</a></li><li><a class="tocitem" href="../../lecture_10/nn/">More complex networks</a></li><li><a class="tocitem" href="../../lecture_10/exercises/">Exercises</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-15" type="checkbox"/><label class="tocitem" for="menuitem-15"><span class="docs-label">11: Statistics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../lecture_11/theory/">Statistics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-16" type="checkbox" checked/><label class="tocitem" for="menuitem-16"><span class="docs-label">12: Ordinary differential equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../theory/">Differential equations</a></li><li><a class="tocitem" href="../ode/">Wave equation</a></li><li><a class="tocitem" href="../diff_eq/">Julia package</a></li><li class="is-active"><a class="tocitem" href>Optimal control</a><ul class="internal"><li><a class="tocitem" href="#Permanent-magnet-synchronous-motors"><span>Permanent magnet synchronous motors</span></a></li><li><a class="tocitem" href="#Computing-trajectories"><span>Computing trajectories</span></a></li><li><a class="tocitem" href="#Solving-the-optimal-control-problem"><span>Solving the optimal control problem</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">12: Ordinary differential equations</a></li><li class="is-active"><a href>Optimal control</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimal control</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/VaclavMacha/JuliaCourse/blob/master/docs/src/lecture_12/optimal_control.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimal-control"><a class="docs-heading-anchor" href="#Optimal-control">Optimal control</a><a id="Optimal-control-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-control" title="Permalink"></a></h1><p>This section considers the optimal control, which combines ordinary differential equations with optimization. It was extensively studied many decades ago, when it was used to steer rockets in space.</p><h2 id="Permanent-magnet-synchronous-motors"><a class="docs-heading-anchor" href="#Permanent-magnet-synchronous-motors">Permanent magnet synchronous motors</a><a id="Permanent-magnet-synchronous-motors-1"></a><a class="docs-heading-anchor-permalink" href="#Permanent-magnet-synchronous-motors" title="Permalink"></a></h2><p>We will consider the problem of optimal steering of a PMSM (permanent magnet synchronous motor), which appear in electrical drives. The motor can be described via a linear equation</p><p class="math-container">\[\dot x(t) = Ax(t) + q(t) + Bu(t),\]</p><p>where <span>$x(t)$</span> is the state, <span>$q(t)$</span> is the bias and <span>$u(t)$</span> is the control term. More specifically, we have</p><p class="math-container">\[A = -\begin{pmatrix} \frac{R_1}{L_1} &amp; 0 \\ 0 &amp; \frac{R_2}{L_2} \end{pmatrix} - \omega \begin{pmatrix} 0 &amp; -1 \\ 1 &amp; 0 \end{pmatrix}, \qquad B = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1\end{pmatrix}, \qquad q(t) = \begin{pmatrix} \frac{R_1}{L_1}\psi_{\rm pm} \\ 0 \end{pmatrix},\]</p><p>where <span>$R$</span> is the resistance, <span>$L$</span> the inductance, <span>$\psi$</span> the flux and <span>$\omega$</span> the rotor speed. The state <span>$x(t)$</span> are the currents in the <span>$dq$</span> reference frame and the control <span>$u(t)$</span> is the provided voltage. For simplicity we assume that the ratio of resistances and inductances is the same and that the bias is constant:</p><p class="math-container">\[\rho := \frac{R_1}{L_1} = \frac{R_2}{L_2},\qquad q:=q(t)\]</p><p>The goal is to apply such voltage so that the system reaches the desired position <span>$x_{\rm tar}$</span> from an initial position <span>$x_0$</span> in minimal possible time. With maximal possible allowed voltage <span>$U_{\rm max}$</span> this amounts to solving</p><p class="math-container">\[\begin{aligned}
\text{minimize}\qquad &amp;\tau \\
\text{subject to}\qquad &amp;\dot x(t) = Ax(t) + q + u(t), \qquad t\in[0,\tau], \\
&amp;||u(t)||\le U_{\rm max},\qquad t\in[0,\tau], \\
&amp;x(0) = x_0,\ x(\tau)=x_{\rm tar}.
\end{aligned}\]</p><p>Discretizing the problem and solving it by means of non-linear programming would result in a large number of variables (their number would also be unknown due to the minimal time <span>$\tau$</span>) and is not feasible. Instead, we analyze the problem and try to simplify it.</p><h2 id="Computing-trajectories"><a class="docs-heading-anchor" href="#Computing-trajectories">Computing trajectories</a><a id="Computing-trajectories-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-trajectories" title="Permalink"></a></h2><p>From the theoretical part, we know that the optimal solution of the ODE equals to</p><p class="math-container">\[\begin{aligned}
x(t) &amp;= e^{At}\left(x_0 + \int_0^t e^{-As}(q+u(s))ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t e^{-As}u(s)ds\right).
\end{aligned}\]</p><p>This term contains the matrix exponential <span>$e^{At}$</span>. To compute it, we may run <code>exp(A)</code>. It is important to realize that matrix exponential is different from elementwise exponential <code>exp.(A)</code> (try it). We set up the parameters</p><pre><code class="language-julia">Ï = 2
Ï = 0.01

A = -Ï*[1 0; 0 1] -Ï*[0 -1; 1 0]</code></pre><p>By computing the eigenvalues and eigenvectors</p><pre><code class="language-julia">using LinearAlgebra

Î», V = eigen(A)</code></pre><pre class="documenter-example-output">LinearAlgebra.Eigen{Complex{Float64},Complex{Float64},Array{Complex{Float64},2},Array{Complex{Float64},1}}
values:
2-element Array{Complex{Float64},1}:
 -0.01 - 2.0000000000000004im
 -0.01 + 2.0000000000000004im
vectors:
2Ã2 Array{Complex{Float64},2}:
      0.0+0.707107im       0.0-0.707107im
 0.707107-0.0im       0.707107+0.0im</pre><p>we can deduce that eigendecomposition</p><p class="math-container">\[A = \frac 12\begin{pmatrix} i &amp; -i \\ 1 &amp; 1 \end{pmatrix} \begin{pmatrix} -\rho - i\omega &amp; 0\\ 0 &amp; -\rho+i\omega \end{pmatrix} \begin{pmatrix} i &amp; 1 \\ -i &amp; 1 \end{pmatrix}.\]</p><p>We have divided the expression by <span>$2$</span> because all eigenvectors should have unit norm. Then the matrix exponential is</p><p class="math-container">\[\begin{aligned}
e^{At} &amp;= \frac 12\begin{pmatrix} i &amp; -i \\ 1 &amp; 1 \end{pmatrix} \begin{pmatrix} e^{-\rho t - i\omega t} &amp; 0\\ 0 &amp; e^{-\rho t+i\omega t} \end{pmatrix} \begin{pmatrix} i &amp; 1 \\ -i &amp; 1 \end{pmatrix} \\
&amp;= \dots = e^{-\rho t}\begin{pmatrix} \cos\omega t &amp; \sin\omega t \\ -\sin\omega t &amp; \cos\omega t\end{pmatrix}.
\end{aligned}\]</p><div class = "exercise-body">
<header class = "exercise-header">Exercise:</header><p><p>Verify that the matrix exponential is computed correctly and that the it is different from elementwise exponential.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>A simple way to verify is to fix some <span>$t$</span> and evaluate all the expressions derived above</p><pre><code class="language-julia">t = 5
exp0 = exp.(t*A)
exp1 = exp(t*A)
exp2 = V*diagm(exp.(Î»*t))*V&#39;
exp3 = exp(-Ï*t)*[cos(Ï*t) sin(Ï*t); -sin(Ï*t) cos(Ï*t)]</code></pre><p>Now, <code>exp1</code>, <code>exp2</code> and <code>exp3</code> must be identical and differ from <code>exp0</code>. Since there are rounding errors for different methods, the matrices will not be exactly identical and we need to check whether they norm is almost zero.</p><pre><code class="language-julia">norm(exp1 - exp0) &gt;= 1e-10 || error(&quot;Matrices are wrong&quot;)
norm(exp1 - exp2) &lt;= 1e-10 || error(&quot;Matrices are wrong&quot;)
norm(exp1 - exp3) &lt;= 1e-10 || error(&quot;Matrices are wrong&quot;)</code></pre><p>Since the computation resulted in no error (note the opposite sign for <code>exp0</code>), our computation seems to be correct.</p></p></details><p>Similarly to the wave equation, this system has many parameters. To keep track of them, and to prevent accidently changing them in a script, we should save them in a structure. We will create this structure so that it can also compute the matrix exponential and other useful functions.</p><div class = "exercise-body">
<header class = "exercise-header">Exercise:</header><p><p>We define the structure</p><pre><code class="language-julia">struct Params
    Ï
    Ï
    A
    invA
    expA
    expAT
    n
end</code></pre><p>which besides <span>$\rho$</span>, <span>$\omega$</span> and <span>$A$</span> also stores the inverse matrix <span>$A^{-1}$</span>, the matrix exponential functions <span>$t\mapsto e^{At}$</span>, <span>$t\mapsto e^{A^\top t}$</span> and the size of <span>$A$</span>.</p><p>Write a constructor (function) <code>Params(Ï, Ï)</code>, which creates this object.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>The inverse matrix can be obtained by <code>inv(A)</code>. The rest is obtained as the formulas above. for the transposition of the exponential, we need to convert it back to <code>Matrix</code>, otherwise we could have problems later.</p><pre><code class="language-julia">function Params(Ï, Ï)
    A = -Ï*[1 0; 0 1] -Ï*[0 -1; 1 0]
    invA = inv(A)
    expA(t) = exp(-Ï*t)*[cos(Ï*t) sin(Ï*t); -sin(Ï*t) cos(Ï*t)]
    expAT(t) = Matrix(expA(t)&#39;)
    n = size(A,1)
    return Params(Ï, Ï, A, invA, expA, expAT, n)
end</code></pre></p></details><p>For the rest of this section, we will work with the following parameter setting</p><pre><code class="language-julia">Ï = 0.1
Ï = 2
x0 = [0;-0.5]
q = [1;0]

ps = Params(Ï, Ï)</code></pre><p>Now we can finally plot the trajectories of the electric motor.</p><div class = "exercise-body">
<header class = "exercise-header">Exercise:</header><p><p>Consider the case of time interval <span>$[0,10]$</span>. The other parameters are specified directly above this exercise.</p><p>Compute the trajectory <span>$x(t)$</span> for no control (<span>$u(t)=0$</span>) using finite differences with <span>$\Delta t=0.01$</span>. Then compute the exact solution using the formulas derived above. Plot the trajectories as a plot (no animations).</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>We store the solution obtained by finite differences in <code>xs1</code> and the true solution in <code>xs2</code>. We initialize both arrays and add <code>x0</code> at the first time instant. Then we use the discretization formula. All the parameters connected with <span>$A$</span> are retrieved from the <code>ps</code> structure.</p><pre><code class="language-julia">using Plots

Ît = 0.01
ts = 0:Ît:10

xs1 = zeros(2, length(ts))
xs1[:,1] = x0
xs2 = zeros(2, length(ts))
xs2[:,1] = x0

eye(n) = Diagonal(ones(n))

for i in 1:length(ts)-1
    xs1[:,i+1] = xs1[:,i] + Ît*(ps.A*xs1[:,i] + q)
    xs2[:,i+1] = ps.expA(ts[i])*(x0 + ps.invA*(eye(ps.n)-ps.expA(-ts[i]))*q)
end

plot(xs1[1,:], xs1[2,:], label=&quot;Finite differences&quot;)
plot!(xs2[1,:], xs2[2,:], label=&quot;True value&quot;)</code></pre></p></details><p><img src="../Comparison1.svg" alt/></p><p>The trajectories are different. Something is wrong. However, when we use the time discretization <span>$\Delta t=0.0001$</span>, the solutions are suddenly equal.</p><p><img src="../Comparison2.svg" alt/></p><p>Can you guess why this happened? The problem is that the finite difference method performs a first order approximation of the non-linear function <span>$x(t)$</span>. But since the trajectory always &quot;bends leftwards&quot;, the finite differences follow this bending with a delay. The error accummulates over time and is quite large at the end.</p><h2 id="Solving-the-optimal-control-problem"><a class="docs-heading-anchor" href="#Solving-the-optimal-control-problem">Solving the optimal control problem</a><a id="Solving-the-optimal-control-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-the-optimal-control-problem" title="Permalink"></a></h2><p>So far, we did not consider any control. This part shows how the optimal control can be computed. Using a rather complicated theory, it can be shown that for any terminal state <span>$x_{\rm tar}$</span>, there is some <span>$p_0$</span> such that the optimal control has form</p><p class="math-container">\[\begin{aligned}
p(t) &amp;= e^{-A^\top t}p_0, \\
u(t) &amp;= U_{\rm max}\frac{p(t)}{||p(t)||}.
\end{aligned}\]</p><p>The next remark hints at the derivation of these formulas. It can be safely skipped.</p><div class = "info-body">
<header class = "info-header">Connection with optimization</header><p><p>Optimal control forms the Hamiltonian (similar to the <a href="../../lecture_07/constrained/#lagrangian">Langrangian</a>)</p><p class="math-container">\[H = \tau + p(t)^\top (Ax(t) + q + u(t))\]</p><p>Since the constraint is time-dependent, the adjoint variable (<a href="../../lecture_07/constrained/#lagrangian">multiplier</a>) <span>$p(t)$</span> must also depend on time. Differentiating the Hamiltonian with respect to the <span>$x(t)$</span> and setting the derivative to <span>$-\dot p(t)$</span> (instead of zero as in nonlinear optimization) results in</p><p class="math-container">\[-\dot p(t) = A^\top p(t),\]</p><p>which has the solution</p><p class="math-container">\[p(t) = e^{-A^\top t}p_0.\]</p><p>This is the first condition written above. The second condition can be obtained by maximizing the Hamiltonian with respect to <span>$u$</span> and arguing that the constraint <span>$||u(t)||=U_{\rm max}$</span> will always be satisfied (this goes beyond the content of this lecture).</p></p></div><p>It is not difficult to show that</p><p class="math-container">\[e^{-At}a^{-A^\top t} = e^{2\rho t}I.\]</p><p>We intend to compute the trajectory. The most difficult part is the integral from  <span>$e^{-As}u(s)$</span>. Since</p><p class="math-container">\[\begin{aligned}
e^{-As}u(s) &amp;= U_{\rm max}\frac{e^{-As}e^{-A^\top s}p_0}{||e^{-A^\top s}p_0||} = U_{\rm max}\frac{e^{-As}e^{-A^\top s}p_0}{\sqrt{p_0^\top e^{-As}e^{-A^\top s}p_0}} =  U_{\rm max}\frac{e^{2\rho s}p_0}{\sqrt{p_0^\top e^{2\rho s}I p_0}} = U_{\rm max}e^{\rho s}\frac{p_0}{||p_0||},
\end{aligned}\]</p><p>the trajectory equals to </p><p class="math-container">\[\begin{aligned}
x(t) &amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t e^{-As}u(s)ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \int_0^t U_{\rm max}e^{\rho s}\frac{p_0}{||p_0||} ds\right) \\
&amp;= e^{At}\left(x_0 + A^{-1}(I-e^{-At})q + \frac{U_{\rm max}}{\rho}(e^{\rho t}-1)\frac{p_0}{||p_0||} \right).
\end{aligned}\]</p><p>This allows us to plot the optimal trajectories.</p><div class = "exercise-body">
<header class = "exercise-header">Exercise:</header><p><p>Write functions <code>x(t, ???)</code> and <code>trajectory(ts, ???)</code> which compute the optimal solution <span>$x(t)$</span> and the trajectory <span>$x(t)_{t\in {\rm ts}}$</span> (saved into a matrix).</p><p>The optimal trajectory depends on the normed vector <span>$p_0$</span>. All such vectors form a unit circle in <span>$\mathbb R^2$</span>. Therefore, they can be parameterized by an angle <span>$\alpha\in[0,2\pi]$</span>. Fix <span>$U_{\rm max}=0.1$</span> and time interval <span>$[0,10]$</span> with time step <span>$\Delta t=0.01$</span>. Then plot eight possible optimal trajectories (each would correspond to a different target <span>$x_{\rm tar}$</span>) with uniformly distributed <span>$\alpha$</span>.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>For functions <code>x</code>, we need to rewrite the previous formula into code. For <code>trajectory</code>, we call <code>x</code> for <code>t in ts</code>. Since <code>x</code> returns a two-dimensional vector, we need to cat the results to a matrix.</p><pre><code class="language-julia">function x(t, ps, x0, U_max, p0, q)
    return ps.expA(t)*(x0 + ps.invA*(eye(ps.n)-ps.expA(-t))*q + U_max/Ï*(exp(Ï*t)-1)*p0)
end

trajectory(ts, ps, x0, U_max, p0, q) = hcat([x(t, ps, x0, U_max, p0, q) for t in ts]...)</code></pre><p>For plotting, we initialize the variables</p><pre><code class="language-julia">U_max = 0.1

Ît = 0.01
ts = 0:Ît:10</code></pre><p>then create an empty plot. We make a uniform discretization of <span>$[0,2\pi]$</span> and for each <span>$\alpha$</span> from this interval, we compute <span>$p_0$</span>, the trajectory and finally plot the result. Since we plot in a loop, we need to <code>display</code> the plot.</p><pre><code class="language-julia">pa = plot()
for Î± = 0:Ï/4:2*Ï
    p0 = [sin(Î±); cos(Î±)]
    traj =  trajectory(ts, ps, x0, U_max, p0, q)
    plot!(traj[1,:], traj[2,:], label=&quot;&quot;)
end
display(pa)</code></pre></p></details><p><img src="../Trajectories.svg" alt/></p><p>Rearranging the previous equation results in</p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho t}-1) \frac{p_0}{||p_0||} = e^{-tA}x(t) - x_0 - A^{-1}(I-e^{-At})q.\]</p><p>We take the norm of both sides to arrive at</p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho t}-1) = ||e^{-tA}x(t) - x_0 - A^{-1}(I-e^{-At})q||.\]</p><p>Since this realization needs to hold true for all <span>$t\in[0,\tau]$</span>, we set <span>$t=\tau$</span> and use the target relation <span>$x(\tau)=x_{\rm tar}$</span></p><p class="math-container">\[\frac{U_{\rm max}}{\rho}(e^{\rho \tau}-1) = ||e^{-\tau A}x_{\rm tar} - x_0 - A^{-1}(I-e^{-A\tau})q||\]</p><p>All data besides <span>$\tau$</span> are known. Therefore, if we solve it, we obtain the optimal time <span>$\tau$</span>. This is done in the next exercise.</p><div class = "exercise-body">
<header class = "exercise-header">Exercise:</header><p><p>Solve the optimal control problem for <span>$x_{\rm tar}= (0.25, -0.5)$</span>. Plot the optimal trajectory to this point.</p></p></div>
<details class = "solution-body">
<summary class = "solution-header">Solution:</summary><p><p>To solve the equation above, we need to find a zero point of </p><p class="math-container">\[f(t) = ||e^{-At}x_{\rm tar} - x0 - A^{-1}(I-e^{-At})q|| - \frac{U_{\rm max}}{\rho}(e^{\rho t}-1)\]</p><p>The graph of the function (plot it) shows that it has a single zero point (for this parameter setting). It can be found by evaluating it at many points at selecting the point with the value closest to zero. A more formal approach is to use the <a href="../../lecture_07/exercises/#l7-exercises">bisection method</a> written earlier.</p><pre><code class="language-julia">x_tar = [0.25;-0.5]

f(t) = norm(ps.expA(-t)*x_tar - x0 - ps.invA*(eye(ps.n)-ps.expA(-t))*q) - U_max/ps.Ï*(exp(ps.Ï*t)-1)

Ï = bisection(f, minimum(ts), maximum(ts))</code></pre><p>To compute the optimal control and optimal trajectory, we first need to compute <span>$p_0$</span> and then use the <code>trajectory</code> function. We restrict the interval <code>ts</code> to <span>$[0,\tau]$</span>.</p><pre><code class="language-julia">p0 = ps.Ï/(U_max*(exp(ps.Ï*Ï)-1))*(ps.expA(-Ï)*x_tar - x0 - ps.invA*(eye(ps.n)-ps.expA(-Ï))*q)
p0 /= norm(p0)

ts_opt = ts[ts .&lt;= Ï + Ît]

traj = trajectory(ts_opt, ps, x0, U_max, p0, q)</code></pre><p>Then we plot the trajectory and the target point.</p><pre><code class="language-julia">plot(traj[1,:], traj[2,:], label=&quot;Optimal trajectory&quot;)
scatter!([x_tar[1]], [x_tar[2]], label=&quot;Target point&quot;)</code></pre></p></details><p><img src="../Optimal.svg" alt/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../diff_eq/">Â« Julia package</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 5 April 2021 15:05">Monday 5 April 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
